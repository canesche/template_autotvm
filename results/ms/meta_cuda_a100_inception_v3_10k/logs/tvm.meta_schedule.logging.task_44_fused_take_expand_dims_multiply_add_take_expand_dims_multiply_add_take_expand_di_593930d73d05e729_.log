2024-04-29 01:54:26 [INFO] [task_scheduler.cc:160] Initializing Task #44: "fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_"
2024-04-29 01:54:26 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        compile_engine_const = T.alloc_buffer((), "int64")
        T_take = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_1 = T.alloc_buffer(())
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_2 = T.alloc_buffer(())
        T_add = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_3 = T.alloc_buffer((), "int64")
        T_take_1 = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_4 = T.alloc_buffer(())
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_5 = T.alloc_buffer(())
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_6 = T.alloc_buffer((), "int64")
        T_take_2 = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_7 = T.alloc_buffer(())
        T_multiply_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_8 = T.alloc_buffer(())
        T_add_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        with T.block("compile_engine_const"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.int64(2)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const[()])
                T.writes(T_take[v_ax0, v_ax1, v_ax2])
                T_take[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3] = T_take[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_1"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.float32(0.44999998807907104)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_1[()])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_1[()]
        with T.block("compile_engine_const_2"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_2[()])
            compile_engine_const_2[()] = T.float32(-0.18799999356269836)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_2[()])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_2[()]
        with T.block("compile_engine_const_3"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_3[()])
            compile_engine_const_3[()] = T.int64(1)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_3[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const_3[()])
                T.writes(T_take_1[v_ax0, v_ax1, v_ax2])
                T_take_1[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_3[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take_1[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_take_1[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_4"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_4[()])
            compile_engine_const_4[()] = T.float32(0.44800001382827759)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_4[()])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_4[()]
        with T.block("compile_engine_const_5"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_5[()])
            compile_engine_const_5[()] = T.float32(-0.087999999523162842)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_5[()])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_5[()]
        with T.block("compile_engine_const_6"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_6[()])
            compile_engine_const_6[()] = T.int64(0)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_6[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const_6[()])
                T.writes(T_take_2[v_ax0, v_ax1, v_ax2])
                T_take_2[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_6[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take_2[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_take_2[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_7"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_7[()])
            compile_engine_const_7[()] = T.float32(0.45800000429153442)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_7[()])
                T.writes(T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_7[()]
        with T.block("compile_engine_const_8"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_8[()])
            compile_engine_const_8[()] = T.float32(-0.029999999329447746)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_8[()])
                T.writes(T_add_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_8[()]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(224), T.int64(224)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1 - T.int64(2), v_ax2, v_ax3], T_add_1[v_ax0, v_ax1 - T.int64(1), v_ax2, v_ax3], T_add_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, T_add[v_ax0, v_ax1 - T.int64(2), v_ax2, v_ax3], T.if_then_else(T.int64(1) <= v_ax1, T_add_1[v_ax0, v_ax1 - T.int64(1), v_ax2, v_ax3], T_add_2[v_ax0, v_ax1, v_ax2, v_ax3]))
2024-04-29 01:54:26 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2024-04-29 01:54:26 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(1176), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
2024-04-29 03:14:47 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 03:14:47 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 03:14:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x7cf9608)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xaaf2788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x85ee438)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0xb49b078)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x3381a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb267888)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x85ee8e8)]: 0 failure(s)
2024-04-29 03:14:50 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 03:14:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x7cf9608)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xaaf2788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x85ee438)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0xb49b078)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x3381a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb267888)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x85ee8e8)]: 0 failure(s)
2024-04-29 03:14:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x7cf9608)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xaaf2788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x85ee438)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0xb49b078)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x3381a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb267888)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x85ee8e8)]: 0 failure(s)
2024-04-29 03:14:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x7cf9608)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xaaf2788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x85ee438)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0xb49b078)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x3381a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb267888)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x85ee8e8)]: 0 failure(s)
2024-04-29 03:14:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x7cf9608)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xaaf2788)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x85ee438)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0xb49b078)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x3381a48)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb267888)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x85ee8e8)]: 0 failure(s)
2024-04-29 03:14:51 [INFO] [evolutionary_search.cc:649] Scores of the best 6 candidates:
[1 : 6]:	0.9101  0.6463  0.4541  0.3528  0.0385  0.0359
2024-04-29 03:14:51 [INFO] [evolutionary_search.cc:727] Got 6 candidate(s) with evolutionary search
2024-04-29 03:14:51 [INFO] [evolutionary_search.cc:730] Sending 6 candidates(s) for measurement
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #1: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(4704), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #2: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(588), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #3: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(1176), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #4: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(147), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #5: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(2352), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-04-29 04:02:37 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #6: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(294), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 15:10:03 [INFO] [task_scheduler.cc:160] Initializing Task #44: "fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_"
2024-05-01 15:10:03 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        compile_engine_const = T.alloc_buffer((), "int64")
        T_take = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_1 = T.alloc_buffer(())
        T_multiply = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_2 = T.alloc_buffer(())
        T_add = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_3 = T.alloc_buffer((), "int64")
        T_take_1 = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_4 = T.alloc_buffer(())
        T_multiply_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_5 = T.alloc_buffer(())
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_6 = T.alloc_buffer((), "int64")
        T_take_2 = T.alloc_buffer((T.int64(1), T.int64(224), T.int64(224)))
        T_expand_dims_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_7 = T.alloc_buffer(())
        T_multiply_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        compile_engine_const_8 = T.alloc_buffer(())
        T_add_2 = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224)))
        with T.block("compile_engine_const"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.int64(2)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const[()])
                T.writes(T_take[v_ax0, v_ax1, v_ax2])
                T_take[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3] = T_take[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_1"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_1[()])
            compile_engine_const_1[()] = T.float32(0.44999998807907104)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_1[()])
                T.writes(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_1[()]
        with T.block("compile_engine_const_2"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_2[()])
            compile_engine_const_2[()] = T.float32(-0.18799999356269836)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_2[()])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_2[()]
        with T.block("compile_engine_const_3"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_3[()])
            compile_engine_const_3[()] = T.int64(1)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take_1"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_3[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const_3[()])
                T.writes(T_take_1[v_ax0, v_ax1, v_ax2])
                T_take_1[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_3[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take_1[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_take_1[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_4"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_4[()])
            compile_engine_const_4[()] = T.float32(0.44800001382827759)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_4[()])
                T.writes(T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims_1[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_4[()]
        with T.block("compile_engine_const_5"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_5[()])
            compile_engine_const_5[()] = T.float32(-0.087999999523162842)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_5[()])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply_1[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_5[()]
        with T.block("compile_engine_const_6"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_6[()])
            compile_engine_const_6[()] = T.int64(0)
        for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_take_2"):
                v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                T.reads(p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_6[()]), T.int64(2)), v_ax1, v_ax2], compile_engine_const_6[()])
                T.writes(T_take_2[v_ax0, v_ax1, v_ax2])
                T_take_2[v_ax0, v_ax1, v_ax2] = p0[v_ax0, T.min(T.max(T.int64(0), compile_engine_const_6[()]), T.int64(2)), v_ax1, v_ax2]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_expand_dims_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_take_2[v_ax0, v_ax2, v_ax3])
                T.writes(T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_take_2[v_ax0, v_ax2, v_ax3]
        with T.block("compile_engine_const_7"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_7[()])
            compile_engine_const_7[()] = T.float32(0.45800000429153442)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_multiply_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_7[()])
                T.writes(T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_expand_dims_2[v_ax0, v_ax1, v_ax2, v_ax3] * compile_engine_const_7[()]
        with T.block("compile_engine_const_8"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const_8[()])
            compile_engine_const_8[()] = T.float32(-0.029999999329447746)
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(224), T.int64(224)):
            with T.block("T_add_2"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3], compile_engine_const_8[()])
                T.writes(T_add_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_2[v_ax0, v_ax1, v_ax2, v_ax3] = T_multiply_2[v_ax0, v_ax1, v_ax2, v_ax3] + compile_engine_const_8[()]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(3), T.int64(224), T.int64(224)):
            with T.block("T_concat"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1 - T.int64(2), v_ax2, v_ax3], T_add_1[v_ax0, v_ax1 - T.int64(1), v_ax2, v_ax3], T_add_2[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, T_add[v_ax0, v_ax1 - T.int64(2), v_ax2, v_ax3], T.if_then_else(T.int64(1) <= v_ax1, T_add_1[v_ax0, v_ax1 - T.int64(1), v_ax2, v_ax3], T_add_2[v_ax0, v_ax1, v_ax2, v_ax3]))
2024-05-01 15:10:03 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2024-05-01 15:10:03 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(1176), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
2024-05-01 16:07:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-05-01 16:07:47 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-05-01 16:07:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3609268)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x3454b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x358ee98)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x4684878)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xb47c788)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x96b66c8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb0d4a58)]: 0 failure(s)
2024-05-01 16:07:48 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3609268)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x3454b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x358ee98)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x4684878)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xb47c788)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x96b66c8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb0d4a58)]: 0 failure(s)
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3609268)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x3454b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x358ee98)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x4684878)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xb47c788)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x96b66c8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb0d4a58)]: 0 failure(s)
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3609268)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x3454b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x358ee98)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x4684878)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xb47c788)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x96b66c8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb0d4a58)]: 0 failure(s)
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3609268)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x3454b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x358ee98)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x4684878)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xb47c788)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x96b66c8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb0d4a58)]: 0 failure(s)
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:649] Scores of the best 6 candidates:
[1 : 6]:	0.9869  0.7927  0.6805  0.6330  0.6245  0.0883
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:727] Got 6 candidate(s) with evolutionary search
2024-05-01 16:07:49 [INFO] [evolutionary_search.cc:730] Sending 6 candidates(s) for measurement
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #1: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(4704), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #2: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(294), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #3: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(588), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #4: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(2352), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #5: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(1176), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
2024-05-01 16:38:05 [INFO] [task_scheduler.cc:121] [Task #44: fused_take_expand_dims_multiply_add_take_expand_dims_multiply_add_take_expand_di_593930d73d05e729_] Trial #6: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32"), T_concat: T.Buffer((T.int64(1), T.int64(3), T.int64(224), T.int64(224)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(147), thread="blockIdx.x"):
            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                with T.block("T_concat"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(3), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) // T.int64(50176))
                    v_ax2 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) % T.int64(50176) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(224), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224))
                    T.reads(p0[v_ax0, T.int64(0):T.int64(3), v_ax2, v_ax3])
                    T.writes(T_concat[v_ax0, v_ax1, v_ax2, v_ax3])
                    T_concat[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(T.int64(2) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(2)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44999998807907104) + T.float32(-0.18799999356269836), T.if_then_else(T.int64(1) <= v_ax1, p0[v_ax0, T.min(T.max(T.int64(0), T.int64(1)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.44800001382827759) + T.float32(-0.087999999523162842), p0[v_ax0, T.min(T.max(T.int64(0), T.int64(0)), T.int64(2)), v_ax2, v_ax3] * T.float32(0.45800000429153442) + T.float32(-0.029999999329447746)))
b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_take", func_name="main")
b2 = sch.get_block(name="T_expand_dims", func_name="main")
b3 = sch.get_block(name="compile_engine_const_1", func_name="main")
b4 = sch.get_block(name="T_multiply", func_name="main")
b5 = sch.get_block(name="compile_engine_const_2", func_name="main")
b6 = sch.get_block(name="T_add", func_name="main")
b7 = sch.get_block(name="compile_engine_const_3", func_name="main")
b8 = sch.get_block(name="T_take_1", func_name="main")
b9 = sch.get_block(name="T_expand_dims_1", func_name="main")
b10 = sch.get_block(name="compile_engine_const_4", func_name="main")
b11 = sch.get_block(name="T_multiply_1", func_name="main")
b12 = sch.get_block(name="compile_engine_const_5", func_name="main")
b13 = sch.get_block(name="T_add_1", func_name="main")
b14 = sch.get_block(name="compile_engine_const_6", func_name="main")
b15 = sch.get_block(name="T_take_2", func_name="main")
b16 = sch.get_block(name="T_expand_dims_2", func_name="main")
b17 = sch.get_block(name="compile_engine_const_7", func_name="main")
b18 = sch.get_block(name="T_multiply_2", func_name="main")
b19 = sch.get_block(name="compile_engine_const_8", func_name="main")
b20 = sch.get_block(name="T_add_2", func_name="main")
b21 = sch.get_block(name="T_concat", func_name="main")
sch.compute_inline(block=b19)
sch.compute_inline(block=b17)
sch.compute_inline(block=b14)
sch.compute_inline(block=b12)
sch.compute_inline(block=b10)
sch.compute_inline(block=b7)
sch.compute_inline(block=b5)
sch.compute_inline(block=b3)
sch.compute_inline(block=b0)
sch.compute_inline(block=b20)
sch.compute_inline(block=b18)
sch.compute_inline(block=b16)
sch.compute_inline(block=b15)
sch.compute_inline(block=b13)
sch.compute_inline(block=b11)
sch.compute_inline(block=b9)
sch.compute_inline(block=b8)
sch.compute_inline(block=b6)
sch.compute_inline(block=b4)
sch.compute_inline(block=b2)
sch.compute_inline(block=b1)
l22, l23, l24, l25 = sch.get_loops(block=b21)
l26 = sch.fuse(l22, l23, l24, l25, preserve_unit_iters=True)
v27 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l28, l29 = sch.split(loop=l26, factors=[None, v27], preserve_unit_iters=True)
sch.bind(loop=l28, thread_axis="blockIdx.x")
sch.bind(loop=l29, thread_axis="threadIdx.x")
sch.enter_postproc()
