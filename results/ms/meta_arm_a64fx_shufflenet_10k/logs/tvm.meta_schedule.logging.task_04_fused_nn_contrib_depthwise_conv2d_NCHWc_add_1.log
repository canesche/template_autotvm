2024-04-28 20:37:33 [INFO] [task_scheduler.cc:160] Initializing Task #4: "fused_nn_contrib_depthwise_conv2d_NCHWc_add_1"
2024-04-28 20:37:33 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)):
            with T.block("PaddedInput"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for b, oco, oh, ow, oci, kh, kw in T.grid(T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("DepthwiseConv2d"):
                v_b, v_oco, v_oh, v_ow, v_oci, v_kh, v_kw = T.axis.remap("SSSSSRR", [b, oco, oh, ow, oci, kh, kw])
                T.reads(PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                with T.init():
                    DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
2024-04-28 20:37:33 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 20:37:33 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
            DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
            for b_0, oco_0, oh_0, ow_0, oci_0, b_1, oco_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(29)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(4)):
                    with T.block("PaddedInput"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(29), oco_1 + ax1)
                        v_i2 = T.axis.spatial(T.int64(16), ax2)
                        v_i3 = T.axis.spatial(T.int64(16), ow_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oci_1, kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2)):
                    with T.block("DepthwiseConv2d"):
                        v_b = T.axis.spatial(T.int64(1), b_0 + b_1 + b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_0 * T.int64(29) + oco_1 + oco_2 + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 + ow_1 + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(2) + oci_2 * T.int64(2) + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)):
                with T.block("T_add"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 29, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v58 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v58)
l59 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l59, preserve_unit_loops=True, index=-1)
2024-04-28 20:37:33 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
            DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
            for b_0, oco_0, oh_0, ow_0, oci_0, b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(2)):
                for kh_0, kw_0 in T.grid(T.int64(3), T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(2)):
                        with T.block("PaddedInput"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(29), oco_1 + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_0 + kw_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(4), oci_1 * T.int64(2) + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                            PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2)):
                        with T.block("DepthwiseConv2d"):
                            v_b = T.axis.spatial(T.int64(1), b_0 + b_1 + b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_0 * T.int64(29) + oco_1 + oco_2 + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(2) + oci_2 * T.int64(2) + oci_3)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(2)):
                    with T.block("T_add"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(29), oco_1 + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oci_1 * T.int64(2) + ax4)
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 29, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
2024-04-28 20:37:33 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
            DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
            for b_0, oco_0, oh_0, ow_0, oci_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1)):
                for b_1, oco_1 in T.grid(T.int64(1), T.int64(29)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(4)):
                        with T.block("PaddedInput"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(29), oco_1 + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(4), ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                            PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for oh_1, ow_1, oci_1, kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(2)):
                        with T.block("DepthwiseConv2d"):
                            v_b = T.axis.spatial(T.int64(1), b_0 + b_1 + b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_0 * T.int64(29) + oco_1 + oco_2 + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(2) + oci_2 * T.int64(2) + oci_3)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(29), T.int64(14), T.int64(1), T.int64(4)):
                    with T.block("T_add"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), ow_0 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 29, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
2024-04-28 20:42:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 20:42:13 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 20:42:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 20:42:19 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 20:42:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 20:42:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 20:42:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 20:42:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 20:42:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9987  0.9986  0.9985  0.9979  0.9971  0.9970  0.9957  0.9955  0.9954  0.9951  0.9946  0.9943  0.9937  0.9930  0.9924  0.9917
[17 : 32]:	0.9914  0.9914  0.9912  0.9901  0.9899  0.9892  0.9891  0.9889  0.9873  0.9865  0.9864  0.9861  0.9861  0.9859  0.9856  0.9854
[33 : 48]:	0.9851  0.9839  0.9837  0.9836  0.9831  0.9825  0.9825  0.9822  0.9818  0.9817  0.9816  0.9810  0.9810  0.9807  0.9800  0.9800
[49 : 64]:	0.9794  0.9793  0.9791  0.9790  0.9783  0.9777  0.9772  0.9764  0.9764  0.9763  0.9757  0.9747  0.9745  0.9742  0.9735  0.9731
2024-04-28 20:42:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 20:42:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #1: GFLOPs: 2.5385. Time: 170.1708 us. Best GFLOPs: 2.5385
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #2: GFLOPs: 9.6849. Time: 44.6037 us. Best GFLOPs: 9.6849
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #3: GFLOPs: 0.4947. Time: 873.2175 us. Best GFLOPs: 9.6849
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #4: GFLOPs: 14.2568. Time: 30.3002 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #5: GFLOPs: 10.7102. Time: 40.3337 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #6: GFLOPs: 1.3859. Time: 311.7056 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #7: GFLOPs: 5.6759. Time: 76.1083 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #8: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(29), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused_fused * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(4)):
                        for ax3_ax4_fused in T.vectorized(T.int64(12)):
                            with T.block("PaddedInput"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(16), oh_2 * T.int64(2) + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_fused_fused * T.int64(7) + ow_1 + ax3_ax4_fused // T.int64(4))
                                v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                                PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(29), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("DepthwiseConv2d_update"):
                            v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 * T.int64(29) + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused_fused * T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2 + oci_3)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(28)):
                    with T.block("T_add"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused_fused * T.int64(7) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=14)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b62)
l85 = sch.fuse(l65, l66, l67, l68, l69, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l83, l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b63)
l107 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b64)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b115)
b136 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #9: GFLOPs: 5.7568. Time: 75.0394 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #10: GFLOPs: 1.4451. Time: 298.9247 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #11: GFLOPs: 11.4897. Time: 37.5976 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #12: GFLOPs: 6.9529. Time: 62.1303 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #13: GFLOPs: 9.5283. Time: 45.3367 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #14: GFLOPs: 0.9018. Time: 479.0066 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #15: GFLOPs: 6.5542. Time: 65.9097 us. Best GFLOPs: 14.2568
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #16: GFLOPs: 26.6957. Time: 16.1818 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #17: GFLOPs: 1.5215. Time: 283.9269 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #18: GFLOPs: 10.8001. Time: 39.9982 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #19: GFLOPs: 2.3218. Time: 186.0560 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #20: GFLOPs: 11.7931. Time: 36.6302 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #21: GFLOPs: 5.3122. Time: 81.3193 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #22: GFLOPs: 18.9394. Time: 22.8088 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #23: GFLOPs: 1.1354. Time: 380.4735 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #24: GFLOPs: 5.1806. Time: 83.3844 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #25: GFLOPs: 10.9464. Time: 39.4634 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #26: GFLOPs: 12.6986. Time: 34.0184 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #27: GFLOPs: 0.1433. Time: 3014.0212 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #28: GFLOPs: 16.1232. Time: 26.7926 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #29: GFLOPs: 3.0762. Time: 140.4271 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #30: GFLOPs: 2.4443. Time: 176.7308 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #31: GFLOPs: 0.6510. Time: 663.5693 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #32: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(1)):
                with T.block("DepthwiseConv2d_init"):
                    v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                    v_oco = T.axis.spatial(T.int64(29), oco_2_init * T.int64(29) + oco_3_init)
                    v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oci_2_init + oci_3_init)
                    T.reads()
                    T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
            for kh_0, kw_0 in T.grid(T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(4), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("PaddedInput"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(14) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), kw_0 + b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                            PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_2 * T.int64(29) + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax4_fused)
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b62)
l82 = sch.fuse(l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b63)
l99 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l99)
sch.annotate(block_or_loop=l99, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l99, ann_key="pragma_unroll_explicit", ann_val=1)
l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b64)
l106 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l106)
b107 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b107)
b123 = sch.decompose_reduction(block=b107, loop=l109)
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #33: GFLOPs: 5.3368. Time: 80.9441 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #34: GFLOPs: 1.9098. Time: 226.1924 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #35: GFLOPs: 6.5079. Time: 66.3787 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #36: GFLOPs: 1.4163. Time: 305.0007 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #37: GFLOPs: 15.4035. Time: 28.0445 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #38: GFLOPs: 9.4255. Time: 45.8316 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #39: GFLOPs: 10.5309. Time: 41.0207 us. Best GFLOPs: 26.6957
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #40: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(3)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_fused_fused + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oci_0, b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(2)):
                    for oci_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("DepthwiseConv2d_init"):
                            v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                            v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init * T.int64(29) + oco_3_init)
                            v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(2) + oci_1 * T.int64(2) + oci_2_init * T.int64(2) + oci_3_fused_init)
                            T.reads()
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(2)):
                    for oci_3_fused in T.vectorized(T.int64(2)):
                        with T.block("DepthwiseConv2d_update"):
                            v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 * T.int64(29) + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_fused_fused + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(2) + oci_1 * T.int64(2) + oci_2 * T.int64(2) + oci_3_fused)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_add"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_fused_fused + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), oci_0 * T.int64(2) + ax4_fused)
                            T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72 = sch.get_loops(block=b62)
l73 = sch.fuse(l65, l66, l67, preserve_unit_iters=True)
sch.parallel(loop=l73)
l74 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.vectorize(loop=l74)
l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b63)
l97 = sch.fuse(l75, preserve_unit_iters=True)
sch.parallel(loop=l97)
l98 = sch.fuse(l96, preserve_unit_iters=True)
sch.vectorize(loop=l98)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b64)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l122)
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #41: GFLOPs: 32.9238. Time: 13.1207 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #42: GFLOPs: 32.0985. Time: 13.4581 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #43: GFLOPs: 16.8594. Time: 25.6227 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #44: GFLOPs: 2.5182. Time: 171.5444 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #45: GFLOPs: 10.2382. Time: 42.1935 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #46: GFLOPs: 2.5081. Time: 172.2358 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #47: GFLOPs: 1.0676. Time: 404.6403 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #48: GFLOPs: 25.9237. Time: 16.6637 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #49: GFLOPs: 6.4123. Time: 67.3685 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #50: GFLOPs: 1.8739. Time: 230.5257 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #51: GFLOPs: 3.3681. Time: 128.2578 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #52: GFLOPs: 3.5069. Time: 123.1822 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #53: GFLOPs: 1.0721. Time: 402.9342 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #54: GFLOPs: 8.2695. Time: 52.2380 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #55: GFLOPs: 2.2340. Time: 193.3645 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #56: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused in T.parallel(T.int64(58), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(16)):
                for ax3_ax4_fused in T.vectorized(T.int64(36)):
                    with T.block("PaddedInput"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(29), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused % T.int64(29) + ax1)
                        v_i2 = T.axis.spatial(T.int64(16), ax2)
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused // T.int64(29) * T.int64(7) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused % T.int64(29) + oco_2_init + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused // T.int64(29) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(2) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused % T.int64(29) + oco_2 + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_fused_fused // T.int64(29) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(2) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(356)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(29), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(784))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(784) // T.int64(56))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(56) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.where(ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1 < T.int64(22736))
                    T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 29, 1, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 7, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v58 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v58)
l59 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l59, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b60 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.unroll_explicit")
b61, b62, b63 = sch.get_child_blocks(b60)
l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75 = sch.get_loops(block=b61)
l76 = sch.fuse(l64, l65, l66, l67, l68, l69, l70, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l74, l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b62)
l96 = sch.fuse(l78, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101 = sch.get_loops(block=b63)
l102 = sch.fuse(l97, l98, l99, l100, l101, preserve_unit_iters=True)
l103, l104 = sch.split(loop=l102, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b105)
b124 = sch.decompose_reduction(block=b105, loop=l110)
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #57: GFLOPs: 18.9760. Time: 22.7648 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #58: GFLOPs: 1.4625. Time: 295.3794 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #59: GFLOPs: 2.8830. Time: 149.8371 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #60: GFLOPs: 2.1549. Time: 200.4655 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #61: GFLOPs: 25.8105. Time: 16.7368 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #62: GFLOPs: 0.2577. Time: 1676.0817 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #63: GFLOPs: 0.2594. Time: 1665.0129 us. Best GFLOPs: 32.9238
2024-04-28 21:11:36 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #64: GFLOPs: 0.4108. Time: 1051.5636 us. Best GFLOPs: 32.9238
2024-04-28 21:45:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:45:06 [INFO] [evolutionary_search.cc:715] Picked top 60 candidate(s) from database
2024-04-28 21:45:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 21:45:11 [INFO] [evolutionary_search.cc:723] Sampled 452 candidate(s)
2024-04-28 21:45:22 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 21:45:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 21:45:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 21:45:55 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 21:46:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0562  1.0318  1.0242  1.0242  1.0224  0.9963  0.9963  0.9748  0.9721  0.9615  0.9599  0.9573  0.9498  0.9471  0.9455  0.9271
[17 : 32]:	0.9147  0.9097  0.9089  0.9086  0.9086  0.9086  0.9056  0.9043  0.9030  0.9030  0.8949  0.8888  0.8824  0.8808  0.8808  0.8775
[33 : 48]:	0.8765  0.8697  0.8695  0.8683  0.8679  0.8658  0.8595  0.8590  0.8566  0.8527  0.8503  0.8490  0.8484  0.8481  0.8478  0.8424
[49 : 64]:	0.8405  0.8390  0.8328  0.8328  0.8328  0.8328  0.8314  0.8314  0.8314  0.8314  0.8275  0.8229  0.8228  0.8187  0.8187  0.8187
2024-04-28 21:46:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:46:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #65: GFLOPs: 4.7098. Time: 91.7210 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #66: GFLOPs: 4.7031. Time: 91.8508 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #67: GFLOPs: 4.7175. Time: 91.5705 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #68: GFLOPs: 4.7416. Time: 91.1044 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #69: GFLOPs: 2.3983. Time: 180.1237 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #70: GFLOPs: 3.1446. Time: 137.3724 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #71: GFLOPs: 3.1549. Time: 136.9262 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #72: GFLOPs: 3.0761. Time: 140.4330 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #73: GFLOPs: 4.3337. Time: 99.6810 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #74: GFLOPs: 4.7528. Time: 90.8903 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #75: GFLOPs: 4.7355. Time: 91.2226 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #76: GFLOPs: 4.6804. Time: 92.2960 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #77: GFLOPs: 4.7575. Time: 90.8003 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #78: GFLOPs: 3.6127. Time: 119.5745 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #79: GFLOPs: 4.7644. Time: 90.6696 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #80: GFLOPs: 5.4382. Time: 79.4355 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #81: GFLOPs: 3.1377. Time: 137.6745 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #82: GFLOPs: 16.0227. Time: 26.9607 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #83: GFLOPs: 2.5243. Time: 171.1303 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #84: GFLOPs: 3.0459. Time: 141.8249 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #85: GFLOPs: 3.0470. Time: 141.7751 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #86: GFLOPs: 3.0404. Time: 142.0833 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #87: GFLOPs: 4.6292. Time: 93.3175 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #88: GFLOPs: 3.0590. Time: 141.2196 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #89: GFLOPs: 3.1614. Time: 136.6448 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #90: GFLOPs: 3.1340. Time: 137.8399 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #91: GFLOPs: 3.1229. Time: 138.3287 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #92: GFLOPs: 4.7687. Time: 90.5875 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #93: GFLOPs: 3.1238. Time: 138.2886 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #94: GFLOPs: 12.7924. Time: 33.7687 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #95: GFLOPs: 12.8339. Time: 33.6595 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #96: GFLOPs: 3.0574. Time: 141.2925 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #97: GFLOPs: 3.1451. Time: 137.3507 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #98: GFLOPs: 2.9663. Time: 145.6295 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #99: GFLOPs: 5.2411. Time: 82.4229 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #100: GFLOPs: 2.5342. Time: 170.4637 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #101: GFLOPs: 3.1116. Time: 138.8308 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #102: GFLOPs: 3.1502. Time: 137.1297 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #103: GFLOPs: 3.0528. Time: 141.5025 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #104: GFLOPs: 3.1258. Time: 138.2016 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #105: GFLOPs: 3.5912. Time: 120.2906 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #106: GFLOPs: 4.3532. Time: 99.2341 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #107: GFLOPs: 4.7692. Time: 90.5783 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #108: GFLOPs: 4.6483. Time: 92.9329 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #109: GFLOPs: 3.0790. Time: 140.2981 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #110: GFLOPs: 3.1861. Time: 135.5847 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #111: GFLOPs: 3.9937. Time: 108.1660 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #112: GFLOPs: 6.9049. Time: 62.5617 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #113: GFLOPs: 3.1040. Time: 139.1715 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #114: GFLOPs: 2.5591. Time: 168.8012 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #115: GFLOPs: 4.6512. Time: 92.8754 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #116: GFLOPs: 4.4973. Time: 96.0531 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #117: GFLOPs: 4.6198. Time: 93.5063 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #118: GFLOPs: 4.4426. Time: 97.2361 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #119: GFLOPs: 4.7075. Time: 91.7650 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #120: GFLOPs: 4.7348. Time: 91.2360 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #121: GFLOPs: 4.6894. Time: 92.1197 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #122: GFLOPs: 4.6206. Time: 93.4909 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #123: GFLOPs: 5.3834. Time: 80.2442 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #124: GFLOPs: 3.1026. Time: 139.2325 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #125: GFLOPs: 3.1705. Time: 136.2519 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #126: GFLOPs: 8.2835. Time: 52.1502 us. Best GFLOPs: 32.9238
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #127: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(16)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_fused_fused * T.int64(2) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oci_0, b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(29), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(4) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(4) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(14)):
                    for ax3_ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_add"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused * T.int64(2) + ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 29, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73 = sch.get_loops(block=b62)
l74 = sch.fuse(l65, l66, l67, l68, preserve_unit_iters=True)
sch.parallel(loop=l74)
l75 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.vectorize(loop=l75)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b63)
l97 = sch.fuse(l76, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b64)
l110 = sch.fuse(l108, l109, preserve_unit_iters=True)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b111)
b133 = sch.decompose_reduction(block=b111, loop=l119)
2024-04-28 21:47:32 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #128: GFLOPs: 1.4748. Time: 292.9100 us. Best GFLOPs: 32.9238
2024-04-28 22:20:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:20:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:20:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 22:20:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:20:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 22:21:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 22:21:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 22:21:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 22:21:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8570  0.8570  0.8536  0.8442  0.8442  0.8435  0.8417  0.8095  0.7786  0.7637  0.7633  0.7488  0.7431  0.7429  0.7420  0.7358
[17 : 32]:	0.7267  0.7261  0.7202  0.7185  0.7138  0.7134  0.7042  0.6966  0.6948  0.6948  0.6865  0.6839  0.6818  0.6770  0.6733  0.6711
[33 : 48]:	0.6705  0.6694  0.6670  0.6670  0.6635  0.6615  0.6602  0.6597  0.6597  0.6597  0.6597  0.6583  0.6583  0.6504  0.6502  0.6500
[49 : 64]:	0.6492  0.6481  0.6472  0.6460  0.6446  0.6440  0.6428  0.6428  0.6390  0.6390  0.6387  0.6378  0.6374  0.6369  0.6359  0.6353
2024-04-28 22:21:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:21:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #129: GFLOPs: 8.7813. Time: 49.1934 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #130: GFLOPs: 8.5326. Time: 50.6272 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #131: GFLOPs: 9.0104. Time: 47.9427 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #132: GFLOPs: 5.0424. Time: 85.6707 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #133: GFLOPs: 10.1454. Time: 42.5792 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #134: GFLOPs: 10.2062. Time: 42.3256 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #135: GFLOPs: 7.3163. Time: 59.0441 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #136: GFLOPs: 9.6627. Time: 44.7061 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #137: GFLOPs: 11.5093. Time: 37.5335 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #138: GFLOPs: 18.8622. Time: 22.9020 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #139: GFLOPs: 13.2750. Time: 32.5411 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #140: GFLOPs: 8.3175. Time: 51.9370 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #141: GFLOPs: 11.4003. Time: 37.8925 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #142: GFLOPs: 9.9104. Time: 43.5888 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #143: GFLOPs: 10.8956. Time: 39.6476 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #144: GFLOPs: 17.8443. Time: 24.2085 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #145: GFLOPs: 12.9668. Time: 33.3147 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #146: GFLOPs: 7.9078. Time: 54.6278 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #147: GFLOPs: 7.7774. Time: 55.5438 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #148: GFLOPs: 13.1068. Time: 32.9588 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #149: GFLOPs: 9.4728. Time: 45.6025 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #150: GFLOPs: 8.5840. Time: 50.3245 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #151: GFLOPs: 8.7928. Time: 49.1290 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #152: GFLOPs: 11.5579. Time: 37.3756 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #153: GFLOPs: 8.4394. Time: 51.1866 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #154: GFLOPs: 8.5372. Time: 50.6003 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #155: GFLOPs: 9.3001. Time: 46.4492 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #156: GFLOPs: 6.3914. Time: 67.5882 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #157: GFLOPs: 9.6320. Time: 44.8486 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #158: GFLOPs: 9.5093. Time: 45.4274 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #159: GFLOPs: 11.3889. Time: 37.9303 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #160: GFLOPs: 8.2961. Time: 52.0709 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #161: GFLOPs: 8.1241. Time: 53.1733 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #162: GFLOPs: 8.1519. Time: 52.9916 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #163: GFLOPs: 7.3370. Time: 58.8776 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #164: GFLOPs: 7.3349. Time: 58.8944 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #165: GFLOPs: 9.6913. Time: 44.5743 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #166: GFLOPs: 12.9230. Time: 33.4276 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #167: GFLOPs: 8.1446. Time: 53.0392 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #168: GFLOPs: 12.5299. Time: 34.4763 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #169: GFLOPs: 14.5046. Time: 29.7825 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #170: GFLOPs: 15.6064. Time: 27.6799 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #171: GFLOPs: 14.6819. Time: 29.4228 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #172: GFLOPs: 15.4237. Time: 28.0078 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #173: GFLOPs: 14.3415. Time: 30.1213 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #174: GFLOPs: 7.2594. Time: 59.5072 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #175: GFLOPs: 8.1987. Time: 52.6896 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #176: GFLOPs: 11.8025. Time: 36.6012 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #177: GFLOPs: 9.4780. Time: 45.5776 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #178: GFLOPs: 7.8848. Time: 54.7870 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #179: GFLOPs: 11.6999. Time: 36.9220 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #180: GFLOPs: 6.3516. Time: 68.0117 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #181: GFLOPs: 18.8275. Time: 22.9443 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #182: GFLOPs: 11.8943. Time: 36.3187 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #183: GFLOPs: 9.2469. Time: 46.7167 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #184: GFLOPs: 8.8403. Time: 48.8654 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #185: GFLOPs: 10.3525. Time: 41.7273 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #186: GFLOPs: 3.8396. Time: 112.5078 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #187: GFLOPs: 8.5811. Time: 50.3412 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #188: GFLOPs: 4.6196. Time: 93.5105 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #189: GFLOPs: 7.9534. Time: 54.3147 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #190: GFLOPs: 2.4190. Time: 178.5761 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #191: GFLOPs: 9.6931. Time: 44.5663 us. Best GFLOPs: 32.9238
2024-04-28 22:22:59 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #192: GFLOPs: 5.3965. Time: 80.0482 us. Best GFLOPs: 32.9238
2024-04-28 23:03:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:03:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:03:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:03:55 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:04:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:04:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:04:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:04:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:04:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8046  0.7743  0.7743  0.7146  0.7146  0.7078  0.7002  0.6995  0.6995  0.6827  0.6718  0.6706  0.6676  0.6666  0.6666  0.6666
[17 : 32]:	0.6666  0.6637  0.6581  0.6581  0.6435  0.6429  0.6402  0.6340  0.6324  0.6291  0.6263  0.6215  0.6166  0.6164  0.6164  0.6164
[33 : 48]:	0.6163  0.6118  0.6027  0.6027  0.6027  0.6027  0.5991  0.5977  0.5950  0.5943  0.5913  0.5903  0.5887  0.5872  0.5841  0.5827
[49 : 64]:	0.5824  0.5807  0.5807  0.5806  0.5800  0.5753  0.5743  0.5728  0.5715  0.5699  0.5680  0.5676  0.5652  0.5648  0.5634  0.5631
2024-04-28 23:04:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:04:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #193: GFLOPs: 3.3043. Time: 130.7337 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #194: GFLOPs: 3.2555. Time: 132.6949 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #195: GFLOPs: 3.3144. Time: 130.3346 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #196: GFLOPs: 8.4266. Time: 51.2645 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #197: GFLOPs: 8.6957. Time: 49.6780 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #198: GFLOPs: 3.3522. Time: 128.8650 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #199: GFLOPs: 8.7444. Time: 49.4013 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #200: GFLOPs: 8.6982. Time: 49.6635 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #201: GFLOPs: 8.6941. Time: 49.6869 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #202: GFLOPs: 8.7265. Time: 49.5025 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #203: GFLOPs: 3.2605. Time: 132.4918 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #204: GFLOPs: 3.2967. Time: 131.0338 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #205: GFLOPs: 5.3071. Time: 81.3981 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #206: GFLOPs: 2.4679. Time: 175.0431 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #207: GFLOPs: 2.4733. Time: 174.6618 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #208: GFLOPs: 2.4352. Time: 177.3938 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #209: GFLOPs: 2.4693. Time: 174.9396 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #210: GFLOPs: 7.8616. Time: 54.9484 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #211: GFLOPs: 3.3942. Time: 127.2721 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #212: GFLOPs: 3.2391. Time: 133.3649 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #213: GFLOPs: 10.3784. Time: 41.6233 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #214: GFLOPs: 3.3868. Time: 127.5494 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #215: GFLOPs: 12.9167. Time: 33.4438 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #216: GFLOPs: 10.2928. Time: 41.9695 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #217: GFLOPs: 10.0844. Time: 42.8367 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #218: GFLOPs: 3.4773. Time: 124.2291 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #219: GFLOPs: 2.4592. Time: 175.6631 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #220: GFLOPs: 4.9798. Time: 86.7477 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #221: GFLOPs: 5.0078. Time: 86.2616 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #222: GFLOPs: 5.4703. Time: 78.9694 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #223: GFLOPs: 5.4541. Time: 79.2041 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #224: GFLOPs: 5.4793. Time: 78.8386 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #225: GFLOPs: 3.3221. Time: 130.0346 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #226: GFLOPs: 3.2823. Time: 131.6115 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #227: GFLOPs: 5.2801. Time: 81.8130 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #228: GFLOPs: 5.0973. Time: 84.7469 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #229: GFLOPs: 5.0526. Time: 85.4971 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #230: GFLOPs: 5.0771. Time: 85.0853 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #231: GFLOPs: 5.0281. Time: 85.9135 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #232: GFLOPs: 5.2679. Time: 82.0034 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #233: GFLOPs: 11.9647. Time: 36.1048 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #234: GFLOPs: 3.0917. Time: 139.7240 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #235: GFLOPs: 3.0866. Time: 139.9548 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #236: GFLOPs: 11.9650. Time: 36.1039 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #237: GFLOPs: 10.2910. Time: 41.9770 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #238: GFLOPs: 6.8299. Time: 63.2493 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #239: GFLOPs: 13.2628. Time: 32.5710 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #240: GFLOPs: 5.1780. Time: 83.4264 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #241: GFLOPs: 11.6802. Time: 36.9844 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #242: GFLOPs: 4.5068. Time: 95.8510 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #243: GFLOPs: 4.5384. Time: 95.1841 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #244: GFLOPs: 20.0235. Time: 21.5738 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #245: GFLOPs: 4.1040. Time: 105.2603 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #246: GFLOPs: 5.8392. Time: 73.9797 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #247: GFLOPs: 6.4374. Time: 67.1053 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #248: GFLOPs: 2.0567. Time: 210.0349 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #249: GFLOPs: 4.8264. Time: 89.5046 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #250: GFLOPs: 9.8911. Time: 43.6738 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #251: GFLOPs: 4.9434. Time: 87.3869 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #252: GFLOPs: 3.0220. Time: 142.9465 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #253: GFLOPs: 4.8352. Time: 89.3406 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #254: GFLOPs: 0.8181. Time: 528.0325 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #255: GFLOPs: 1.6119. Time: 268.0013 us. Best GFLOPs: 32.9238
2024-04-28 23:06:03 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #256: GFLOPs: 2.7295. Time: 158.2636 us. Best GFLOPs: 32.9238
2024-04-28 23:39:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:39:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:39:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:39:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:39:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:40:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:40:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:40:28 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-28 23:40:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7199  0.7199  0.7000  0.7000  0.7000  0.6963  0.6101  0.6068  0.5997  0.5913  0.5826  0.5814  0.5805  0.5799  0.5775  0.5775
[17 : 32]:	0.5775  0.5760  0.5696  0.5689  0.5669  0.5669  0.5665  0.5638  0.5638  0.5580  0.5571  0.5546  0.5529  0.5515  0.5474  0.5457
[33 : 48]:	0.5441  0.5406  0.5406  0.5368  0.5344  0.5321  0.5320  0.5286  0.5278  0.5276  0.5272  0.5252  0.5248  0.5247  0.5230  0.5230
[49 : 64]:	0.5228  0.5227  0.5224  0.5224  0.5199  0.5183  0.5176  0.5134  0.5125  0.5099  0.5080  0.5069  0.5066  0.5054  0.5043  0.5029
2024-04-28 23:40:35 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:40:35 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #257: GFLOPs: 4.8051. Time: 89.9003 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #258: GFLOPs: 2.9644. Time: 145.7257 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #259: GFLOPs: 4.8527. Time: 89.0192 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #260: GFLOPs: 4.7868. Time: 90.2456 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #261: GFLOPs: 2.9704. Time: 145.4317 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #262: GFLOPs: 4.7444. Time: 91.0508 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #263: GFLOPs: 9.1498. Time: 47.2121 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #264: GFLOPs: 18.5547. Time: 23.2816 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #265: GFLOPs: 3.1131. Time: 138.7619 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #266: GFLOPs: 16.3994. Time: 26.3415 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #267: GFLOPs: 4.1103. Time: 105.0976 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #268: GFLOPs: 8.8727. Time: 48.6870 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #269: GFLOPs: 4.0916. Time: 105.5783 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #270: GFLOPs: 15.4026. Time: 28.0461 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #271: GFLOPs: 17.4137. Time: 24.8071 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #272: GFLOPs: 17.4467. Time: 24.7603 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #273: GFLOPs: 7.6714. Time: 56.3109 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #274: GFLOPs: 7.6106. Time: 56.7609 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #275: GFLOPs: 4.0230. Time: 107.3775 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #276: GFLOPs: 10.9511. Time: 39.4466 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #277: GFLOPs: 17.8997. Time: 24.1336 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #278: GFLOPs: 17.9476. Time: 24.0692 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #279: GFLOPs: 5.1785. Time: 83.4187 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #280: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(4), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oci_1 in range(T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(29), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + oci_1 * T.int64(2) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(29), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_2 * T.int64(29) + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + oci_1 * T.int64(2) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_add"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + ax4_fused)
                            T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b62)
l79 = sch.fuse(l65, l66, l67, l68, l69, l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b63)
l97 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b64)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b106)
b123 = sch.decompose_reduction(block=b106, loop=l109)
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #281: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(4), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oci_1 in range(T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(29), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + oci_1 * T.int64(2) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_2 * T.int64(29) + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + oci_1 * T.int64(2) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_add"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_fused_fused // T.int64(49) * T.int64(2) + ax4_fused)
                            T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b62)
l79 = sch.fuse(l65, l66, l67, l68, l69, l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b63)
l97 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b64)
l105 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b106)
b123 = sch.decompose_reduction(block=b106, loop=l109)
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #282: GFLOPs: 2.0886. Time: 206.8262 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #283: GFLOPs: 10.3470. Time: 41.7498 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #284: GFLOPs: 7.4452. Time: 58.0221 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #285: GFLOPs: 3.5280. Time: 122.4440 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #286: GFLOPs: 1.9760. Time: 218.6123 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #287: GFLOPs: 2.0869. Time: 206.9964 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #288: GFLOPs: 10.4013. Time: 41.5319 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #289: GFLOPs: 2.9182. Time: 148.0320 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #290: GFLOPs: 7.9645. Time: 54.2386 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #291: GFLOPs: 15.0248. Time: 28.7514 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #292: GFLOPs: 7.6718. Time: 56.3080 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #293: GFLOPs: 2.9008. Time: 148.9177 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #294: GFLOPs: 6.4427. Time: 67.0497 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #295: GFLOPs: 7.7799. Time: 55.5258 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #296: GFLOPs: 8.9494. Time: 48.2694 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #297: GFLOPs: 3.4338. Time: 125.8034 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #298: GFLOPs: 4.4711. Time: 96.6163 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #299: GFLOPs: 5.3699. Time: 80.4455 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #300: GFLOPs: 3.5655. Time: 121.1583 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #301: GFLOPs: 15.5620. Time: 27.7589 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #302: GFLOPs: 4.9804. Time: 86.7370 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #303: GFLOPs: 9.4318. Time: 45.8009 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #304: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(2) * T.int64(2) + oci_1 * T.int64(2) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(2) * T.int64(2) + oci_1 * T.int64(2) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], p0[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_oci % T.int64(4)], T.float32(0)) * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_add"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused // T.int64(14) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), b_0_oco_0_oh_0_ow_0_oci_0_fused % T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 29, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63 = sch.get_child_blocks(b61)
l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b62)
l88 = sch.fuse(l64, l65, l66, l67, l68, preserve_unit_iters=True)
sch.parallel(loop=l88)
sch.annotate(block_or_loop=l88, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l88, ann_key="pragma_unroll_explicit", ann_val=1)
l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b63)
l95 = sch.fuse(l94, preserve_unit_iters=True)
sch.vectorize(loop=l95)
b96 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b96)
b117 = sch.decompose_reduction(block=b96, loop=l103)
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #305: GFLOPs: 15.2459. Time: 28.3345 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #306: GFLOPs: 9.4720. Time: 45.6062 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #307: GFLOPs: 12.4034. Time: 34.8279 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #308: GFLOPs: 9.7553. Time: 44.2821 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #309: GFLOPs: 6.3429. Time: 68.1051 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #310: GFLOPs: 5.2207. Time: 82.7446 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #311: GFLOPs: 12.5313. Time: 34.4725 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #312: GFLOPs: 1.9935. Time: 216.6982 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #313: GFLOPs: 3.2070. Time: 134.6983 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #314: GFLOPs: 13.9574. Time: 30.9502 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #315: GFLOPs: 16.0321. Time: 26.9450 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #316: GFLOPs: 14.7996. Time: 29.1888 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #317: GFLOPs: 7.2651. Time: 59.4600 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #318: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(29), T.int64(7), T.int64(1)):
                for oci_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(2) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(2) * T.int64(2) + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_2_init * T.int64(2) + oci_3_fused_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
            for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(29), T.int64(7), T.int64(3)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("PaddedInput"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(16), kh_1 + b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(2) * T.int64(7) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_2 + b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(2) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(4), oci_2 * T.int64(2) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                            PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_1, b_3, oco_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(29), T.int64(7), T.int64(1)):
                    for oci_3_fused in T.vectorized(T.int64(2)):
                        with T.block("DepthwiseConv2d_update"):
                            v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_2 * T.int64(29) + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(2) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(2) * T.int64(2) + ow_2 + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_2 * T.int64(2) + oci_3_fused)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(7)):
                for ax3_ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_add"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused % T.int64(2) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_ow_1_oci_1_fused_fused // T.int64(2) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=17)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b62)
l88 = sch.fuse(l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b63)
l105 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b64)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b114)
b130 = sch.decompose_reduction(block=b114, loop=l116)
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #319: GFLOPs: 4.4575. Time: 96.9126 us. Best GFLOPs: 32.9238
2024-04-28 23:42:12 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #320: GFLOPs: 2.8245. Time: 152.9394 us. Best GFLOPs: 32.9238
2024-04-29 00:19:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:19:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:19:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:19:43 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:19:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:20:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:20:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:20:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:20:38 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7156  0.6587  0.6101  0.5953  0.5953  0.5920  0.5746  0.5691  0.5668  0.5660  0.5660  0.5570  0.5557  0.5557  0.5557  0.5499
[17 : 32]:	0.5485  0.5485  0.5458  0.5430  0.5430  0.5430  0.5318  0.5318  0.5305  0.5305  0.5302  0.5270  0.5198  0.5178  0.5169  0.5157
[33 : 48]:	0.5143  0.5136  0.5134  0.5117  0.5066  0.5040  0.5038  0.5010  0.5010  0.4959  0.4959  0.4915  0.4915  0.4915  0.4905  0.4905
[49 : 64]:	0.4905  0.4905  0.4901  0.4901  0.4875  0.4872  0.4869  0.4847  0.4829  0.4816  0.4812  0.4811  0.4810  0.4807  0.4798  0.4797
2024-04-29 00:20:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:20:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #321: GFLOPs: 2.2792. Time: 189.5302 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #322: GFLOPs: 5.4227. Time: 79.6627 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #323: GFLOPs: 2.2579. Time: 191.3188 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #324: GFLOPs: 6.0508. Time: 71.3927 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #325: GFLOPs: 6.0646. Time: 71.2307 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #326: GFLOPs: 7.9889. Time: 54.0728 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #327: GFLOPs: 18.6506. Time: 23.1619 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #328: GFLOPs: 3.2888. Time: 131.3516 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #329: GFLOPs: 18.1529. Time: 23.7970 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #330: GFLOPs: 3.2500. Time: 132.9191 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #331: GFLOPs: 3.2537. Time: 132.7679 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #332: GFLOPs: 14.5171. Time: 29.7569 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #333: GFLOPs: 16.4643. Time: 26.2376 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #334: GFLOPs: 16.5302. Time: 26.1331 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #335: GFLOPs: 16.2471. Time: 26.5883 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #336: GFLOPs: 5.5519. Time: 77.8087 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #337: GFLOPs: 6.5033. Time: 66.4254 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #338: GFLOPs: 6.1113. Time: 70.6857 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #339: GFLOPs: 16.4676. Time: 26.2324 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #340: GFLOPs: 17.8205. Time: 24.2408 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #341: GFLOPs: 17.9752. Time: 24.0323 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #342: GFLOPs: 17.8798. Time: 24.1605 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #343: GFLOPs: 18.2600. Time: 23.6573 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #344: GFLOPs: 18.4828. Time: 23.3723 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #345: GFLOPs: 16.6993. Time: 25.8684 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #346: GFLOPs: 17.1376. Time: 25.2067 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #347: GFLOPs: 17.7212. Time: 24.3767 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #348: GFLOPs: 6.0299. Time: 71.6404 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #349: GFLOPs: 17.6596. Time: 24.4617 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #350: GFLOPs: 10.7478. Time: 40.1928 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #351: GFLOPs: 17.7764. Time: 24.3009 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #352: GFLOPs: 14.9102. Time: 28.9724 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #353: GFLOPs: 4.0043. Time: 107.8803 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #354: GFLOPs: 16.0834. Time: 26.8591 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #355: GFLOPs: 14.8228. Time: 29.1432 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #356: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(3)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_fused_fused // T.int64(7) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oci_0, b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused // T.int64(7) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(4) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 * T.int64(29) + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused // T.int64(7) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), oci_0 * T.int64(4) + oci_1 * T.int64(4) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_add"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused // T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l47, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63, b64 = sch.get_child_blocks(b61)
l65, l66, l67, l68, l69, l70, l71, l72, l73 = sch.get_loops(block=b62)
l74 = sch.fuse(l65, l66, l67, l68, preserve_unit_iters=True)
sch.parallel(loop=l74)
l75 = sch.fuse(l72, l73, preserve_unit_iters=True)
sch.vectorize(loop=l75)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b63)
l97 = sch.fuse(l76, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b64)
l110 = sch.fuse(l108, l109, preserve_unit_iters=True)
sch.vectorize(loop=l110)
b111 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b111)
b133 = sch.decompose_reduction(block=b111, loop=l119)
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #357: GFLOPs: 16.5774. Time: 26.0587 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #358: GFLOPs: 6.7690. Time: 63.8175 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #359: GFLOPs: 17.7372. Time: 24.3547 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #360: GFLOPs: 16.1506. Time: 26.7473 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #361: GFLOPs: 16.3237. Time: 26.4637 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #362: GFLOPs: 6.4496. Time: 66.9783 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #363: GFLOPs: 6.1193. Time: 70.5937 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #364: GFLOPs: 15.2762. Time: 28.2782 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #365: GFLOPs: 16.0099. Time: 26.9824 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #366: GFLOPs: 15.8482. Time: 27.2577 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #367: GFLOPs: 14.8060. Time: 29.1762 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #368: GFLOPs: 14.6877. Time: 29.4112 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #369: GFLOPs: 15.0135. Time: 28.7731 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #370: GFLOPs: 14.5877. Time: 29.6129 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #371: GFLOPs: 4.3479. Time: 99.3554 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #372: GFLOPs: 18.8036. Time: 22.9734 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #373: GFLOPs: 14.6303. Time: 29.5267 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #374: GFLOPs: 17.0175. Time: 25.3847 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #375: GFLOPs: 15.2946. Time: 28.2443 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #376: GFLOPs: 15.6968. Time: 27.5205 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #377: GFLOPs: 19.3619. Time: 22.3110 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #378: GFLOPs: 17.0399. Time: 25.3513 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #379: GFLOPs: 8.5066. Time: 50.7821 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #380: GFLOPs: 6.5072. Time: 66.3857 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #381: GFLOPs: 4.3385. Time: 99.5694 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #382: GFLOPs: 3.4295. Time: 125.9605 us. Best GFLOPs: 32.9238
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #383: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for b_1, oco_1, oh_1, ow_1, oci_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init, oci_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(29), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_init"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2_init + b_3_init)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2_init * T.int64(29) + oco_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused * T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                        v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2_init + oci_3_init)
                        T.reads()
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3, oci_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(29), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("DepthwiseConv2d_update"):
                        v_b = T.axis.spatial(T.int64(1), b_1 + b_2 + b_3)
                        v_oco = T.axis.spatial(T.int64(29), oco_1 * T.int64(29) + oco_2 * T.int64(29) + oco_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused * T.int64(7) + ow_1 + ow_2 + ow_3)
                        v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2 + oci_3)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], p0[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                        T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_oci % T.int64(4)], T.float32(0)) * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(28)):
                    with T.block("T_add"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_fused * T.int64(7) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 29])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[1, 3])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
b58, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b58, loop=l46, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v59 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v59)
l60 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l60, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b61 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b61, ann_key="meta_schedule.unroll_explicit")
b62, b63 = sch.get_child_blocks(b61)
l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b62)
l88 = sch.fuse(l64, l65, l66, l67, l68, preserve_unit_iters=True)
sch.parallel(loop=l88)
sch.annotate(block_or_loop=l88, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l88, ann_key="pragma_unroll_explicit", ann_val=1)
l89, l90, l91, l92, l93, l94 = sch.get_loops(block=b63)
l95 = sch.fuse(l93, l94, preserve_unit_iters=True)
sch.vectorize(loop=l95)
b96 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b96)
b117 = sch.decompose_reduction(block=b96, loop=l103)
2024-04-29 00:22:14 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #384: GFLOPs: 4.4619. Time: 96.8159 us. Best GFLOPs: 32.9238
2024-04-29 00:59:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:59:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:59:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:59:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:59:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:59:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:59:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 00:59:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:00:04 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5768  0.5720  0.5663  0.5663  0.5663  0.5663  0.5616  0.5572  0.5509  0.5502  0.5272  0.5186  0.5184  0.5181  0.5162  0.5148
[17 : 32]:	0.5148  0.5147  0.5102  0.5093  0.5075  0.5071  0.5057  0.5041  0.5034  0.5005  0.5004  0.5000  0.4988  0.4976  0.4963  0.4962
[33 : 48]:	0.4955  0.4927  0.4914  0.4847  0.4847  0.4847  0.4839  0.4834  0.4825  0.4821  0.4813  0.4805  0.4805  0.4790  0.4778  0.4778
[49 : 64]:	0.4752  0.4724  0.4723  0.4718  0.4718  0.4715  0.4708  0.4705  0.4705  0.4696  0.4693  0.4689  0.4677  0.4675  0.4670  0.4670
2024-04-29 01:00:04 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:00:04 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #385: GFLOPs: 10.3248. Time: 41.8396 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #386: GFLOPs: 19.1168. Time: 22.5971 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #387: GFLOPs: 20.0840. Time: 21.5088 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #388: GFLOPs: 19.7800. Time: 21.8395 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #389: GFLOPs: 20.4996. Time: 21.0728 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #390: GFLOPs: 20.1764. Time: 21.4103 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #391: GFLOPs: 20.0877. Time: 21.5049 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #392: GFLOPs: 20.2827. Time: 21.2982 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #393: GFLOPs: 18.3190. Time: 23.5812 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #394: GFLOPs: 18.7330. Time: 23.0601 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #395: GFLOPs: 9.9153. Time: 43.5676 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #396: GFLOPs: 12.7964. Time: 33.7583 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #397: GFLOPs: 16.8752. Time: 25.5987 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #398: GFLOPs: 16.8542. Time: 25.6306 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #399: GFLOPs: 14.1568. Time: 30.5142 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #400: GFLOPs: 6.9946. Time: 61.7592 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #401: GFLOPs: 5.7886. Time: 74.6272 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #402: GFLOPs: 8.0582. Time: 53.6082 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #403: GFLOPs: 14.0024. Time: 30.8507 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #404: GFLOPs: 18.0778. Time: 23.8958 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #405: GFLOPs: 17.4296. Time: 24.7845 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #406: GFLOPs: 17.1496. Time: 25.1892 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #407: GFLOPs: 19.0329. Time: 22.6967 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #408: GFLOPs: 11.8580. Time: 36.4298 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #409: GFLOPs: 9.1665. Time: 47.1264 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #410: GFLOPs: 19.1482. Time: 22.5601 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #411: GFLOPs: 18.3765. Time: 23.5074 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #412: GFLOPs: 12.9598. Time: 33.3326 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #413: GFLOPs: 18.5465. Time: 23.2919 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #414: GFLOPs: 18.4537. Time: 23.4091 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #415: GFLOPs: 17.8288. Time: 24.2296 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #416: GFLOPs: 19.0249. Time: 22.7062 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #417: GFLOPs: 5.9773. Time: 72.2703 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #418: GFLOPs: 13.9880. Time: 30.8826 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #419: GFLOPs: 18.3298. Time: 23.5673 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #420: GFLOPs: 14.6362. Time: 29.5147 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #421: GFLOPs: 11.9700. Time: 36.0888 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #422: GFLOPs: 11.8218. Time: 36.5412 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #423: GFLOPs: 18.8933. Time: 22.8644 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #424: GFLOPs: 7.5284. Time: 57.3803 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #425: GFLOPs: 17.4206. Time: 24.7973 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #426: GFLOPs: 15.7428. Time: 27.4401 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #427: GFLOPs: 16.3270. Time: 26.4582 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #428: GFLOPs: 12.2204. Time: 35.3495 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #429: GFLOPs: 11.3585. Time: 38.0317 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #430: GFLOPs: 16.7765. Time: 25.7493 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #431: GFLOPs: 11.4757. Time: 37.6434 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #432: GFLOPs: 11.6299. Time: 37.1442 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #433: GFLOPs: 17.2198. Time: 25.0864 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #434: GFLOPs: 16.0022. Time: 26.9953 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #435: GFLOPs: 16.9837. Time: 25.4352 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #436: GFLOPs: 12.9045. Time: 33.4753 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #437: GFLOPs: 12.7691. Time: 33.8304 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #438: GFLOPs: 15.3369. Time: 28.1663 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #439: GFLOPs: 8.3702. Time: 51.6100 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #440: GFLOPs: 14.3793. Time: 30.0421 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #441: GFLOPs: 19.5986. Time: 22.0416 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #442: GFLOPs: 21.6683. Time: 19.9362 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #443: GFLOPs: 18.6888. Time: 23.1146 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #444: GFLOPs: 15.9847. Time: 27.0248 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #445: GFLOPs: 16.7363. Time: 25.8113 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #446: GFLOPs: 6.8856. Time: 62.7369 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #447: GFLOPs: 6.0901. Time: 70.9320 us. Best GFLOPs: 32.9238
2024-04-29 01:01:26 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #448: GFLOPs: 1.3075. Time: 330.3848 us. Best GFLOPs: 32.9238
2024-04-29 01:32:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:32:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:32:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:32:12 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:32:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:32:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:32:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:32:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x5955c98)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x56be4c8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x32d5598)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x511bb38)]: 0 failure(s)
2024-04-29 01:33:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6356  0.6356  0.6356  0.6239  0.6239  0.6239  0.6205  0.6166  0.6147  0.6079  0.6067  0.6058  0.6051  0.6029  0.5951  0.5895
[17 : 32]:	0.5895  0.5839  0.5835  0.5826  0.5803  0.5803  0.5738  0.5738  0.5738  0.5738  0.5738  0.5728  0.5728  0.5684  0.5684  0.5682
[33 : 48]:	0.5682  0.5682  0.5640  0.5640  0.5640  0.5623  0.5623  0.5607  0.5594  0.5594  0.5594  0.5565  0.5565  0.5552  0.5525  0.5518
[49 : 64]:	0.5512  0.5512  0.5512  0.5511  0.5484  0.5480  0.5478  0.5478  0.5478  0.5471  0.5471  0.5471  0.5471  0.5465  0.5465  0.5465
2024-04-29 01:33:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:33:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #449: GFLOPs: 10.8027. Time: 39.9884 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #450: GFLOPs: 10.6538. Time: 40.5474 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #451: GFLOPs: 19.9601. Time: 21.6424 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #452: GFLOPs: 14.9631. Time: 28.8699 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #453: GFLOPs: 20.2777. Time: 21.3034 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #454: GFLOPs: 20.4392. Time: 21.1350 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #455: GFLOPs: 10.8188. Time: 39.9292 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #456: GFLOPs: 20.1227. Time: 21.4675 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #457: GFLOPs: 11.0275. Time: 39.1733 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #458: GFLOPs: 15.4952. Time: 27.8786 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #459: GFLOPs: 20.2646. Time: 21.3171 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #460: GFLOPs: 20.5309. Time: 21.0407 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #461: GFLOPs: 8.8670. Time: 48.7181 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #462: GFLOPs: 17.0483. Time: 25.3389 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #463: GFLOPs: 15.0739. Time: 28.6577 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #464: GFLOPs: 19.1194. Time: 22.5940 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #465: GFLOPs: 19.1821. Time: 22.5201 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #466: GFLOPs: 17.2469. Time: 25.0470 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #467: GFLOPs: 8.8652. Time: 48.7282 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #468: GFLOPs: 12.5425. Time: 34.4416 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #469: GFLOPs: 19.5623. Time: 22.0825 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #470: GFLOPs: 19.3042. Time: 22.3777 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #471: GFLOPs: 19.1972. Time: 22.5025 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #472: GFLOPs: 18.5402. Time: 23.2998 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #473: GFLOPs: 19.2121. Time: 22.4850 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #474: GFLOPs: 19.1893. Time: 22.5117 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #475: GFLOPs: 19.2431. Time: 22.4487 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #476: GFLOPs: 18.9479. Time: 22.7985 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #477: GFLOPs: 18.8537. Time: 22.9125 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #478: GFLOPs: 6.1135. Time: 70.6612 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #479: GFLOPs: 10.1240. Time: 42.6693 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #480: GFLOPs: 18.9594. Time: 22.7847 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #481: GFLOPs: 10.6398. Time: 40.6008 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #482: GFLOPs: 10.2914. Time: 41.9754 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #483: GFLOPs: 10.2909. Time: 41.9774 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #484: GFLOPs: 12.3104. Time: 35.0910 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #485: GFLOPs: 18.9265. Time: 22.8243 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #486: GFLOPs: 19.6310. Time: 22.0052 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #487: GFLOPs: 19.1664. Time: 22.5386 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #488: GFLOPs: 7.2296. Time: 59.7520 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #489: GFLOPs: 10.1917. Time: 42.3857 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #490: GFLOPs: 18.2260. Time: 23.7015 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #491: GFLOPs: 18.3395. Time: 23.5549 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #492: GFLOPs: 19.5684. Time: 22.0756 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #493: GFLOPs: 18.4633. Time: 23.3969 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #494: GFLOPs: 19.9468. Time: 21.6568 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #495: GFLOPs: 18.5665. Time: 23.2669 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #496: GFLOPs: 15.4198. Time: 28.0149 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #497: GFLOPs: 18.6031. Time: 23.2211 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #498: GFLOPs: 18.3723. Time: 23.5128 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #499: GFLOPs: 19.1217. Time: 22.5912 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #500: GFLOPs: 12.6050. Time: 34.2709 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #501: GFLOPs: 18.2250. Time: 23.7028 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #502: GFLOPs: 18.8056. Time: 22.9710 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #503: GFLOPs: 11.7704. Time: 36.7008 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #504: GFLOPs: 11.7880. Time: 36.6460 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #505: GFLOPs: 11.8004. Time: 36.6076 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #506: GFLOPs: 19.3041. Time: 22.3778 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #507: GFLOPs: 19.2591. Time: 22.4301 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #508: GFLOPs: 18.5117. Time: 23.3357 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #509: GFLOPs: 18.9114. Time: 22.8425 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:121] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #510: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(29), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        PaddedInput = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(16), T.int64(16), T.int64(4)))
        DepthwiseConv2d = T.alloc_buffer((T.int64(1), T.int64(29), T.int64(14), T.int64(14), T.int64(4)))
        for b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(29), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(12)):
                    with T.block("PaddedInput"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused // T.int64(7) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4])
                        PaddedInput[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oci_1 in T.grid(T.int64(1), T.int64(1)):
                for b_2_init, oco_2_init, oh_2_init, ow_2_init, oci_2_init, b_3_init, oco_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oci_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("DepthwiseConv2d_init"):
                            v_b = T.axis.spatial(T.int64(1), b_2_init + b_3_init)
                            v_oco = T.axis.spatial(T.int64(29), oco_2_init + oco_3_init)
                            v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused // T.int64(7) + ow_1 + ow_2_init + ow_3_init)
                            v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2_init * T.int64(2) + oci_3_fused_init)
                            T.reads()
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = T.float32(0)
                for kh_0, kw_0, b_2, oco_2, oh_2, ow_2, oci_2, kh_1, kw_1, b_3, oco_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(29), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oci_3_fused in T.vectorized(T.int64(2)):
                        with T.block("DepthwiseConv2d_update"):
                            v_b = T.axis.spatial(T.int64(1), b_2 + b_3)
                            v_oco = T.axis.spatial(T.int64(29), oco_2 + oco_3)
                            v_oh = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused % T.int64(7) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), b_0_oco_0_oh_0_ow_0_oci_0_b_1_oco_1_oh_1_fused_fused // T.int64(7) + ow_1 + ow_2 + ow_3)
                            v_oci = T.axis.spatial(T.int64(4), oci_1 * T.int64(4) + oci_2 * T.int64(2) + oci_3_fused)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci], PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)], p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci])
                            T.writes(DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] = DepthwiseConv2d[v_b, v_oco, v_oh, v_ow, v_oci] + PaddedInput[v_b, v_oci // T.int64(4) + v_oco, v_oh + v_kh, v_ow + v_kw, v_oci % T.int64(4)] * p1[v_oco, T.int64(0), v_kh, v_kw, T.int64(0), v_oci]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(356)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(29), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(784))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(784) // T.int64(56))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(56) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.where(ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1 < T.int64(22736))
                    T.reads(DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = DepthwiseConv2d[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
b0 = sch.get_block(name="PaddedInput", func_name="main")
b1 = sch.get_block(name="DepthwiseConv2d", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l3, l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
v10, v11, v12, v13 = sch.sample_perfect_tile(loop=l3, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l14, l15, l16, l17 = sch.split(loop=l3, factors=[v10, v11, v12, v13], preserve_unit_iters=True)
v18, v19, v20, v21 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 29, 1])
l22, l23, l24, l25 = sch.split(loop=l4, factors=[v18, v19, v20, v21], preserve_unit_iters=True)
v26, v27, v28, v29 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l30, l31, l32, l33 = sch.split(loop=l5, factors=[v26, v27, v28, v29], preserve_unit_iters=True)
v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l38, l39, l40, l41 = sch.split(loop=l6, factors=[v34, v35, v36, v37], preserve_unit_iters=True)
v42, v43, v44, v45 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l46, l47, l48, l49 = sch.split(loop=l7, factors=[v42, v43, v44, v45], preserve_unit_iters=True)
v50, v51 = sch.sample_perfect_tile(loop=l8, n=2, max_innermost_factor=64, decision=[3, 1])
l52, l53 = sch.split(loop=l8, factors=[v50, v51], preserve_unit_iters=True)
v54, v55 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l56, l57 = sch.split(loop=l9, factors=[v54, v55], preserve_unit_iters=True)
sch.reorder(l14, l22, l30, l38, l46, l15, l23, l31, l39, l47, l52, l56, l16, l24, l32, l40, l48, l53, l57, l17, l25, l33, l41, l49)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.vectorize", ann_val=64)
v58 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v58)
l59 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l59, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b60 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b60, ann_key="meta_schedule.unroll_explicit")
b61, b62, b63 = sch.get_child_blocks(b60)
l64, l65, l66, l67, l68, l69, l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b61)
l77 = sch.fuse(l64, l65, l66, l67, l68, l69, l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b62)
l96 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102 = sch.get_loops(block=b63)
l103 = sch.fuse(l98, l99, l100, l101, l102, preserve_unit_iters=True)
l104, l105 = sch.split(loop=l103, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.vectorize(loop=l105)
b106 = sch.get_block(name="DepthwiseConv2d", func_name="main")
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123 = sch.get_loops(block=b106)
b124 = sch.decompose_reduction(block=b106, loop=l110)
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #511: GFLOPs: 7.4246. Time: 58.1825 us. Best GFLOPs: 32.9238
2024-04-29 01:34:49 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_contrib_depthwise_conv2d_NCHWc_add_1] Trial #512: GFLOPs: 6.1783. Time: 69.9195 us. Best GFLOPs: 32.9238
