2024-04-29 13:20:01 [INFO] [task_scheduler.cc:160] Initializing Task #20: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18"
2024-04-29 13:20:01 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4), T.int64(128), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 13:20:01 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 13:20:01 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
            for n_0, oc_chunk_0, oh_0 in T.grid(T.int64(1), T.int64(4), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(32), T.int64(4), T.int64(16), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), oh_0 * T.int64(2) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-29 13:20:01 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(14), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(64), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 13:20:01 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(14), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(64), oc_chunk_0 * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 13:55:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 13:55:07 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 13:55:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 13:55:13 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 13:55:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 13:55:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 13:55:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 13:55:35 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 13:55:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0000  0.9997  0.9989  0.9984  0.9983  0.9981  0.9974  0.9972  0.9972  0.9972  0.9971  0.9957  0.9956  0.9941  0.9940  0.9931
[17 : 32]:	0.9929  0.9926  0.9922  0.9920  0.9919  0.9911  0.9904  0.9892  0.9891  0.9889  0.9886  0.9877  0.9871  0.9866  0.9863  0.9857
[33 : 48]:	0.9851  0.9841  0.9827  0.9819  0.9818  0.9810  0.9798  0.9797  0.9796  0.9791  0.9790  0.9788  0.9785  0.9783  0.9775  0.9774
[49 : 64]:	0.9771  0.9770  0.9753  0.9748  0.9747  0.9746  0.9746  0.9746  0.9746  0.9744  0.9741  0.9730  0.9725  0.9723  0.9713  0.9694
2024-04-29 13:55:37 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 13:55:37 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #1: GFLOPs: 7.2164. Time: 16033.6403 us. Best GFLOPs: 7.2164
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #2: GFLOPs: 160.7249. Time: 719.9000 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #3: GFLOPs: 48.5858. Time: 2381.4770 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #4: GFLOPs: 32.0178. Time: 3613.8016 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #5: GFLOPs: 3.7804. Time: 30606.6145 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #6: GFLOPs: 35.4914. Time: 3260.1096 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #7: GFLOPs: 49.3233. Time: 2345.8652 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #8: GFLOPs: 44.7167. Time: 2587.5337 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #9: GFLOPs: 13.1471. Time: 8800.8819 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #10: GFLOPs: 52.4769. Time: 2204.8895 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #11: GFLOPs: 136.6708. Time: 846.6029 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #12: GFLOPs: 13.2126. Time: 8757.2351 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #13: GFLOPs: 2.0628. Time: 56091.5793 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #14: GFLOPs: 28.9734. Time: 3993.5194 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #15: GFLOPs: 130.1307. Time: 889.1512 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #16: GFLOPs: 7.8563. Time: 14727.8340 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #17: GFLOPs: 14.7036. Time: 7869.1998 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #18: GFLOPs: 64.5903. Time: 1791.3813 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #19: GFLOPs: 53.3533. Time: 2168.6725 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #20: GFLOPs: 32.9981. Time: 3506.4350 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #21: GFLOPs: 108.7563. Time: 1063.8998 us. Best GFLOPs: 160.7249
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #22: GFLOPs: 239.5427. Time: 483.0281 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #23: GFLOPs: 3.0754. Time: 37623.2452 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #24: GFLOPs: 15.4670. Time: 7480.8115 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #25: GFLOPs: 12.0377. Time: 9611.9275 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #26: GFLOPs: 9.6858. Time: 11945.8861 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #27: GFLOPs: 42.3479. Time: 2732.2685 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #28: GFLOPs: 5.3190. Time: 21753.1634 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #29: GFLOPs: 9.1395. Time: 12660.0431 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #30: GFLOPs: 54.3789. Time: 2127.7724 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #31: GFLOPs: 3.6425. Time: 31765.8637 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #32: GFLOPs: 63.6121. Time: 1818.9272 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #33: GFLOPs: 7.8405. Time: 14757.5413 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #34: GFLOPs: 6.9765. Time: 16584.9897 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #35: GFLOPs: 1.7185. Time: 67328.4867 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #36: GFLOPs: 7.8798. Time: 14683.9011 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #37: GFLOPs: 21.2689. Time: 5440.1305 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #38: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(32), T.int64(16)):
                for ax3_ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(16), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(14) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(14), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(14) + oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(14) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_fused_fused * T.int64(16) + oc_chunk_1 * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_0 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l76, l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b120)
b146 = sch.decompose_reduction(block=b120, loop=l130)
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #39: GFLOPs: 48.3937. Time: 2390.9291 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #40: GFLOPs: 46.2215. Time: 2503.2897 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #41: GFLOPs: 77.0737. Time: 1501.2363 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #42: GFLOPs: 9.3951. Time: 12315.5479 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #43: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(49), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(32), T.int64(3)):
                    for ax3_ax4_fused in T.vectorized(T.int64(12)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(16), oh_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                            v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(64), T.int64(2)):
                for ax3_ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 16, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l83, l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #44: GFLOPs: 5.6547. Time: 20462.0414 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #45: GFLOPs: 28.1669. Time: 4107.8729 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #46: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(32), T.int64(16), T.int64(16), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(2), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(32) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0 in T.grid(T.int64(64), T.int64(1), T.int64(3)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(7)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(32), ic_0 // T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(16), oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(16), kw_0 + ow_1 * T.int64(7) + ax3)
                                v_i4 = T.axis.spatial(T.int64(4), ic_0 % T.int64(2) * T.int64(2) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(32) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(32), T.int64(14)):
                for ax3_ax4_fused in T.vectorized(T.int64(56)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(64), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(32) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 16, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b68)
l89 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b121)
b144 = sch.decompose_reduction(block=b121, loop=l128)
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #47: GFLOPs: 35.1873. Time: 3288.2847 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #48: GFLOPs: 126.3030. Time: 916.0976 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #49: GFLOPs: 40.3868. Time: 2864.9458 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #50: GFLOPs: 0.6791. Time: 170372.8287 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #51: GFLOPs: 61.3811. Time: 1885.0397 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #52: GFLOPs: 77.5152. Time: 1492.6856 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #53: GFLOPs: 45.2703. Time: 2555.8912 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #54: GFLOPs: 53.2016. Time: 2174.8555 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #55: GFLOPs: 0.6841. Time: 169146.2330 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #56: GFLOPs: 91.5434. Time: 1263.9457 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #57: GFLOPs: 11.0196. Time: 10499.9792 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #58: GFLOPs: 5.6008. Time: 20658.6858 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #59: GFLOPs: 121.8412. Time: 949.6449 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #60: GFLOPs: 82.8235. Time: 1397.0172 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #61: GFLOPs: 5.1825. Time: 22326.4124 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #62: GFLOPs: 58.7439. Time: 1969.6662 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #63: GFLOPs: 51.6359. Time: 2240.8013 us. Best GFLOPs: 239.5427
2024-04-29 15:04:55 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #64: GFLOPs: 93.5869. Time: 1236.3463 us. Best GFLOPs: 239.5427
2024-04-29 15:36:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 15:36:11 [INFO] [evolutionary_search.cc:715] Picked top 61 candidate(s) from database
2024-04-29 15:36:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 15:36:15 [INFO] [evolutionary_search.cc:723] Sampled 451 candidate(s)
2024-04-29 15:36:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 15:36:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 15:36:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 15:37:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 15:37:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9078  0.8991  0.8866  0.8745  0.8725  0.8700  0.8695  0.8594  0.8507  0.8418  0.8331  0.8267  0.8267  0.8264  0.8260  0.8189
[17 : 32]:	0.8184  0.8020  0.7997  0.7947  0.7864  0.7837  0.7822  0.7799  0.7758  0.7745  0.7662  0.7649  0.7649  0.7621  0.7551  0.7534
[33 : 48]:	0.7498  0.7455  0.7401  0.7341  0.7310  0.7304  0.7294  0.7290  0.7286  0.7284  0.7200  0.7192  0.7190  0.7170  0.7148  0.7144
[49 : 64]:	0.7139  0.7136  0.7101  0.7101  0.7082  0.7082  0.7062  0.7018  0.7018  0.7018  0.6985  0.6947  0.6935  0.6912  0.6899  0.6899
2024-04-29 15:37:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 15:37:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #65: GFLOPs: 143.1884. Time: 808.0671 us. Best GFLOPs: 239.5427
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #66: GFLOPs: 286.1679. Time: 404.3286 us. Best GFLOPs: 286.1679
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #67: GFLOPs: 249.6689. Time: 463.4372 us. Best GFLOPs: 286.1679
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #68: GFLOPs: 375.5645. Time: 308.0852 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #69: GFLOPs: 158.4734. Time: 730.1278 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #70: GFLOPs: 259.9502. Time: 445.1077 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #71: GFLOPs: 267.5841. Time: 432.4093 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #72: GFLOPs: 252.3326. Time: 458.5450 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #73: GFLOPs: 251.8720. Time: 459.3836 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #74: GFLOPs: 215.4807. Time: 536.9661 us. Best GFLOPs: 375.5645
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #75: GFLOPs: 376.7559. Time: 307.1109 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #76: GFLOPs: 209.9898. Time: 551.0069 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #77: GFLOPs: 216.8749. Time: 533.5142 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #78: GFLOPs: 127.4548. Time: 907.8184 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #79: GFLOPs: 89.4988. Time: 1292.8208 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #80: GFLOPs: 153.8161. Time: 752.2351 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #81: GFLOPs: 129.6947. Time: 892.1403 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #82: GFLOPs: 239.4340. Time: 483.2475 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #83: GFLOPs: 154.6760. Time: 748.0531 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #84: GFLOPs: 265.4838. Time: 435.8302 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #85: GFLOPs: 259.8435. Time: 445.2906 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #86: GFLOPs: 153.1615. Time: 755.4499 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #87: GFLOPs: 54.5026. Time: 2122.9400 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #88: GFLOPs: 101.4295. Time: 1140.7514 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #89: GFLOPs: 179.2256. Time: 645.5877 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #90: GFLOPs: 229.9452. Time: 503.1889 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #91: GFLOPs: 185.4472. Time: 623.9289 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #92: GFLOPs: 236.9049. Time: 488.4063 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #93: GFLOPs: 93.2426. Time: 1240.9123 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #94: GFLOPs: 207.7140. Time: 557.0442 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #95: GFLOPs: 164.7914. Time: 702.1353 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #96: GFLOPs: 185.9504. Time: 622.2406 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #97: GFLOPs: 74.4512. Time: 1554.1162 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #98: GFLOPs: 191.8422. Time: 603.1304 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #99: GFLOPs: 340.6345. Time: 339.6775 us. Best GFLOPs: 376.7559
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #100: GFLOPs: 465.6050. Time: 248.5065 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #101: GFLOPs: 235.6205. Time: 491.0687 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #102: GFLOPs: 382.9157. Time: 302.1706 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #103: GFLOPs: 138.9019. Time: 833.0041 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #104: GFLOPs: 182.9001. Time: 632.6177 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #105: GFLOPs: 313.3658. Time: 369.2357 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #106: GFLOPs: 108.3157. Time: 1068.2278 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #107: GFLOPs: 87.0053. Time: 1329.8706 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #108: GFLOPs: 219.1252. Time: 528.0354 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #109: GFLOPs: 258.1570. Time: 448.1996 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #110: GFLOPs: 133.7607. Time: 865.0213 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #111: GFLOPs: 95.9041. Time: 1206.4741 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #112: GFLOPs: 333.2697. Time: 347.1838 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #113: GFLOPs: 265.4142. Time: 435.9445 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #114: GFLOPs: 417.9605. Time: 276.8344 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #115: GFLOPs: 82.3735. Time: 1404.6495 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #116: GFLOPs: 152.8110. Time: 757.1829 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #117: GFLOPs: 263.9553. Time: 438.3540 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #118: GFLOPs: 245.4336. Time: 471.4344 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #119: GFLOPs: 243.9935. Time: 474.2169 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #120: GFLOPs: 138.0062. Time: 838.4108 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #121: GFLOPs: 121.5001. Time: 952.3112 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #122: GFLOPs: 133.3653. Time: 867.5861 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #123: GFLOPs: 384.6623. Time: 300.7986 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #124: GFLOPs: 256.6418. Time: 450.8457 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #125: GFLOPs: 336.3442. Time: 344.0103 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #126: GFLOPs: 12.9976. Time: 8902.0726 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #127: GFLOPs: 113.5586. Time: 1018.9087 us. Best GFLOPs: 465.6050
2024-04-29 15:38:26 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #128: GFLOPs: 59.6614. Time: 1939.3768 us. Best GFLOPs: 465.6050
2024-04-29 16:59:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 16:59:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 16:59:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 16:59:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 16:59:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 17:00:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 17:00:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 17:00:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 17:00:38 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9719  0.9078  0.8965  0.8902  0.8388  0.8384  0.8384  0.8332  0.8299  0.8283  0.7923  0.7793  0.7750  0.7699  0.7698  0.7653
[17 : 32]:	0.7621  0.7551  0.7538  0.7497  0.7456  0.7439  0.7439  0.7377  0.7377  0.7377  0.7364  0.7364  0.7321  0.7202  0.7170  0.7164
[33 : 48]:	0.7153  0.7082  0.7082  0.7082  0.7080  0.7061  0.7001  0.6975  0.6975  0.6958  0.6834  0.6800  0.6793  0.6764  0.6749  0.6743
[49 : 64]:	0.6734  0.6722  0.6699  0.6667  0.6661  0.6654  0.6620  0.6528  0.6493  0.6456  0.6444  0.6438  0.6414  0.6402  0.6344  0.6326
2024-04-29 17:00:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 17:00:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #129: GFLOPs: 465.1666. Time: 248.7407 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #130: GFLOPs: 214.1590. Time: 540.2802 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #131: GFLOPs: 462.6444. Time: 250.0968 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #132: GFLOPs: 181.1131. Time: 638.8596 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #133: GFLOPs: 396.8478. Time: 291.5623 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #134: GFLOPs: 272.4128. Time: 424.7445 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #135: GFLOPs: 367.7075. Time: 314.6682 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #136: GFLOPs: 394.1206. Time: 293.5798 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #137: GFLOPs: 373.7769. Time: 309.5586 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #138: GFLOPs: 382.5625. Time: 302.4495 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #139: GFLOPs: 215.0040. Time: 538.1568 us. Best GFLOPs: 465.6050
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #140: GFLOPs: 537.3392. Time: 215.3311 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #141: GFLOPs: 120.1095. Time: 963.3362 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #142: GFLOPs: 393.4216. Time: 294.1014 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #143: GFLOPs: 374.7977. Time: 308.7155 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #144: GFLOPs: 380.9379. Time: 303.7395 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #145: GFLOPs: 394.5495. Time: 293.2607 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #146: GFLOPs: 358.6103. Time: 322.6507 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #147: GFLOPs: 361.5568. Time: 320.0213 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #148: GFLOPs: 147.4019. Time: 784.9685 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #149: GFLOPs: 80.3847. Time: 1439.4019 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #150: GFLOPs: 60.9790. Time: 1897.4702 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #151: GFLOPs: 61.0461. Time: 1895.3857 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #152: GFLOPs: 335.7620. Time: 344.6067 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #153: GFLOPs: 256.9714. Time: 450.2675 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #154: GFLOPs: 334.4515. Time: 345.9571 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #155: GFLOPs: 258.3600. Time: 447.8475 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #156: GFLOPs: 328.4710. Time: 352.2559 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #157: GFLOPs: 70.3447. Time: 1644.8409 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #158: GFLOPs: 211.3385. Time: 547.4907 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #159: GFLOPs: 189.3622. Time: 611.0294 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #160: GFLOPs: 160.7422. Time: 719.8224 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #161: GFLOPs: 126.6715. Time: 913.4327 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #162: GFLOPs: 60.3564. Time: 1917.0422 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #163: GFLOPs: 60.3623. Time: 1916.8575 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #164: GFLOPs: 58.9118. Time: 1964.0523 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #165: GFLOPs: 450.5266. Time: 256.8236 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #166: GFLOPs: 335.6475. Time: 344.7243 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #167: GFLOPs: 420.2697. Time: 275.3133 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #168: GFLOPs: 291.2301. Time: 397.3004 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #169: GFLOPs: 293.9165. Time: 393.6691 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #170: GFLOPs: 290.6100. Time: 398.1482 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #171: GFLOPs: 260.2607. Time: 444.5767 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #172: GFLOPs: 138.3249. Time: 836.4789 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #173: GFLOPs: 99.0051. Time: 1168.6861 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #174: GFLOPs: 171.2670. Time: 675.5876 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #175: GFLOPs: 170.3842. Time: 679.0881 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #176: GFLOPs: 225.5903. Time: 512.9026 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #177: GFLOPs: 172.6086. Time: 670.3365 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #178: GFLOPs: 107.1054. Time: 1080.2987 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #179: GFLOPs: 293.3808. Time: 394.3879 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #180: GFLOPs: 286.0469. Time: 404.4997 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #181: GFLOPs: 370.9562. Time: 311.9125 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #182: GFLOPs: 315.0216. Time: 367.2950 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #183: GFLOPs: 143.1989. Time: 808.0082 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #184: GFLOPs: 73.0132. Time: 1584.7250 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #185: GFLOPs: 229.0960. Time: 505.0540 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #186: GFLOPs: 206.5465. Time: 560.1928 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #187: GFLOPs: 316.7506. Time: 365.2901 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #188: GFLOPs: 286.7353. Time: 403.5284 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #189: GFLOPs: 117.1295. Time: 987.8455 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #190: GFLOPs: 15.2200. Time: 7602.2434 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #191: GFLOPs: 9.7705. Time: 11842.3096 us. Best GFLOPs: 537.3392
2024-04-29 17:02:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #192: GFLOPs: 75.2008. Time: 1538.6248 us. Best GFLOPs: 537.3392
2024-04-29 18:39:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 18:39:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 18:39:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:39:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 18:39:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:40:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:40:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:40:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:40:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9302  0.9302  0.8962  0.8486  0.8376  0.8376  0.8254  0.7761  0.7739  0.7485  0.7485  0.7281  0.7173  0.7160  0.7160  0.7158
[17 : 32]:	0.7144  0.7124  0.7108  0.7108  0.7078  0.6997  0.6983  0.6953  0.6947  0.6937  0.6918  0.6844  0.6838  0.6815  0.6793  0.6784
[33 : 48]:	0.6784  0.6757  0.6750  0.6729  0.6714  0.6702  0.6695  0.6690  0.6658  0.6658  0.6657  0.6631  0.6599  0.6579  0.6552  0.6551
[49 : 64]:	0.6525  0.6483  0.6482  0.6443  0.6382  0.6370  0.6322  0.6305  0.6271  0.6271  0.6266  0.6266  0.6266  0.6266  0.6266  0.6205
2024-04-29 18:40:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 18:40:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #193: GFLOPs: 375.1907. Time: 308.3921 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #194: GFLOPs: 381.0273. Time: 303.6681 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #195: GFLOPs: 361.5817. Time: 319.9992 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #196: GFLOPs: 526.9626. Time: 219.5713 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #197: GFLOPs: 465.2205. Time: 248.7118 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #198: GFLOPs: 426.7581. Time: 271.1275 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #199: GFLOPs: 526.9900. Time: 219.5599 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #200: GFLOPs: 380.9836. Time: 303.7030 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #201: GFLOPs: 426.6011. Time: 271.2273 us. Best GFLOPs: 537.3392
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #202: GFLOPs: 553.8262. Time: 208.9209 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #203: GFLOPs: 384.2310. Time: 301.1361 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #204: GFLOPs: 378.9607. Time: 305.3242 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #205: GFLOPs: 378.9862. Time: 305.3036 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #206: GFLOPs: 382.6334. Time: 302.3935 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #207: GFLOPs: 398.7432. Time: 290.1764 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #208: GFLOPs: 280.3371. Time: 412.7382 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #209: GFLOPs: 416.2491. Time: 277.9726 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #210: GFLOPs: 126.2044. Time: 916.8133 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #211: GFLOPs: 178.4487. Time: 648.3983 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #212: GFLOPs: 183.9316. Time: 629.0699 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #213: GFLOPs: 399.5416. Time: 289.5965 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #214: GFLOPs: 104.2550. Time: 1109.8351 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #215: GFLOPs: 168.9528. Time: 684.8415 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #216: GFLOPs: 394.3474. Time: 293.4110 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #217: GFLOPs: 410.1208. Time: 282.1263 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #218: GFLOPs: 326.8069. Time: 354.0497 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #219: GFLOPs: 410.0950. Time: 282.1440 us. Best GFLOPs: 553.8262
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #220: GFLOPs: 557.2634. Time: 207.6322 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #221: GFLOPs: 387.1711. Time: 298.8494 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #222: GFLOPs: 194.4116. Time: 595.1592 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #223: GFLOPs: 150.3284. Time: 769.6872 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #224: GFLOPs: 357.9402. Time: 323.2547 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #225: GFLOPs: 360.7479. Time: 320.7388 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #226: GFLOPs: 385.8543. Time: 299.8693 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #227: GFLOPs: 290.2452. Time: 398.6487 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #228: GFLOPs: 432.6591. Time: 267.4296 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #229: GFLOPs: 270.6761. Time: 427.4697 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #230: GFLOPs: 398.8126. Time: 290.1259 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #231: GFLOPs: 359.5471. Time: 321.8100 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #232: GFLOPs: 356.7271. Time: 324.3540 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #233: GFLOPs: 161.1741. Time: 717.8937 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #234: GFLOPs: 125.7796. Time: 919.9098 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #235: GFLOPs: 348.4887. Time: 332.0219 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #236: GFLOPs: 345.5620. Time: 334.8339 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #237: GFLOPs: 48.3539. Time: 2392.8960 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #238: GFLOPs: 78.7616. Time: 1469.0636 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #239: GFLOPs: 82.8204. Time: 1397.0694 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #240: GFLOPs: 107.3682. Time: 1077.6545 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #241: GFLOPs: 247.2030. Time: 468.0600 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #242: GFLOPs: 174.2352. Time: 664.0784 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #243: GFLOPs: 412.2085. Time: 280.6974 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #244: GFLOPs: 275.0071. Time: 420.7377 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #245: GFLOPs: 512.8424. Time: 225.6168 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #246: GFLOPs: 171.7886. Time: 673.5362 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #247: GFLOPs: 276.7367. Time: 418.1081 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #248: GFLOPs: 111.1115. Time: 1041.3495 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #249: GFLOPs: 365.1096. Time: 316.9072 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #250: GFLOPs: 160.9362. Time: 718.9547 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #251: GFLOPs: 327.8035. Time: 352.9732 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #252: GFLOPs: 332.1720. Time: 348.3311 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #253: GFLOPs: 257.3254. Time: 449.6480 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #254: GFLOPs: 10.8158. Time: 10697.8890 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #255: GFLOPs: 51.3478. Time: 2253.3736 us. Best GFLOPs: 557.2634
2024-04-29 18:42:23 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #256: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(32), T.int64(14), T.int64(14), T.int64(4)), "float32"), p1: T.Buffer((T.int64(64), T.int64(32), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(64), T.int64(14), T.int64(14), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(8), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(2), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(14), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(64), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(128), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 2, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
l103 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l103)
b104 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b104)
b127 = sch.decompose_reduction(block=b104, loop=l111)
2024-04-29 18:42:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 18:42:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 18:42:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:42:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 18:42:40 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:42:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:43:05 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:43:17 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x579fcc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x65a3b48)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x65f55d8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x65b91d8)]: 0 failure(s)
2024-04-29 18:43:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9397  0.9037  0.8682  0.8451  0.8451  0.8391  0.8391  0.8391  0.8003  0.8003  0.8003  0.7734  0.7523  0.7510  0.7383  0.7237
[17 : 32]:	0.7184  0.7129  0.6982  0.6935  0.6900  0.6900  0.6876  0.6860  0.6715  0.6706  0.6686  0.6657  0.6581  0.6554  0.6516  0.6516
[33 : 48]:	0.6483  0.6378  0.6378  0.6378  0.6361  0.6361  0.6361  0.6358  0.6327  0.6306  0.6252  0.6248  0.6216  0.6216  0.6203  0.6192
[49 : 64]:	0.6161  0.6152  0.6146  0.6126  0.6111  0.6107  0.6078  0.6073  0.6054  0.6017  0.6000  0.5998  0.5987  0.5971  0.5971  0.5940
2024-04-29 18:43:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 18:43:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #257: GFLOPs: 291.4607. Time: 396.9861 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #258: GFLOPs: 533.5303. Time: 216.8684 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #259: GFLOPs: 557.1297. Time: 207.6821 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #260: GFLOPs: 535.0909. Time: 216.2359 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #261: GFLOPs: 379.5020. Time: 304.8887 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #262: GFLOPs: 376.7199. Time: 307.1403 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #263: GFLOPs: 506.3090. Time: 228.5281 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #264: GFLOPs: 381.2578. Time: 303.4846 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #265: GFLOPs: 384.4821. Time: 300.9395 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #266: GFLOPs: 538.5959. Time: 214.8287 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #267: GFLOPs: 382.5929. Time: 302.4255 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #268: GFLOPs: 421.8904. Time: 274.2557 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #269: GFLOPs: 422.5089. Time: 273.8543 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #270: GFLOPs: 445.1464. Time: 259.9277 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #271: GFLOPs: 281.6585. Time: 410.8019 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #272: GFLOPs: 539.3285. Time: 214.5369 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #273: GFLOPs: 409.9188. Time: 282.2653 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #274: GFLOPs: 435.0921. Time: 265.9342 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #275: GFLOPs: 281.8167. Time: 410.5713 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #276: GFLOPs: 200.5505. Time: 576.9412 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #277: GFLOPs: 191.2283. Time: 605.0667 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #278: GFLOPs: 381.2663. Time: 303.4778 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #279: GFLOPs: 275.7612. Time: 419.5872 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #280: GFLOPs: 444.2511. Time: 260.4515 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #281: GFLOPs: 282.1761. Time: 410.0484 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #282: GFLOPs: 337.8387. Time: 342.4885 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #283: GFLOPs: 336.4618. Time: 343.8900 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #284: GFLOPs: 464.2591. Time: 249.2269 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #285: GFLOPs: 224.6173. Time: 515.1244 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #286: GFLOPs: 186.1520. Time: 621.5666 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #287: GFLOPs: 168.9274. Time: 684.9442 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #288: GFLOPs: 554.2087. Time: 208.7767 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #289: GFLOPs: 449.3787. Time: 257.4796 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #290: GFLOPs: 300.9967. Time: 384.4090 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #291: GFLOPs: 215.2297. Time: 537.5924 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #292: GFLOPs: 376.8592. Time: 307.0268 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #293: GFLOPs: 210.9712. Time: 548.4438 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #294: GFLOPs: 331.6789. Time: 348.8490 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #295: GFLOPs: 396.1618. Time: 292.0672 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #296: GFLOPs: 444.4664. Time: 260.3253 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #297: GFLOPs: 159.7831. Time: 724.1433 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #298: GFLOPs: 400.3101. Time: 289.0406 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #299: GFLOPs: 423.4464. Time: 273.2480 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #300: GFLOPs: 389.7874. Time: 296.8435 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #301: GFLOPs: 283.2162. Time: 408.5425 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #302: GFLOPs: 282.9065. Time: 408.9897 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #303: GFLOPs: 132.4636. Time: 873.4917 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #304: GFLOPs: 394.9871. Time: 292.9358 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #305: GFLOPs: 115.2679. Time: 1003.7997 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #306: GFLOPs: 321.8422. Time: 359.5111 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #307: GFLOPs: 136.3595. Time: 848.5351 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #308: GFLOPs: 155.0398. Time: 746.2976 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #309: GFLOPs: 401.8538. Time: 287.9302 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #310: GFLOPs: 334.8731. Time: 345.5215 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #311: GFLOPs: 224.3161. Time: 515.8160 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #312: GFLOPs: 405.2322. Time: 285.5298 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #313: GFLOPs: 485.5122. Time: 238.3171 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #314: GFLOPs: 272.3338. Time: 424.8678 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #315: GFLOPs: 422.1373. Time: 274.0953 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #316: GFLOPs: 114.8574. Time: 1007.3873 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #317: GFLOPs: 299.2527. Time: 386.6493 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #318: GFLOPs: 67.1567. Time: 1722.9227 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #319: GFLOPs: 179.4454. Time: 644.7969 us. Best GFLOPs: 557.2634
2024-04-29 18:45:00 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_18] Trial #320: GFLOPs: 31.2725. Time: 3699.9233 us. Best GFLOPs: 557.2634
