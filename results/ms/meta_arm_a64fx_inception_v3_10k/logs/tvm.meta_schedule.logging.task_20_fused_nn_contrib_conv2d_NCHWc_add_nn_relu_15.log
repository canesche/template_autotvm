2024-04-29 07:42:13 [INFO] [task_scheduler.cc:160] Initializing Task #20: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15"
2024-04-29 07:42:13 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4), T.int64(160), T.int64(1), T.int64(7)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 07:42:13 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 07:42:13 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
            for n_0, oc_chunk_0 in T.grid(T.int64(1), T.int64(5)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(6), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(4)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                        v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(6) + ow_1 * T.int64(6) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[5, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 3])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 6, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[20, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-29 07:42:13 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(5), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(20), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(6), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(4)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                        v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(6) + ow_1 * T.int64(6) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(3), T.int64(6), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), ow_0 * T.int64(6) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[5, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 3])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 6, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[20, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 07:42:13 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(5), T.int64(4), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(40), T.int64(3), T.int64(12), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + ax2)
                        v_i3 = T.axis.spatial(T.int64(18), ow_0 * T.int64(6) + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                for oc_block_0 in range(T.int64(1)):
                    for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(20), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(6), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(4)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + oh_1 * T.int64(3) + oh_2 * T.int64(3) + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(6) + ow_1 * T.int64(6) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(3), T.int64(6), T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(40), oc_chunk_0 * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(12), oh_0 * T.int64(3) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(12), ow_0 * T.int64(6) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[5, 2, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 1, 3])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 6, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[20, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 08:14:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:14:00 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 08:14:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 08:14:05 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 08:14:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 08:14:15 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 08:14:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 08:14:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 08:14:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9993  0.9991  0.9989  0.9984  0.9983  0.9982  0.9977  0.9977  0.9966  0.9966  0.9965  0.9960  0.9947  0.9946  0.9946  0.9946
[17 : 32]:	0.9943  0.9937  0.9933  0.9932  0.9929  0.9925  0.9920  0.9914  0.9907  0.9906  0.9898  0.9892  0.9890  0.9885  0.9878  0.9875
[33 : 48]:	0.9875  0.9870  0.9868  0.9866  0.9865  0.9863  0.9862  0.9856  0.9853  0.9853  0.9850  0.9848  0.9848  0.9847  0.9843  0.9833
[49 : 64]:	0.9833  0.9829  0.9824  0.9815  0.9809  0.9803  0.9800  0.9798  0.9795  0.9795  0.9794  0.9787  0.9768  0.9766  0.9763  0.9753
2024-04-29 08:14:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:14:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #1: GFLOPs: 18.1835. Time: 2840.8068 us. Best GFLOPs: 18.1835
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #2: GFLOPs: 56.6263. Time: 912.2214 us. Best GFLOPs: 56.6263
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #3: GFLOPs: 63.1533. Time: 817.9417 us. Best GFLOPs: 63.1533
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #4: GFLOPs: 90.9960. Time: 567.6696 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #5: GFLOPs: 19.8649. Time: 2600.3434 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #6: GFLOPs: 38.9440. Time: 1326.4075 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #7: GFLOPs: 36.3557. Time: 1420.8420 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #8: GFLOPs: 5.5570. Time: 9295.6132 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #9: GFLOPs: 21.7137. Time: 2378.9430 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #10: GFLOPs: 8.5654. Time: 6030.7692 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #11: GFLOPs: 8.8610. Time: 5829.5629 us. Best GFLOPs: 90.9960
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #12: GFLOPs: 149.4103. Time: 345.7305 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #13: GFLOPs: 8.1493. Time: 6338.6359 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #14: GFLOPs: 32.1189. Time: 1608.2663 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #15: GFLOPs: 50.1198. Time: 1030.6442 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #16: GFLOPs: 20.6993. Time: 2495.5273 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #17: GFLOPs: 105.5700. Time: 489.3025 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #18: GFLOPs: 94.5010. Time: 546.6149 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #19: GFLOPs: 50.3962. Time: 1024.9918 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #20: GFLOPs: 21.1422. Time: 2443.2483 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #21: GFLOPs: 44.7056. Time: 1155.4627 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #22: GFLOPs: 3.2463. Time: 15912.0543 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #23: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(6), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(6), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(20) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(12) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(20)):
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(12)):
                        for ax3_ax4_fused in T.vectorized(T.int64(40)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(40), ic_0 * T.int64(2) + ax1)
                                v_i2 = T.axis.spatial(T.int64(12), ax2)
                                v_i3 = T.axis.spatial(T.int64(18), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ax3_ax4_fused // T.int64(4))
                                v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                                T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(6), T.int64(2), T.int64(2), T.int64(8), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(20) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(12) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(20), T.int64(12)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(20) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 5, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 6, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[3, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[20, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l85, l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #24: GFLOPs: 33.5594. Time: 1539.2302 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #25: GFLOPs: 7.9515. Time: 6496.3429 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #26: GFLOPs: 4.6969. Time: 10997.9104 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #27: GFLOPs: 10.8626. Time: 4755.3526 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #28: GFLOPs: 20.8891. Time: 2472.8477 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #29: GFLOPs: 6.6741. Time: 7739.7756 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #30: GFLOPs: 7.6598. Time: 6743.7449 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #31: GFLOPs: 13.6437. Time: 3786.0446 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #32: GFLOPs: 88.0255. Time: 586.8262 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #33: GFLOPs: 29.7371. Time: 1737.0795 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #34: GFLOPs: 3.9751. Time: 12994.7746 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #35: GFLOPs: 18.5223. Time: 2788.8440 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #36: GFLOPs: 45.9657. Time: 1123.7886 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #37: GFLOPs: 28.8818. Time: 1788.5218 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #38: GFLOPs: 3.8346. Time: 13470.7839 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #39: GFLOPs: 18.3157. Time: 2820.2890 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #40: GFLOPs: 50.3519. Time: 1025.8942 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #41: GFLOPs: 32.4986. Time: 1589.4729 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #42: GFLOPs: 112.4478. Time: 459.3747 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #43: GFLOPs: 10.0833. Time: 5122.9013 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #44: GFLOPs: 53.6719. Time: 962.4339 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #45: GFLOPs: 31.3745. Time: 1646.4248 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #46: GFLOPs: 27.1832. Time: 1900.2799 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #47: GFLOPs: 25.2011. Time: 2049.7378 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #48: GFLOPs: 7.9184. Time: 6523.4805 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #49: GFLOPs: 7.4833. Time: 6902.7545 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #50: GFLOPs: 18.8310. Time: 2743.1125 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #51: GFLOPs: 36.6200. Time: 1410.5865 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #52: GFLOPs: 75.0607. Time: 688.1854 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #53: GFLOPs: 13.5750. Time: 3805.1936 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #54: GFLOPs: 20.1017. Time: 2569.7129 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #55: GFLOPs: 7.5133. Time: 6875.2184 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #56: GFLOPs: 29.7676. Time: 1735.3004 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #57: GFLOPs: 21.6338. Time: 2387.7294 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #58: GFLOPs: 44.2536. Time: 1167.2637 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #59: GFLOPs: 101.1083. Time: 510.8944 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #60: GFLOPs: 1.7961. Time: 28760.3638 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #61: GFLOPs: 17.6776. Time: 2922.1015 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #62: GFLOPs: 46.7589. Time: 1104.7244 us. Best GFLOPs: 149.4103
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #63: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(40), T.int64(12)):
                for ax3_ax4_fused in T.vectorized(T.int64(48)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(18), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(6) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(3), T.int64(3), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(6) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(10), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(2), T.int64(1), T.int64(16), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(40), oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(6) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(8), T.int64(4)):
                    for ax3_ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(40), oc_chunk_1 * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(12), oh_1 * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused * T.int64(6) + ow_1 * T.int64(2) + ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 5, 4, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 3, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 3, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[10, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l78, l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-29 09:16:32 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #64: GFLOPs: 5.6505. Time: 9141.7118 us. Best GFLOPs: 149.4103
2024-04-29 09:37:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:37:33 [INFO] [evolutionary_search.cc:715] Picked top 62 candidate(s) from database
2024-04-29 09:37:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 09:37:37 [INFO] [evolutionary_search.cc:723] Sampled 450 candidate(s)
2024-04-29 09:37:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 09:37:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 09:38:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 09:38:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 09:38:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9908  0.9908  0.9908  0.9886  0.9819  0.9368  0.9368  0.9368  0.9113  0.9113  0.9013  0.9002  0.8896  0.8669  0.8593  0.8581
[17 : 32]:	0.8262  0.8262  0.7896  0.7880  0.7880  0.7872  0.7842  0.7517  0.7473  0.7473  0.7432  0.7432  0.7388  0.7362  0.7320  0.7224
[33 : 48]:	0.7219  0.7213  0.7093  0.7014  0.7014  0.7014  0.7014  0.6980  0.6961  0.6946  0.6917  0.6902  0.6846  0.6845  0.6743  0.6626
[49 : 64]:	0.6554  0.6471  0.6471  0.6440  0.6434  0.6428  0.6396  0.6391  0.6375  0.6374  0.6365  0.6365  0.6359  0.6355  0.6351  0.6339
2024-04-29 09:38:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:38:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #65: GFLOPs: 65.2855. Time: 791.2270 us. Best GFLOPs: 149.4103
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #66: GFLOPs: 134.7427. Time: 383.3654 us. Best GFLOPs: 149.4103
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #67: GFLOPs: 138.1472. Time: 373.9178 us. Best GFLOPs: 149.4103
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #68: GFLOPs: 157.7304. Time: 327.4936 us. Best GFLOPs: 157.7304
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #69: GFLOPs: 138.7477. Time: 372.2993 us. Best GFLOPs: 157.7304
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #70: GFLOPs: 153.6859. Time: 336.1121 us. Best GFLOPs: 157.7304
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #71: GFLOPs: 149.5237. Time: 345.4681 us. Best GFLOPs: 157.7304
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #72: GFLOPs: 158.5826. Time: 325.7337 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #73: GFLOPs: 50.0791. Time: 1031.4820 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #74: GFLOPs: 39.7119. Time: 1300.7617 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #75: GFLOPs: 63.1076. Time: 818.5335 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #76: GFLOPs: 14.0817. Time: 3668.2770 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #77: GFLOPs: 26.9357. Time: 1917.7427 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #78: GFLOPs: 112.5419. Time: 458.9907 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #79: GFLOPs: 138.9620. Time: 371.7253 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #80: GFLOPs: 47.4612. Time: 1088.3772 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #81: GFLOPs: 126.8901. Time: 407.0899 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #82: GFLOPs: 124.8932. Time: 413.5988 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #83: GFLOPs: 156.8258. Time: 329.3825 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #84: GFLOPs: 33.4698. Time: 1543.3506 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #85: GFLOPs: 47.5126. Time: 1087.1985 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #86: GFLOPs: 145.5277. Time: 354.9544 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #87: GFLOPs: 79.3501. Time: 650.9842 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #88: GFLOPs: 112.4997. Time: 459.1628 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #89: GFLOPs: 139.0175. Time: 371.5769 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #90: GFLOPs: 29.9241. Time: 1726.2235 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #91: GFLOPs: 113.0009. Time: 457.1264 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #92: GFLOPs: 31.6948. Time: 1629.7849 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #93: GFLOPs: 113.0894. Time: 456.7687 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #94: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(8640)):
            for i4_fused in T.vectorized(T.int64(4)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(40), i0_i1_i2_i3_fused // T.int64(216))
                    v_i2 = T.axis.spatial(T.int64(12), i0_i1_i2_i3_fused % T.int64(216) // T.int64(18))
                    v_i3 = T.axis.spatial(T.int64(18), i0_i1_i2_i3_fused % T.int64(18))
                    v_i4 = T.axis.spatial(T.int64(4), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(320), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(80) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(40) // T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(12), oh_2_init * T.int64(6) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(40) * T.int64(6) + ow_2_init * T.int64(2) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(5), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(6), T.int64(2), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(80) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(40) // T.int64(4) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(12), oh_2 * T.int64(6) + oh_3)
                    v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(40) * T.int64(6) + ow_2 * T.int64(2) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(5) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(360)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(40), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(576))
                    v_ax2 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(576) // T.int64(48))
                    v_ax3 = T.axis.spatial(T.int64(12), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(48) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 10, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 6])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 1, 3, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 4, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 5])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, preserve_unit_iters=True)
sch.parallel(loop=l103)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l104, l105, l106, l107, l108, preserve_unit_iters=True)
l110, l111 = sch.split(loop=l109, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b112)
b130 = sch.decompose_reduction(block=b112, loop=l114)
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #95: GFLOPs: 140.1033. Time: 368.6970 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #96: GFLOPs: 71.2709. Time: 724.7796 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #97: GFLOPs: 134.8198. Time: 383.1462 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #98: GFLOPs: 113.9781. Time: 453.2071 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #99: GFLOPs: 110.9436. Time: 465.6030 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #100: GFLOPs: 51.0786. Time: 1011.2972 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #101: GFLOPs: 154.3363. Time: 334.6956 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #102: GFLOPs: 50.9316. Time: 1014.2168 us. Best GFLOPs: 158.5826
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #103: GFLOPs: 185.6220. Time: 278.2842 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #104: GFLOPs: 44.0114. Time: 1173.6876 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #105: GFLOPs: 161.9052. Time: 319.0488 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #106: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(640), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(20) // T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(3) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(12), ow_2_init * T.int64(4) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(20) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(10), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(16), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(20) // T.int64(2) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(3) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(12), ow_2 * T.int64(4) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(20) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw - T.int64(3), v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(3) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw - T.int64(3), v_ic % T.int64(4)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(12), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(20) // T.int64(2) + ax1)
                    v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) * T.int64(3) + ax2)
                    v_ax3 = T.axis.spatial(T.int64(12), ax3)
                    v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(20) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 10, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 3, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 3, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[10, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=640)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #107: GFLOPs: 134.0822. Time: 385.2538 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #108: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(40), T.int64(40), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(40), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(40), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(640), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(40) // T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(3) + oh_2_init + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(12), ow_2_init * T.int64(4) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(40) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(10), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(16), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(40) // T.int64(4) + oc_chunk_2 + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(3) + oh_2 + oh_3)
                    v_ow = T.axis.spatial(T.int64(12), ow_2 * T.int64(4) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(40) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(160), ic_0 * T.int64(16) + ic_1)
                    v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                    v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw - T.int64(3), v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(3) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw - T.int64(3), v_ic % T.int64(4)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(12), T.int64(1)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), ax0)
                    v_ax1 = T.axis.spatial(T.int64(40), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(160) * T.int64(10) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(40) // T.int64(4) + ax1)
                    v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(160) // T.int64(80) * T.int64(6) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) // T.int64(2) * T.int64(3) + ax2)
                    v_ax3 = T.axis.spatial(T.int64(12), ax3)
                    v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(80) // T.int64(40) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(2) + ax4)
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 10, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 3, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 3, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[10, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=640)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l96)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b69)
b103 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120 = sch.get_loops(block=b103)
b121 = sch.decompose_reduction(block=b103, loop=l105)
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #109: GFLOPs: 42.4762. Time: 1216.1093 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #110: GFLOPs: 19.7397. Time: 2616.8377 us. Best GFLOPs: 185.6220
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #111: GFLOPs: 190.8169. Time: 270.7081 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #112: GFLOPs: 90.8293. Time: 568.7114 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #113: GFLOPs: 59.8320. Time: 863.3454 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #114: GFLOPs: 129.7453. Time: 398.1314 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #115: GFLOPs: 114.4063. Time: 451.5109 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #116: GFLOPs: 123.2018. Time: 419.2771 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #117: GFLOPs: 135.5611. Time: 381.0510 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #118: GFLOPs: 141.0061. Time: 366.3366 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #119: GFLOPs: 114.6647. Time: 450.4932 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #120: GFLOPs: 110.8678. Time: 465.9213 us. Best GFLOPs: 190.8169
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #121: GFLOPs: 213.9414. Time: 241.4478 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #122: GFLOPs: 125.6991. Time: 410.9472 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #123: GFLOPs: 121.7423. Time: 424.3033 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #124: GFLOPs: 119.4826. Time: 432.3281 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #125: GFLOPs: 17.1280. Time: 3015.8686 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #126: GFLOPs: 57.6312. Time: 896.3151 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #127: GFLOPs: 71.7523. Time: 719.9171 us. Best GFLOPs: 213.9414
2024-04-29 09:39:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #128: GFLOPs: 102.0498. Time: 506.1811 us. Best GFLOPs: 213.9414
2024-04-29 10:19:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 10:19:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 10:19:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 10:19:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 10:19:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 10:19:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 10:19:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 10:19:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 10:19:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9995  0.9191  0.9191  0.8990  0.8886  0.8840  0.8828  0.8767  0.8665  0.8664  0.8557  0.8454  0.8392  0.8317  0.8140  0.8127
[17 : 32]:	0.8041  0.7898  0.7844  0.7746  0.7615  0.7554  0.7470  0.7456  0.7405  0.7349  0.7270  0.7233  0.7147  0.7096  0.7052  0.7023
[33 : 48]:	0.7011  0.6980  0.6945  0.6937  0.6937  0.6880  0.6867  0.6815  0.6805  0.6796  0.6780  0.6768  0.6728  0.6696  0.6687  0.6647
[49 : 64]:	0.6635  0.6623  0.6603  0.6602  0.6602  0.6589  0.6587  0.6580  0.6566  0.6562  0.6562  0.6562  0.6562  0.6562  0.6562  0.6561
2024-04-29 10:19:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 10:19:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #129: GFLOPs: 90.9046. Time: 568.2405 us. Best GFLOPs: 213.9414
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #130: GFLOPs: 64.1678. Time: 805.0096 us. Best GFLOPs: 213.9414
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #131: GFLOPs: 194.5290. Time: 265.5423 us. Best GFLOPs: 213.9414
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #132: GFLOPs: 220.2555. Time: 234.5262 us. Best GFLOPs: 220.2555
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #133: GFLOPs: 242.3172. Time: 213.1738 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #134: GFLOPs: 89.0241. Time: 580.2441 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #135: GFLOPs: 106.2180. Time: 486.3174 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #136: GFLOPs: 82.4446. Time: 626.5505 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #137: GFLOPs: 80.8268. Time: 639.0907 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #138: GFLOPs: 144.6287. Time: 357.1607 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #139: GFLOPs: 157.9960. Time: 326.9429 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #140: GFLOPs: 163.7354. Time: 315.4826 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #141: GFLOPs: 86.9833. Time: 593.8576 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #142: GFLOPs: 165.2243. Time: 312.6396 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #143: GFLOPs: 87.2657. Time: 591.9357 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #144: GFLOPs: 212.7670. Time: 242.7805 us. Best GFLOPs: 242.3172
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #145: GFLOPs: 259.3918. Time: 199.1416 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #146: GFLOPs: 62.2508. Time: 829.8000 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #147: GFLOPs: 78.7161. Time: 656.2279 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #148: GFLOPs: 135.2911. Time: 381.8112 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #149: GFLOPs: 110.0481. Time: 469.3917 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #150: GFLOPs: 112.7679. Time: 458.0707 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #151: GFLOPs: 214.1665. Time: 241.1940 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #152: GFLOPs: 240.8463. Time: 214.4757 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #153: GFLOPs: 185.8447. Time: 277.9509 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #154: GFLOPs: 97.4296. Time: 530.1846 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #155: GFLOPs: 79.1595. Time: 652.5516 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #156: GFLOPs: 219.3072. Time: 235.5402 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #157: GFLOPs: 66.8655. Time: 772.5309 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #158: GFLOPs: 75.4674. Time: 684.4764 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #159: GFLOPs: 170.8009. Time: 302.4322 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #160: GFLOPs: 114.5692. Time: 450.8688 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #161: GFLOPs: 124.7340. Time: 414.1267 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #162: GFLOPs: 172.6164. Time: 299.2513 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #163: GFLOPs: 82.0657. Time: 629.4432 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #164: GFLOPs: 194.3570. Time: 265.7773 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #165: GFLOPs: 84.4636. Time: 611.5734 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #166: GFLOPs: 114.8209. Time: 449.8804 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #167: GFLOPs: 81.7374. Time: 631.9713 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #168: GFLOPs: 213.9094. Time: 241.4839 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #169: GFLOPs: 115.3909. Time: 447.6582 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #170: GFLOPs: 79.9303. Time: 646.2590 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #171: GFLOPs: 160.2813. Time: 322.2815 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #172: GFLOPs: 106.1875. Time: 486.4572 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #173: GFLOPs: 65.1809. Time: 792.4970 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #174: GFLOPs: 84.1957. Time: 613.5192 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #175: GFLOPs: 107.3100. Time: 481.3689 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #176: GFLOPs: 72.2305. Time: 715.1508 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #177: GFLOPs: 186.4150. Time: 277.1005 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #178: GFLOPs: 105.7533. Time: 488.4546 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #179: GFLOPs: 87.4914. Time: 590.4084 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #180: GFLOPs: 39.0896. Time: 1321.4670 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #181: GFLOPs: 40.2644. Time: 1282.9129 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #182: GFLOPs: 82.9728. Time: 622.5618 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #183: GFLOPs: 103.1158. Time: 500.9483 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #184: GFLOPs: 100.5143. Time: 513.9139 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #185: GFLOPs: 93.3189. Time: 553.5394 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #186: GFLOPs: 139.1121. Time: 371.3240 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #187: GFLOPs: 138.7430. Time: 372.3120 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #188: GFLOPs: 138.7401. Time: 372.3197 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #189: GFLOPs: 138.8417. Time: 372.0472 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #190: GFLOPs: 35.1950. Time: 1467.6986 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #191: GFLOPs: 82.0912. Time: 629.2477 us. Best GFLOPs: 259.3918
2024-04-29 10:21:29 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #192: GFLOPs: 65.3131. Time: 790.8931 us. Best GFLOPs: 259.3918
2024-04-29 11:17:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 11:17:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 11:17:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:17:42 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 11:17:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:18:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:18:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:18:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:18:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8629  0.8330  0.8148  0.7976  0.7830  0.7612  0.7498  0.7450  0.7388  0.7387  0.7288  0.7231  0.7228  0.7201  0.7086  0.7047
[17 : 32]:	0.6837  0.6830  0.6769  0.6679  0.6615  0.6601  0.6594  0.6562  0.6530  0.6529  0.6526  0.6489  0.6480  0.6410  0.6364  0.6324
[33 : 48]:	0.6296  0.6268  0.6262  0.6261  0.6235  0.6206  0.6203  0.6195  0.6181  0.6181  0.6173  0.6156  0.6150  0.6143  0.6143  0.6143
[49 : 64]:	0.6132  0.6131  0.6127  0.6116  0.6111  0.6091  0.6088  0.6061  0.6015  0.6013  0.6008  0.5999  0.5989  0.5985  0.5973  0.5962
2024-04-29 11:18:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 11:18:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #193: GFLOPs: 53.9665. Time: 957.1804 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #194: GFLOPs: 86.6197. Time: 596.3501 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #195: GFLOPs: 231.6179. Time: 223.0211 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #196: GFLOPs: 216.2723. Time: 238.8455 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #197: GFLOPs: 180.8675. Time: 285.5995 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #198: GFLOPs: 96.3094. Time: 536.3512 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #199: GFLOPs: 85.3226. Time: 605.4159 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #200: GFLOPs: 78.5811. Time: 657.3547 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #201: GFLOPs: 78.3597. Time: 659.2123 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #202: GFLOPs: 158.2997. Time: 326.3156 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #203: GFLOPs: 237.1491. Time: 217.8194 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #204: GFLOPs: 157.3602. Time: 328.2639 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #205: GFLOPs: 52.7782. Time: 978.7321 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #206: GFLOPs: 191.3628. Time: 269.9358 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #207: GFLOPs: 166.0103. Time: 311.1594 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #208: GFLOPs: 182.6143. Time: 282.8676 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #209: GFLOPs: 258.1902. Time: 200.0683 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #210: GFLOPs: 197.1475. Time: 262.0154 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #211: GFLOPs: 186.7147. Time: 276.6556 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #212: GFLOPs: 83.8666. Time: 615.9264 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #213: GFLOPs: 211.0123. Time: 244.7994 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #214: GFLOPs: 95.6695. Time: 539.9390 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #215: GFLOPs: 113.7388. Time: 454.1606 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #216: GFLOPs: 253.9233. Time: 203.4302 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #217: GFLOPs: 124.0658. Time: 416.3573 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #218: GFLOPs: 228.7924. Time: 225.7753 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #219: GFLOPs: 197.2319. Time: 261.9032 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #220: GFLOPs: 84.1682. Time: 613.7197 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #221: GFLOPs: 87.4170. Time: 590.9108 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #222: GFLOPs: 66.8694. Time: 772.4861 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #223: GFLOPs: 82.7007. Time: 624.6101 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #224: GFLOPs: 104.6984. Time: 493.3761 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #225: GFLOPs: 58.2201. Time: 887.2478 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #226: GFLOPs: 172.2808. Time: 299.8342 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #227: GFLOPs: 67.3429. Time: 767.0541 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #228: GFLOPs: 109.3816. Time: 472.2519 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #229: GFLOPs: 100.9670. Time: 511.6097 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #230: GFLOPs: 49.4227. Time: 1045.1812 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #231: GFLOPs: 106.8801. Time: 483.3047 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #232: GFLOPs: 61.1168. Time: 845.1957 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #233: GFLOPs: 84.7073. Time: 609.8138 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #234: GFLOPs: 194.5820. Time: 265.4700 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #235: GFLOPs: 75.8541. Time: 680.9873 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #236: GFLOPs: 232.4020. Time: 222.2687 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #237: GFLOPs: 156.3000. Time: 330.4906 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #238: GFLOPs: 57.3194. Time: 901.1904 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #239: GFLOPs: 56.1642. Time: 919.7264 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #240: GFLOPs: 58.3066. Time: 885.9321 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #241: GFLOPs: 248.4978. Time: 207.8718 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #242: GFLOPs: 190.6324. Time: 270.9701 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #243: GFLOPs: 192.2606. Time: 268.6753 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #244: GFLOPs: 224.6121. Time: 229.9773 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #245: GFLOPs: 62.6414. Time: 824.6250 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #246: GFLOPs: 86.7622. Time: 595.3707 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #247: GFLOPs: 106.6222. Time: 484.4741 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #248: GFLOPs: 201.1191. Time: 256.8412 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #249: GFLOPs: 160.5280. Time: 321.7862 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #250: GFLOPs: 165.7143. Time: 311.7154 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #251: GFLOPs: 192.2848. Time: 268.6415 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #252: GFLOPs: 205.2766. Time: 251.6394 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #253: GFLOPs: 170.9426. Time: 302.1814 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #254: GFLOPs: 127.6328. Time: 404.7209 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #255: GFLOPs: 2.2427. Time: 23032.6778 us. Best GFLOPs: 259.3918
2024-04-29 11:19:52 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #256: GFLOPs: 45.3063. Time: 1140.1447 us. Best GFLOPs: 259.3918
2024-04-29 11:24:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 11:24:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 11:24:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:24:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 11:24:43 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:24:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:25:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:25:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 11:25:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9450  0.9417  0.9297  0.9293  0.9056  0.8955  0.8679  0.8668  0.8643  0.8572  0.8553  0.8530  0.8501  0.8420  0.8397  0.8168
[17 : 32]:	0.8159  0.8118  0.8054  0.7976  0.7956  0.7931  0.7918  0.7874  0.7845  0.7820  0.7820  0.7820  0.7811  0.7790  0.7764  0.7726
[33 : 48]:	0.7702  0.7655  0.7612  0.7590  0.7586  0.7508  0.7508  0.7500  0.7473  0.7473  0.7434  0.7429  0.7397  0.7373  0.7361  0.7334
[49 : 64]:	0.7294  0.7287  0.7270  0.7218  0.7215  0.7213  0.7211  0.7191  0.7170  0.7144  0.7143  0.7136  0.7136  0.7126  0.7121  0.7113
2024-04-29 11:25:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 11:25:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #257: GFLOPs: 130.4158. Time: 396.0846 us. Best GFLOPs: 259.3918
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #258: GFLOPs: 147.0759. Time: 351.2179 us. Best GFLOPs: 259.3918
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #259: GFLOPs: 142.7620. Time: 361.8307 us. Best GFLOPs: 259.3918
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #260: GFLOPs: 258.0318. Time: 200.1912 us. Best GFLOPs: 259.3918
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #261: GFLOPs: 274.9807. Time: 187.8520 us. Best GFLOPs: 274.9807
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #262: GFLOPs: 282.3554. Time: 182.9456 us. Best GFLOPs: 282.3554
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #263: GFLOPs: 288.5041. Time: 179.0466 us. Best GFLOPs: 288.5041
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #264: GFLOPs: 402.0204. Time: 128.4902 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #265: GFLOPs: 295.6240. Time: 174.7344 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #266: GFLOPs: 220.1497. Time: 234.6389 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #267: GFLOPs: 47.5916. Time: 1085.3940 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #268: GFLOPs: 228.0900. Time: 226.4706 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #269: GFLOPs: 289.2396. Time: 178.5913 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #270: GFLOPs: 234.5352. Time: 220.2470 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #271: GFLOPs: 221.5158. Time: 233.1919 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #272: GFLOPs: 235.5203. Time: 219.3258 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #273: GFLOPs: 182.7568. Time: 282.6471 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #274: GFLOPs: 398.2809. Time: 129.6966 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #275: GFLOPs: 287.6181. Time: 179.5982 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #276: GFLOPs: 397.1470. Time: 130.0669 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #277: GFLOPs: 214.4585. Time: 240.8657 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #278: GFLOPs: 221.1223. Time: 233.6069 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #279: GFLOPs: 279.9230. Time: 184.5353 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #280: GFLOPs: 193.5540. Time: 266.8799 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #281: GFLOPs: 255.0190. Time: 202.5562 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #282: GFLOPs: 196.2310. Time: 263.2392 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #283: GFLOPs: 197.8300. Time: 261.1115 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #284: GFLOPs: 209.2341. Time: 246.8799 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #285: GFLOPs: 219.7370. Time: 235.0796 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #286: GFLOPs: 204.7208. Time: 252.3226 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #287: GFLOPs: 208.7387. Time: 247.4658 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #288: GFLOPs: 213.8426. Time: 241.5593 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #289: GFLOPs: 207.2967. Time: 249.1871 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #290: GFLOPs: 232.3045. Time: 222.3620 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #291: GFLOPs: 179.9847. Time: 287.0004 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #292: GFLOPs: 213.8918. Time: 241.5038 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #293: GFLOPs: 220.7857. Time: 233.9629 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #294: GFLOPs: 395.0092. Time: 130.7708 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #295: GFLOPs: 199.6102. Time: 258.7828 us. Best GFLOPs: 402.0204
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #296: GFLOPs: 426.2495. Time: 121.1865 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #297: GFLOPs: 408.9652. Time: 126.3082 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #298: GFLOPs: 407.1229. Time: 126.8798 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #299: GFLOPs: 177.4490. Time: 291.1015 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #300: GFLOPs: 112.1301. Time: 460.6764 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #301: GFLOPs: 234.6583. Time: 220.1315 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #302: GFLOPs: 196.7285. Time: 262.5734 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #303: GFLOPs: 202.7835. Time: 254.7331 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #304: GFLOPs: 201.0579. Time: 256.9194 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #305: GFLOPs: 233.9134. Time: 220.8325 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #306: GFLOPs: 234.7908. Time: 220.0073 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #307: GFLOPs: 204.0897. Time: 253.1028 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #308: GFLOPs: 197.7459. Time: 261.2226 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #309: GFLOPs: 201.7780. Time: 256.0026 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #310: GFLOPs: 208.1474. Time: 248.1687 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #311: GFLOPs: 205.8807. Time: 250.9010 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #312: GFLOPs: 209.9172. Time: 246.0765 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #313: GFLOPs: 180.5777. Time: 286.0579 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #314: GFLOPs: 190.3184. Time: 271.4171 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #315: GFLOPs: 88.4571. Time: 583.9633 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #316: GFLOPs: 162.9010. Time: 317.0987 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #317: GFLOPs: 253.2916. Time: 203.9376 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #318: GFLOPs: 161.9748. Time: 318.9118 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #319: GFLOPs: 3.1426. Time: 16437.0871 us. Best GFLOPs: 426.2495
2024-04-29 11:26:49 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #320: GFLOPs: 240.9600. Time: 214.3745 us. Best GFLOPs: 426.2495
2024-04-29 12:59:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 12:59:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 12:59:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 12:59:40 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 12:59:49 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 12:59:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 13:00:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 13:00:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x96996b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x94f9e58)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x98e4538)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xb648c58)]: 0 failure(s)
2024-04-29 13:00:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9318  0.9138  0.9077  0.8919  0.8825  0.8781  0.8711  0.8685  0.8643  0.8634  0.8586  0.8573  0.8422  0.8375  0.8301  0.8263
[17 : 32]:	0.8207  0.8183  0.8078  0.8056  0.8001  0.7972  0.7945  0.7938  0.7799  0.7791  0.7760  0.7743  0.7743  0.7740  0.7715  0.7690
[33 : 48]:	0.7588  0.7552  0.7535  0.7419  0.7392  0.7380  0.7351  0.7323  0.7322  0.7282  0.7271  0.7197  0.7091  0.7082  0.7021  0.7018
[49 : 64]:	0.6992  0.6899  0.6842  0.6840  0.6822  0.6814  0.6786  0.6784  0.6780  0.6760  0.6760  0.6753  0.6719  0.6691  0.6659  0.6566
2024-04-29 13:00:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 13:00:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #321: GFLOPs: 215.7817. Time: 239.3887 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #322: GFLOPs: 400.9080. Time: 128.8467 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #323: GFLOPs: 184.7653. Time: 279.5746 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #324: GFLOPs: 401.8425. Time: 128.5471 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #325: GFLOPs: 425.0575. Time: 121.5263 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #326: GFLOPs: 187.8503. Time: 274.9832 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #327: GFLOPs: 306.3564. Time: 168.6130 us. Best GFLOPs: 426.2495
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #328: GFLOPs: 481.0754. Time: 107.3754 us. Best GFLOPs: 481.0754
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #329: GFLOPs: 424.0997. Time: 121.8008 us. Best GFLOPs: 481.0754
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #330: GFLOPs: 440.3410. Time: 117.3084 us. Best GFLOPs: 481.0754
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #331: GFLOPs: 526.2933. Time: 98.1500 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #332: GFLOPs: 327.3819. Time: 157.7842 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #333: GFLOPs: 305.5569. Time: 169.0542 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #334: GFLOPs: 407.9538. Time: 126.6214 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #335: GFLOPs: 322.0381. Time: 160.4024 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #336: GFLOPs: 346.3729. Time: 149.1331 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #337: GFLOPs: 193.7012. Time: 266.6772 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #338: GFLOPs: 394.2206. Time: 131.0324 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #339: GFLOPs: 402.3608. Time: 128.3815 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #340: GFLOPs: 359.2056. Time: 143.8053 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #341: GFLOPs: 459.5622. Time: 112.4019 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #342: GFLOPs: 452.9432. Time: 114.0445 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #343: GFLOPs: 205.9753. Time: 250.7857 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #344: GFLOPs: 114.7182. Time: 450.2832 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #345: GFLOPs: 384.5204. Time: 134.3379 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #346: GFLOPs: 238.8804. Time: 216.2407 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #347: GFLOPs: 364.9632. Time: 141.5367 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #348: GFLOPs: 238.8813. Time: 216.2399 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #349: GFLOPs: 239.2939. Time: 215.8671 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #350: GFLOPs: 183.2132. Time: 281.9431 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #351: GFLOPs: 361.4576. Time: 142.9094 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #352: GFLOPs: 184.9835. Time: 279.2448 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #353: GFLOPs: 198.3218. Time: 260.4639 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #354: GFLOPs: 150.7674. Time: 342.6183 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #355: GFLOPs: 380.8559. Time: 135.6305 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #356: GFLOPs: 184.0208. Time: 280.7057 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #357: GFLOPs: 365.5632. Time: 141.3044 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #358: GFLOPs: 232.5936. Time: 222.0855 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #359: GFLOPs: 146.0632. Time: 353.6528 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #360: GFLOPs: 140.6769. Time: 367.1938 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #361: GFLOPs: 112.0421. Time: 461.0381 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #362: GFLOPs: 148.1118. Time: 348.7613 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #363: GFLOPs: 260.3672. Time: 198.3955 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #364: GFLOPs: 315.6902. Time: 163.6277 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #365: GFLOPs: 161.0892. Time: 320.6652 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #366: GFLOPs: 86.4714. Time: 597.3729 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #367: GFLOPs: 269.0369. Time: 192.0022 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #368: GFLOPs: 248.1871. Time: 208.1320 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #369: GFLOPs: 299.8984. Time: 172.2439 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #370: GFLOPs: 209.5149. Time: 246.5490 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #371: GFLOPs: 140.3881. Time: 367.9493 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #372: GFLOPs: 368.1586. Time: 140.3082 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #373: GFLOPs: 105.0016. Time: 491.9513 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #374: GFLOPs: 299.4250. Time: 172.5163 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #375: GFLOPs: 211.7864. Time: 243.9046 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #376: GFLOPs: 494.1846. Time: 104.5271 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #377: GFLOPs: 140.5999. Time: 367.3947 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #378: GFLOPs: 160.1721. Time: 322.5010 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #379: GFLOPs: 105.1687. Time: 491.1699 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #380: GFLOPs: 403.1250. Time: 128.1381 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #381: GFLOPs: 263.6119. Time: 195.9535 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #382: GFLOPs: 43.5473. Time: 1186.1972 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #383: GFLOPs: 57.9868. Time: 890.8174 us. Best GFLOPs: 526.2933
2024-04-29 13:01:53 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_15] Trial #384: GFLOPs: 63.4330. Time: 814.3349 us. Best GFLOPs: 526.2933
