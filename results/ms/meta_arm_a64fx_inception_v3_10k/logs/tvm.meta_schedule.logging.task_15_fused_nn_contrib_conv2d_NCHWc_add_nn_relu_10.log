2024-04-29 07:41:49 [INFO] [task_scheduler.cc:160] Initializing Task #15: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10"
2024-04-29 07:41:49 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4), T.int64(192), T.int64(1), T.int64(7)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-29 07:41:49 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 07:41:49 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(12), T.int64(4), T.int64(2), T.int64(16), T.int64(1), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(3), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(48), ic_0 * T.int64(3) + ax1)
                        v_i2 = T.axis.spatial(T.int64(12), oh_1 + ax2)
                        v_i3 = T.axis.spatial(T.int64(18), ow_1 * T.int64(3) + kw_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(2), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(48), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(12) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(12) + ow_1 * T.int64(3) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(12) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 12, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 3, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 12])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-29 07:41:49 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(12), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(1), T.int64(9), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(12), oh_1 + ax2)
                        v_i3 = T.axis.spatial(T.int64(18), ow_1 * T.int64(3) + ax3)
                        v_i4 = T.axis.spatial(T.int64(4), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(2)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(2), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(48), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(12) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(12) + ow_1 * T.int64(3) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(12) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(48), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(12), oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(12), ow_1 * T.int64(3) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 12, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 3, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 12])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 07:41:49 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(12), T.int64(4), T.int64(2)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(1), T.int64(9), T.int64(4)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(12), oh_1 + ax2)
                            v_i3 = T.axis.spatial(T.int64(18), ow_1 * T.int64(3) + ax3)
                            v_i4 = T.axis.spatial(T.int64(4), ax4)
                            T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(7), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(2), T.int64(12), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(48), oc_chunk_0 * T.int64(16) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), oh_0 * T.int64(12) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), ow_0 * T.int64(12) + ow_1 * T.int64(3) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(12) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(12), T.int64(12), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(48), oc_chunk_0 * T.int64(16) + ax1)
                        v_ax2, v_ax3, v_ax4 = T.axis.remap("SSS", [ax2, ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 4, 4, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 12, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 3, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 12])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-29 08:05:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 08:05:37 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 08:05:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 4 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 08:05:41 [INFO] [evolutionary_search.cc:723] Sampled 508 candidate(s)
2024-04-29 08:05:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 3 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 08:05:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 08:05:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 08:06:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 08:06:03 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9997  0.9994  0.9992  0.9989  0.9984  0.9981  0.9980  0.9964  0.9954  0.9951  0.9949  0.9946  0.9943  0.9930  0.9923
[17 : 32]:	0.9903  0.9901  0.9900  0.9896  0.9888  0.9887  0.9887  0.9883  0.9881  0.9876  0.9865  0.9853  0.9845  0.9844  0.9839  0.9837
[33 : 48]:	0.9836  0.9828  0.9818  0.9812  0.9804  0.9795  0.9790  0.9785  0.9784  0.9782  0.9781  0.9777  0.9770  0.9766  0.9764  0.9759
[49 : 64]:	0.9756  0.9754  0.9752  0.9749  0.9748  0.9743  0.9740  0.9738  0.9737  0.9731  0.9722  0.9704  0.9694  0.9675  0.9671  0.9666
2024-04-29 08:06:03 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 08:06:03 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #1: GFLOPs: 74.3085. Time: 1000.8698 us. Best GFLOPs: 74.3085
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #2: GFLOPs: 37.0087. Time: 2009.6107 us. Best GFLOPs: 74.3085
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #3: GFLOPs: 5.1691. Time: 14387.9036 us. Best GFLOPs: 74.3085
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #4: GFLOPs: 57.3568. Time: 1296.6758 us. Best GFLOPs: 74.3085
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #5: GFLOPs: 110.7860. Time: 671.3222 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #6: GFLOPs: 18.6317. Time: 3991.7569 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #7: GFLOPs: 37.1866. Time: 1999.9994 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #8: GFLOPs: 2.6059. Time: 28540.1530 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #9: GFLOPs: 9.2427. Time: 8046.6992 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #10: GFLOPs: 7.5707. Time: 9823.8291 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #11: GFLOPs: 3.9827. Time: 18673.9815 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #12: GFLOPs: 18.6229. Time: 3993.6353 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #13: GFLOPs: 2.1230. Time: 35032.6010 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #14: GFLOPs: 37.6011. Time: 1977.9505 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #15: GFLOPs: 55.7683. Time: 1333.6094 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #16: GFLOPs: 23.0026. Time: 3233.2417 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #17: GFLOPs: 110.3389. Time: 674.0428 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #18: GFLOPs: 101.1905. Time: 734.9815 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #19: GFLOPs: 63.3846. Time: 1173.3630 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #20: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(9), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(12)):
                    for ax3_ax4_fused in T.vectorized(T.int64(28)):
                        with T.block("data_pad"):
                            v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_i3 = T.axis.spatial(T.int64(18), ow_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ax3_ax4_fused // T.int64(4))
                            v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                for oc_block_1 in range(T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(12) + oh_2_init * T.int64(4) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(96), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(16) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(12) + oh_2 * T.int64(4) + oh_3)
                                v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(12)):
                for ax3_ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(3) * T.int64(16) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(3) * T.int64(4) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 3, 4])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[3, 4, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l83, l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108 = sch.get_loops(block=b69)
l109 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l109)
l110 = sch.fuse(l108, preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.annotate(block_or_loop=l109, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l109, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #21: GFLOPs: 5.5544. Time: 13389.9191 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #22: GFLOPs: 77.8334. Time: 955.5430 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #23: GFLOPs: 26.5162. Time: 2804.8193 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #24: GFLOPs: 34.7216. Time: 2141.9818 us. Best GFLOPs: 110.7860
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #25: GFLOPs: 118.7721. Time: 626.1832 us. Best GFLOPs: 118.7721
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #26: GFLOPs: 5.2139. Time: 14264.3968 us. Best GFLOPs: 118.7721
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #27: GFLOPs: 30.4161. Time: 2445.1891 us. Best GFLOPs: 118.7721
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #28: GFLOPs: 3.9145. Time: 18999.4052 us. Best GFLOPs: 118.7721
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #29: GFLOPs: 71.8334. Time: 1035.3551 us. Best GFLOPs: 118.7721
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #30: GFLOPs: 130.0264. Time: 571.9846 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #31: GFLOPs: 3.9428. Time: 18862.9968 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #32: GFLOPs: 19.7582. Time: 3764.1557 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #33: GFLOPs: 41.7345. Time: 1782.0539 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #34: GFLOPs: 9.5068. Time: 7823.1654 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #35: GFLOPs: 61.2060. Time: 1215.1274 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #36: GFLOPs: 2.0520. Time: 36244.2740 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #37: GFLOPs: 14.3562. Time: 5180.5453 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #38: GFLOPs: 2.5247. Time: 29458.3380 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #39: GFLOPs: 15.6854. Time: 4741.5590 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #40: GFLOPs: 6.6549. Time: 11175.6659 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #41: GFLOPs: 53.1364. Time: 1399.6655 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #42: GFLOPs: 9.7978. Time: 7590.7735 us. Best GFLOPs: 130.0264
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #43: GFLOPs: 222.0657. Time: 334.9149 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #44: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(72), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(6)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + ax2)
                        v_i3 = T.axis.spatial(T.int64(18), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(24) // T.int64(8) * T.int64(4) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(8), T.int64(6), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(24) * T.int64(16) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(24) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(6), T.int64(1), T.int64(2), T.int64(12), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(24) * T.int64(16) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(24) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(12) + ic_1)
                        v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(6), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(24) * T.int64(16) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(24) // T.int64(8) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(8) // T.int64(4) * T.int64(2) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 1, 8, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 6, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[3, 2, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 12])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86 = sch.fuse(l83, l84, preserve_unit_iters=True)
sch.vectorize(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b114)
b133 = sch.decompose_reduction(block=b114, loop=l117)
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #45: GFLOPs: 5.3885. Time: 13802.1942 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #46: GFLOPs: 88.7694. Time: 837.8240 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #47: GFLOPs: 0.7845. Time: 94808.0863 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #48: GFLOPs: 24.8362. Time: 2994.5401 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #49: GFLOPs: 18.5253. Time: 4014.6821 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #50: GFLOPs: 62.5704. Time: 1188.6313 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #51: GFLOPs: 42.8591. Time: 1735.2917 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #52: GFLOPs: 10.0647. Time: 7389.4804 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #53: GFLOPs: 91.6625. Time: 811.3804 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #54: GFLOPs: 163.5514. Time: 454.7384 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #55: GFLOPs: 72.0107. Time: 1032.8060 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #56: GFLOPs: 193.3560. Time: 384.6434 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #57: GFLOPs: 159.6203. Time: 465.9378 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #58: GFLOPs: 3.0732. Time: 24200.6052 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #59: GFLOPs: 37.2662. Time: 1995.7262 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #60: GFLOPs: 6.1254. Time: 12141.8480 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #61: GFLOPs: 0.3767. Time: 197419.2853 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #62: GFLOPs: 44.8890. Time: 1656.8235 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #63: GFLOPs: 69.8617. Time: 1064.5765 us. Best GFLOPs: 222.0657
2024-04-29 09:16:13 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #64: GFLOPs: 12.6763. Time: 5867.1038 us. Best GFLOPs: 222.0657
2024-04-29 09:39:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 09:39:47 [INFO] [evolutionary_search.cc:715] Picked top 62 candidate(s) from database
2024-04-29 09:39:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 09:39:51 [INFO] [evolutionary_search.cc:723] Sampled 445 candidate(s)
2024-04-29 09:39:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 09:40:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 09:40:18 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 09:40:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 09:40:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9819  0.9566  0.9451  0.8577  0.8501  0.8486  0.8473  0.8392  0.8392  0.8288  0.8155  0.7923  0.7845  0.7826  0.7826  0.7826
[17 : 32]:	0.7807  0.7774  0.7711  0.7701  0.7698  0.7686  0.7672  0.7656  0.7613  0.7611  0.7611  0.7611  0.7551  0.7470  0.7436  0.7411
[33 : 48]:	0.7398  0.7344  0.7341  0.7338  0.7333  0.7313  0.7306  0.7290  0.7282  0.7266  0.7206  0.7182  0.7158  0.7142  0.7132  0.7119
[49 : 64]:	0.7111  0.7097  0.7092  0.7069  0.7065  0.7053  0.7027  0.7014  0.6986  0.6959  0.6947  0.6940  0.6927  0.6922  0.6920  0.6905
2024-04-29 09:40:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 09:40:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 09:41:49 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #65: GFLOPs: 111.6646. Time: 666.0405 us. Best GFLOPs: 222.0657
2024-04-29 09:41:49 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #66: GFLOPs: 149.3589. Time: 497.9492 us. Best GFLOPs: 222.0657
2024-04-29 09:41:49 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #67: GFLOPs: 89.1894. Time: 833.8781 us. Best GFLOPs: 222.0657
2024-04-29 09:41:49 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #68: GFLOPs: 89.2635. Time: 833.1863 us. Best GFLOPs: 222.0657
2024-04-29 09:41:49 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #69: GFLOPs: 139.5792. Time: 532.8381 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #70: GFLOPs: 81.6350. Time: 911.0445 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #71: GFLOPs: 99.4232. Time: 748.0458 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #72: GFLOPs: 61.2250. Time: 1214.7505 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #73: GFLOPs: 30.8952. Time: 2407.2742 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #74: GFLOPs: 150.2242. Time: 495.0807 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #75: GFLOPs: 87.3727. Time: 851.2173 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #76: GFLOPs: 62.4646. Time: 1190.6439 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #77: GFLOPs: 100.9665. Time: 736.6121 us. Best GFLOPs: 222.0657
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #78: GFLOPs: 224.3725. Time: 331.4717 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #79: GFLOPs: 223.7267. Time: 332.4285 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #80: GFLOPs: 189.5835. Time: 392.2973 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #81: GFLOPs: 79.8952. Time: 930.8833 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #82: GFLOPs: 186.0374. Time: 399.7750 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #83: GFLOPs: 133.9536. Time: 555.2155 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #84: GFLOPs: 131.8578. Time: 564.0402 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #85: GFLOPs: 67.3732. Time: 1103.8969 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #86: GFLOPs: 95.1828. Time: 781.3717 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #87: GFLOPs: 98.3679. Time: 756.0713 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #88: GFLOPs: 171.7239. Time: 433.0970 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #89: GFLOPs: 197.3108. Time: 376.9339 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #90: GFLOPs: 66.0090. Time: 1126.7113 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #91: GFLOPs: 67.6118. Time: 1100.0020 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #92: GFLOPs: 65.6989. Time: 1132.0294 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #93: GFLOPs: 129.1501. Time: 575.8657 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #94: GFLOPs: 190.3524. Time: 390.7129 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #95: GFLOPs: 100.0975. Time: 743.0064 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #96: GFLOPs: 69.7507. Time: 1066.2703 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #97: GFLOPs: 87.4592. Time: 850.3754 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #98: GFLOPs: 113.8712. Time: 653.1338 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #99: GFLOPs: 127.2508. Time: 584.4611 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #100: GFLOPs: 151.3501. Time: 491.3979 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #101: GFLOPs: 75.5632. Time: 984.2506 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #102: GFLOPs: 104.5734. Time: 711.2050 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #103: GFLOPs: 126.9073. Time: 586.0427 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #104: GFLOPs: 162.2374. Time: 458.4216 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #105: GFLOPs: 152.1775. Time: 488.7263 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #106: GFLOPs: 101.8675. Time: 730.0967 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #107: GFLOPs: 87.8697. Time: 846.4028 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #108: GFLOPs: 84.8632. Time: 876.3880 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #109: GFLOPs: 74.5628. Time: 997.4565 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #110: GFLOPs: 55.1380. Time: 1348.8546 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #111: GFLOPs: 84.0976. Time: 884.3664 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #112: GFLOPs: 122.6727. Time: 606.2728 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #113: GFLOPs: 129.2790. Time: 575.2916 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #114: GFLOPs: 181.6200. Time: 409.4985 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #115: GFLOPs: 95.3936. Time: 779.6451 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #116: GFLOPs: 63.2631. Time: 1175.6154 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #117: GFLOPs: 79.1871. Time: 939.2080 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #118: GFLOPs: 85.8118. Time: 866.7009 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #119: GFLOPs: 102.9602. Time: 722.3479 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #120: GFLOPs: 133.2413. Time: 558.1837 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #121: GFLOPs: 118.8691. Time: 625.6724 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #122: GFLOPs: 57.1527. Time: 1301.3045 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #123: GFLOPs: 18.3936. Time: 4043.4211 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #124: GFLOPs: 82.5281. Time: 901.1855 us. Best GFLOPs: 224.3725
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #125: GFLOPs: 225.8630. Time: 329.2843 us. Best GFLOPs: 225.8630
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #126: GFLOPs: 51.1073. Time: 1455.2334 us. Best GFLOPs: 225.8630
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #127: GFLOPs: 1.7674. Time: 42079.8017 us. Best GFLOPs: 225.8630
2024-04-29 09:41:50 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #128: GFLOPs: 60.3168. Time: 1233.0422 us. Best GFLOPs: 225.8630
2024-04-29 10:02:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 10:02:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 10:02:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 6 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:02:55 [INFO] [evolutionary_search.cc:723] Sampled 404 candidate(s)
2024-04-29 10:03:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:03:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:03:22 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:03:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:03:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9972  0.9972  0.9643  0.9643  0.9643  0.9643  0.9529  0.9519  0.9305  0.9305  0.9305  0.9305  0.9305  0.9305  0.9305  0.9294
[17 : 32]:	0.9275  0.9275  0.9220  0.9220  0.9220  0.9149  0.9067  0.8918  0.8834  0.8793  0.8741  0.8665  0.8637  0.8634  0.8620  0.8620
[33 : 48]:	0.8608  0.8596  0.8596  0.8585  0.8578  0.8560  0.8560  0.8543  0.8503  0.8411  0.8385  0.8385  0.8385  0.8375  0.8338  0.8338
[49 : 64]:	0.8338  0.8338  0.8338  0.8338  0.8250  0.8235  0.8233  0.8233  0.8212  0.8208  0.8029  0.8018  0.7965  0.7906  0.7901  0.7834
2024-04-29 10:03:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 10:03:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #129: GFLOPs: 227.1213. Time: 327.4598 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #130: GFLOPs: 113.7006. Time: 654.1137 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #131: GFLOPs: 216.8305. Time: 343.0012 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #132: GFLOPs: 225.0045. Time: 330.5406 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #133: GFLOPs: 219.0469. Time: 339.5306 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #134: GFLOPs: 67.3894. Time: 1103.6326 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #135: GFLOPs: 226.2813. Time: 328.6755 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #136: GFLOPs: 193.1076. Time: 385.1383 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #137: GFLOPs: 188.0233. Time: 395.5528 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #138: GFLOPs: 108.4464. Time: 685.8052 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #139: GFLOPs: 180.9360. Time: 411.0464 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #140: GFLOPs: 209.4475. Time: 355.0920 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #141: GFLOPs: 189.4556. Time: 392.5624 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #142: GFLOPs: 181.3881. Time: 410.0221 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #143: GFLOPs: 215.0817. Time: 345.7901 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #144: GFLOPs: 187.9986. Time: 395.6046 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #145: GFLOPs: 210.3664. Time: 353.5409 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #146: GFLOPs: 215.6659. Time: 344.8535 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #147: GFLOPs: 198.2097. Time: 375.2245 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #148: GFLOPs: 197.0176. Time: 377.4948 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #149: GFLOPs: 188.0063. Time: 395.5885 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #150: GFLOPs: 227.0640. Time: 327.5426 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #151: GFLOPs: 147.9964. Time: 502.5333 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #152: GFLOPs: 196.0301. Time: 379.3964 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #153: GFLOPs: 196.1396. Time: 379.1845 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #154: GFLOPs: 101.4210. Time: 733.3111 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #155: GFLOPs: 43.4135. Time: 1713.1323 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #156: GFLOPs: 81.4156. Time: 913.4992 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #157: GFLOPs: 172.8113. Time: 430.3719 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #158: GFLOPs: 213.3923. Time: 348.5276 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #159: GFLOPs: 187.4095. Time: 396.8482 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #160: GFLOPs: 182.3725. Time: 407.8088 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #161: GFLOPs: 185.8474. Time: 400.1838 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #162: GFLOPs: 212.3509. Time: 350.2369 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #163: GFLOPs: 209.0543. Time: 355.7599 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #164: GFLOPs: 184.5575. Time: 402.9808 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #165: GFLOPs: 198.2958. Time: 375.0615 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #166: GFLOPs: 223.7706. Time: 332.3632 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #167: GFLOPs: 224.2795. Time: 331.6091 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #168: GFLOPs: 203.4230. Time: 365.6083 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #169: GFLOPs: 197.8163. Time: 375.9707 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #170: GFLOPs: 212.8309. Time: 349.4470 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #171: GFLOPs: 211.4016. Time: 351.8096 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #172: GFLOPs: 104.9766. Time: 708.4733 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #173: GFLOPs: 198.3717. Time: 374.9180 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #174: GFLOPs: 196.6171. Time: 378.2637 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #175: GFLOPs: 183.5428. Time: 405.2087 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #176: GFLOPs: 189.4851. Time: 392.5012 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #177: GFLOPs: 97.9163. Time: 759.5584 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #178: GFLOPs: 180.9091. Time: 411.1077 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #179: GFLOPs: 140.3161. Time: 530.0398 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #180: GFLOPs: 190.5370. Time: 390.3344 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #181: GFLOPs: 221.6575. Time: 335.5317 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #182: GFLOPs: 129.3607. Time: 574.9280 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #183: GFLOPs: 175.8359. Time: 422.9689 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #184: GFLOPs: 181.8281. Time: 409.0298 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #185: GFLOPs: 92.1620. Time: 806.9825 us. Best GFLOPs: 227.1213
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #186: GFLOPs: 227.4246. Time: 327.0232 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #187: GFLOPs: 224.5767. Time: 331.1703 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #188: GFLOPs: 50.7477. Time: 1465.5463 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #189: GFLOPs: 162.5685. Time: 457.4880 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #190: GFLOPs: 50.6552. Time: 1468.2225 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #191: GFLOPs: 5.2782. Time: 14090.6498 us. Best GFLOPs: 227.4246
2024-04-29 10:04:52 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #192: GFLOPs: 75.8510. Time: 980.5163 us. Best GFLOPs: 227.4246
2024-04-29 10:28:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 10:28:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 10:28:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 6 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:28:05 [INFO] [evolutionary_search.cc:723] Sampled 404 candidate(s)
2024-04-29 10:28:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:28:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:28:31 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:28:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:28:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9712  0.9712  0.9712  0.9380  0.9380  0.9380  0.9380  0.9376  0.9363  0.9335  0.9288  0.9257  0.9224  0.9220  0.9204  0.9204
[17 : 32]:	0.9172  0.9171  0.9163  0.9092  0.8993  0.8981  0.8934  0.8866  0.8866  0.8860  0.8849  0.8849  0.8822  0.8822  0.8822  0.8822
[33 : 48]:	0.8814  0.8814  0.8814  0.8774  0.8772  0.8772  0.8725  0.8684  0.8660  0.8645  0.8626  0.8621  0.8621  0.8615  0.8592  0.8590
[49 : 64]:	0.8590  0.8590  0.8585  0.8564  0.8564  0.8564  0.8564  0.8564  0.8545  0.8531  0.8509  0.8458  0.8458  0.8458  0.8458  0.8422
2024-04-29 10:28:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 10:28:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #193: GFLOPs: 111.3933. Time: 667.6621 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #194: GFLOPs: 99.0337. Time: 750.9881 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #195: GFLOPs: 211.9891. Time: 350.8346 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #196: GFLOPs: 179.8304. Time: 413.5736 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #197: GFLOPs: 216.4993. Time: 343.5259 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #198: GFLOPs: 213.3902. Time: 348.5311 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #199: GFLOPs: 181.5475. Time: 409.6621 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #200: GFLOPs: 179.2794. Time: 414.8448 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #201: GFLOPs: 105.5502. Time: 704.6230 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #202: GFLOPs: 198.3491. Time: 374.9607 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #203: GFLOPs: 210.0534. Time: 354.0676 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #204: GFLOPs: 106.2784. Time: 699.7951 us. Best GFLOPs: 227.4246
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #205: GFLOPs: 228.5122. Time: 325.4668 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #206: GFLOPs: 183.9598. Time: 404.2902 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #207: GFLOPs: 225.4412. Time: 329.9003 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #208: GFLOPs: 219.9858. Time: 338.0814 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #209: GFLOPs: 196.3863. Time: 378.7082 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #210: GFLOPs: 212.8818. Time: 349.3635 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #211: GFLOPs: 204.6464. Time: 363.4226 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #212: GFLOPs: 214.5373. Time: 346.6675 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #213: GFLOPs: 215.4461. Time: 345.2053 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #214: GFLOPs: 59.9053. Time: 1241.5110 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #215: GFLOPs: 192.7173. Time: 385.9182 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #216: GFLOPs: 181.4201. Time: 409.9496 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #217: GFLOPs: 183.3306. Time: 405.6777 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #218: GFLOPs: 159.2571. Time: 467.0003 us. Best GFLOPs: 228.5122
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #219: GFLOPs: 235.1605. Time: 316.2653 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #220: GFLOPs: 234.6374. Time: 316.9704 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #221: GFLOPs: 187.0360. Time: 397.6407 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #222: GFLOPs: 182.5153. Time: 407.4897 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #223: GFLOPs: 206.5252. Time: 360.1165 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #224: GFLOPs: 201.7305. Time: 368.6756 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #225: GFLOPs: 96.6235. Time: 769.7206 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #226: GFLOPs: 100.2233. Time: 742.0738 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #227: GFLOPs: 93.6036. Time: 794.5544 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #228: GFLOPs: 108.7755. Time: 683.7304 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #229: GFLOPs: 107.5408. Time: 691.5804 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #230: GFLOPs: 108.2096. Time: 687.3058 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #231: GFLOPs: 203.5362. Time: 365.4049 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #232: GFLOPs: 140.3480. Time: 529.9195 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #233: GFLOPs: 208.1217. Time: 357.3541 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #234: GFLOPs: 192.7921. Time: 385.7685 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #235: GFLOPs: 173.0895. Time: 429.6802 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #236: GFLOPs: 197.5256. Time: 376.5240 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #237: GFLOPs: 121.7975. Time: 610.6293 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #238: GFLOPs: 182.7482. Time: 406.9705 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #239: GFLOPs: 201.3226. Time: 369.4226 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #240: GFLOPs: 187.4184. Time: 396.8292 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #241: GFLOPs: 187.5338. Time: 396.5852 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #242: GFLOPs: 182.8925. Time: 406.6494 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #243: GFLOPs: 121.3087. Time: 613.0898 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #244: GFLOPs: 208.2805. Time: 357.0816 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #245: GFLOPs: 223.9678. Time: 332.0706 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #246: GFLOPs: 224.4948. Time: 331.2910 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #247: GFLOPs: 230.7239. Time: 322.3469 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #248: GFLOPs: 189.3847. Time: 392.7091 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #249: GFLOPs: 81.9869. Time: 907.1339 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #250: GFLOPs: 64.1843. Time: 1158.7430 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #251: GFLOPs: 210.7727. Time: 352.8594 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #252: GFLOPs: 223.1935. Time: 333.2226 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #253: GFLOPs: 209.4837. Time: 355.0305 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #254: GFLOPs: 51.8033. Time: 1435.6840 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #255: GFLOPs: 97.9382. Time: 759.3885 us. Best GFLOPs: 235.1605
2024-04-29 10:30:18 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #256: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(24), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + oh_1 * T.int64(6) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(3) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(32)):
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(6)):
                        for ax3_ax4_fused in T.vectorized(T.int64(36)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(48), ic_0 * T.int64(6) // T.int64(4) + ax1)
                                v_i2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + ax2)
                                v_i3 = T.axis.spatial(T.int64(18), ow_1 * T.int64(3) + ax3_ax4_fused // T.int64(4))
                                v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                                T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(6), T.int64(3), T.int64(1), T.int64(6), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + oh_1 * T.int64(6) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(3) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(6), T.int64(12)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) // T.int64(2) * T.int64(6) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[6, 1, 2, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 6, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 3, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l85, l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-29 10:49:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 10:49:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 10:50:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:50:02 [INFO] [evolutionary_search.cc:723] Sampled 405 candidate(s)
2024-04-29 10:50:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:50:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:50:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:50:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 10:50:41 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9765  0.9765  0.9731  0.9690  0.9541  0.9507  0.9482  0.9467  0.9387  0.9120  0.9091  0.9058  0.9048  0.9013  0.9013  0.9013
[17 : 32]:	0.9013  0.8985  0.8985  0.8961  0.8903  0.8869  0.8868  0.8868  0.8856  0.8836  0.8817  0.8802  0.8780  0.8780  0.8778  0.8778
[33 : 48]:	0.8778  0.8778  0.8778  0.8717  0.8708  0.8695  0.8648  0.8637  0.8636  0.8636  0.8636  0.8635  0.8635  0.8635  0.8622  0.8622
[49 : 64]:	0.8622  0.8620  0.8620  0.8616  0.8610  0.8603  0.8560  0.8544  0.8544  0.8542  0.8542  0.8542  0.8542  0.8542  0.8505  0.8482
2024-04-29 10:50:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 10:50:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #257: GFLOPs: 234.9438. Time: 316.5571 us. Best GFLOPs: 235.1605
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #258: GFLOPs: 237.1381. Time: 313.6279 us. Best GFLOPs: 237.1381
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #259: GFLOPs: 231.7688. Time: 320.8936 us. Best GFLOPs: 237.1381
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #260: GFLOPs: 193.3021. Time: 384.7507 us. Best GFLOPs: 237.1381
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #261: GFLOPs: 237.6891. Time: 312.9009 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #262: GFLOPs: 226.0435. Time: 329.0212 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #263: GFLOPs: 222.1017. Time: 334.8607 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #264: GFLOPs: 198.3292. Time: 374.9982 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #265: GFLOPs: 210.5040. Time: 353.3098 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #266: GFLOPs: 200.0388. Time: 371.7934 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #267: GFLOPs: 206.6065. Time: 359.9747 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #268: GFLOPs: 217.2202. Time: 342.3859 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #269: GFLOPs: 215.6932. Time: 344.8098 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #270: GFLOPs: 236.4730. Time: 314.5100 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #271: GFLOPs: 203.6729. Time: 365.1596 us. Best GFLOPs: 237.6891
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #272: GFLOPs: 240.6886. Time: 309.0015 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #273: GFLOPs: 206.2704. Time: 360.5612 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #274: GFLOPs: 223.6502. Time: 332.5422 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #275: GFLOPs: 200.1557. Time: 371.5764 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #276: GFLOPs: 234.3298. Time: 317.3865 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #277: GFLOPs: 219.2614. Time: 339.1985 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #278: GFLOPs: 112.6908. Time: 659.9750 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #279: GFLOPs: 95.0034. Time: 782.8471 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #280: GFLOPs: 100.3579. Time: 741.0786 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #281: GFLOPs: 216.8755. Time: 342.9301 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #282: GFLOPs: 199.4076. Time: 372.9703 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #283: GFLOPs: 206.5204. Time: 360.1248 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #284: GFLOPs: 219.3531. Time: 339.0566 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #285: GFLOPs: 212.1641. Time: 350.5453 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #286: GFLOPs: 189.7987. Time: 391.8525 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #287: GFLOPs: 205.5378. Time: 361.8465 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #288: GFLOPs: 191.1348. Time: 389.1134 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #289: GFLOPs: 216.5745. Time: 343.4067 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #290: GFLOPs: 209.5255. Time: 354.9597 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #291: GFLOPs: 216.6526. Time: 343.2828 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #292: GFLOPs: 189.0270. Time: 393.4524 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #293: GFLOPs: 227.5541. Time: 326.8370 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #294: GFLOPs: 186.2210. Time: 399.3810 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #295: GFLOPs: 193.9181. Time: 383.5285 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #296: GFLOPs: 213.8914. Time: 347.7144 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #297: GFLOPs: 100.3608. Time: 741.0575 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #298: GFLOPs: 91.2256. Time: 815.2660 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #299: GFLOPs: 73.0398. Time: 1018.2545 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #300: GFLOPs: 228.0626. Time: 326.1084 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #301: GFLOPs: 215.5668. Time: 345.0120 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #302: GFLOPs: 190.8342. Time: 389.7264 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #303: GFLOPs: 198.7268. Time: 374.2481 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #304: GFLOPs: 194.1434. Time: 383.0835 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #305: GFLOPs: 191.1008. Time: 389.1827 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #306: GFLOPs: 190.3474. Time: 390.7231 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #307: GFLOPs: 181.9545. Time: 408.7457 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #308: GFLOPs: 133.2003. Time: 558.3555 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #309: GFLOPs: 219.6662. Time: 338.5733 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #310: GFLOPs: 194.6451. Time: 382.0960 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #311: GFLOPs: 62.9060. Time: 1182.2900 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #312: GFLOPs: 221.3961. Time: 335.9278 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #313: GFLOPs: 181.7523. Time: 409.2005 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #314: GFLOPs: 149.7553. Time: 496.6309 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #315: GFLOPs: 149.8941. Time: 496.1711 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #316: GFLOPs: 155.7423. Time: 477.5397 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #317: GFLOPs: 133.2430. Time: 558.1766 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #318: GFLOPs: 89.3884. Time: 832.0223 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #319: GFLOPs: 18.0968. Time: 4109.7322 us. Best GFLOPs: 240.6886
2024-04-29 10:51:53 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #320: GFLOPs: 48.1226. Time: 1545.4931 us. Best GFLOPs: 240.6886
2024-04-29 11:22:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 11:22:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 11:22:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:22:14 [INFO] [evolutionary_search.cc:723] Sampled 405 candidate(s)
2024-04-29 11:22:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:22:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:22:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:22:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:22:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9590  0.9590  0.9590  0.9492  0.9461  0.9395  0.9289  0.9176  0.9171  0.9123  0.9038  0.9009  0.9009  0.9009  0.8985  0.8979
[17 : 32]:	0.8972  0.8972  0.8972  0.8912  0.8877  0.8877  0.8877  0.8877  0.8877  0.8823  0.8823  0.8823  0.8823  0.8823  0.8813  0.8813
[33 : 48]:	0.8787  0.8778  0.8768  0.8693  0.8684  0.8684  0.8651  0.8651  0.8638  0.8623  0.8623  0.8623  0.8620  0.8620  0.8613  0.8570
[49 : 64]:	0.8557  0.8556  0.8550  0.8549  0.8549  0.8549  0.8549  0.8548  0.8548  0.8548  0.8539  0.8526  0.8507  0.8481  0.8467  0.8467
2024-04-29 11:22:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 11:22:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #321: GFLOPs: 227.7317. Time: 326.5823 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #322: GFLOPs: 238.0868. Time: 312.3782 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #323: GFLOPs: 237.4020. Time: 313.2792 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #324: GFLOPs: 112.7859. Time: 659.4184 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #325: GFLOPs: 118.5968. Time: 627.1090 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #326: GFLOPs: 197.9593. Time: 375.6991 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #327: GFLOPs: 224.6589. Time: 331.0490 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #328: GFLOPs: 195.0690. Time: 381.2657 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #329: GFLOPs: 219.3403. Time: 339.0764 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #330: GFLOPs: 219.2354. Time: 339.2387 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #331: GFLOPs: 204.4554. Time: 363.7621 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #332: GFLOPs: 232.6260. Time: 319.7111 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #333: GFLOPs: 229.5306. Time: 324.0227 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #334: GFLOPs: 230.0181. Time: 323.3359 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #335: GFLOPs: 220.8713. Time: 336.7261 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #336: GFLOPs: 216.3356. Time: 343.7859 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #337: GFLOPs: 228.1358. Time: 326.0037 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #338: GFLOPs: 234.1509. Time: 317.6290 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #339: GFLOPs: 202.6200. Time: 367.0572 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #340: GFLOPs: 214.8012. Time: 346.2416 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #341: GFLOPs: 222.3560. Time: 334.4777 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #342: GFLOPs: 216.0078. Time: 344.3076 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #343: GFLOPs: 208.8586. Time: 356.0931 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #344: GFLOPs: 66.9290. Time: 1111.2236 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #345: GFLOPs: 222.0920. Time: 334.8752 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #346: GFLOPs: 231.2631. Time: 321.5953 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #347: GFLOPs: 237.4043. Time: 313.2762 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #348: GFLOPs: 215.3905. Time: 345.2944 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #349: GFLOPs: 225.9767. Time: 329.1186 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #350: GFLOPs: 219.5980. Time: 338.6785 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #351: GFLOPs: 226.0159. Time: 329.0614 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #352: GFLOPs: 210.5985. Time: 353.1513 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #353: GFLOPs: 208.4768. Time: 356.7454 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #354: GFLOPs: 202.1995. Time: 367.8206 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #355: GFLOPs: 202.4050. Time: 367.4471 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #356: GFLOPs: 180.8659. Time: 411.2059 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #357: GFLOPs: 214.3054. Time: 347.0427 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #358: GFLOPs: 67.5857. Time: 1100.4266 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #359: GFLOPs: 182.7472. Time: 406.9727 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #360: GFLOPs: 170.1964. Time: 436.9841 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #361: GFLOPs: 186.6377. Time: 398.4893 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #362: GFLOPs: 104.9937. Time: 708.3576 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #363: GFLOPs: 176.0324. Time: 422.4967 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #364: GFLOPs: 210.6133. Time: 353.1264 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #365: GFLOPs: 216.0215. Time: 344.2858 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #366: GFLOPs: 199.5658. Time: 372.6746 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #367: GFLOPs: 209.5153. Time: 354.9771 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #368: GFLOPs: 210.3817. Time: 353.5151 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #369: GFLOPs: 194.1581. Time: 383.0545 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #370: GFLOPs: 175.6070. Time: 423.5203 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #371: GFLOPs: 199.0636. Time: 373.6149 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #372: GFLOPs: 208.5299. Time: 356.6544 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #373: GFLOPs: 206.8558. Time: 359.5410 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #374: GFLOPs: 224.1947. Time: 331.7345 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #375: GFLOPs: 216.7461. Time: 343.1347 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #376: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(144), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(6)):
                for ax3_ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(12) // T.int64(6) * T.int64(6) + ax2)
                        v_i3 = T.axis.spatial(T.int64(18), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(6) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(12) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(12) // T.int64(6) * T.int64(6) + oh_1 * T.int64(6) + oh_2_init * T.int64(3) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(6) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(24), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(3), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(12) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(12) // T.int64(6) * T.int64(6) + oh_1 * T.int64(6) + oh_2 * T.int64(3) + oh_3)
                                v_ow = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(6) * T.int64(2) + ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(8) + ic_1)
                                v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(7), kw_0 * T.int64(7) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(6)):
                    for ax3_ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(12) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(12) // T.int64(6) * T.int64(6) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(6) * T.int64(2) + ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[12, 2, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 2, 3])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[6, 2, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[24, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 7])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l78, l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l112, l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b115)
b139 = sch.decompose_reduction(block=b115, loop=l123)
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #377: GFLOPs: 197.8151. Time: 375.9728 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #378: GFLOPs: 202.8622. Time: 366.6188 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #379: GFLOPs: 208.1737. Time: 357.2647 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #380: GFLOPs: 155.0462. Time: 479.6835 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #381: GFLOPs: 220.5554. Time: 337.2083 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #382: GFLOPs: 16.1151. Time: 4615.1302 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #383: GFLOPs: 55.4754. Time: 1340.6510 us. Best GFLOPs: 240.6886
2024-04-29 11:24:29 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #384: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(10368)):
            for i4_fused in T.vectorized(T.int64(4)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(48), i0_i1_i2_i3_fused // T.int64(216))
                    v_i2 = T.axis.spatial(T.int64(12), i0_i1_i2_i3_fused % T.int64(216) // T.int64(18))
                    v_i3 = T.axis.spatial(T.int64(18), i0_i1_i2_i3_fused % T.int64(18))
                    v_i4 = T.axis.spatial(T.int64(4), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(6), T.int64(2), T.int64(4), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(12) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(6) + oh_2_init * T.int64(3) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(3) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(12), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(2), T.int64(3), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(12) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), oh_1 * T.int64(6) + oh_2 * T.int64(3) + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(3) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(12), T.int64(12)):
                for ax3_ax4_fused in T.vectorized(T.int64(48)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(12) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 6, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 3])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 4, 3, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[12, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-29 11:47:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 11:47:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 11:47:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:47:09 [INFO] [evolutionary_search.cc:723] Sampled 405 candidate(s)
2024-04-29 11:47:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:47:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:47:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:47:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 11:47:49 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1114  0.9786  0.9645  0.9557  0.9550  0.9388  0.9388  0.9388  0.9388  0.9388  0.9388  0.9388  0.9388  0.9347  0.9201  0.9192
[17 : 32]:	0.9192  0.9176  0.9140  0.9125  0.9125  0.9115  0.9094  0.9094  0.9094  0.9094  0.9094  0.8954  0.8951  0.8949  0.8926  0.8926
[33 : 48]:	0.8926  0.8907  0.8876  0.8850  0.8850  0.8834  0.8819  0.8795  0.8794  0.8780  0.8748  0.8737  0.8718  0.8709  0.8694  0.8692
[49 : 64]:	0.8686  0.8686  0.8686  0.8676  0.8660  0.8657  0.8656  0.8656  0.8655  0.8645  0.8638  0.8638  0.8634  0.8626  0.8626  0.8626
2024-04-29 11:47:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 11:47:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #385: GFLOPs: 159.3014. Time: 466.8705 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #386: GFLOPs: 233.7164. Time: 318.2195 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #387: GFLOPs: 221.8263. Time: 335.2765 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #388: GFLOPs: 226.3069. Time: 328.6384 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #389: GFLOPs: 91.2301. Time: 815.2252 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #390: GFLOPs: 221.6121. Time: 335.6005 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #391: GFLOPs: 238.4993. Time: 311.8379 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #392: GFLOPs: 239.6117. Time: 310.3901 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #393: GFLOPs: 236.4960. Time: 314.4794 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #394: GFLOPs: 240.5937. Time: 309.1234 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #395: GFLOPs: 235.8516. Time: 315.3386 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #396: GFLOPs: 194.7023. Time: 381.9838 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #397: GFLOPs: 236.2408. Time: 314.8191 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #398: GFLOPs: 232.4175. Time: 319.9980 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #399: GFLOPs: 230.1878. Time: 323.0976 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #400: GFLOPs: 227.7777. Time: 326.5163 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #401: GFLOPs: 228.0366. Time: 326.1455 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #402: GFLOPs: 228.2122. Time: 325.8946 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #403: GFLOPs: 191.6410. Time: 388.0857 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #404: GFLOPs: 231.3852. Time: 321.4256 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #405: GFLOPs: 206.4222. Time: 360.2961 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #406: GFLOPs: 232.8532. Time: 319.3992 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #407: GFLOPs: 238.1248. Time: 312.3284 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #408: GFLOPs: 238.6450. Time: 311.6475 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #409: GFLOPs: 196.7513. Time: 378.0057 us. Best GFLOPs: 240.6886
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #410: GFLOPs: 240.7041. Time: 308.9815 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #411: GFLOPs: 237.8213. Time: 312.7270 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #412: GFLOPs: 203.9794. Time: 364.6110 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #413: GFLOPs: 219.8053. Time: 338.3590 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #414: GFLOPs: 230.6907. Time: 322.3932 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #415: GFLOPs: 239.1951. Time: 310.9307 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #416: GFLOPs: 239.6896. Time: 310.2893 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #417: GFLOPs: 237.9685. Time: 312.5335 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #418: GFLOPs: 214.0268. Time: 347.4945 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #419: GFLOPs: 209.2020. Time: 355.5087 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #420: GFLOPs: 191.9181. Time: 387.5254 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #421: GFLOPs: 213.1827. Time: 348.8704 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #422: GFLOPs: 219.7825. Time: 338.3941 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #423: GFLOPs: 79.4794. Time: 935.7539 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #424: GFLOPs: 207.4649. Time: 358.4854 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #425: GFLOPs: 233.4857. Time: 318.5339 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #426: GFLOPs: 191.4061. Time: 388.5618 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #427: GFLOPs: 216.1892. Time: 344.0186 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #428: GFLOPs: 229.8532. Time: 323.5679 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #429: GFLOPs: 232.0338. Time: 320.5270 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #430: GFLOPs: 212.8990. Time: 349.3352 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #431: GFLOPs: 212.3352. Time: 350.2628 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #432: GFLOPs: 86.9596. Time: 855.2605 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #433: GFLOPs: 234.5091. Time: 317.1439 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #434: GFLOPs: 235.1385. Time: 316.2950 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #435: GFLOPs: 234.9313. Time: 316.5739 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #436: GFLOPs: 174.5206. Time: 426.1568 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #437: GFLOPs: 215.3837. Time: 345.3052 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #438: GFLOPs: 213.0107. Time: 349.1520 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #439: GFLOPs: 228.9267. Time: 324.8775 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #440: GFLOPs: 214.4635. Time: 346.7869 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #441: GFLOPs: 239.7948. Time: 310.1532 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #442: GFLOPs: 227.8228. Time: 326.4516 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #443: GFLOPs: 186.5549. Time: 398.6661 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #444: GFLOPs: 186.1506. Time: 399.5320 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #445: GFLOPs: 94.3686. Time: 788.1126 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #446: GFLOPs: 12.5885. Time: 5908.0300 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #447: GFLOPs: 46.2597. Time: 1607.7295 us. Best GFLOPs: 240.7041
2024-04-29 11:49:12 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #448: GFLOPs: 145.2383. Time: 512.0764 us. Best GFLOPs: 240.7041
2024-04-29 12:13:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 12:13:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 12:13:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:13:38 [INFO] [evolutionary_search.cc:723] Sampled 405 candidate(s)
2024-04-29 12:13:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:13:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:14:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:14:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:14:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9952  0.9952  0.9952  0.9879  0.9879  0.9879  0.9879  0.9750  0.9750  0.9588  0.9576  0.9504  0.9487  0.9465  0.9465  0.9465
[17 : 32]:	0.9428  0.9428  0.9428  0.9380  0.9333  0.9333  0.9333  0.9333  0.9333  0.9300  0.9265  0.9249  0.9249  0.9249  0.9236  0.9236
[33 : 48]:	0.9236  0.9218  0.9218  0.9205  0.9205  0.9196  0.9196  0.9120  0.9031  0.9004  0.8964  0.8963  0.8944  0.8927  0.8905  0.8905
[49 : 64]:	0.8872  0.8866  0.8843  0.8831  0.8817  0.8817  0.8810  0.8806  0.8763  0.8750  0.8747  0.8747  0.8745  0.8734  0.8728  0.8728
2024-04-29 12:14:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 12:14:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #449: GFLOPs: 227.3805. Time: 327.0866 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #450: GFLOPs: 229.4919. Time: 324.0774 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #451: GFLOPs: 231.7804. Time: 320.8775 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #452: GFLOPs: 239.5883. Time: 310.4205 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #453: GFLOPs: 239.4287. Time: 310.6275 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #454: GFLOPs: 156.7501. Time: 474.4695 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #455: GFLOPs: 196.7386. Time: 378.0301 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #456: GFLOPs: 155.6659. Time: 477.7739 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #457: GFLOPs: 230.9165. Time: 322.0780 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #458: GFLOPs: 236.4852. Time: 314.4938 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #459: GFLOPs: 227.7687. Time: 326.5292 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #460: GFLOPs: 229.5761. Time: 323.9585 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #461: GFLOPs: 216.7990. Time: 343.0510 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #462: GFLOPs: 235.8986. Time: 315.2758 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #463: GFLOPs: 240.2724. Time: 309.5367 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #464: GFLOPs: 239.2312. Time: 310.8839 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #465: GFLOPs: 227.3787. Time: 327.0892 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #466: GFLOPs: 228.0056. Time: 326.1899 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #467: GFLOPs: 226.2234. Time: 328.7596 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #468: GFLOPs: 236.1074. Time: 314.9969 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #469: GFLOPs: 222.5235. Time: 334.2259 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #470: GFLOPs: 237.2286. Time: 313.5082 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #471: GFLOPs: 238.2225. Time: 312.2002 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #472: GFLOPs: 239.1267. Time: 311.0198 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #473: GFLOPs: 229.6470. Time: 323.8585 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #474: GFLOPs: 220.0304. Time: 338.0129 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #475: GFLOPs: 223.9841. Time: 332.0464 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #476: GFLOPs: 205.9147. Time: 361.1841 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #477: GFLOPs: 237.6852. Time: 312.9060 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #478: GFLOPs: 230.3169. Time: 322.9164 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #479: GFLOPs: 233.2231. Time: 318.8925 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #480: GFLOPs: 240.1850. Time: 309.6493 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #481: GFLOPs: 231.5774. Time: 321.1587 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #482: GFLOPs: 215.8984. Time: 344.4820 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #483: GFLOPs: 217.1947. Time: 342.4260 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #484: GFLOPs: 221.3831. Time: 335.9477 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #485: GFLOPs: 214.1850. Time: 347.2378 us. Best GFLOPs: 240.7041
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #486: GFLOPs: 267.8300. Time: 277.6878 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #487: GFLOPs: 203.7844. Time: 364.9599 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #488: GFLOPs: 221.8421. Time: 335.2525 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #489: GFLOPs: 215.1320. Time: 345.7093 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #490: GFLOPs: 225.1452. Time: 330.3340 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #491: GFLOPs: 229.3352. Time: 324.2988 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #492: GFLOPs: 218.7375. Time: 340.0108 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #493: GFLOPs: 225.9176. Time: 329.2047 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #494: GFLOPs: 221.9385. Time: 335.1069 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #495: GFLOPs: 198.1914. Time: 375.2591 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #496: GFLOPs: 200.5890. Time: 370.7737 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #497: GFLOPs: 208.5046. Time: 356.6977 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #498: GFLOPs: 230.5758. Time: 322.5539 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #499: GFLOPs: 211.7350. Time: 351.2557 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #500: GFLOPs: 225.4269. Time: 329.9212 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #501: GFLOPs: 210.7177. Time: 352.9515 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #502: GFLOPs: 95.6225. Time: 777.7787 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #503: GFLOPs: 100.8613. Time: 737.3800 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #504: GFLOPs: 235.3327. Time: 316.0339 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #505: GFLOPs: 217.6201. Time: 341.7567 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #506: GFLOPs: 219.7353. Time: 338.4669 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #507: GFLOPs: 172.0856. Time: 432.1869 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #508: GFLOPs: 174.2874. Time: 426.7269 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #509: GFLOPs: 228.2040. Time: 325.9063 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #510: GFLOPs: 127.9841. Time: 581.1121 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #511: GFLOPs: 18.7867. Time: 3958.8174 us. Best GFLOPs: 267.8300
2024-04-29 12:15:32 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #512: GFLOPs: 19.4780. Time: 3818.3070 us. Best GFLOPs: 267.8300
2024-04-29 12:39:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 12:39:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 12:39:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:39:16 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-29 12:39:25 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:39:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:39:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:39:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xe62b8b8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0xcfd94a8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0xc1512f8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0xc80e598)]: 0 failure(s)
2024-04-29 12:39:56 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8714  0.8524  0.8523  0.8523  0.8523  0.8523  0.8510  0.8496  0.8496  0.8465  0.8465  0.8465  0.8441  0.8438  0.8438  0.8414
[17 : 32]:	0.8411  0.8411  0.8389  0.8359  0.8339  0.8337  0.8337  0.8335  0.8326  0.8318  0.8312  0.8297  0.8288  0.8283  0.8278  0.8201
[33 : 48]:	0.8164  0.8144  0.8144  0.8144  0.8144  0.8144  0.8144  0.8144  0.8134  0.8117  0.8117  0.8117  0.8113  0.8113  0.8107  0.8107
[49 : 64]:	0.8086  0.8071  0.8059  0.8059  0.8059  0.8035  0.8009  0.7994  0.7985  0.7980  0.7960  0.7936  0.7928  0.7928  0.7920  0.7920
2024-04-29 12:39:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 12:39:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #513: GFLOPs: 110.2698. Time: 674.4653 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #514: GFLOPs: 112.5310. Time: 660.9124 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #515: GFLOPs: 236.6122. Time: 314.3249 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #516: GFLOPs: 236.0143. Time: 315.1213 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #517: GFLOPs: 221.7836. Time: 335.3410 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #518: GFLOPs: 224.8428. Time: 330.7784 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #519: GFLOPs: 239.7528. Time: 310.2075 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #520: GFLOPs: 240.7528. Time: 308.9190 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #521: GFLOPs: 240.2107. Time: 309.6162 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #522: GFLOPs: 232.8266. Time: 319.4356 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #523: GFLOPs: 231.5789. Time: 321.1567 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #524: GFLOPs: 235.7642. Time: 315.4555 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #525: GFLOPs: 232.8597. Time: 319.3902 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #526: GFLOPs: 207.6956. Time: 358.0871 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #527: GFLOPs: 245.0760. Time: 303.4696 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #528: GFLOPs: 234.7053. Time: 316.8787 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #529: GFLOPs: 241.3961. Time: 308.0958 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #530: GFLOPs: 241.6666. Time: 307.7509 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #531: GFLOPs: 228.9485. Time: 324.8465 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #532: GFLOPs: 221.6756. Time: 335.5043 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #533: GFLOPs: 110.7431. Time: 671.5824 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #534: GFLOPs: 237.3798. Time: 313.3085 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #535: GFLOPs: 234.5324. Time: 317.1124 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #536: GFLOPs: 230.7619. Time: 322.2938 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #537: GFLOPs: 233.0339. Time: 319.1516 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #538: GFLOPs: 235.6481. Time: 315.6109 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #539: GFLOPs: 221.5020. Time: 335.7673 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #540: GFLOPs: 229.5909. Time: 323.9376 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #541: GFLOPs: 224.3118. Time: 331.5614 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #542: GFLOPs: 225.6098. Time: 329.6537 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #543: GFLOPs: 224.4907. Time: 331.2972 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #544: GFLOPs: 236.4881. Time: 314.4899 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #545: GFLOPs: 221.7660. Time: 335.3675 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #546: GFLOPs: 238.0230. Time: 312.4619 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #547: GFLOPs: 224.6589. Time: 331.0491 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #548: GFLOPs: 235.5394. Time: 315.7566 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #549: GFLOPs: 235.4897. Time: 315.8233 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #550: GFLOPs: 231.1875. Time: 321.7005 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #551: GFLOPs: 226.2206. Time: 328.7637 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #552: GFLOPs: 225.7284. Time: 329.4806 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #553: GFLOPs: 229.3670. Time: 324.2538 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #554: GFLOPs: 232.7186. Time: 319.5839 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #555: GFLOPs: 233.9319. Time: 317.9263 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #556: GFLOPs: 227.0425. Time: 327.5736 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #557: GFLOPs: 219.3405. Time: 339.0761 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #558: GFLOPs: 219.5239. Time: 338.7927 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #559: GFLOPs: 233.4391. Time: 318.5976 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #560: GFLOPs: 231.4697. Time: 321.3082 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #561: GFLOPs: 230.1278. Time: 323.1818 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #562: GFLOPs: 228.7573. Time: 325.1180 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #563: GFLOPs: 233.3533. Time: 318.7146 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #564: GFLOPs: 194.2710. Time: 382.8318 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #565: GFLOPs: 233.7778. Time: 318.1360 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #566: GFLOPs: 213.4005. Time: 348.5143 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #567: GFLOPs: 223.0409. Time: 333.4506 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #568: GFLOPs: 230.8854. Time: 322.1213 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #569: GFLOPs: 223.7226. Time: 332.4345 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #570: GFLOPs: 217.3816. Time: 342.1317 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #571: GFLOPs: 219.5973. Time: 338.6795 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #572: GFLOPs: 204.9947. Time: 362.8051 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #573: GFLOPs: 218.9815. Time: 339.6320 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #574: GFLOPs: 41.6063. Time: 1787.5447 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:131] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #575: GFLOPs: 19.4450. Time: 3824.7913 us. Best GFLOPs: 267.8300
2024-04-29 12:41:38 [INFO] [task_scheduler.cc:121] [Task #15: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_10] Trial #576: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32"), p1: T.Buffer((T.int64(48), T.int64(48), T.int64(1), T.int64(7), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(48), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(18), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(12), T.int64(12), T.int64(4)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(10368)):
            for i4_fused in T.vectorized(T.int64(4)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(48), i0_i1_i2_i3_fused // T.int64(216))
                    v_i2 = T.axis.spatial(T.int64(12), i0_i1_i2_i3_fused % T.int64(216) // T.int64(18))
                    v_i3 = T.axis.spatial(T.int64(18), i0_i1_i2_i3_fused % T.int64(18))
                    v_i4 = T.axis.spatial(T.int64(4), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(3) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2, v_i3 - T.int64(3), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(6), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(2), T.int64(6)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(24) + oc_chunk_1 * T.int64(24) + oc_chunk_2_init * T.int64(12) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(4) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(6) + ow_2_init * T.int64(6) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(7), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(2), T.int64(6)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(24) + oc_chunk_1 * T.int64(24) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(4) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(12), ow_1 * T.int64(6) + ow_2 * T.int64(6) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(1), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(7), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(24), T.int64(4)):
                for ax3_ax4_fused in T.vectorized(T.int64(48)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(48), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(3) * T.int64(24) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(12), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(3) * T.int64(4) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(12), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 2, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[3, 2, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 6])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[7, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
