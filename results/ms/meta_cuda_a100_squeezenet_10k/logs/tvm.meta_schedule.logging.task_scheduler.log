2024-04-28 23:45:15 [INFO] Logging directory: results/ms/meta_cuda_a100_squeezenet_10k/logs
2024-04-28 23:45:40 [INFO] LocalBuilder: max_workers = 64
2024-04-28 23:45:43 [INFO] [task_scheduler.cc:159] Initializing Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-28 23:45:44 [INFO] [task_scheduler.cc:159] Initializing Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-28 23:45:44 [INFO] [task_scheduler.cc:159] Initializing Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-28 23:45:45 [INFO] [task_scheduler.cc:159] Initializing Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-28 23:45:46 [INFO] [task_scheduler.cc:159] Initializing Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-28 23:45:46 [INFO] [task_scheduler.cc:159] Initializing Task #5: "fused_nn_max_pool2d"
2024-04-28 23:45:47 [INFO] [task_scheduler.cc:159] Initializing Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-28 23:45:47 [INFO] [task_scheduler.cc:159] Initializing Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-28 23:45:47 [INFO] [task_scheduler.cc:159] Initializing Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-04-28 23:45:47 [INFO] [task_scheduler.cc:159] Initializing Task #9: "fused_concatenate"
2024-04-28 23:45:48 [INFO] [task_scheduler.cc:159] Initializing Task #10: "fused_nn_max_pool2d_1"
2024-04-28 23:45:48 [INFO] [task_scheduler.cc:159] Initializing Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-28 23:45:48 [INFO] [task_scheduler.cc:159] Initializing Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-28 23:45:48 [INFO] [task_scheduler.cc:159] Initializing Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-28 23:45:49 [INFO] [task_scheduler.cc:159] Initializing Task #14: "fused_concatenate_1"
2024-04-28 23:45:49 [INFO] [task_scheduler.cc:159] Initializing Task #15: "fused_nn_max_pool2d_2"
2024-04-28 23:45:49 [INFO] [task_scheduler.cc:159] Initializing Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-28 23:45:49 [INFO] [task_scheduler.cc:159] Initializing Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-28 23:45:49 [INFO] [task_scheduler.cc:159] Initializing Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-04-28 23:45:50 [INFO] [task_scheduler.cc:159] Initializing Task #19: "fused_concatenate_2"
2024-04-28 23:45:50 [INFO] [task_scheduler.cc:159] Initializing Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-28 23:45:50 [INFO] [task_scheduler.cc:159] Initializing Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-28 23:45:50 [INFO] [task_scheduler.cc:159] Initializing Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:159] Initializing Task #23: "fused_concatenate_3"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:159] Initializing Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:159] Initializing Task #25: "fused_nn_global_avg_pool2d"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:159] Initializing Task #26: "fused_nn_batch_flatten"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:159] Initializing Task #27: "fused_nn_softmax"
2024-04-28 23:45:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |            N/A |          N/A |                   N/A |      0 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |            N/A |          N/A |                   N/A |      0 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2024-04-28 23:45:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-28 23:47:35 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-28 23:48:03 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-28 23:48:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-28 23:50:17 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-28 23:51:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-28 23:51:45 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-28 23:53:17 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-28 23:54:07 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-28 23:54:44 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-28 23:56:15 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-28 23:57:06 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-28 23:57:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-28 23:58:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-28 23:58:32 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-28 23:59:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #5: "fused_nn_max_pool2d"
2024-04-28 23:59:13 [INFO] [task_scheduler.cc:193] Sending 61 sample(s) to builder
2024-04-28 23:59:34 [INFO] [task_scheduler.cc:195] Sending 61 sample(s) to runner
2024-04-28 23:59:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 00:00:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:00:29 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:00:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 00:01:02 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:01:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:01:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-04-29 00:02:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:02:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:02:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #9: "fused_concatenate"
2024-04-29 00:02:43 [INFO] [task_scheduler.cc:193] Sending 1 sample(s) to builder
2024-04-29 00:02:46 [INFO] [task_scheduler.cc:195] Sending 1 sample(s) to runner
2024-04-29 00:02:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #10: "fused_nn_max_pool2d_1"
2024-04-29 00:02:49 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 00:03:09 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 00:03:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 00:03:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:04:17 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:04:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 00:05:21 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 00:05:50 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 00:06:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 00:06:43 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:07:30 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:08:13 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-04-29 00:08:15 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-04-29 00:08:20 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-04-29 00:08:23 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #15: "fused_nn_max_pool2d_2"
2024-04-29 00:08:26 [INFO] [task_scheduler.cc:193] Sending 61 sample(s) to builder
2024-04-29 00:08:48 [INFO] [task_scheduler.cc:195] Sending 61 sample(s) to runner
2024-04-29 00:09:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 00:09:44 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:10:14 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:10:48 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 00:11:07 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 00:11:30 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 00:11:55 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-04-29 00:12:12 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:13:01 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:13:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #19: "fused_concatenate_2"
2024-04-29 00:13:08 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-04-29 00:13:13 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-04-29 00:13:13 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 00:13:32 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:14:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:14:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 00:14:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:15:17 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:15:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 00:16:14 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:16:54 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:17:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-04-29 00:17:31 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-04-29 00:17:34 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-04-29 00:17:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:17:56 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 00:18:25 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 00:18:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 00:19:02 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 00:19:24 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 00:19:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #26: "fused_nn_batch_flatten"
2024-04-29 00:20:00 [INFO] [task_scheduler.cc:193] Sending 5 sample(s) to builder
2024-04-29 00:20:04 [INFO] [task_scheduler.cc:195] Sending 5 sample(s) to runner
2024-04-29 00:20:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #27: "fused_nn_softmax"
2024-04-29 00:20:09 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 00:20:33 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 00:21:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.871594	tr-a-peak@32: 0.856895	tr-rmse: 0.827229	tr-rmse: 0.827229
2024-04-29 00:21:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.050145	tr-a-peak@32: 1.000000	tr-rmse: 0.493680	tr-rmse: 0.493680
2024-04-29 00:21:12 [DEBUG] XGB iter  50: tr-p-rmse: 0.050157	tr-a-peak@32: 1.000000	tr-rmse: 0.494089	tr-rmse: 0.494089
2024-04-29 00:21:12 [DEBUG] XGB iter  75: tr-p-rmse: 0.050157	tr-a-peak@32: 1.000000	tr-rmse: 0.494088	tr-rmse: 0.494088
2024-04-29 00:21:12 [DEBUG] XGB stopped. Best iteration: [27] tr-p-rmse:0.05011	tr-a-peak@32:1.00000	tr-rmse:0.49384	tr-rmse:0.49384 
2024-04-29 00:21:12 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 00:21:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |            N/A |          N/A |                   N/A |      0 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 63
Total latency (us): 39.7536

2024-04-29 00:21:13 [DEBUG] XGB iter   0: tr-p-rmse: 2.818199	tr-a-peak@32: 0.678748	tr-rmse: 0.931862	tr-rmse: 0.931862
2024-04-29 00:21:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.042172	tr-a-peak@32: 1.000000	tr-rmse: 0.598696	tr-rmse: 0.598696
2024-04-29 00:21:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.041919	tr-a-peak@32: 1.000000	tr-rmse: 0.599348	tr-rmse: 0.599348
2024-04-29 00:21:14 [DEBUG] XGB iter  75: tr-p-rmse: 0.041919	tr-a-peak@32: 1.000000	tr-rmse: 0.599346	tr-rmse: 0.599346
2024-04-29 00:21:14 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.04191	tr-a-peak@32:1.00000	tr-rmse:0.59929	tr-rmse:0.59929 
2024-04-29 00:21:14 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 00:21:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 127
Total latency (us): 78.4929

2024-04-29 00:21:15 [DEBUG] XGB iter   0: tr-p-rmse: 2.852396	tr-a-peak@32: 0.794007	tr-rmse: 0.911675	tr-rmse: 0.911675
2024-04-29 00:21:15 [DEBUG] XGB iter  25: tr-p-rmse: 0.052371	tr-a-peak@32: 1.000000	tr-rmse: 0.576734	tr-rmse: 0.576734
2024-04-29 00:21:15 [DEBUG] XGB iter  50: tr-p-rmse: 0.051672	tr-a-peak@32: 1.000000	tr-rmse: 0.577401	tr-rmse: 0.577401
2024-04-29 00:21:16 [DEBUG] XGB iter  75: tr-p-rmse: 0.051673	tr-a-peak@32: 1.000000	tr-rmse: 0.577399	tr-rmse: 0.577399
2024-04-29 00:21:16 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.05162	tr-a-peak@32:1.00000	tr-rmse:0.57761	tr-rmse:0.57761 
2024-04-29 00:21:16 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 00:21:16 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 191
Total latency (us): 114.979

2024-04-29 00:21:17 [DEBUG] XGB iter   0: tr-p-rmse: 2.877821	tr-a-peak@32: 0.874002	tr-rmse: 0.907756	tr-rmse: 0.907756
2024-04-29 00:21:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.045674	tr-a-peak@32: 1.000000	tr-rmse: 0.572244	tr-rmse: 0.572244
2024-04-29 00:21:17 [DEBUG] XGB iter  50: tr-p-rmse: 0.043217	tr-a-peak@32: 1.000000	tr-rmse: 0.572972	tr-rmse: 0.572972
2024-04-29 00:21:17 [DEBUG] XGB iter  75: tr-p-rmse: 0.043219	tr-a-peak@32: 1.000000	tr-rmse: 0.572970	tr-rmse: 0.572970
2024-04-29 00:21:17 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.04298	tr-a-peak@32:1.00000	tr-rmse:0.57354	tr-rmse:0.57354 
2024-04-29 00:21:18 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 00:21:18 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 255
Total latency (us): 148.024

2024-04-29 00:21:18 [DEBUG] XGB iter   0: tr-p-rmse: 2.668804	tr-a-peak@32: 0.597875	tr-rmse: 0.894207	tr-rmse: 0.894207
2024-04-29 00:21:18 [DEBUG] XGB iter  25: tr-p-rmse: 0.153936	tr-a-peak@32: 0.968750	tr-rmse: 0.569750	tr-rmse: 0.569750
2024-04-29 00:21:19 [DEBUG] XGB iter  50: tr-p-rmse: 0.153424	tr-a-peak@32: 0.968750	tr-rmse: 0.570159	tr-rmse: 0.570159
2024-04-29 00:21:19 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.15230	tr-a-peak@32:0.96875	tr-rmse:0.57176	tr-rmse:0.57176 
2024-04-29 00:21:19 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 00:21:19 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 319
Total latency (us): 158.044

2024-04-29 00:21:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.631605	tr-a-peak@32: 1.000000	tr-rmse: 0.864324	tr-rmse: 0.864324
2024-04-29 00:21:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.170144	tr-a-peak@32: 0.906250	tr-rmse: 0.550192	tr-rmse: 0.550192
2024-04-29 00:21:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.169688	tr-a-peak@32: 0.906250	tr-rmse: 0.550575	tr-rmse: 0.550575
2024-04-29 00:21:20 [DEBUG] XGB iter  75: tr-p-rmse: 0.169688	tr-a-peak@32: 0.906250	tr-rmse: 0.550575	tr-rmse: 0.550575
2024-04-29 00:21:20 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.16939	tr-a-peak@32:0.90625	tr-rmse:0.55087	tr-rmse:0.55087 
2024-04-29 00:21:20 [INFO] [task_scheduler.cc:237] [Updated] Task #5: "fused_nn_max_pool2d"
2024-04-29 00:21:20 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 319
Total latency (us): 158.044

2024-04-29 00:21:21 [DEBUG] XGB iter   0: tr-p-rmse: 2.439650	tr-a-peak@32: 0.982471	tr-rmse: 0.856277	tr-rmse: 0.856277
2024-04-29 00:21:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.219520	tr-a-peak@32: 0.781250	tr-rmse: 0.552840	tr-rmse: 0.552840
2024-04-29 00:21:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.219338	tr-a-peak@32: 0.781250	tr-rmse: 0.552977	tr-rmse: 0.552977
2024-04-29 00:21:22 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.21848	tr-a-peak@32:0.78125	tr-rmse:0.55386	tr-rmse:0.55386 
2024-04-29 00:21:22 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 00:21:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 383
Total latency (us): 164.102

2024-04-29 00:21:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.380487	tr-a-peak@32: 0.825802	tr-rmse: 0.848784	tr-rmse: 0.848784
2024-04-29 00:21:23 [DEBUG] XGB iter  25: tr-p-rmse: 0.347477	tr-a-peak@32: 0.343750	tr-rmse: 0.556249	tr-rmse: 0.556249
2024-04-29 00:21:23 [DEBUG] XGB iter  50: tr-p-rmse: 0.347395	tr-a-peak@32: 0.343750	tr-rmse: 0.556354	tr-rmse: 0.556354
2024-04-29 00:21:23 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.34694	tr-a-peak@32:0.37500	tr-rmse:0.55720	tr-rmse:0.55720 
2024-04-29 00:21:23 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 00:21:23 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 447
Total latency (us): 171.511

2024-04-29 00:21:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.218434	tr-a-peak@32: 1.000000	tr-rmse: 0.816351	tr-rmse: 0.816351
2024-04-29 00:21:24 [DEBUG] XGB iter  25: tr-p-rmse: 0.347642	tr-a-peak@32: 0.218750	tr-rmse: 0.608598	tr-rmse: 0.608598
2024-04-29 00:21:25 [DEBUG] XGB iter  50: tr-p-rmse: 0.347636	tr-a-peak@32: 0.218750	tr-rmse: 0.608603	tr-rmse: 0.608603
2024-04-29 00:21:25 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.34743	tr-a-peak@32:0.21875	tr-rmse:0.60878	tr-rmse:0.60878 
2024-04-29 00:21:25 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-04-29 00:21:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 447
Total latency (us): 171.511

2024-04-29 00:21:25 [DEBUG] XGB iter   0: tr-p-rmse: 2.218111	tr-a-peak@32: 1.000000	tr-rmse: 0.816098	tr-rmse: 0.816098
2024-04-29 00:21:26 [DEBUG] XGB iter  25: tr-p-rmse: 0.367778	tr-a-peak@32: 0.000000	tr-rmse: 0.608199	tr-rmse: 0.608199
2024-04-29 00:21:26 [DEBUG] XGB iter  50: tr-p-rmse: 0.367751	tr-a-peak@32: 0.000000	tr-rmse: 0.608218	tr-rmse: 0.608218
2024-04-29 00:21:26 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.36750	tr-a-peak@32:0.00000	tr-rmse:0.60840	tr-rmse:0.60840 
2024-04-29 00:21:26 [INFO] [task_scheduler.cc:237] [Updated] Task #9: "fused_concatenate"
2024-04-29 00:21:26 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 447
Total latency (us): 171.511

2024-04-29 00:21:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.228224	tr-a-peak@32: 0.968750	tr-rmse: 0.812300	tr-rmse: 0.812300
2024-04-29 00:21:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.374189	tr-a-peak@32: 0.000000	tr-rmse: 0.605072	tr-rmse: 0.605072
2024-04-29 00:21:27 [DEBUG] XGB iter  50: tr-p-rmse: 0.374169	tr-a-peak@32: 0.000000	tr-rmse: 0.605087	tr-rmse: 0.605087
2024-04-29 00:21:28 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.37385	tr-a-peak@32:0.00000	tr-rmse:0.60560	tr-rmse:0.60560 
2024-04-29 00:21:28 [INFO] [task_scheduler.cc:237] [Updated] Task #10: "fused_nn_max_pool2d_1"
2024-04-29 00:21:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 509
Total latency (us): 175.115

2024-04-29 00:21:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.103759	tr-a-peak@32: 1.000000	tr-rmse: 0.799709	tr-rmse: 0.799709
2024-04-29 00:21:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.369873	tr-a-peak@32: 0.031250	tr-rmse: 0.598674	tr-rmse: 0.598674
2024-04-29 00:21:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.369869	tr-a-peak@32: 0.031250	tr-rmse: 0.598677	tr-rmse: 0.598677
2024-04-29 00:21:29 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.36965	tr-a-peak@32:0.03125	tr-rmse:0.59886	tr-rmse:0.59886 
2024-04-29 00:21:29 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 00:21:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 573
Total latency (us): 184.107

2024-04-29 00:21:30 [DEBUG] XGB iter   0: tr-p-rmse: 1.968264	tr-a-peak@32: 1.000000	tr-rmse: 0.785927	tr-rmse: 0.785927
2024-04-29 00:21:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.330465	tr-a-peak@32: 0.281250	tr-rmse: 0.593448	tr-rmse: 0.593448
2024-04-29 00:21:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.330452	tr-a-peak@32: 0.281250	tr-rmse: 0.593457	tr-rmse: 0.593457
2024-04-29 00:21:31 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.33007	tr-a-peak@32:0.28125	tr-rmse:0.59386	tr-rmse:0.59386 
2024-04-29 00:21:31 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 00:21:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 636
Total latency (us): 199.213

2024-04-29 00:21:31 [DEBUG] XGB iter   0: tr-p-rmse: 1.951238	tr-a-peak@32: 0.968750	tr-rmse: 0.770064	tr-rmse: 0.770064
2024-04-29 00:21:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.295670	tr-a-peak@32: 0.500000	tr-rmse: 0.586082	tr-rmse: 0.586082
2024-04-29 00:21:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.295657	tr-a-peak@32: 0.500000	tr-rmse: 0.586090	tr-rmse: 0.586090
2024-04-29 00:21:33 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.29554	tr-a-peak@32:0.50000	tr-rmse:0.58619	tr-rmse:0.58619 
2024-04-29 00:21:33 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 00:21:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 700
Total latency (us): 210.518

2024-04-29 00:21:33 [DEBUG] XGB iter   0: tr-p-rmse: 1.948495	tr-a-peak@32: 0.968750	tr-rmse: 0.768846	tr-rmse: 0.768846
2024-04-29 00:21:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.285026	tr-a-peak@32: 0.687500	tr-rmse: 0.584058	tr-rmse: 0.584058
2024-04-29 00:21:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.285024	tr-a-peak@32: 0.687500	tr-rmse: 0.584059	tr-rmse: 0.584059
2024-04-29 00:21:34 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.28471	tr-a-peak@32:0.68750	tr-rmse:0.58450	tr-rmse:0.58450 
2024-04-29 00:21:34 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-04-29 00:21:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 706
Total latency (us): 216.6

2024-04-29 00:21:34 [DEBUG] XGB iter   0: tr-p-rmse: 1.921731	tr-a-peak@32: 0.968750	tr-rmse: 0.761297	tr-rmse: 0.761297
2024-04-29 00:21:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.285234	tr-a-peak@32: 0.656250	tr-rmse: 0.578657	tr-rmse: 0.578657
2024-04-29 00:21:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.285219	tr-a-peak@32: 0.656250	tr-rmse: 0.578666	tr-rmse: 0.578666
2024-04-29 00:21:36 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.28492	tr-a-peak@32:0.65625	tr-rmse:0.57904	tr-rmse:0.57904 
2024-04-29 00:21:36 [INFO] [task_scheduler.cc:237] [Updated] Task #15: "fused_nn_max_pool2d_2"
2024-04-29 00:21:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 767
Total latency (us): 219.732

2024-04-29 00:21:36 [DEBUG] XGB iter   0: tr-p-rmse: 1.856665	tr-a-peak@32: 0.968750	tr-rmse: 0.755856	tr-rmse: 0.755856
2024-04-29 00:21:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.276683	tr-a-peak@32: 0.500000	tr-rmse: 0.574171	tr-rmse: 0.574171
2024-04-29 00:21:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.276686	tr-a-peak@32: 0.500000	tr-rmse: 0.574168	tr-rmse: 0.574168
2024-04-29 00:21:37 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.27661	tr-a-peak@32:0.50000	tr-rmse:0.57424	tr-rmse:0.57424 
2024-04-29 00:21:37 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 00:21:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 831
Total latency (us): 226.631

2024-04-29 00:21:38 [DEBUG] XGB iter   0: tr-p-rmse: 1.810959	tr-a-peak@32: 0.968750	tr-rmse: 0.751300	tr-rmse: 0.751300
2024-04-29 00:21:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.279114	tr-a-peak@32: 0.437500	tr-rmse: 0.571694	tr-rmse: 0.571694
2024-04-29 00:21:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.279117	tr-a-peak@32: 0.437500	tr-rmse: 0.571692	tr-rmse: 0.571692
2024-04-29 00:21:39 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.27902	tr-a-peak@32:0.43750	tr-rmse:0.57175	tr-rmse:0.57175 
2024-04-29 00:21:39 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 00:21:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 894
Total latency (us): 236.601

2024-04-29 00:21:40 [DEBUG] XGB iter   0: tr-p-rmse: 1.807182	tr-a-peak@32: 0.601917	tr-rmse: 0.743416	tr-rmse: 0.743416
2024-04-29 00:21:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.289446	tr-a-peak@32: 0.406250	tr-rmse: 0.603525	tr-rmse: 0.603525
2024-04-29 00:21:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.289495	tr-a-peak@32: 0.406250	tr-rmse: 0.603488	tr-rmse: 0.603488
2024-04-29 00:21:41 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.28936	tr-a-peak@32:0.40625	tr-rmse:0.60365	tr-rmse:0.60365 
2024-04-29 00:21:41 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-04-29 00:21:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 894
Total latency (us): 236.601

2024-04-29 00:21:41 [DEBUG] XGB iter   0: tr-p-rmse: 1.813483	tr-a-peak@32: 0.677469	tr-rmse: 0.742753	tr-rmse: 0.742753
2024-04-29 00:21:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.301118	tr-a-peak@32: 0.218750	tr-rmse: 0.602598	tr-rmse: 0.602598
2024-04-29 00:21:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.301116	tr-a-peak@32: 0.218750	tr-rmse: 0.602600	tr-rmse: 0.602600
2024-04-29 00:21:43 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.30110	tr-a-peak@32:0.21875	tr-rmse:0.60261	tr-rmse:0.60261 
2024-04-29 00:21:43 [INFO] [task_scheduler.cc:237] [Updated] Task #19: "fused_concatenate_2"
2024-04-29 00:21:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 894
Total latency (us): 236.601

2024-04-29 00:21:43 [DEBUG] XGB iter   0: tr-p-rmse: 1.758185	tr-a-peak@32: 0.651184	tr-rmse: 0.737157	tr-rmse: 0.737157
2024-04-29 00:21:44 [DEBUG] XGB iter  25: tr-p-rmse: 0.300909	tr-a-peak@32: 0.406250	tr-rmse: 0.600784	tr-rmse: 0.600784
2024-04-29 00:21:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.300909	tr-a-peak@32: 0.406250	tr-rmse: 0.600784	tr-rmse: 0.600784
2024-04-29 00:21:44 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.30090	tr-a-peak@32:0.40625	tr-rmse:0.60079	tr-rmse:0.60079 
2024-04-29 00:21:45 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 00:21:45 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 958
Total latency (us): 255.297

2024-04-29 00:21:45 [DEBUG] XGB iter   0: tr-p-rmse: 1.717100	tr-a-peak@32: 0.738602	tr-rmse: 0.730507	tr-rmse: 0.730507
2024-04-29 00:21:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.308330	tr-a-peak@32: 0.156250	tr-rmse: 0.597356	tr-rmse: 0.597356
2024-04-29 00:21:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.308331	tr-a-peak@32: 0.156250	tr-rmse: 0.597356	tr-rmse: 0.597356
2024-04-29 00:21:46 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.30829	tr-a-peak@32:0.15625	tr-rmse:0.59738	tr-rmse:0.59738 
2024-04-29 00:21:46 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 00:21:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1022
Total latency (us): 264.25

2024-04-29 00:21:47 [DEBUG] XGB iter   0: tr-p-rmse: 1.680054	tr-a-peak@32: 0.880746	tr-rmse: 0.723795	tr-rmse: 0.723795
2024-04-29 00:21:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.287081	tr-a-peak@32: 0.343750	tr-rmse: 0.594398	tr-rmse: 0.594398
2024-04-29 00:21:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.287081	tr-a-peak@32: 0.343750	tr-rmse: 0.594398	tr-rmse: 0.594398
2024-04-29 00:21:48 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.28705	tr-a-peak@32:0.34375	tr-rmse:0.59442	tr-rmse:0.59442 
2024-04-29 00:21:48 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 00:21:48 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1086
Total latency (us): 277.645

2024-04-29 00:21:48 [DEBUG] XGB iter   0: tr-p-rmse: 1.675959	tr-a-peak@32: 0.880746	tr-rmse: 0.722891	tr-rmse: 0.722891
2024-04-29 00:21:49 [DEBUG] XGB iter  25: tr-p-rmse: 0.283487	tr-a-peak@32: 0.281250	tr-rmse: 0.593024	tr-rmse: 0.593024
2024-04-29 00:21:50 [DEBUG] XGB iter  50: tr-p-rmse: 0.283482	tr-a-peak@32: 0.281250	tr-rmse: 0.593028	tr-rmse: 0.593028
2024-04-29 00:21:50 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.28345	tr-a-peak@32:0.28125	tr-rmse:0.59305	tr-rmse:0.59305 
2024-04-29 00:21:50 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-04-29 00:21:50 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1092
Total latency (us): 283.201

2024-04-29 00:21:50 [DEBUG] XGB iter   0: tr-p-rmse: 1.640071	tr-a-peak@32: 0.938346	tr-rmse: 0.717292	tr-rmse: 0.717292
2024-04-29 00:21:51 [DEBUG] XGB iter  25: tr-p-rmse: 0.273199	tr-a-peak@32: 0.468750	tr-rmse: 0.590430	tr-rmse: 0.590430
2024-04-29 00:21:51 [DEBUG] XGB iter  50: tr-p-rmse: 0.273229	tr-a-peak@32: 0.468750	tr-rmse: 0.590409	tr-rmse: 0.590409
2024-04-29 00:21:52 [DEBUG] XGB iter  75: tr-p-rmse: 0.273229	tr-a-peak@32: 0.468750	tr-rmse: 0.590409	tr-rmse: 0.590409
2024-04-29 00:21:52 [DEBUG] XGB stopped. Best iteration: [25] tr-p-rmse:0.27320	tr-a-peak@32:0.46875	tr-rmse:0.59043	tr-rmse:0.59043 
2024-04-29 00:21:52 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:21:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      2869.0463 |      60.4361 |               60.4361 |     62 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1154
Total latency (us): 343.637

2024-04-29 00:21:52 [DEBUG] XGB iter   0: tr-p-rmse: 1.577533	tr-a-peak@32: 0.871817	tr-rmse: 0.710618	tr-rmse: 0.710618
2024-04-29 00:21:53 [DEBUG] XGB iter  25: tr-p-rmse: 0.283783	tr-a-peak@32: 0.218750	tr-rmse: 0.587308	tr-rmse: 0.587308
2024-04-29 00:21:53 [DEBUG] XGB iter  50: tr-p-rmse: 0.283779	tr-a-peak@32: 0.218750	tr-rmse: 0.587311	tr-rmse: 0.587311
2024-04-29 00:21:54 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.28375	tr-a-peak@32:0.21875	tr-rmse:0.58733	tr-rmse:0.58733 
2024-04-29 00:21:54 [INFO] [task_scheduler.cc:237] [Updated] Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 00:21:54 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      2869.0463 |      60.4361 |               60.4361 |     62 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1216
Total latency (us): 347.181

2024-04-29 00:21:54 [DEBUG] XGB iter   0: tr-p-rmse: 1.574081	tr-a-peak@32: 0.869127	tr-rmse: 0.709413	tr-rmse: 0.709413
2024-04-29 00:21:55 [DEBUG] XGB iter  25: tr-p-rmse: 0.281763	tr-a-peak@32: 0.156250	tr-rmse: 0.586862	tr-rmse: 0.586862
2024-04-29 00:21:55 [DEBUG] XGB iter  50: tr-p-rmse: 0.281762	tr-a-peak@32: 0.156250	tr-rmse: 0.586863	tr-rmse: 0.586863
2024-04-29 00:21:55 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.28175	tr-a-peak@32:0.15625	tr-rmse:0.58687	tr-rmse:0.58687 
2024-04-29 00:21:55 [INFO] [task_scheduler.cc:237] [Updated] Task #26: "fused_nn_batch_flatten"
2024-04-29 00:21:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      2869.0463 |      60.4361 |               60.4361 |     62 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1221
Total latency (us): 349.616

2024-04-29 00:21:56 [DEBUG] XGB iter   0: tr-p-rmse: 1.569880	tr-a-peak@32: 0.991871	tr-rmse: 0.710741	tr-rmse: 0.710741
2024-04-29 00:21:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.279423	tr-a-peak@32: 0.093750	tr-rmse: 0.587783	tr-rmse: 0.587783
2024-04-29 00:21:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.279415	tr-a-peak@32: 0.093750	tr-rmse: 0.587788	tr-rmse: 0.587788
2024-04-29 00:21:57 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.27936	tr-a-peak@32:0.09375	tr-rmse:0.58782	tr-rmse:0.58782 
2024-04-29 00:21:57 [INFO] [task_scheduler.cc:237] [Updated] Task #27: "fused_nn_softmax"
2024-04-29 00:21:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      2869.0463 |      60.4361 |               60.4361 |     62 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1284
Total latency (us): 353.117

2024-04-29 00:21:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:22:24 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:22:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:23:31 [DEBUG] XGB validation: p-rmse: 1.009602	a-peak@32: 1.000000
2024-04-29 00:23:31 [DEBUG] XGB iter   0: tr-p-rmse: 1.542843	tr-a-peak@32: 0.956413	tr-rmse: 0.685930	tr-rmse: 0.685930
2024-04-29 00:23:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.258684	tr-a-peak@32: 0.250000	tr-rmse: 0.578479	tr-rmse: 0.578479
2024-04-29 00:23:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.258684	tr-a-peak@32: 0.250000	tr-rmse: 0.578479	tr-rmse: 0.578479
2024-04-29 00:23:33 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.25865	tr-a-peak@32:0.25000	tr-rmse:0.57851	tr-rmse:0.57851 
2024-04-29 00:23:33 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:23:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1539.1583 |      19.8768 |               39.7536 |     63 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    126 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1348
Total latency (us): 339.12

2024-04-29 00:23:33 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 00:25:43 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:26:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:27:11 [DEBUG] XGB validation: p-rmse: 2.373611	a-peak@32: 0.116939
2024-04-29 00:27:11 [DEBUG] XGB iter   0: tr-p-rmse: 1.532342	tr-a-peak@32: 0.996261	tr-rmse: 0.691219	tr-rmse: 0.691219
2024-04-29 00:27:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.232905	tr-a-peak@32: 0.531250	tr-rmse: 0.574597	tr-rmse: 0.574597
2024-04-29 00:27:12 [DEBUG] XGB iter  50: tr-p-rmse: 0.232905	tr-a-peak@32: 0.531250	tr-rmse: 0.574597	tr-rmse: 0.574597
2024-04-29 00:27:12 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.23289	tr-a-peak@32:0.53125	tr-rmse:0.57461	tr-rmse:0.57461 
2024-04-29 00:27:12 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 00:27:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    126 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1412
Total latency (us): 337.248

2024-04-29 00:27:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 00:29:29 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:29:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:30:27 [DEBUG] XGB validation: p-rmse: 1.523736	a-peak@32: 0.939616
2024-04-29 00:30:28 [DEBUG] XGB iter   0: tr-p-rmse: 1.712890	tr-a-peak@32: 0.997964	tr-rmse: 0.728576	tr-rmse: 0.728576
2024-04-29 00:30:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.276610	tr-a-peak@32: 0.406250	tr-rmse: 0.584933	tr-rmse: 0.584933
2024-04-29 00:30:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.276614	tr-a-peak@32: 0.406250	tr-rmse: 0.584931	tr-rmse: 0.584931
2024-04-29 00:30:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.276614	tr-a-peak@32: 0.406250	tr-rmse: 0.584931	tr-rmse: 0.584931
2024-04-29 00:30:29 [DEBUG] XGB stopped. Best iteration: [25] tr-p-rmse:0.27661	tr-a-peak@32:0.40625	tr-rmse:0.58493	tr-rmse:0.58493 
2024-04-29 00:30:30 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 00:30:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      1946.5304 |      18.2430 |               36.4860 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    126 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1476
Total latency (us): 337.248

2024-04-29 00:30:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 00:32:29 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:32:57 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:33:37 [DEBUG] XGB validation: p-rmse: 0.480833	a-peak@32: 0.768467
2024-04-29 00:33:37 [DEBUG] XGB iter   0: tr-p-rmse: 1.852854	tr-a-peak@32: 0.812500	tr-rmse: 0.753325	tr-rmse: 0.753325
2024-04-29 00:33:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.292272	tr-a-peak@32: 0.000000	tr-rmse: 0.587942	tr-rmse: 0.587942
2024-04-29 00:33:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.292273	tr-a-peak@32: 0.000000	tr-rmse: 0.587942	tr-rmse: 0.587942
2024-04-29 00:33:39 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.29222	tr-a-peak@32:0.00000	tr-rmse:0.58798	tr-rmse:0.58798 
2024-04-29 00:33:39 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 00:33:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2744.4353 |      16.5225 |               33.0450 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    126 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1540
Total latency (us): 333.31

2024-04-29 00:33:39 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 00:35:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:36:31 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:37:08 [DEBUG] XGB validation: p-rmse: 1.058120	a-peak@32: 0.919218
2024-04-29 00:37:10 [DEBUG] XGB iter   0: tr-p-rmse: 1.908000	tr-a-peak@32: 0.689396	tr-rmse: 0.784026	tr-rmse: 0.784026
2024-04-29 00:37:11 [DEBUG] XGB iter  25: tr-p-rmse: 0.292016	tr-a-peak@32: 0.000000	tr-rmse: 0.597505	tr-rmse: 0.597505
2024-04-29 00:37:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.292011	tr-a-peak@32: 0.000000	tr-rmse: 0.597508	tr-rmse: 0.597508
2024-04-29 00:37:12 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.29197	tr-a-peak@32:0.00000	tr-rmse:0.59757	tr-rmse:0.59757 
2024-04-29 00:37:12 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 00:37:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    126 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1604
Total latency (us): 331.732

2024-04-29 00:37:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:37:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:38:07 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:38:45 [DEBUG] XGB validation: p-rmse: 1.681506	a-peak@32: 0.500062
2024-04-29 00:38:45 [DEBUG] XGB iter   0: tr-p-rmse: 1.883858	tr-a-peak@32: 0.842054	tr-rmse: 0.776428	tr-rmse: 0.776428
2024-04-29 00:38:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.268698	tr-a-peak@32: 0.062500	tr-rmse: 0.594175	tr-rmse: 0.594175
2024-04-29 00:38:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.268697	tr-a-peak@32: 0.062500	tr-rmse: 0.594175	tr-rmse: 0.594175
2024-04-29 00:38:47 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.26869	tr-a-peak@32:0.06250	tr-rmse:0.59418	tr-rmse:0.59418 
2024-04-29 00:38:47 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:38:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       935.9092 |      19.3697 |               38.7393 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1668
Total latency (us): 331.732

2024-04-29 00:38:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 00:41:13 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:42:02 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:42:43 [DEBUG] XGB validation: p-rmse: 1.237557	a-peak@32: 0.976061
2024-04-29 00:42:43 [DEBUG] XGB iter   0: tr-p-rmse: 1.874016	tr-a-peak@32: 1.000000	tr-rmse: 0.799618	tr-rmse: 0.799618
2024-04-29 00:42:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.235841	tr-a-peak@32: 0.406201	tr-rmse: 0.601618	tr-rmse: 0.601618
2024-04-29 00:42:45 [DEBUG] XGB iter  50: tr-p-rmse: 0.235842	tr-a-peak@32: 0.406201	tr-rmse: 0.601617	tr-rmse: 0.601617
2024-04-29 00:42:45 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.23560	tr-a-peak@32:0.40620	tr-rmse:0.60214	tr-rmse:0.60214 
2024-04-29 00:42:45 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 00:42:45 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1615.2023 |      18.9410 |               37.8820 |    127 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1732
Total latency (us): 330.098

2024-04-29 00:42:45 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 00:44:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:45:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:46:08 [DEBUG] XGB validation: p-rmse: 0.435052	a-peak@32: 0.964651
2024-04-29 00:46:09 [DEBUG] XGB iter   0: tr-p-rmse: 1.945481	tr-a-peak@32: 0.995477	tr-rmse: 0.811808	tr-rmse: 0.811808
2024-04-29 00:46:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.213086	tr-a-peak@32: 0.656250	tr-rmse: 0.600976	tr-rmse: 0.600976
2024-04-29 00:46:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.213076	tr-a-peak@32: 0.656250	tr-rmse: 0.600982	tr-rmse: 0.600982
2024-04-29 00:46:10 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.21297	tr-a-peak@32:0.65625	tr-rmse:0.60110	tr-rmse:0.60110 
2024-04-29 00:46:10 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 00:46:10 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       445.4432 |      18.6967 |               18.6967 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1796
Total latency (us): 322.314

2024-04-29 00:46:10 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 00:46:33 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:47:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:47:39 [DEBUG] XGB validation: p-rmse: 0.173202	a-peak@32: 0.675054
2024-04-29 00:47:39 [DEBUG] XGB iter   0: tr-p-rmse: 1.969213	tr-a-peak@32: 1.000000	tr-rmse: 0.798714	tr-rmse: 0.798714
2024-04-29 00:47:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.233211	tr-a-peak@32: 0.187134	tr-rmse: 0.596580	tr-rmse: 0.596580
2024-04-29 00:47:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.233207	tr-a-peak@32: 0.187134	tr-rmse: 0.596583	tr-rmse: 0.596583
2024-04-29 00:47:40 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.23312	tr-a-peak@32:0.18713	tr-rmse:0.59664	tr-rmse:0.59664 
2024-04-29 00:47:41 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 00:47:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1860
Total latency (us): 316.004

2024-04-29 00:47:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 00:49:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:50:06 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:50:45 [DEBUG] XGB validation: p-rmse: 0.517771	a-peak@32: 0.863845
2024-04-29 00:50:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.036598	tr-a-peak@32: 1.000000	tr-rmse: 0.813225	tr-rmse: 0.813225
2024-04-29 00:50:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.231374	tr-a-peak@32: 0.281250	tr-rmse: 0.599181	tr-rmse: 0.599181
2024-04-29 00:50:47 [DEBUG] XGB iter  50: tr-p-rmse: 0.231335	tr-a-peak@32: 0.281250	tr-rmse: 0.599208	tr-rmse: 0.599208
2024-04-29 00:50:47 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.23118	tr-a-peak@32:0.28125	tr-rmse:0.59944	tr-rmse:0.59944 
2024-04-29 00:50:47 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 00:50:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2882.1168 |      15.7332 |               31.4664 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1924
Total latency (us): 316.004

2024-04-29 00:50:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 00:52:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:53:16 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:53:56 [DEBUG] XGB validation: p-rmse: 0.669803	a-peak@32: 0.821561
2024-04-29 00:53:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.082352	tr-a-peak@32: 1.000000	tr-rmse: 0.834674	tr-rmse: 0.834674
2024-04-29 00:53:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.211099	tr-a-peak@32: 0.530884	tr-rmse: 0.611758	tr-rmse: 0.611758
2024-04-29 00:53:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.211067	tr-a-peak@32: 0.530884	tr-rmse: 0.611782	tr-rmse: 0.611782
2024-04-29 00:53:58 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21102	tr-a-peak@32:0.53088	tr-rmse:0.61184	tr-rmse:0.61184 
2024-04-29 00:53:58 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 00:53:58 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3733.8031 |      46.4390 |               46.4390 |    190 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1988
Total latency (us): 315.324

2024-04-29 00:53:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:54:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:54:45 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:55:26 [DEBUG] XGB validation: p-rmse: 0.719348	a-peak@32: 0.944684
2024-04-29 00:55:26 [DEBUG] XGB iter   0: tr-p-rmse: 2.061533	tr-a-peak@32: 0.855540	tr-rmse: 0.826816	tr-rmse: 0.826816
2024-04-29 00:55:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.223885	tr-a-peak@32: 0.406250	tr-rmse: 0.608279	tr-rmse: 0.608279
2024-04-29 00:55:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.223764	tr-a-peak@32: 0.406250	tr-rmse: 0.608355	tr-rmse: 0.608355
2024-04-29 00:55:28 [DEBUG] XGB iter  75: tr-p-rmse: 0.223764	tr-a-peak@32: 0.406250	tr-rmse: 0.608355	tr-rmse: 0.608355
2024-04-29 00:55:28 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.22371	tr-a-peak@32:0.40625	tr-rmse:0.60839	tr-rmse:0.60839 
2024-04-29 00:55:28 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 00:55:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |       793.7199 |      15.1068 |               15.1068 |     63 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3941.9167 |      43.9872 |               43.9872 |    254 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2052
Total latency (us): 312.872

2024-04-29 00:55:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 00:55:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:56:25 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:57:04 [DEBUG] XGB validation: p-rmse: 0.602913	a-peak@32: 0.715205
2024-04-29 00:57:04 [DEBUG] XGB iter   0: tr-p-rmse: 2.026694	tr-a-peak@32: 0.994806	tr-rmse: 0.819164	tr-rmse: 0.819164
2024-04-29 00:57:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.223074	tr-a-peak@32: 0.281250	tr-rmse: 0.604810	tr-rmse: 0.604810
2024-04-29 00:57:05 [DEBUG] XGB iter  50: tr-p-rmse: 0.222986	tr-a-peak@32: 0.281250	tr-rmse: 0.604883	tr-rmse: 0.604883
2024-04-29 00:57:06 [DEBUG] XGB iter  75: tr-p-rmse: 0.222986	tr-a-peak@32: 0.281250	tr-rmse: 0.604883	tr-rmse: 0.604883
2024-04-29 00:57:06 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.22296	tr-a-peak@32:0.28125	tr-rmse:0.60492	tr-rmse:0.60492 
2024-04-29 00:57:06 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 00:57:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       839.7200 |       6.6979 |               13.3957 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3941.9167 |      43.9872 |               43.9872 |    254 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2116
Total latency (us): 306.133

2024-04-29 00:57:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 00:57:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 00:57:57 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 00:58:32 [DEBUG] XGB validation: p-rmse: 0.963051	a-peak@32: 0.946395
2024-04-29 00:58:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.026729	tr-a-peak@32: 1.000000	tr-rmse: 0.811853	tr-rmse: 0.811853
2024-04-29 00:58:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.217908	tr-a-peak@32: 0.404899	tr-rmse: 0.608599	tr-rmse: 0.608599
2024-04-29 00:58:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.217872	tr-a-peak@32: 0.404899	tr-rmse: 0.608631	tr-rmse: 0.608631
2024-04-29 00:58:34 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21784	tr-a-peak@32:0.40490	tr-rmse:0.60870	tr-rmse:0.60870 
2024-04-29 00:58:34 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 00:58:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |       977.1141 |      18.5529 |               37.1057 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3941.9167 |      43.9872 |               43.9872 |    254 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2180
Total latency (us): 304.151

2024-04-29 00:58:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:00:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:01:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:02:02 [DEBUG] XGB validation: p-rmse: 0.837675	a-peak@32: 0.863165
2024-04-29 01:02:02 [DEBUG] XGB iter   0: tr-p-rmse: 2.061512	tr-a-peak@32: 1.000000	tr-rmse: 0.804692	tr-rmse: 0.804692
2024-04-29 01:02:03 [DEBUG] XGB iter  25: tr-p-rmse: 0.221271	tr-a-peak@32: 0.375000	tr-rmse: 0.595241	tr-rmse: 0.595241
2024-04-29 01:02:04 [DEBUG] XGB iter  50: tr-p-rmse: 0.221123	tr-a-peak@32: 0.375000	tr-rmse: 0.595276	tr-rmse: 0.595276
2024-04-29 01:02:04 [DEBUG] XGB iter  75: tr-p-rmse: 0.221123	tr-a-peak@32: 0.375000	tr-rmse: 0.595276	tr-rmse: 0.595276
2024-04-29 01:02:04 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.22109	tr-a-peak@32:0.37500	tr-rmse:0.59530	tr-rmse:0.59530 
2024-04-29 01:02:04 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:02:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3941.9167 |      43.9872 |               43.9872 |    254 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2244
Total latency (us): 297.979

2024-04-29 01:02:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:02:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:02:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:03:32 [DEBUG] XGB validation: p-rmse: 0.908465	a-peak@32: 0.890143
2024-04-29 01:03:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.057548	tr-a-peak@32: 1.000000	tr-rmse: 0.800788	tr-rmse: 0.800788
2024-04-29 01:03:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.208314	tr-a-peak@32: 0.593750	tr-rmse: 0.589329	tr-rmse: 0.589329
2024-04-29 01:03:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.208280	tr-a-peak@32: 0.593750	tr-rmse: 0.589353	tr-rmse: 0.589353
2024-04-29 01:03:34 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.20820	tr-a-peak@32:0.59375	tr-rmse:0.58941	tr-rmse:0.58941 
2024-04-29 01:03:35 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:03:35 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2308
Total latency (us): 286.96

2024-04-29 01:03:35 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 01:03:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:04:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:04:59 [DEBUG] XGB validation: p-rmse: 1.024657	a-peak@32: 0.910462
2024-04-29 01:04:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.043827	tr-a-peak@32: 0.995873	tr-rmse: 0.795951	tr-rmse: 0.795951
2024-04-29 01:05:00 [DEBUG] XGB iter  25: tr-p-rmse: 0.259406	tr-a-peak@32: 0.000000	tr-rmse: 0.593715	tr-rmse: 0.593715
2024-04-29 01:05:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.259365	tr-a-peak@32: 0.000000	tr-rmse: 0.593750	tr-rmse: 0.593750
2024-04-29 01:05:01 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.25926	tr-a-peak@32:0.00000	tr-rmse:0.59384	tr-rmse:0.59384 
2024-04-29 01:05:01 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 01:05:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2372
Total latency (us): 286.96

2024-04-29 01:05:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:07:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:07:36 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:08:19 [DEBUG] XGB validation: p-rmse: 1.145467	a-peak@32: 0.962444
2024-04-29 01:08:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.082318	tr-a-peak@32: 1.000000	tr-rmse: 0.807856	tr-rmse: 0.807856
2024-04-29 01:08:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.254430	tr-a-peak@32: 0.000000	tr-rmse: 0.597790	tr-rmse: 0.597790
2024-04-29 01:08:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.254282	tr-a-peak@32: 0.000000	tr-rmse: 0.597883	tr-rmse: 0.597883
2024-04-29 01:08:21 [DEBUG] XGB iter  75: tr-p-rmse: 0.254282	tr-a-peak@32: 0.000000	tr-rmse: 0.597883	tr-rmse: 0.597883
2024-04-29 01:08:21 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.25424	tr-a-peak@32:0.00000	tr-rmse:0.59792	tr-rmse:0.59792 
2024-04-29 01:08:21 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:08:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      2945.7750 |      15.3932 |               30.7864 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2436
Total latency (us): 286.96

2024-04-29 01:08:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:10:16 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:10:58 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:11:36 [DEBUG] XGB validation: p-rmse: 0.712539	a-peak@32: 0.981538
2024-04-29 01:11:36 [DEBUG] XGB iter   0: tr-p-rmse: 2.145184	tr-a-peak@32: 1.000000	tr-rmse: 0.817651	tr-rmse: 0.817651
2024-04-29 01:11:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.201921	tr-a-peak@32: 0.375000	tr-rmse: 0.595639	tr-rmse: 0.595639
2024-04-29 01:11:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.201378	tr-a-peak@32: 0.375000	tr-rmse: 0.595750	tr-rmse: 0.595750
2024-04-29 01:11:38 [DEBUG] XGB iter  75: tr-p-rmse: 0.201378	tr-a-peak@32: 0.375000	tr-rmse: 0.595750	tr-rmse: 0.595750
2024-04-29 01:11:38 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20127	tr-a-peak@32:0.37500	tr-rmse:0.59584	tr-rmse:0.59584 
2024-04-29 01:11:39 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:11:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    191 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2500
Total latency (us): 284.272

2024-04-29 01:11:39 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:13:52 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:14:16 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:14:55 [DEBUG] XGB validation: p-rmse: 0.711371	a-peak@32: 0.978106
2024-04-29 01:14:55 [DEBUG] XGB iter   0: tr-p-rmse: 2.168007	tr-a-peak@32: 1.000000	tr-rmse: 0.826027	tr-rmse: 0.826027
2024-04-29 01:14:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.199781	tr-a-peak@32: 0.500000	tr-rmse: 0.600043	tr-rmse: 0.600043
2024-04-29 01:14:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.199586	tr-a-peak@32: 0.500000	tr-rmse: 0.600166	tr-rmse: 0.600166
2024-04-29 01:14:57 [DEBUG] XGB iter  75: tr-p-rmse: 0.199586	tr-a-peak@32: 0.500000	tr-rmse: 0.600166	tr-rmse: 0.600166
2024-04-29 01:14:57 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.19951	tr-a-peak@32:0.50000	tr-rmse:0.60023	tr-rmse:0.60023 
2024-04-29 01:14:57 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:14:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4407.0633 |      10.0199 |               10.0199 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2564
Total latency (us): 284.272

2024-04-29 01:14:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 01:15:24 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:15:55 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:16:11 [DEBUG] XGB validation: p-rmse: 1.660256	a-peak@32: 0.980923
2024-04-29 01:16:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.129560	tr-a-peak@32: 1.000000	tr-rmse: 0.824557	tr-rmse: 0.824557
2024-04-29 01:16:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.290189	tr-a-peak@32: 0.000000	tr-rmse: 0.600695	tr-rmse: 0.600695
2024-04-29 01:16:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.290078	tr-a-peak@32: 0.000000	tr-rmse: 0.600796	tr-rmse: 0.600796
2024-04-29 01:16:13 [DEBUG] XGB iter  75: tr-p-rmse: 0.290078	tr-a-peak@32: 0.000000	tr-rmse: 0.600796	tr-rmse: 0.600796
2024-04-29 01:16:13 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.29000	tr-a-peak@32:0.00000	tr-rmse:0.60084	tr-rmse:0.60084 
2024-04-29 01:16:14 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 01:16:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2628
Total latency (us): 283.623

2024-04-29 01:16:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 01:16:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:17:03 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:17:09 [DEBUG] XGB validation: p-rmse: 1.281656	a-peak@32: 1.000000
2024-04-29 01:17:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.115551	tr-a-peak@32: 1.000000	tr-rmse: 0.824557	tr-rmse: 0.824557
2024-04-29 01:17:11 [DEBUG] XGB iter  25: tr-p-rmse: 0.329982	tr-a-peak@32: 0.000000	tr-rmse: 0.600695	tr-rmse: 0.600695
2024-04-29 01:17:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.329859	tr-a-peak@32: 0.000000	tr-rmse: 0.600796	tr-rmse: 0.600796
2024-04-29 01:17:11 [DEBUG] XGB iter  75: tr-p-rmse: 0.329859	tr-a-peak@32: 0.000000	tr-rmse: 0.600796	tr-rmse: 0.600796
2024-04-29 01:17:11 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.32978	tr-a-peak@32:0.00000	tr-rmse:0.60084	tr-rmse:0.60084 
2024-04-29 01:17:12 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 01:17:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       669.3432 |       8.9918 |                8.9918 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2692
Total latency (us): 283.623

2024-04-29 01:17:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 01:17:38 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:18:04 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:18:35 [DEBUG] XGB validation: p-rmse: 1.296021	a-peak@32: 0.248741
2024-04-29 01:18:35 [DEBUG] XGB iter   0: tr-p-rmse: 2.103363	tr-a-peak@32: 0.989458	tr-rmse: 0.821828	tr-rmse: 0.821828
2024-04-29 01:18:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.289839	tr-a-peak@32: 0.000000	tr-rmse: 0.596409	tr-rmse: 0.596409
2024-04-29 01:18:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.289757	tr-a-peak@32: 0.000000	tr-rmse: 0.596508	tr-rmse: 0.596508
2024-04-29 01:18:38 [DEBUG] XGB iter  75: tr-p-rmse: 0.289757	tr-a-peak@32: 0.000000	tr-rmse: 0.596508	tr-rmse: 0.596508
2024-04-29 01:18:38 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.28969	tr-a-peak@32:0.00000	tr-rmse:0.59656	tr-rmse:0.59656 
2024-04-29 01:18:38 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 01:18:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2756
Total latency (us): 281.193

2024-04-29 01:18:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 01:19:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:19:25 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:20:04 [DEBUG] XGB validation: p-rmse: 1.403726	a-peak@32: 0.989684
2024-04-29 01:20:04 [DEBUG] XGB iter   0: tr-p-rmse: 2.086853	tr-a-peak@32: 0.968750	tr-rmse: 0.815927	tr-rmse: 0.815927
2024-04-29 01:20:06 [DEBUG] XGB iter  25: tr-p-rmse: 0.256726	tr-a-peak@32: 0.000000	tr-rmse: 0.593570	tr-rmse: 0.593570
2024-04-29 01:20:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.256275	tr-a-peak@32: 0.000000	tr-rmse: 0.593642	tr-rmse: 0.593642
2024-04-29 01:20:07 [DEBUG] XGB iter  75: tr-p-rmse: 0.256275	tr-a-peak@32: 0.000000	tr-rmse: 0.593642	tr-rmse: 0.593642
2024-04-29 01:20:07 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.25626	tr-a-peak@32:0.00000	tr-rmse:0.59365	tr-rmse:0.59365 
2024-04-29 01:20:07 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 01:20:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2820
Total latency (us): 281.193

2024-04-29 01:20:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:22:11 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:23:02 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:23:42 [DEBUG] XGB validation: p-rmse: 0.683026	a-peak@32: 0.722747
2024-04-29 01:23:42 [DEBUG] XGB iter   0: tr-p-rmse: 2.121993	tr-a-peak@32: 0.968750	tr-rmse: 0.821198	tr-rmse: 0.821198
2024-04-29 01:23:44 [DEBUG] XGB iter  25: tr-p-rmse: 0.264524	tr-a-peak@32: 0.000000	tr-rmse: 0.593103	tr-rmse: 0.593103
2024-04-29 01:23:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.264394	tr-a-peak@32: 0.000000	tr-rmse: 0.593222	tr-rmse: 0.593222
2024-04-29 01:23:45 [DEBUG] XGB iter  75: tr-p-rmse: 0.264394	tr-a-peak@32: 0.000000	tr-rmse: 0.593222	tr-rmse: 0.593222
2024-04-29 01:23:45 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.26434	tr-a-peak@32:0.00000	tr-rmse:0.59328	tr-rmse:0.59328 
2024-04-29 01:23:45 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:23:45 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2884
Total latency (us): 281.193

2024-04-29 01:23:45 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:26:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:26:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:27:07 [DEBUG] XGB validation: p-rmse: 1.025734	a-peak@32: 0.616798
2024-04-29 01:27:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.136326	tr-a-peak@32: 1.000000	tr-rmse: 0.821697	tr-rmse: 0.821697
2024-04-29 01:27:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.231233	tr-a-peak@32: 0.000000	tr-rmse: 0.590678	tr-rmse: 0.590678
2024-04-29 01:27:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.231051	tr-a-peak@32: 0.000000	tr-rmse: 0.590824	tr-rmse: 0.590824
2024-04-29 01:27:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.231051	tr-a-peak@32: 0.000000	tr-rmse: 0.590824	tr-rmse: 0.590824
2024-04-29 01:27:09 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.23096	tr-a-peak@32:0.00000	tr-rmse:0.59090	tr-rmse:0.59090 
2024-04-29 01:27:09 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:27:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2032.9525 |      15.0488 |               30.0976 |    255 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2948
Total latency (us): 281.193

2024-04-29 01:27:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:29:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:29:51 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:30:31 [DEBUG] XGB validation: p-rmse: 0.633663	a-peak@32: 0.831744
2024-04-29 01:30:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.165558	tr-a-peak@32: 1.000000	tr-rmse: 0.831334	tr-rmse: 0.831334
2024-04-29 01:30:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.235738	tr-a-peak@32: 0.000000	tr-rmse: 0.593598	tr-rmse: 0.593598
2024-04-29 01:30:33 [DEBUG] XGB iter  50: tr-p-rmse: 0.234937	tr-a-peak@32: 0.000000	tr-rmse: 0.593765	tr-rmse: 0.593765
2024-04-29 01:30:33 [DEBUG] XGB iter  75: tr-p-rmse: 0.234937	tr-a-peak@32: 0.000000	tr-rmse: 0.593765	tr-rmse: 0.593765
2024-04-29 01:30:33 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.23490	tr-a-peak@32:0.00000	tr-rmse:0.59379	tr-rmse:0.59379 
2024-04-29 01:30:33 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:30:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5259.2856 |      32.9691 |               32.9691 |    318 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3012
Total latency (us): 280.992

2024-04-29 01:30:33 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:30:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:31:19 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:31:59 [DEBUG] XGB validation: p-rmse: 0.708715	a-peak@32: 0.652459
2024-04-29 01:31:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.161498	tr-a-peak@32: 1.000000	tr-rmse: 0.827179	tr-rmse: 0.827179
2024-04-29 01:32:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.218149	tr-a-peak@32: 0.031250	tr-rmse: 0.594646	tr-rmse: 0.594646
2024-04-29 01:32:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.217119	tr-a-peak@32: 0.031250	tr-rmse: 0.594783	tr-rmse: 0.594783
2024-04-29 01:32:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.217119	tr-a-peak@32: 0.031250	tr-rmse: 0.594783	tr-rmse: 0.594783
2024-04-29 01:32:02 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.21708	tr-a-peak@32:0.03125	tr-rmse:0.59481	tr-rmse:0.59481 
2024-04-29 01:32:02 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:32:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3076
Total latency (us): 280.406

2024-04-29 01:32:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:34:07 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:34:31 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:35:11 [DEBUG] XGB validation: p-rmse: 0.640435	a-peak@32: 0.961487
2024-04-29 01:35:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.176330	tr-a-peak@32: 1.000000	tr-rmse: 0.835076	tr-rmse: 0.835076
2024-04-29 01:35:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.208928	tr-a-peak@32: 0.057882	tr-rmse: 0.599071	tr-rmse: 0.599071
2024-04-29 01:35:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.207644	tr-a-peak@32: 0.062500	tr-rmse: 0.599201	tr-rmse: 0.599201
2024-04-29 01:35:14 [DEBUG] XGB iter  75: tr-p-rmse: 0.207644	tr-a-peak@32: 0.062500	tr-rmse: 0.599201	tr-rmse: 0.599201
2024-04-29 01:35:14 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.20760	tr-a-peak@32:0.06250	tr-rmse:0.59923	tr-rmse:0.59923 
2024-04-29 01:35:14 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:35:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1685.4517 |       7.4088 |                7.4088 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3140
Total latency (us): 280.406

2024-04-29 01:35:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 01:35:40 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:36:05 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:36:43 [DEBUG] XGB validation: p-rmse: 0.888875	a-peak@32: 0.931719
2024-04-29 01:36:43 [DEBUG] XGB iter   0: tr-p-rmse: 2.172538	tr-a-peak@32: 1.000000	tr-rmse: 0.829686	tr-rmse: 0.829686
2024-04-29 01:36:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.210437	tr-a-peak@32: 0.125000	tr-rmse: 0.598027	tr-rmse: 0.598027
2024-04-29 01:36:45 [DEBUG] XGB iter  50: tr-p-rmse: 0.209750	tr-a-peak@32: 0.125000	tr-rmse: 0.598170	tr-rmse: 0.598170
2024-04-29 01:36:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.209750	tr-a-peak@32: 0.125000	tr-rmse: 0.598170	tr-rmse: 0.598170
2024-04-29 01:36:46 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20967	tr-a-peak@32:0.12500	tr-rmse:0.59827	tr-rmse:0.59827 
2024-04-29 01:36:46 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 01:36:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       604.3784 |       6.8989 |                6.8989 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3204
Total latency (us): 280.298

2024-04-29 01:36:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 01:37:13 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:37:37 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:38:14 [DEBUG] XGB validation: p-rmse: 0.588927	a-peak@32: 0.718706
2024-04-29 01:38:14 [DEBUG] XGB iter   0: tr-p-rmse: 2.175959	tr-a-peak@32: 1.000000	tr-rmse: 0.825524	tr-rmse: 0.825524
2024-04-29 01:38:15 [DEBUG] XGB iter  25: tr-p-rmse: 0.221731	tr-a-peak@32: 0.000000	tr-rmse: 0.595669	tr-rmse: 0.595669
2024-04-29 01:38:16 [DEBUG] XGB iter  50: tr-p-rmse: 0.221469	tr-a-peak@32: 0.000000	tr-rmse: 0.595784	tr-rmse: 0.595784
2024-04-29 01:38:16 [DEBUG] XGB iter  75: tr-p-rmse: 0.221469	tr-a-peak@32: 0.000000	tr-rmse: 0.595784	tr-rmse: 0.595784
2024-04-29 01:38:16 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.22145	tr-a-peak@32:0.00000	tr-rmse:0.59580	tr-rmse:0.59580 
2024-04-29 01:38:16 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 01:38:16 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1172.0920 |      15.4666 |               30.9332 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3268
Total latency (us): 280.207

2024-04-29 01:38:16 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:40:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:41:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:41:39 [DEBUG] XGB validation: p-rmse: 0.968277	a-peak@32: 0.633272
2024-04-29 01:41:39 [DEBUG] XGB iter   0: tr-p-rmse: 2.187137	tr-a-peak@32: 1.000000	tr-rmse: 0.829711	tr-rmse: 0.829711
2024-04-29 01:41:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.227058	tr-a-peak@32: 0.000000	tr-rmse: 0.597199	tr-rmse: 0.597199
2024-04-29 01:41:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.226484	tr-a-peak@32: 0.000000	tr-rmse: 0.597306	tr-rmse: 0.597306
2024-04-29 01:41:42 [DEBUG] XGB iter  75: tr-p-rmse: 0.226484	tr-a-peak@32: 0.000000	tr-rmse: 0.597306	tr-rmse: 0.597306
2024-04-29 01:41:42 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.22646	tr-a-peak@32:0.00000	tr-rmse:0.59733	tr-rmse:0.59733 
2024-04-29 01:41:42 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 01:41:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2046.5713 |      14.9487 |               29.8974 |    319 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3332
Total latency (us): 279.185

2024-04-29 01:41:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:43:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:44:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:45:01 [DEBUG] XGB validation: p-rmse: 0.414298	a-peak@32: 0.859998
2024-04-29 01:45:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.210935	tr-a-peak@32: 1.000000	tr-rmse: 0.831964	tr-rmse: 0.831964
2024-04-29 01:45:03 [DEBUG] XGB iter  25: tr-p-rmse: 0.207787	tr-a-peak@32: 0.250000	tr-rmse: 0.594975	tr-rmse: 0.594975
2024-04-29 01:45:03 [DEBUG] XGB iter  50: tr-p-rmse: 0.207405	tr-a-peak@32: 0.250000	tr-rmse: 0.595115	tr-rmse: 0.595115
2024-04-29 01:45:04 [DEBUG] XGB iter  75: tr-p-rmse: 0.207405	tr-a-peak@32: 0.250000	tr-rmse: 0.595115	tr-rmse: 0.595115
2024-04-29 01:45:04 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20728	tr-a-peak@32:0.25000	tr-rmse:0.59521	tr-rmse:0.59521 
2024-04-29 01:45:04 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 01:45:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3396
Total latency (us): 276.833

2024-04-29 01:45:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:45:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:45:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:46:33 [DEBUG] XGB validation: p-rmse: 0.243026	a-peak@32: 0.930217
2024-04-29 01:46:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.186662	tr-a-peak@32: 1.000000	tr-rmse: 0.826806	tr-rmse: 0.826806
2024-04-29 01:46:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.186955	tr-a-peak@32: 0.687500	tr-rmse: 0.599367	tr-rmse: 0.599367
2024-04-29 01:46:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.185873	tr-a-peak@32: 0.687500	tr-rmse: 0.599457	tr-rmse: 0.599457
2024-04-29 01:46:36 [DEBUG] XGB iter  75: tr-p-rmse: 0.185873	tr-a-peak@32: 0.687500	tr-rmse: 0.599457	tr-rmse: 0.599457
2024-04-29 01:46:36 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.18584	tr-a-peak@32:0.68750	tr-rmse:0.59948	tr-rmse:0.59948 
2024-04-29 01:46:36 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:46:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2182.0339 |      16.2740 |               32.5481 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3460
Total latency (us): 276.833

2024-04-29 01:46:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:48:42 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:49:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:49:50 [DEBUG] XGB validation: p-rmse: 0.154279	a-peak@32: 0.940519
2024-04-29 01:49:51 [DEBUG] XGB iter   0: tr-p-rmse: 2.204484	tr-a-peak@32: 1.000000	tr-rmse: 0.826587	tr-rmse: 0.826587
2024-04-29 01:49:52 [DEBUG] XGB iter  25: tr-p-rmse: 0.195517	tr-a-peak@32: 0.343750	tr-rmse: 0.598054	tr-rmse: 0.598054
2024-04-29 01:49:53 [DEBUG] XGB iter  50: tr-p-rmse: 0.195152	tr-a-peak@32: 0.343750	tr-rmse: 0.598179	tr-rmse: 0.598179
2024-04-29 01:49:53 [DEBUG] XGB iter  75: tr-p-rmse: 0.195152	tr-a-peak@32: 0.343750	tr-rmse: 0.598179	tr-rmse: 0.598179
2024-04-29 01:49:53 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.19513	tr-a-peak@32:0.34375	tr-rmse:0.59820	tr-rmse:0.59820 
2024-04-29 01:49:53 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 01:49:53 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       672.3799 |      12.3863 |               12.3863 |    128 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3524
Total latency (us): 272.253

2024-04-29 01:49:53 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 01:50:16 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:50:38 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:51:17 [DEBUG] XGB validation: p-rmse: 0.499341	a-peak@32: 0.989348
2024-04-29 01:51:17 [DEBUG] XGB iter   0: tr-p-rmse: 2.199536	tr-a-peak@32: 1.000000	tr-rmse: 0.822463	tr-rmse: 0.822463
2024-04-29 01:51:18 [DEBUG] XGB iter  25: tr-p-rmse: 0.217757	tr-a-peak@32: 0.031250	tr-rmse: 0.595803	tr-rmse: 0.595803
2024-04-29 01:51:19 [DEBUG] XGB iter  50: tr-p-rmse: 0.217148	tr-a-peak@32: 0.062500	tr-rmse: 0.595903	tr-rmse: 0.595903
2024-04-29 01:51:19 [DEBUG] XGB iter  75: tr-p-rmse: 0.217148	tr-a-peak@32: 0.062500	tr-rmse: 0.595903	tr-rmse: 0.595903
2024-04-29 01:51:19 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.21713	tr-a-peak@32:0.06250	tr-rmse:0.59592	tr-rmse:0.59592 
2024-04-29 01:51:19 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 01:51:19 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3588
Total latency (us): 271.484

2024-04-29 01:51:19 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-04-29 01:51:24 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 01:51:24 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 01:51:24 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-04-29 01:51:24 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1038.6034 |       6.0581 |                6.0581 |     64 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3588
Total latency (us): 271.484

2024-04-29 01:51:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 01:51:50 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:52:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:52:48 [DEBUG] XGB validation: p-rmse: 0.946068	a-peak@32: 0.733499
2024-04-29 01:52:48 [DEBUG] XGB iter   0: tr-p-rmse: 2.167311	tr-a-peak@32: 1.000000	tr-rmse: 0.817491	tr-rmse: 0.817491
2024-04-29 01:52:49 [DEBUG] XGB iter  25: tr-p-rmse: 0.206453	tr-a-peak@32: 0.000000	tr-rmse: 0.592356	tr-rmse: 0.592356
2024-04-29 01:52:50 [DEBUG] XGB iter  50: tr-p-rmse: 0.205478	tr-a-peak@32: 0.000000	tr-rmse: 0.592515	tr-rmse: 0.592515
2024-04-29 01:52:50 [DEBUG] XGB iter  75: tr-p-rmse: 0.205478	tr-a-peak@32: 0.000000	tr-rmse: 0.592515	tr-rmse: 0.592515
2024-04-29 01:52:50 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.20544	tr-a-peak@32:0.00000	tr-rmse:0.59255	tr-rmse:0.59255 
2024-04-29 01:52:50 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 01:52:50 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3652
Total latency (us): 271.48

2024-04-29 01:52:50 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:54:44 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:55:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:55:48 [DEBUG] XGB validation: p-rmse: 0.804393	a-peak@32: 0.959522
2024-04-29 01:55:48 [DEBUG] XGB iter   0: tr-p-rmse: 2.188179	tr-a-peak@32: 1.000000	tr-rmse: 0.828177	tr-rmse: 0.828177
2024-04-29 01:55:50 [DEBUG] XGB iter  25: tr-p-rmse: 0.195571	tr-a-peak@32: 0.000000	tr-rmse: 0.599436	tr-rmse: 0.599436
2024-04-29 01:55:50 [DEBUG] XGB iter  50: tr-p-rmse: 0.195409	tr-a-peak@32: 0.000000	tr-rmse: 0.599546	tr-rmse: 0.599546
2024-04-29 01:55:51 [DEBUG] XGB iter  75: tr-p-rmse: 0.195409	tr-a-peak@32: 0.000000	tr-rmse: 0.599546	tr-rmse: 0.599546
2024-04-29 01:55:51 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.19533	tr-a-peak@32:0.00000	tr-rmse:0.59961	tr-rmse:0.59961 
2024-04-29 01:55:51 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 01:55:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |       985.5242 |       5.7069 |               11.4139 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3716
Total latency (us): 271.48

2024-04-29 01:55:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 01:56:15 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:56:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:57:24 [DEBUG] XGB validation: p-rmse: 0.638915	a-peak@32: 0.933358
2024-04-29 01:57:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.189467	tr-a-peak@32: 1.000000	tr-rmse: 0.824536	tr-rmse: 0.824536
2024-04-29 01:57:26 [DEBUG] XGB iter  25: tr-p-rmse: 0.186985	tr-a-peak@32: 0.218750	tr-rmse: 0.600099	tr-rmse: 0.600099
2024-04-29 01:57:26 [DEBUG] XGB iter  50: tr-p-rmse: 0.185538	tr-a-peak@32: 0.218750	tr-rmse: 0.600232	tr-rmse: 0.600232
2024-04-29 01:57:27 [DEBUG] XGB iter  75: tr-p-rmse: 0.185538	tr-a-peak@32: 0.218750	tr-rmse: 0.600232	tr-rmse: 0.600232
2024-04-29 01:57:27 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.18550	tr-a-peak@32:0.21875	tr-rmse:0.60026	tr-rmse:0.60026 
2024-04-29 01:57:27 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 01:57:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1089.6297 |       5.6520 |               11.3040 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3780
Total latency (us): 271.272

2024-04-29 01:57:27 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 01:57:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 01:58:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 01:59:02 [DEBUG] XGB validation: p-rmse: 0.771897	a-peak@32: 0.939572
2024-04-29 01:59:02 [DEBUG] XGB iter   0: tr-p-rmse: 2.179251	tr-a-peak@32: 0.973792	tr-rmse: 0.821193	tr-rmse: 0.821193
2024-04-29 01:59:03 [DEBUG] XGB iter  25: tr-p-rmse: 0.174956	tr-a-peak@32: 0.843750	tr-rmse: 0.599486	tr-rmse: 0.599486
2024-04-29 01:59:04 [DEBUG] XGB iter  50: tr-p-rmse: 0.174545	tr-a-peak@32: 0.843750	tr-rmse: 0.599660	tr-rmse: 0.599660
2024-04-29 01:59:04 [DEBUG] XGB iter  75: tr-p-rmse: 0.174545	tr-a-peak@32: 0.843750	tr-rmse: 0.599660	tr-rmse: 0.599660
2024-04-29 01:59:04 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.17449	tr-a-peak@32:0.84375	tr-rmse:0.59977	tr-rmse:0.59977 
2024-04-29 01:59:04 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 01:59:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3844
Total latency (us): 268.849

2024-04-29 01:59:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 01:59:28 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 01:59:53 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 02:00:33 [DEBUG] XGB validation: p-rmse: 1.176091	a-peak@32: 0.601164
2024-04-29 02:00:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.178406	tr-a-peak@32: 0.980545	tr-rmse: 0.817733	tr-rmse: 0.817733
2024-04-29 02:00:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.202962	tr-a-peak@32: 0.000000	tr-rmse: 0.598012	tr-rmse: 0.598012
2024-04-29 02:00:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.202673	tr-a-peak@32: 0.000000	tr-rmse: 0.598152	tr-rmse: 0.598152
2024-04-29 02:00:35 [DEBUG] XGB iter  75: tr-p-rmse: 0.202673	tr-a-peak@32: 0.000000	tr-rmse: 0.598152	tr-rmse: 0.598152
2024-04-29 02:00:36 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.20264	tr-a-peak@32:0.00000	tr-rmse:0.59817	tr-rmse:0.59817 
2024-04-29 02:00:36 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:00:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1212.1203 |      14.9558 |               29.9116 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3907
Total latency (us): 268.849

2024-04-29 02:00:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:02:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:03:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:03:59 [DEBUG] XGB validation: p-rmse: 1.875077	a-peak@32: 0.198938
2024-04-29 02:03:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.164327	tr-a-peak@32: 1.000000	tr-rmse: 0.817705	tr-rmse: 0.817705
2024-04-29 02:04:00 [DEBUG] XGB iter  25: tr-p-rmse: 0.187146	tr-a-peak@32: 0.531250	tr-rmse: 0.597350	tr-rmse: 0.597350
2024-04-29 02:04:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.186892	tr-a-peak@32: 0.531250	tr-rmse: 0.597496	tr-rmse: 0.597496
2024-04-29 02:04:01 [DEBUG] XGB iter  75: tr-p-rmse: 0.186892	tr-a-peak@32: 0.531250	tr-rmse: 0.597496	tr-rmse: 0.597496
2024-04-29 02:04:01 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.18679	tr-a-peak@32:0.53125	tr-rmse:0.59760	tr-rmse:0.59760 
2024-04-29 02:04:01 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:04:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3971
Total latency (us): 268.446

2024-04-29 02:04:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-04-29 02:04:06 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 02:04:06 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 02:04:06 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-04-29 02:04:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2539.4105 |      13.9838 |               27.9675 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3971
Total latency (us): 268.446

2024-04-29 02:04:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:06:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:06:32 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:07:11 [DEBUG] XGB validation: p-rmse: 0.300402	a-peak@32: 0.842680
2024-04-29 02:07:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.196553	tr-a-peak@32: 0.954337	tr-rmse: 0.828504	tr-rmse: 0.828504
2024-04-29 02:07:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.185241	tr-a-peak@32: 0.406250	tr-rmse: 0.603235	tr-rmse: 0.603235
2024-04-29 02:07:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.184287	tr-a-peak@32: 0.375000	tr-rmse: 0.603408	tr-rmse: 0.603408
2024-04-29 02:07:13 [DEBUG] XGB iter  75: tr-p-rmse: 0.184287	tr-a-peak@32: 0.375000	tr-rmse: 0.603408	tr-rmse: 0.603408
2024-04-29 02:07:13 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.18425	tr-a-peak@32:0.37500	tr-rmse:0.60344	tr-rmse:0.60344 
2024-04-29 02:07:14 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:07:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       626.5047 |       9.9700 |                9.9700 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4035
Total latency (us): 267.3

2024-04-29 02:07:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 02:07:40 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:08:05 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:08:42 [DEBUG] XGB validation: p-rmse: 0.505631	a-peak@32: 1.000000
2024-04-29 02:08:42 [DEBUG] XGB iter   0: tr-p-rmse: 2.160436	tr-a-peak@32: 1.000000	tr-rmse: 0.824841	tr-rmse: 0.824841
2024-04-29 02:08:44 [DEBUG] XGB iter  25: tr-p-rmse: 0.179635	tr-a-peak@32: 0.718750	tr-rmse: 0.601380	tr-rmse: 0.601380
2024-04-29 02:08:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.178776	tr-a-peak@32: 0.718750	tr-rmse: 0.601544	tr-rmse: 0.601544
2024-04-29 02:08:45 [DEBUG] XGB iter  75: tr-p-rmse: 0.178776	tr-a-peak@32: 0.718750	tr-rmse: 0.601544	tr-rmse: 0.601544
2024-04-29 02:08:45 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.17874	tr-a-peak@32:0.71875	tr-rmse:0.60157	tr-rmse:0.60157 
2024-04-29 02:08:45 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 02:08:45 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3227.6380 |      14.0489 |               28.0979 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4099
Total latency (us): 264.45

2024-04-29 02:08:45 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:10:45 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:11:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:12:11 [DEBUG] XGB validation: p-rmse: 0.944933	a-peak@32: 0.804740
2024-04-29 02:12:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.170928	tr-a-peak@32: 1.000000	tr-rmse: 0.828099	tr-rmse: 0.828099
2024-04-29 02:12:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.184273	tr-a-peak@32: 0.625000	tr-rmse: 0.602551	tr-rmse: 0.602551
2024-04-29 02:12:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.183614	tr-a-peak@32: 0.625000	tr-rmse: 0.602723	tr-rmse: 0.602723
2024-04-29 02:12:13 [DEBUG] XGB iter  75: tr-p-rmse: 0.183614	tr-a-peak@32: 0.625000	tr-rmse: 0.602723	tr-rmse: 0.602723
2024-04-29 02:12:13 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.18357	tr-a-peak@32:0.62500	tr-rmse:0.60276	tr-rmse:0.60276 
2024-04-29 02:12:14 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:12:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2221.3371 |      13.7726 |               27.5452 |    383 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4163
Total latency (us): 264.036

2024-04-29 02:12:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:14:38 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:15:02 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:15:39 [DEBUG] XGB validation: p-rmse: 0.454941	a-peak@32: 0.957641
2024-04-29 02:15:39 [DEBUG] XGB iter   0: tr-p-rmse: 2.175472	tr-a-peak@32: 1.000000	tr-rmse: 0.839889	tr-rmse: 0.839889
2024-04-29 02:15:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.198721	tr-a-peak@32: 0.187500	tr-rmse: 0.611692	tr-rmse: 0.611692
2024-04-29 02:15:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.197765	tr-a-peak@32: 0.156250	tr-rmse: 0.611857	tr-rmse: 0.611857
2024-04-29 02:15:41 [DEBUG] XGB iter  75: tr-p-rmse: 0.197765	tr-a-peak@32: 0.156250	tr-rmse: 0.611857	tr-rmse: 0.611857
2024-04-29 02:15:42 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.19771	tr-a-peak@32:0.15625	tr-rmse:0.61190	tr-rmse:0.61190 
2024-04-29 02:15:42 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:15:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4227
Total latency (us): 263.989

2024-04-29 02:15:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 02:16:10 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:16:34 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:16:52 [DEBUG] XGB validation: p-rmse: 1.997717	a-peak@32: 0.624566
2024-04-29 02:16:53 [DEBUG] XGB iter   0: tr-p-rmse: 2.167311	tr-a-peak@32: 0.973792	tr-rmse: 0.839678	tr-rmse: 0.839678
2024-04-29 02:16:54 [DEBUG] XGB iter  25: tr-p-rmse: 0.226260	tr-a-peak@32: 0.000000	tr-rmse: 0.611517	tr-rmse: 0.611517
2024-04-29 02:16:55 [DEBUG] XGB iter  50: tr-p-rmse: 0.224840	tr-a-peak@32: 0.000000	tr-rmse: 0.611674	tr-rmse: 0.611674
2024-04-29 02:16:55 [DEBUG] XGB iter  75: tr-p-rmse: 0.224840	tr-a-peak@32: 0.000000	tr-rmse: 0.611674	tr-rmse: 0.611674
2024-04-29 02:16:55 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.22482	tr-a-peak@32:0.00000	tr-rmse:0.61169	tr-rmse:0.61169 
2024-04-29 02:16:56 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 02:16:56 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    128 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4291
Total latency (us): 263.989

2024-04-29 02:16:56 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 02:17:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:17:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:17:54 [DEBUG] XGB validation: p-rmse: 1.167196	a-peak@32: 1.000000
2024-04-29 02:17:54 [DEBUG] XGB iter   0: tr-p-rmse: 2.157427	tr-a-peak@32: 0.973792	tr-rmse: 0.839678	tr-rmse: 0.839678
2024-04-29 02:17:55 [DEBUG] XGB iter  25: tr-p-rmse: 0.252091	tr-a-peak@32: 0.000000	tr-rmse: 0.611468	tr-rmse: 0.611468
2024-04-29 02:17:56 [DEBUG] XGB iter  50: tr-p-rmse: 0.250952	tr-a-peak@32: 0.000000	tr-rmse: 0.611607	tr-rmse: 0.611607
2024-04-29 02:17:56 [DEBUG] XGB iter  75: tr-p-rmse: 0.250952	tr-a-peak@32: 0.000000	tr-rmse: 0.611607	tr-rmse: 0.611607
2024-04-29 02:17:56 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.25089	tr-a-peak@32:0.00000	tr-rmse:0.61166	tr-rmse:0.61166 
2024-04-29 02:17:57 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 02:17:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4355
Total latency (us): 263.989

2024-04-29 02:17:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:20:12 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:20:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:21:08 [DEBUG] XGB validation: p-rmse: 1.546483	a-peak@32: 0.020343
2024-04-29 02:21:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.175838	tr-a-peak@32: 1.000000	tr-rmse: 0.839349	tr-rmse: 0.839349
2024-04-29 02:21:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.226272	tr-a-peak@32: 0.000000	tr-rmse: 0.609436	tr-rmse: 0.609436
2024-04-29 02:21:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.225556	tr-a-peak@32: 0.000000	tr-rmse: 0.609662	tr-rmse: 0.609662
2024-04-29 02:21:11 [DEBUG] XGB iter  75: tr-p-rmse: 0.225556	tr-a-peak@32: 0.000000	tr-rmse: 0.609662	tr-rmse: 0.609662
2024-04-29 02:21:11 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.22547	tr-a-peak@32:0.00000	tr-rmse:0.60971	tr-rmse:0.60971 
2024-04-29 02:21:12 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:21:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4419
Total latency (us): 263.989

2024-04-29 02:21:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:23:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:23:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:24:03 [DEBUG] XGB validation: p-rmse: 0.365169	a-peak@32: 0.839822
2024-04-29 02:24:03 [DEBUG] XGB iter   0: tr-p-rmse: 2.186036	tr-a-peak@32: 1.000000	tr-rmse: 0.851492	tr-rmse: 0.851492
2024-04-29 02:24:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.212177	tr-a-peak@32: 0.218750	tr-rmse: 0.619205	tr-rmse: 0.619205
2024-04-29 02:24:05 [DEBUG] XGB iter  50: tr-p-rmse: 0.211063	tr-a-peak@32: 0.218750	tr-rmse: 0.619372	tr-rmse: 0.619372
2024-04-29 02:24:06 [DEBUG] XGB iter  75: tr-p-rmse: 0.211063	tr-a-peak@32: 0.218750	tr-rmse: 0.619372	tr-rmse: 0.619372
2024-04-29 02:24:06 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.21097	tr-a-peak@32:0.21875	tr-rmse:0.61943	tr-rmse:0.61943 
2024-04-29 02:24:06 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:24:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1432.9189 |       8.3679 |                8.3679 |    127 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4483
Total latency (us): 263.989

2024-04-29 02:24:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 02:24:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:24:58 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:25:36 [DEBUG] XGB validation: p-rmse: 0.646365	a-peak@32: 0.862511
2024-04-29 02:25:36 [DEBUG] XGB iter   0: tr-p-rmse: 2.173626	tr-a-peak@32: 1.000000	tr-rmse: 0.848585	tr-rmse: 0.848585
2024-04-29 02:25:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.207455	tr-a-peak@32: 0.656250	tr-rmse: 0.619460	tr-rmse: 0.619460
2024-04-29 02:25:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.206692	tr-a-peak@32: 0.687500	tr-rmse: 0.619635	tr-rmse: 0.619635
2024-04-29 02:25:39 [DEBUG] XGB iter  75: tr-p-rmse: 0.206692	tr-a-peak@32: 0.687500	tr-rmse: 0.619635	tr-rmse: 0.619635
2024-04-29 02:25:39 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.20663	tr-a-peak@32:0.68750	tr-rmse:0.61967	tr-rmse:0.61967 
2024-04-29 02:25:39 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 02:25:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    447 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4547
Total latency (us): 263.596

2024-04-29 02:25:39 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:28:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:28:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:29:06 [DEBUG] XGB validation: p-rmse: 0.841840	a-peak@32: 0.994272
2024-04-29 02:29:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.197107	tr-a-peak@32: 1.000000	tr-rmse: 0.850051	tr-rmse: 0.850051
2024-04-29 02:29:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.209607	tr-a-peak@32: 0.250000	tr-rmse: 0.619986	tr-rmse: 0.619986
2024-04-29 02:29:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.208538	tr-a-peak@32: 0.312500	tr-rmse: 0.620184	tr-rmse: 0.620184
2024-04-29 02:29:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.208538	tr-a-peak@32: 0.312500	tr-rmse: 0.620184	tr-rmse: 0.620184
2024-04-29 02:29:09 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.20852	tr-a-peak@32:0.31250	tr-rmse:0.62022	tr-rmse:0.62022 
2024-04-29 02:29:09 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:29:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    509 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4611
Total latency (us): 263.596

2024-04-29 02:29:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:29:33 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:30:13 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:30:55 [DEBUG] XGB validation: p-rmse: 0.314341	a-peak@32: 0.908672
2024-04-29 02:30:55 [DEBUG] XGB iter   0: tr-p-rmse: 2.179011	tr-a-peak@32: 1.000000	tr-rmse: 0.846546	tr-rmse: 0.846546
2024-04-29 02:30:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.221750	tr-a-peak@32: 0.000000	tr-rmse: 0.620540	tr-rmse: 0.620540
2024-04-29 02:30:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.220441	tr-a-peak@32: 0.000000	tr-rmse: 0.620698	tr-rmse: 0.620698
2024-04-29 02:30:58 [DEBUG] XGB iter  75: tr-p-rmse: 0.220441	tr-a-peak@32: 0.000000	tr-rmse: 0.620698	tr-rmse: 0.620698
2024-04-29 02:30:58 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.22043	tr-a-peak@32:0.00000	tr-rmse:0.62071	tr-rmse:0.62071 
2024-04-29 02:30:58 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:30:58 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4675
Total latency (us): 263.596

2024-04-29 02:30:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:32:53 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:33:17 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:33:56 [DEBUG] XGB validation: p-rmse: 0.393456	a-peak@32: 0.969002
2024-04-29 02:33:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.209663	tr-a-peak@32: 1.000000	tr-rmse: 0.853613	tr-rmse: 0.853613
2024-04-29 02:33:58 [DEBUG] XGB iter  25: tr-p-rmse: 0.200770	tr-a-peak@32: 0.375000	tr-rmse: 0.624188	tr-rmse: 0.624188
2024-04-29 02:33:59 [DEBUG] XGB iter  50: tr-p-rmse: 0.199397	tr-a-peak@32: 0.406250	tr-rmse: 0.624338	tr-rmse: 0.624338
2024-04-29 02:33:59 [DEBUG] XGB iter  75: tr-p-rmse: 0.199397	tr-a-peak@32: 0.406250	tr-rmse: 0.624338	tr-rmse: 0.624338
2024-04-29 02:33:59 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.19937	tr-a-peak@32:0.40625	tr-rmse:0.62435	tr-rmse:0.62435 
2024-04-29 02:33:59 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:33:59 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       716.8579 |      11.6178 |               11.6178 |    192 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4739
Total latency (us): 263.596

2024-04-29 02:33:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 02:34:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:34:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:35:18 [DEBUG] XGB validation: p-rmse: 0.638165	a-peak@32: 0.795128
2024-04-29 02:35:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.201741	tr-a-peak@32: 1.000000	tr-rmse: 0.851858	tr-rmse: 0.851858
2024-04-29 02:35:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.200212	tr-a-peak@32: 0.437500	tr-rmse: 0.621153	tr-rmse: 0.621153
2024-04-29 02:35:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.199443	tr-a-peak@32: 0.468750	tr-rmse: 0.621351	tr-rmse: 0.621351
2024-04-29 02:35:21 [DEBUG] XGB iter  75: tr-p-rmse: 0.199443	tr-a-peak@32: 0.468750	tr-rmse: 0.621351	tr-rmse: 0.621351
2024-04-29 02:35:21 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.19937	tr-a-peak@32:0.46875	tr-rmse:0.62140	tr-rmse:0.62140 
2024-04-29 02:35:22 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 02:35:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2647.9150 |      13.4108 |               26.8215 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4803
Total latency (us): 261.409

2024-04-29 02:35:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:37:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:37:42 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:38:12 [DEBUG] XGB validation: p-rmse: 0.653786	a-peak@32: 0.216169
2024-04-29 02:38:12 [DEBUG] XGB iter   0: tr-p-rmse: 2.198878	tr-a-peak@32: 1.000000	tr-rmse: 0.856636	tr-rmse: 0.856636
2024-04-29 02:38:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.222027	tr-a-peak@32: 0.000000	tr-rmse: 0.624698	tr-rmse: 0.624698
2024-04-29 02:38:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.221270	tr-a-peak@32: 0.000000	tr-rmse: 0.624882	tr-rmse: 0.624882
2024-04-29 02:38:15 [DEBUG] XGB iter  75: tr-p-rmse: 0.221270	tr-a-peak@32: 0.000000	tr-rmse: 0.624882	tr-rmse: 0.624882
2024-04-29 02:38:15 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.22123	tr-a-peak@32:0.00000	tr-rmse:0.62503	tr-rmse:0.62503 
2024-04-29 02:38:15 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 02:38:15 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1228.6724 |      14.7543 |               29.5087 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4867
Total latency (us): 261.195

2024-04-29 02:38:15 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:40:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:41:07 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:41:46 [DEBUG] XGB validation: p-rmse: 0.726279	a-peak@32: 0.677229
2024-04-29 02:41:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.214966	tr-a-peak@32: 1.000000	tr-rmse: 0.847905	tr-rmse: 0.847905
2024-04-29 02:41:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.246137	tr-a-peak@32: 0.000000	tr-rmse: 0.617153	tr-rmse: 0.617153
2024-04-29 02:41:49 [DEBUG] XGB iter  50: tr-p-rmse: 0.245429	tr-a-peak@32: 0.000000	tr-rmse: 0.617361	tr-rmse: 0.617361
2024-04-29 02:41:49 [DEBUG] XGB iter  75: tr-p-rmse: 0.245429	tr-a-peak@32: 0.000000	tr-rmse: 0.617361	tr-rmse: 0.617361
2024-04-29 02:41:49 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.24530	tr-a-peak@32:0.00000	tr-rmse:0.61751	tr-rmse:0.61751 
2024-04-29 02:41:49 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 02:41:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4931
Total latency (us): 256.626

2024-04-29 02:41:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 02:42:13 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:42:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:43:19 [DEBUG] XGB validation: p-rmse: 1.950438	a-peak@32: 0.590130
2024-04-29 02:43:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.218901	tr-a-peak@32: 1.000000	tr-rmse: 0.845080	tr-rmse: 0.845080
2024-04-29 02:43:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.207159	tr-a-peak@32: 0.156250	tr-rmse: 0.614136	tr-rmse: 0.614136
2024-04-29 02:43:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.206748	tr-a-peak@32: 0.156250	tr-rmse: 0.614318	tr-rmse: 0.614318
2024-04-29 02:43:22 [DEBUG] XGB iter  75: tr-p-rmse: 0.206748	tr-a-peak@32: 0.156250	tr-rmse: 0.614318	tr-rmse: 0.614318
2024-04-29 02:43:22 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20657	tr-a-peak@32:0.15625	tr-rmse:0.61442	tr-rmse:0.61442 
2024-04-29 02:43:22 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 02:43:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4995
Total latency (us): 256.626

2024-04-29 02:43:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 02:43:46 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:44:10 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:44:49 [DEBUG] XGB validation: p-rmse: 0.626806	a-peak@32: 0.883260
2024-04-29 02:44:49 [DEBUG] XGB iter   0: tr-p-rmse: 2.247353	tr-a-peak@32: 1.000000	tr-rmse: 0.843130	tr-rmse: 0.843130
2024-04-29 02:44:51 [DEBUG] XGB iter  25: tr-p-rmse: 0.211904	tr-a-peak@32: 0.427766	tr-rmse: 0.613973	tr-rmse: 0.613973
2024-04-29 02:44:52 [DEBUG] XGB iter  50: tr-p-rmse: 0.210689	tr-a-peak@32: 0.336936	tr-rmse: 0.614136	tr-rmse: 0.614136
2024-04-29 02:44:52 [DEBUG] XGB iter  75: tr-p-rmse: 0.210689	tr-a-peak@32: 0.336936	tr-rmse: 0.614136	tr-rmse: 0.614136
2024-04-29 02:44:52 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.21067	tr-a-peak@32:0.33694	tr-rmse:0.61415	tr-rmse:0.61415 
2024-04-29 02:44:52 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 02:44:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    511 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5059
Total latency (us): 256.626

2024-04-29 02:44:52 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:47:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:47:30 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:47:40 [DEBUG] XGB validation: p-rmse: 1.886262	a-peak@32: 1.000000
2024-04-29 02:47:40 [DEBUG] XGB iter   0: tr-p-rmse: 2.242844	tr-a-peak@32: 1.000000	tr-rmse: 0.842782	tr-rmse: 0.842782
2024-04-29 02:47:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.241966	tr-a-peak@32: 0.000000	tr-rmse: 0.613837	tr-rmse: 0.613837
2024-04-29 02:47:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.241043	tr-a-peak@32: 0.000000	tr-rmse: 0.614020	tr-rmse: 0.614020
2024-04-29 02:47:43 [DEBUG] XGB iter  75: tr-p-rmse: 0.241043	tr-a-peak@32: 0.000000	tr-rmse: 0.614020	tr-rmse: 0.614020
2024-04-29 02:47:43 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.24096	tr-a-peak@32:0.00000	tr-rmse:0.61406	tr-rmse:0.61406 
2024-04-29 02:47:43 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 02:47:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     62 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5123
Total latency (us): 256.626

2024-04-29 02:47:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #10: "fused_nn_max_pool2d_1"
2024-04-29 02:47:51 [INFO] [task_scheduler.cc:193] Sending 8 sample(s) to builder
2024-04-29 02:47:55 [INFO] [task_scheduler.cc:195] Sending 8 sample(s) to runner
2024-04-29 02:47:56 [DEBUG] XGB validation: p-rmse: 0.769997	a-peak@32: 1.000000
2024-04-29 02:47:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.242577	tr-a-peak@32: 1.000000	tr-rmse: 0.842782	tr-rmse: 0.842782
2024-04-29 02:47:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.242246	tr-a-peak@32: 0.000000	tr-rmse: 0.613837	tr-rmse: 0.613837
2024-04-29 02:47:58 [DEBUG] XGB iter  50: tr-p-rmse: 0.241324	tr-a-peak@32: 0.000000	tr-rmse: 0.614020	tr-rmse: 0.614020
2024-04-29 02:47:59 [DEBUG] XGB iter  75: tr-p-rmse: 0.241324	tr-a-peak@32: 0.000000	tr-rmse: 0.614020	tr-rmse: 0.614020
2024-04-29 02:47:59 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.24124	tr-a-peak@32:0.00000	tr-rmse:0.61406	tr-rmse:0.61406 
2024-04-29 02:47:59 [INFO] [task_scheduler.cc:237] [Updated] Task #10: "fused_nn_max_pool2d_1"
2024-04-29 02:47:59 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    573 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5131
Total latency (us): 256.626

2024-04-29 02:47:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:48:21 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:48:44 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:49:06 [DEBUG] XGB validation: p-rmse: 0.795637	a-peak@32: 0.000000
2024-04-29 02:49:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.234117	tr-a-peak@32: 1.000000	tr-rmse: 0.841886	tr-rmse: 0.841886
2024-04-29 02:49:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.273104	tr-a-peak@32: 0.000000	tr-rmse: 0.614047	tr-rmse: 0.614047
2024-04-29 02:49:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.272141	tr-a-peak@32: 0.000000	tr-rmse: 0.614172	tr-rmse: 0.614172
2024-04-29 02:49:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.272141	tr-a-peak@32: 0.000000	tr-rmse: 0.614172	tr-rmse: 0.614172
2024-04-29 02:49:09 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.27209	tr-a-peak@32:0.00000	tr-rmse:0.61422	tr-rmse:0.61422 
2024-04-29 02:49:09 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:49:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5195
Total latency (us): 256.626

2024-04-29 02:49:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 02:49:16 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 02:49:38 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 02:50:12 [DEBUG] XGB validation: p-rmse: 0.071554	a-peak@32: 1.000000
2024-04-29 02:50:12 [DEBUG] XGB iter   0: tr-p-rmse: 2.222485	tr-a-peak@32: 1.000000	tr-rmse: 0.839587	tr-rmse: 0.839587
2024-04-29 02:50:14 [DEBUG] XGB iter  25: tr-p-rmse: 0.253622	tr-a-peak@32: 0.000000	tr-rmse: 0.613189	tr-rmse: 0.613189
2024-04-29 02:50:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.252647	tr-a-peak@32: 0.000000	tr-rmse: 0.613346	tr-rmse: 0.613346
2024-04-29 02:50:15 [DEBUG] XGB iter  75: tr-p-rmse: 0.252647	tr-a-peak@32: 0.000000	tr-rmse: 0.613346	tr-rmse: 0.613346
2024-04-29 02:50:15 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.25258	tr-a-peak@32:0.00000	tr-rmse:0.61338	tr-rmse:0.61338 
2024-04-29 02:50:15 [INFO] [task_scheduler.cc:237] [Updated] Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 02:50:15 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |     63 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5257
Total latency (us): 256.626

2024-04-29 02:50:15 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #27: "fused_nn_softmax"
2024-04-29 02:50:23 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 02:50:46 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 02:51:22 [DEBUG] XGB validation: p-rmse: 0.123310	a-peak@32: 0.988982
2024-04-29 02:51:23 [DEBUG] XGB iter   0: tr-p-rmse: 2.211444	tr-a-peak@32: 0.897701	tr-rmse: 0.838356	tr-rmse: 0.838356
2024-04-29 02:51:24 [DEBUG] XGB iter  25: tr-p-rmse: 0.247056	tr-a-peak@32: 0.000000	tr-rmse: 0.613327	tr-rmse: 0.613327
2024-04-29 02:51:25 [DEBUG] XGB iter  50: tr-p-rmse: 0.246374	tr-a-peak@32: 0.000000	tr-rmse: 0.613501	tr-rmse: 0.613501
2024-04-29 02:51:25 [DEBUG] XGB iter  75: tr-p-rmse: 0.246374	tr-a-peak@32: 0.000000	tr-rmse: 0.613501	tr-rmse: 0.613501
2024-04-29 02:51:25 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.24626	tr-a-peak@32:0.00000	tr-rmse:0.61361	tr-rmse:0.61361 
2024-04-29 02:51:25 [INFO] [task_scheduler.cc:237] [Updated] Task #27: "fused_nn_softmax"
2024-04-29 02:51:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5319
Total latency (us): 256.626

2024-04-29 02:51:25 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:53:27 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:53:51 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:54:29 [DEBUG] XGB validation: p-rmse: 0.305808	a-peak@32: 0.951707
2024-04-29 02:54:29 [DEBUG] XGB iter   0: tr-p-rmse: 2.182914	tr-a-peak@32: 0.968750	tr-rmse: 0.848644	tr-rmse: 0.848644
2024-04-29 02:54:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.250800	tr-a-peak@32: 0.000000	tr-rmse: 0.619503	tr-rmse: 0.619503
2024-04-29 02:54:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.249227	tr-a-peak@32: 0.000000	tr-rmse: 0.619645	tr-rmse: 0.619645
2024-04-29 02:54:32 [DEBUG] XGB iter  75: tr-p-rmse: 0.249227	tr-a-peak@32: 0.000000	tr-rmse: 0.619645	tr-rmse: 0.619645
2024-04-29 02:54:32 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.24921	tr-a-peak@32:0.00000	tr-rmse:0.61966	tr-rmse:0.61966 
2024-04-29 02:54:32 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 02:54:32 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       612.4448 |       6.8081 |                6.8081 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5383
Total latency (us): 256.626

2024-04-29 02:54:32 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 02:55:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:55:23 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:55:59 [DEBUG] XGB validation: p-rmse: 0.456281	a-peak@32: 0.935349
2024-04-29 02:55:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.183736	tr-a-peak@32: 1.000000	tr-rmse: 0.846504	tr-rmse: 0.846504
2024-04-29 02:56:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.257493	tr-a-peak@32: 0.000000	tr-rmse: 0.621224	tr-rmse: 0.621224
2024-04-29 02:56:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.255998	tr-a-peak@32: 0.000000	tr-rmse: 0.621352	tr-rmse: 0.621352
2024-04-29 02:56:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.255998	tr-a-peak@32: 0.000000	tr-rmse: 0.621352	tr-rmse: 0.621352
2024-04-29 02:56:02 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.25597	tr-a-peak@32:0.00000	tr-rmse:0.62137	tr-rmse:0.62137 
2024-04-29 02:56:02 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 02:56:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       917.2496 |       6.5616 |                6.5616 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5447
Total latency (us): 256.175

2024-04-29 02:56:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 02:56:29 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:56:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:57:30 [DEBUG] XGB validation: p-rmse: 0.752970	a-peak@32: 0.739195
2024-04-29 02:57:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.170102	tr-a-peak@32: 1.000000	tr-rmse: 0.843718	tr-rmse: 0.843718
2024-04-29 02:57:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.238113	tr-a-peak@32: 0.000000	tr-rmse: 0.617693	tr-rmse: 0.617693
2024-04-29 02:57:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.236577	tr-a-peak@32: 0.000000	tr-rmse: 0.617792	tr-rmse: 0.617792
2024-04-29 02:57:33 [DEBUG] XGB iter  75: tr-p-rmse: 0.236577	tr-a-peak@32: 0.000000	tr-rmse: 0.617792	tr-rmse: 0.617792
2024-04-29 02:57:33 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.23654	tr-a-peak@32:0.00000	tr-rmse:0.61781	tr-rmse:0.61781 
2024-04-29 02:57:33 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 02:57:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5354.5253 |      32.3827 |               32.3827 |    637 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5511
Total latency (us): 255.502

2024-04-29 02:57:33 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:57:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 02:58:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 02:59:02 [DEBUG] XGB validation: p-rmse: 0.392686	a-peak@32: 0.848034
2024-04-29 02:59:02 [DEBUG] XGB iter   0: tr-p-rmse: 2.166103	tr-a-peak@32: 1.000000	tr-rmse: 0.840983	tr-rmse: 0.840983
2024-04-29 02:59:04 [DEBUG] XGB iter  25: tr-p-rmse: 0.236337	tr-a-peak@32: 0.000000	tr-rmse: 0.618591	tr-rmse: 0.618591
2024-04-29 02:59:05 [DEBUG] XGB iter  50: tr-p-rmse: 0.235373	tr-a-peak@32: 0.000000	tr-rmse: 0.618729	tr-rmse: 0.618729
2024-04-29 02:59:05 [DEBUG] XGB iter  75: tr-p-rmse: 0.235373	tr-a-peak@32: 0.000000	tr-rmse: 0.618729	tr-rmse: 0.618729
2024-04-29 02:59:05 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.23532	tr-a-peak@32:0.00000	tr-rmse:0.61876	tr-rmse:0.61876 
2024-04-29 02:59:06 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 02:59:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5575
Total latency (us): 255.371

2024-04-29 02:59:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:01:19 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:01:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:02:27 [DEBUG] XGB validation: p-rmse: 0.806714	a-peak@32: 1.000000
2024-04-29 03:02:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.186813	tr-a-peak@32: 0.942801	tr-rmse: 0.843857	tr-rmse: 0.843857
2024-04-29 03:02:28 [DEBUG] XGB iter  25: tr-p-rmse: 0.232958	tr-a-peak@32: 0.096605	tr-rmse: 0.618685	tr-rmse: 0.618685
2024-04-29 03:02:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.231481	tr-a-peak@32: 0.125000	tr-rmse: 0.618842	tr-rmse: 0.618842
2024-04-29 03:02:30 [DEBUG] XGB iter  75: tr-p-rmse: 0.231481	tr-a-peak@32: 0.125000	tr-rmse: 0.618842	tr-rmse: 0.618842
2024-04-29 03:02:30 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.23146	tr-a-peak@32:0.12500	tr-rmse:0.61885	tr-rmse:0.61885 
2024-04-29 03:02:30 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:02:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     61 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5639
Total latency (us): 255.371

2024-04-29 03:02:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #15: "fused_nn_max_pool2d_2"
2024-04-29 03:02:37 [INFO] [task_scheduler.cc:193] Sending 9 sample(s) to builder
2024-04-29 03:02:41 [INFO] [task_scheduler.cc:195] Sending 9 sample(s) to runner
2024-04-29 03:02:49 [DEBUG] XGB validation: p-rmse: 0.505694	a-peak@32: 0.666667
2024-04-29 03:02:49 [DEBUG] XGB iter   0: tr-p-rmse: 2.186481	tr-a-peak@32: 0.942801	tr-rmse: 0.843824	tr-rmse: 0.843824
2024-04-29 03:02:51 [DEBUG] XGB iter  25: tr-p-rmse: 0.233761	tr-a-peak@32: 0.156250	tr-rmse: 0.618687	tr-rmse: 0.618687
2024-04-29 03:02:51 [DEBUG] XGB iter  50: tr-p-rmse: 0.232685	tr-a-peak@32: 0.000000	tr-rmse: 0.618856	tr-rmse: 0.618856
2024-04-29 03:02:52 [DEBUG] XGB iter  75: tr-p-rmse: 0.232685	tr-a-peak@32: 0.000000	tr-rmse: 0.618856	tr-rmse: 0.618856
2024-04-29 03:02:52 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.23259	tr-a-peak@32:0.00000	tr-rmse:0.61890	tr-rmse:0.61890 
2024-04-29 03:02:52 [INFO] [task_scheduler.cc:237] [Updated] Task #15: "fused_nn_max_pool2d_2"
2024-04-29 03:02:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       883.1446 |       9.4303 |                9.4303 |    256 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5648
Total latency (us): 255.371

2024-04-29 03:02:52 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 03:03:17 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:03:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:04:24 [DEBUG] XGB validation: p-rmse: 0.375853	a-peak@32: 0.970685
2024-04-29 03:04:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.194566	tr-a-peak@32: 1.000000	tr-rmse: 0.842405	tr-rmse: 0.842405
2024-04-29 03:04:26 [DEBUG] XGB iter  25: tr-p-rmse: 0.225737	tr-a-peak@32: 0.250000	tr-rmse: 0.618703	tr-rmse: 0.618703
2024-04-29 03:04:26 [DEBUG] XGB iter  50: tr-p-rmse: 0.224586	tr-a-peak@32: 0.281250	tr-rmse: 0.618839	tr-rmse: 0.618839
2024-04-29 03:04:27 [DEBUG] XGB iter  75: tr-p-rmse: 0.224586	tr-a-peak@32: 0.281250	tr-rmse: 0.618839	tr-rmse: 0.618839
2024-04-29 03:04:27 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.22456	tr-a-peak@32:0.28125	tr-rmse:0.61885	tr-rmse:0.61885 
2024-04-29 03:04:27 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 03:04:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5712
Total latency (us): 254.608

2024-04-29 03:04:27 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 03:04:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:05:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:05:55 [DEBUG] XGB validation: p-rmse: 1.340646	a-peak@32: 0.799882
2024-04-29 03:05:55 [DEBUG] XGB iter   0: tr-p-rmse: 2.187369	tr-a-peak@32: 1.000000	tr-rmse: 0.841846	tr-rmse: 0.841846
2024-04-29 03:05:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.234083	tr-a-peak@32: 0.000000	tr-rmse: 0.618520	tr-rmse: 0.618520
2024-04-29 03:05:58 [DEBUG] XGB iter  50: tr-p-rmse: 0.233042	tr-a-peak@32: 0.000000	tr-rmse: 0.618669	tr-rmse: 0.618669
2024-04-29 03:05:58 [DEBUG] XGB iter  75: tr-p-rmse: 0.233042	tr-a-peak@32: 0.000000	tr-rmse: 0.618669	tr-rmse: 0.618669
2024-04-29 03:05:59 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.23304	tr-a-peak@32:0.00000	tr-rmse:0.61867	tr-rmse:0.61867 
2024-04-29 03:05:59 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 03:05:59 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5776
Total latency (us): 254.608

2024-04-29 03:05:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:07:45 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 03:08:11 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 03:08:18 [DEBUG] XGB validation: p-rmse: 0.992352	a-peak@32: 1.000000
2024-04-29 03:08:18 [DEBUG] XGB iter   0: tr-p-rmse: 2.187538	tr-a-peak@32: 1.000000	tr-rmse: 0.841846	tr-rmse: 0.841846
2024-04-29 03:08:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.264184	tr-a-peak@32: 0.000000	tr-rmse: 0.618520	tr-rmse: 0.618520
2024-04-29 03:08:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.263134	tr-a-peak@32: 0.000000	tr-rmse: 0.618669	tr-rmse: 0.618669
2024-04-29 03:08:21 [DEBUG] XGB stopped. Best iteration: [16] tr-p-rmse:0.26062	tr-a-peak@32:0.00000	tr-rmse:0.62210	tr-rmse:0.62210 
2024-04-29 03:08:22 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:08:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2669.2125 |      13.3037 |               26.6075 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5839
Total latency (us): 254.608

2024-04-29 03:08:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:10:13 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:10:37 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:11:00 [DEBUG] XGB validation: p-rmse: 0.894357	a-peak@32: 0.000000
2024-04-29 03:11:00 [DEBUG] XGB iter   0: tr-p-rmse: 2.189593	tr-a-peak@32: 1.000000	tr-rmse: 0.844871	tr-rmse: 0.844871
2024-04-29 03:11:02 [DEBUG] XGB iter  25: tr-p-rmse: 0.271060	tr-a-peak@32: 0.000000	tr-rmse: 0.620375	tr-rmse: 0.620375
2024-04-29 03:11:03 [DEBUG] XGB iter  50: tr-p-rmse: 0.269647	tr-a-peak@32: 0.000000	tr-rmse: 0.620553	tr-rmse: 0.620553
2024-04-29 03:11:03 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26901	tr-a-peak@32:0.37500	tr-rmse:0.62657	tr-rmse:0.62657 
2024-04-29 03:11:04 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:11:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    575 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5903
Total latency (us): 254.433

2024-04-29 03:11:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:13:19 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:13:45 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:14:02 [DEBUG] XGB validation: p-rmse: 0.916206	a-peak@32: 0.922951
2024-04-29 03:14:02 [DEBUG] XGB iter   0: tr-p-rmse: 2.157737	tr-a-peak@32: 1.000000	tr-rmse: 0.845664	tr-rmse: 0.845664
2024-04-29 03:14:04 [DEBUG] XGB iter  25: tr-p-rmse: 0.281192	tr-a-peak@32: 0.000000	tr-rmse: 0.622843	tr-rmse: 0.622843
2024-04-29 03:14:05 [DEBUG] XGB iter  50: tr-p-rmse: 0.280095	tr-a-peak@32: 0.000000	tr-rmse: 0.623008	tr-rmse: 0.623008
2024-04-29 03:14:05 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.27613	tr-a-peak@32:0.00000	tr-rmse:0.62885	tr-rmse:0.62885 
2024-04-29 03:14:06 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:14:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5967
Total latency (us): 254.433

2024-04-29 03:14:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-04-29 03:14:10 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 03:14:10 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 03:14:10 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-04-29 03:14:10 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    128 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5967
Total latency (us): 254.433

2024-04-29 03:14:10 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 03:14:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:15:03 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:15:09 [DEBUG] XGB validation: p-rmse: 1.097853	a-peak@32: 1.000000
2024-04-29 03:15:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.151132	tr-a-peak@32: 1.000000	tr-rmse: 0.845664	tr-rmse: 0.845664
2024-04-29 03:15:11 [DEBUG] XGB iter  25: tr-p-rmse: 0.295686	tr-a-peak@32: 0.000000	tr-rmse: 0.622893	tr-rmse: 0.622893
2024-04-29 03:15:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.294461	tr-a-peak@32: 0.000000	tr-rmse: 0.623030	tr-rmse: 0.623030
2024-04-29 03:15:12 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.28998	tr-a-peak@32:0.00000	tr-rmse:0.62885	tr-rmse:0.62885 
2024-04-29 03:15:12 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 03:15:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1239.5842 |       8.9524 |                8.9524 |    192 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6031
Total latency (us): 254.433

2024-04-29 03:15:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 03:15:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:16:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:16:26 [DEBUG] XGB validation: p-rmse: 0.871247	a-peak@32: 0.059838
2024-04-29 03:16:26 [DEBUG] XGB iter   0: tr-p-rmse: 2.177366	tr-a-peak@32: 1.000000	tr-rmse: 0.845902	tr-rmse: 0.845902
2024-04-29 03:16:28 [DEBUG] XGB iter  25: tr-p-rmse: 0.299598	tr-a-peak@32: 0.000000	tr-rmse: 0.621595	tr-rmse: 0.621595
2024-04-29 03:16:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.298506	tr-a-peak@32: 0.000000	tr-rmse: 0.621769	tr-rmse: 0.621769
2024-04-29 03:16:29 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29277	tr-a-peak@32:0.00000	tr-rmse:0.62800	tr-rmse:0.62800 
2024-04-29 03:16:29 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 03:16:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1003.8298 |       5.6029 |               11.2057 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6095
Total latency (us): 254.408

2024-04-29 03:16:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 03:16:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:17:19 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:17:54 [DEBUG] XGB validation: p-rmse: 0.436585	a-peak@32: 0.770202
2024-04-29 03:17:54 [DEBUG] XGB iter   0: tr-p-rmse: 2.170586	tr-a-peak@32: 1.000000	tr-rmse: 0.843454	tr-rmse: 0.843454
2024-04-29 03:17:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.302607	tr-a-peak@32: 0.000000	tr-rmse: 0.621890	tr-rmse: 0.621890
2024-04-29 03:17:56 [DEBUG] XGB iter  50: tr-p-rmse: 0.301418	tr-a-peak@32: 0.000000	tr-rmse: 0.622063	tr-rmse: 0.622063
2024-04-29 03:17:57 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.29713	tr-a-peak@32:0.06250	tr-rmse:0.63217	tr-rmse:0.63217 
2024-04-29 03:17:57 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 03:17:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1386.8435 |       4.4407 |                8.8815 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6159
Total latency (us): 254.045

2024-04-29 03:17:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 03:18:21 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:18:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:19:25 [DEBUG] XGB validation: p-rmse: 0.662883	a-peak@32: 0.871455
2024-04-29 03:19:25 [DEBUG] XGB iter   0: tr-p-rmse: 2.164733	tr-a-peak@32: 1.000000	tr-rmse: 0.840460	tr-rmse: 0.840460
2024-04-29 03:19:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.287990	tr-a-peak@32: 0.000000	tr-rmse: 0.620902	tr-rmse: 0.620902
2024-04-29 03:19:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.287201	tr-a-peak@32: 0.000000	tr-rmse: 0.621017	tr-rmse: 0.621017
2024-04-29 03:19:28 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.28440	tr-a-peak@32:0.28125	tr-rmse:0.63047	tr-rmse:0.63047 
2024-04-29 03:19:28 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 03:19:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    701 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6223
Total latency (us): 253.55

2024-04-29 03:19:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:19:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:20:15 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:20:57 [DEBUG] XGB validation: p-rmse: 0.076402	a-peak@32: 0.999044
2024-04-29 03:20:57 [DEBUG] XGB iter   0: tr-p-rmse: 2.153447	tr-a-peak@32: 1.000000	tr-rmse: 0.838257	tr-rmse: 0.838257
2024-04-29 03:20:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.307989	tr-a-peak@32: 0.000000	tr-rmse: 0.622079	tr-rmse: 0.622079
2024-04-29 03:21:00 [DEBUG] XGB iter  50: tr-p-rmse: 0.306725	tr-a-peak@32: 0.000000	tr-rmse: 0.622253	tr-rmse: 0.622253
2024-04-29 03:21:00 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.30086	tr-a-peak@32:0.00000	tr-rmse:0.62817	tr-rmse:0.62817 
2024-04-29 03:21:00 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:21:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    765 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6287
Total latency (us): 253.55

2024-04-29 03:21:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:23:17 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 03:23:59 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 03:24:35 [DEBUG] XGB validation: p-rmse: 0.748343	a-peak@32: 0.835189
2024-04-29 03:24:35 [DEBUG] XGB iter   0: tr-p-rmse: 2.164929	tr-a-peak@32: 0.972034	tr-rmse: 0.839345	tr-rmse: 0.839345
2024-04-29 03:24:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.294762	tr-a-peak@32: 0.000000	tr-rmse: 0.622462	tr-rmse: 0.622462
2024-04-29 03:24:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.293373	tr-a-peak@32: 0.000000	tr-rmse: 0.622614	tr-rmse: 0.622614
2024-04-29 03:24:38 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29149	tr-a-peak@32:0.13146	tr-rmse:0.62847	tr-rmse:0.62847 
2024-04-29 03:24:38 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:24:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    765 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6350
Total latency (us): 253.55

2024-04-29 03:24:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-04-29 03:24:42 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 03:24:42 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 03:24:42 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-04-29 03:24:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    639 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    765 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6350
Total latency (us): 253.55

2024-04-29 03:24:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:26:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:27:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:28:02 [DEBUG] XGB validation: p-rmse: 0.548766	a-peak@32: 0.986622
2024-04-29 03:28:03 [DEBUG] XGB iter   0: tr-p-rmse: 2.144821	tr-a-peak@32: 1.000000	tr-rmse: 0.845071	tr-rmse: 0.845071
2024-04-29 03:28:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.300199	tr-a-peak@32: 0.000000	tr-rmse: 0.625204	tr-rmse: 0.625204
2024-04-29 03:28:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.298366	tr-a-peak@32: 0.000000	tr-rmse: 0.625333	tr-rmse: 0.625333
2024-04-29 03:28:06 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29700	tr-a-peak@32:0.00000	tr-rmse:0.63095	tr-rmse:0.63095 
2024-04-29 03:28:06 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:28:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2225.0676 |      13.7495 |               27.4990 |    639 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    765 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6414
Total latency (us): 253.55

2024-04-29 03:28:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:30:17 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:30:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:31:18 [DEBUG] XGB validation: p-rmse: 0.640572	a-peak@32: 0.584951
2024-04-29 03:31:18 [DEBUG] XGB iter   0: tr-p-rmse: 2.187203	tr-a-peak@32: 1.000000	tr-rmse: 0.851472	tr-rmse: 0.851472
2024-04-29 03:31:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.289224	tr-a-peak@32: 0.000000	tr-rmse: 0.628583	tr-rmse: 0.628583
2024-04-29 03:31:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.287993	tr-a-peak@32: 0.000000	tr-rmse: 0.628757	tr-rmse: 0.628757
2024-04-29 03:31:21 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.28606	tr-a-peak@32:0.02629	tr-rmse:0.63505	tr-rmse:0.63505 
2024-04-29 03:31:21 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:31:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    765 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6478
Total latency (us): 253.465

2024-04-29 03:31:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:31:46 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:32:23 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:33:03 [DEBUG] XGB validation: p-rmse: 0.101737	a-peak@32: 0.983124
2024-04-29 03:33:04 [DEBUG] XGB iter   0: tr-p-rmse: 2.162665	tr-a-peak@32: 1.000000	tr-rmse: 0.848729	tr-rmse: 0.848729
2024-04-29 03:33:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.301929	tr-a-peak@32: 0.000000	tr-rmse: 0.631070	tr-rmse: 0.631070
2024-04-29 03:33:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.300039	tr-a-peak@32: 0.000000	tr-rmse: 0.631098	tr-rmse: 0.631098
2024-04-29 03:33:07 [DEBUG] XGB iter  75: tr-p-rmse: 0.300039	tr-a-peak@32: 0.000000	tr-rmse: 0.631098	tr-rmse: 0.631098
2024-04-29 03:33:07 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.30003	tr-a-peak@32:0.00000	tr-rmse:0.63110	tr-rmse:0.63110 
2024-04-29 03:33:07 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:33:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2686.9316 |      13.2160 |               26.4320 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6542
Total latency (us): 253.465

2024-04-29 03:33:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:34:57 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:35:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:36:06 [DEBUG] XGB validation: p-rmse: 0.439986	a-peak@32: 0.967495
2024-04-29 03:36:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.179370	tr-a-peak@32: 1.000000	tr-rmse: 0.853302	tr-rmse: 0.853302
2024-04-29 03:36:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.299805	tr-a-peak@32: 0.000000	tr-rmse: 0.632739	tr-rmse: 0.632739
2024-04-29 03:36:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.298236	tr-a-peak@32: 0.000000	tr-rmse: 0.632816	tr-rmse: 0.632816
2024-04-29 03:36:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.298236	tr-a-peak@32: 0.000000	tr-rmse: 0.632816	tr-rmse: 0.632816
2024-04-29 03:36:09 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.29817	tr-a-peak@32:0.00000	tr-rmse:0.63286	tr-rmse:0.63286 
2024-04-29 03:36:09 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:36:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1503.5295 |       7.9750 |                7.9750 |    191 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6606
Total latency (us): 252.989

2024-04-29 03:36:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 03:36:38 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:36:59 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:37:36 [DEBUG] XGB validation: p-rmse: 0.345877	a-peak@32: 0.928092
2024-04-29 03:37:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.163165	tr-a-peak@32: 1.000000	tr-rmse: 0.850564	tr-rmse: 0.850564
2024-04-29 03:37:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.291096	tr-a-peak@32: 0.062500	tr-rmse: 0.632271	tr-rmse: 0.632271
2024-04-29 03:37:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.289905	tr-a-peak@32: 0.000000	tr-rmse: 0.632383	tr-rmse: 0.632383
2024-04-29 03:37:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.289905	tr-a-peak@32: 0.000000	tr-rmse: 0.632383	tr-rmse: 0.632383
2024-04-29 03:37:40 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.28988	tr-a-peak@32:0.00000	tr-rmse:0.63239	tr-rmse:0.63239 
2024-04-29 03:37:40 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 03:37:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1453.7528 |      12.4700 |               24.9399 |    703 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    255 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6670
Total latency (us): 252.959

2024-04-29 03:37:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:40:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:40:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:41:06 [DEBUG] XGB validation: p-rmse: 0.486635	a-peak@32: 0.913851
2024-04-29 03:41:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.185649	tr-a-peak@32: 1.000000	tr-rmse: 0.852328	tr-rmse: 0.852328
2024-04-29 03:41:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.282840	tr-a-peak@32: 0.000000	tr-rmse: 0.632607	tr-rmse: 0.632607
2024-04-29 03:41:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.281727	tr-a-peak@32: 0.000000	tr-rmse: 0.632726	tr-rmse: 0.632726
2024-04-29 03:41:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.281727	tr-a-peak@32: 0.000000	tr-rmse: 0.632726	tr-rmse: 0.632726
2024-04-29 03:41:09 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.28166	tr-a-peak@32:0.00000	tr-rmse:0.63277	tr-rmse:0.63277 
2024-04-29 03:41:10 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 03:41:10 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    255 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6734
Total latency (us): 252.087

2024-04-29 03:41:10 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 03:41:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:42:05 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:42:41 [DEBUG] XGB validation: p-rmse: 0.463090	a-peak@32: 0.918364
2024-04-29 03:42:41 [DEBUG] XGB iter   0: tr-p-rmse: 2.210607	tr-a-peak@32: 0.972641	tr-rmse: 0.850284	tr-rmse: 0.850284
2024-04-29 03:42:43 [DEBUG] XGB iter  25: tr-p-rmse: 0.272835	tr-a-peak@32: 0.000000	tr-rmse: 0.630504	tr-rmse: 0.630504
2024-04-29 03:42:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.271369	tr-a-peak@32: 0.000000	tr-rmse: 0.630658	tr-rmse: 0.630658
2024-04-29 03:42:44 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26673	tr-a-peak@32:0.62500	tr-rmse:0.63692	tr-rmse:0.63692 
2024-04-29 03:42:45 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-04-29 03:42:45 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6798
Total latency (us): 252.087

2024-04-29 03:42:45 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:44:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:45:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:45:46 [DEBUG] XGB validation: p-rmse: 0.260442	a-peak@32: 0.946192
2024-04-29 03:45:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.212666	tr-a-peak@32: 0.972641	tr-rmse: 0.858331	tr-rmse: 0.858331
2024-04-29 03:45:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.274953	tr-a-peak@32: 0.000000	tr-rmse: 0.636132	tr-rmse: 0.636132
2024-04-29 03:45:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.273870	tr-a-peak@32: 0.000000	tr-rmse: 0.636291	tr-rmse: 0.636291
2024-04-29 03:45:49 [DEBUG] XGB iter  75: tr-p-rmse: 0.273870	tr-a-peak@32: 0.000000	tr-rmse: 0.636291	tr-rmse: 0.636291
2024-04-29 03:45:49 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.27380	tr-a-peak@32:0.00000	tr-rmse:0.63632	tr-rmse:0.63632 
2024-04-29 03:45:49 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 03:45:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2231.9182 |      13.7073 |               27.4146 |    703 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6862
Total latency (us): 252.087

2024-04-29 03:45:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:48:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:48:25 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:49:03 [DEBUG] XGB validation: p-rmse: 0.197669	a-peak@32: 0.923843
2024-04-29 03:49:03 [DEBUG] XGB iter   0: tr-p-rmse: 2.210232	tr-a-peak@32: 1.000000	tr-rmse: 0.864705	tr-rmse: 0.864705
2024-04-29 03:49:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.274487	tr-a-peak@32: 0.000000	tr-rmse: 0.641132	tr-rmse: 0.641132
2024-04-29 03:49:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.272512	tr-a-peak@32: 0.000000	tr-rmse: 0.641211	tr-rmse: 0.641211
2024-04-29 03:49:07 [DEBUG] XGB iter  75: tr-p-rmse: 0.272512	tr-a-peak@32: 0.000000	tr-rmse: 0.641211	tr-rmse: 0.641211
2024-04-29 03:49:07 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27249	tr-a-peak@32:0.00000	tr-rmse:0.64122	tr-rmse:0.64122 
2024-04-29 03:49:07 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 03:49:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5376.3555 |      32.2512 |               32.2512 |    829 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6926
Total latency (us): 251.665

2024-04-29 03:49:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:49:33 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:49:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:50:37 [DEBUG] XGB validation: p-rmse: 0.158882	a-peak@32: 0.990386
2024-04-29 03:50:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.198390	tr-a-peak@32: 1.000000	tr-rmse: 0.862288	tr-rmse: 0.862288
2024-04-29 03:50:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.271534	tr-a-peak@32: 0.000000	tr-rmse: 0.640985	tr-rmse: 0.640985
2024-04-29 03:50:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.269089	tr-a-peak@32: 0.000000	tr-rmse: 0.641082	tr-rmse: 0.641082
2024-04-29 03:50:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.269089	tr-a-peak@32: 0.000000	tr-rmse: 0.641082	tr-rmse: 0.641082
2024-04-29 03:50:41 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26907	tr-a-peak@32:0.00000	tr-rmse:0.64108	tr-rmse:0.64108 
2024-04-29 03:50:41 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:50:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6990
Total latency (us): 251.287

2024-04-29 03:50:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #26: "fused_nn_batch_flatten"
2024-04-29 03:50:43 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 03:50:43 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 03:50:43 [INFO] [task_scheduler.cc:237] [Updated] Task #26: "fused_nn_batch_flatten"
2024-04-29 03:50:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1710.4747 |       7.3004 |                7.3004 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6990
Total latency (us): 251.287

2024-04-29 03:50:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 03:51:12 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:51:39 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:52:18 [DEBUG] XGB validation: p-rmse: 0.575670	a-peak@32: 0.950047
2024-04-29 03:52:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.209183	tr-a-peak@32: 1.000000	tr-rmse: 0.860702	tr-rmse: 0.860702
2024-04-29 03:52:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.273577	tr-a-peak@32: 0.312500	tr-rmse: 0.640622	tr-rmse: 0.640622
2024-04-29 03:52:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.271587	tr-a-peak@32: 0.000000	tr-rmse: 0.640762	tr-rmse: 0.640762
2024-04-29 03:52:22 [DEBUG] XGB iter  75: tr-p-rmse: 0.271587	tr-a-peak@32: 0.000000	tr-rmse: 0.640762	tr-rmse: 0.640762
2024-04-29 03:52:22 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27155	tr-a-peak@32:0.00000	tr-rmse:0.64078	tr-rmse:0.64078 
2024-04-29 03:52:22 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 03:52:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2736.2433 |      12.9778 |               25.9557 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7054
Total latency (us): 251.02

2024-04-29 03:52:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:54:16 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:54:42 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:55:20 [DEBUG] XGB validation: p-rmse: 0.284171	a-peak@32: 0.846964
2024-04-29 03:55:20 [DEBUG] XGB iter   0: tr-p-rmse: 2.175566	tr-a-peak@32: 0.672770	tr-rmse: 0.864943	tr-rmse: 0.864943
2024-04-29 03:55:22 [DEBUG] XGB iter  25: tr-p-rmse: 0.276310	tr-a-peak@32: 0.000000	tr-rmse: 0.643243	tr-rmse: 0.643243
2024-04-29 03:55:23 [DEBUG] XGB iter  50: tr-p-rmse: 0.274474	tr-a-peak@32: 0.000000	tr-rmse: 0.643337	tr-rmse: 0.643337
2024-04-29 03:55:24 [DEBUG] XGB iter  75: tr-p-rmse: 0.274474	tr-a-peak@32: 0.000000	tr-rmse: 0.643337	tr-rmse: 0.643337
2024-04-29 03:55:24 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27445	tr-a-peak@32:0.00000	tr-rmse:0.64335	tr-rmse:0.64335 
2024-04-29 03:55:24 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 03:55:24 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7118
Total latency (us): 250.994

2024-04-29 03:55:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 03:55:50 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:56:25 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:56:56 [DEBUG] XGB validation: p-rmse: 2.313087	a-peak@32: 0.983515
2024-04-29 03:56:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.187533	tr-a-peak@32: 0.970107	tr-rmse: 0.864304	tr-rmse: 0.864304
2024-04-29 03:56:58 [DEBUG] XGB iter  25: tr-p-rmse: 0.286587	tr-a-peak@32: 0.000000	tr-rmse: 0.642294	tr-rmse: 0.642294
2024-04-29 03:56:59 [DEBUG] XGB iter  50: tr-p-rmse: 0.283959	tr-a-peak@32: 0.000000	tr-rmse: 0.642386	tr-rmse: 0.642386
2024-04-29 03:57:00 [DEBUG] XGB iter  75: tr-p-rmse: 0.283959	tr-a-peak@32: 0.000000	tr-rmse: 0.642386	tr-rmse: 0.642386
2024-04-29 03:57:00 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.28392	tr-a-peak@32:0.00000	tr-rmse:0.64240	tr-rmse:0.64240 
2024-04-29 03:57:00 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 03:57:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    191 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7182
Total latency (us): 250.994

2024-04-29 03:57:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 03:57:28 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:57:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:57:59 [DEBUG] XGB validation: p-rmse: 1.149477	a-peak@32: 1.000000
2024-04-29 03:57:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.182212	tr-a-peak@32: 0.968299	tr-rmse: 0.864304	tr-rmse: 0.864304
2024-04-29 03:58:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.298922	tr-a-peak@32: 0.000000	tr-rmse: 0.642294	tr-rmse: 0.642294
2024-04-29 03:58:02 [DEBUG] XGB iter  50: tr-p-rmse: 0.296394	tr-a-peak@32: 0.000000	tr-rmse: 0.642386	tr-rmse: 0.642386
2024-04-29 03:58:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.296394	tr-a-peak@32: 0.000000	tr-rmse: 0.642386	tr-rmse: 0.642386
2024-04-29 03:58:02 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.29636	tr-a-peak@32:0.00000	tr-rmse:0.64240	tr-rmse:0.64240 
2024-04-29 03:58:03 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 03:58:03 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7246
Total latency (us): 250.994

2024-04-29 03:58:03 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 03:58:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:58:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 03:59:08 [DEBUG] XGB validation: p-rmse: 1.181784	a-peak@32: 0.000000
2024-04-29 03:59:08 [DEBUG] XGB iter   0: tr-p-rmse: 2.177515	tr-a-peak@32: 0.969664	tr-rmse: 0.863854	tr-rmse: 0.863854
2024-04-29 03:59:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.301431	tr-a-peak@32: 0.000000	tr-rmse: 0.641991	tr-rmse: 0.641991
2024-04-29 03:59:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.299634	tr-a-peak@32: 0.000000	tr-rmse: 0.642097	tr-rmse: 0.642097
2024-04-29 03:59:12 [DEBUG] XGB iter  75: tr-p-rmse: 0.299634	tr-a-peak@32: 0.000000	tr-rmse: 0.642097	tr-rmse: 0.642097
2024-04-29 03:59:12 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.29961	tr-a-peak@32:0.00000	tr-rmse:0.64211	tr-rmse:0.64211 
2024-04-29 03:59:12 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 03:59:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    893 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7310
Total latency (us): 250.994

2024-04-29 03:59:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 03:59:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 03:59:59 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:00:43 [DEBUG] XGB validation: p-rmse: 0.227985	a-peak@32: 0.931959
2024-04-29 04:00:43 [DEBUG] XGB iter   0: tr-p-rmse: 2.186603	tr-a-peak@32: 0.968750	tr-rmse: 0.861114	tr-rmse: 0.861114
2024-04-29 04:00:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.279788	tr-a-peak@32: 0.000000	tr-rmse: 0.641795	tr-rmse: 0.641795
2024-04-29 04:00:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.278248	tr-a-peak@32: 0.000000	tr-rmse: 0.641945	tr-rmse: 0.641945
2024-04-29 04:00:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.278248	tr-a-peak@32: 0.000000	tr-rmse: 0.641945	tr-rmse: 0.641945
2024-04-29 04:00:47 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27822	tr-a-peak@32:0.00000	tr-rmse:0.64196	tr-rmse:0.64196 
2024-04-29 04:00:47 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:00:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7374
Total latency (us): 250.994

2024-04-29 04:00:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:02:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:03:07 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:03:46 [DEBUG] XGB validation: p-rmse: 0.866640	a-peak@32: 0.814703
2024-04-29 04:03:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.193402	tr-a-peak@32: 1.000000	tr-rmse: 0.865149	tr-rmse: 0.865149
2024-04-29 04:03:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.282301	tr-a-peak@32: 0.000000	tr-rmse: 0.643203	tr-rmse: 0.643203
2024-04-29 04:03:49 [DEBUG] XGB iter  50: tr-p-rmse: 0.280247	tr-a-peak@32: 0.000000	tr-rmse: 0.643303	tr-rmse: 0.643303
2024-04-29 04:03:49 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.27966	tr-a-peak@32:0.17452	tr-rmse:0.64896	tr-rmse:0.64896 
2024-04-29 04:03:49 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:03:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    767 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7438
Total latency (us): 250.994

2024-04-29 04:03:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:05:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:06:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:07:05 [DEBUG] XGB validation: p-rmse: 0.819936	a-peak@32: 0.738118
2024-04-29 04:07:05 [DEBUG] XGB iter   0: tr-p-rmse: 2.184878	tr-a-peak@32: 1.000000	tr-rmse: 0.871103	tr-rmse: 0.871103
2024-04-29 04:07:07 [DEBUG] XGB iter  25: tr-p-rmse: 0.278850	tr-a-peak@32: 0.000000	tr-rmse: 0.646981	tr-rmse: 0.646981
2024-04-29 04:07:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.276682	tr-a-peak@32: 0.000000	tr-rmse: 0.647090	tr-rmse: 0.647090
2024-04-29 04:07:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.276682	tr-a-peak@32: 0.000000	tr-rmse: 0.647090	tr-rmse: 0.647090
2024-04-29 04:07:09 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27668	tr-a-peak@32:0.00000	tr-rmse:0.64709	tr-rmse:0.64709 
2024-04-29 04:07:09 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:07:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1242.9659 |       8.9280 |                8.9280 |    256 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7502
Total latency (us): 250.994

2024-04-29 04:07:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 04:07:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:08:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:08:36 [DEBUG] XGB validation: p-rmse: 0.460839	a-peak@32: 0.829323
2024-04-29 04:08:36 [DEBUG] XGB iter   0: tr-p-rmse: 2.190283	tr-a-peak@32: 0.718750	tr-rmse: 0.869434	tr-rmse: 0.869434
2024-04-29 04:08:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.292915	tr-a-peak@32: 0.000000	tr-rmse: 0.647425	tr-rmse: 0.647425
2024-04-29 04:08:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.290293	tr-a-peak@32: 0.000000	tr-rmse: 0.647551	tr-rmse: 0.647551
2024-04-29 04:08:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.290293	tr-a-peak@32: 0.000000	tr-rmse: 0.647551	tr-rmse: 0.647551
2024-04-29 04:08:40 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.29028	tr-a-peak@32:0.00000	tr-rmse:0.64755	tr-rmse:0.64755 
2024-04-29 04:08:40 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 04:08:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2738.9995 |      12.9648 |               25.9296 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7566
Total latency (us): 250.432

2024-04-29 04:08:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:10:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:10:59 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:11:37 [DEBUG] XGB validation: p-rmse: 0.314559	a-peak@32: 0.925526
2024-04-29 04:11:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.192221	tr-a-peak@32: 0.718750	tr-rmse: 0.874057	tr-rmse: 0.874057
2024-04-29 04:11:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.300021	tr-a-peak@32: 0.000000	tr-rmse: 0.649689	tr-rmse: 0.649689
2024-04-29 04:11:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.297227	tr-a-peak@32: 0.000000	tr-rmse: 0.649822	tr-rmse: 0.649822
2024-04-29 04:11:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.297227	tr-a-peak@32: 0.000000	tr-rmse: 0.649822	tr-rmse: 0.649822
2024-04-29 04:11:41 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.29722	tr-a-peak@32:0.00000	tr-rmse:0.64983	tr-rmse:0.64983 
2024-04-29 04:11:41 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:11:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1037.4411 |       5.4213 |               10.8427 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7630
Total latency (us): 250.019

2024-04-29 04:11:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 04:12:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:12:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:13:03 [DEBUG] XGB validation: p-rmse: 0.508057	a-peak@32: 0.909313
2024-04-29 04:13:03 [DEBUG] XGB iter   0: tr-p-rmse: 2.194604	tr-a-peak@32: 0.718750	tr-rmse: 0.871155	tr-rmse: 0.871155
2024-04-29 04:13:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.291270	tr-a-peak@32: 0.000000	tr-rmse: 0.648965	tr-rmse: 0.648965
2024-04-29 04:13:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.289474	tr-a-peak@32: 0.000000	tr-rmse: 0.649076	tr-rmse: 0.649076
2024-04-29 04:13:06 [DEBUG] XGB iter  75: tr-p-rmse: 0.289474	tr-a-peak@32: 0.000000	tr-rmse: 0.649076	tr-rmse: 0.649076
2024-04-29 04:13:07 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.28947	tr-a-peak@32:0.00000	tr-rmse:0.64908	tr-rmse:0.64908 
2024-04-29 04:13:07 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 04:13:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |    957 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7694
Total latency (us): 249.54

2024-04-29 04:13:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:13:31 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:13:54 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:14:30 [DEBUG] XGB validation: p-rmse: 0.381728	a-peak@32: 0.969618
2024-04-29 04:14:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.185865	tr-a-peak@32: 1.000000	tr-rmse: 0.869344	tr-rmse: 0.869344
2024-04-29 04:14:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.272082	tr-a-peak@32: 0.128253	tr-rmse: 0.647815	tr-rmse: 0.647815
2024-04-29 04:14:33 [DEBUG] XGB iter  50: tr-p-rmse: 0.270253	tr-a-peak@32: 0.102602	tr-rmse: 0.647960	tr-rmse: 0.647960
2024-04-29 04:14:34 [DEBUG] XGB iter  75: tr-p-rmse: 0.270253	tr-a-peak@32: 0.102602	tr-rmse: 0.647960	tr-rmse: 0.647960
2024-04-29 04:14:34 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27022	tr-a-peak@32:0.10260	tr-rmse:0.64797	tr-rmse:0.64797 
2024-04-29 04:14:34 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:14:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3275.9683 |      13.8417 |               27.6834 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7758
Total latency (us): 249.54

2024-04-29 04:14:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:16:31 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:16:55 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:17:33 [DEBUG] XGB validation: p-rmse: 0.225169	a-peak@32: 0.889891
2024-04-29 04:17:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.195605	tr-a-peak@32: 1.000000	tr-rmse: 0.874324	tr-rmse: 0.874324
2024-04-29 04:17:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.269021	tr-a-peak@32: 0.217773	tr-rmse: 0.650683	tr-rmse: 0.650683
2024-04-29 04:17:36 [DEBUG] XGB iter  50: tr-p-rmse: 0.267476	tr-a-peak@32: 0.182615	tr-rmse: 0.650813	tr-rmse: 0.650813
2024-04-29 04:17:37 [DEBUG] XGB iter  75: tr-p-rmse: 0.267476	tr-a-peak@32: 0.182615	tr-rmse: 0.650813	tr-rmse: 0.650813
2024-04-29 04:17:37 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.26745	tr-a-peak@32:0.18261	tr-rmse:0.65082	tr-rmse:0.65082 
2024-04-29 04:17:37 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:17:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       655.9277 |       6.3567 |                6.3567 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7822
Total latency (us): 249.306

2024-04-29 04:17:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 04:18:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:18:31 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:19:06 [DEBUG] XGB validation: p-rmse: 0.159392	a-peak@32: 0.967541
2024-04-29 04:19:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.190863	tr-a-peak@32: 1.000000	tr-rmse: 0.872169	tr-rmse: 0.872169
2024-04-29 04:19:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.281280	tr-a-peak@32: 0.000000	tr-rmse: 0.651141	tr-rmse: 0.651141
2024-04-29 04:19:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.278496	tr-a-peak@32: 0.000000	tr-rmse: 0.651249	tr-rmse: 0.651249
2024-04-29 04:19:10 [DEBUG] XGB iter  75: tr-p-rmse: 0.278496	tr-a-peak@32: 0.000000	tr-rmse: 0.651249	tr-rmse: 0.651249
2024-04-29 04:19:10 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27849	tr-a-peak@32:0.00000	tr-rmse:0.65125	tr-rmse:0.65125 
2024-04-29 04:19:10 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-04-29 04:19:10 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    831 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7886
Total latency (us): 248.991

2024-04-29 04:19:10 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:21:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:22:02 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:22:42 [DEBUG] XGB validation: p-rmse: 0.895750	a-peak@32: 0.512667
2024-04-29 04:22:43 [DEBUG] XGB iter   0: tr-p-rmse: 2.197947	tr-a-peak@32: 1.000000	tr-rmse: 0.873334	tr-rmse: 0.873334
2024-04-29 04:22:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.271706	tr-a-peak@32: 0.000000	tr-rmse: 0.651664	tr-rmse: 0.651664
2024-04-29 04:22:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.269024	tr-a-peak@32: 0.000000	tr-rmse: 0.651787	tr-rmse: 0.651787
2024-04-29 04:22:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.269024	tr-a-peak@32: 0.000000	tr-rmse: 0.651787	tr-rmse: 0.651787
2024-04-29 04:22:46 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26902	tr-a-peak@32:0.00000	tr-rmse:0.65179	tr-rmse:0.65179 
2024-04-29 04:22:46 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:22:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    767 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7950
Total latency (us): 248.991

2024-04-29 04:22:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 04:24:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:25:16 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:25:54 [DEBUG] XGB validation: p-rmse: 0.750672	a-peak@32: 0.865537
2024-04-29 04:25:54 [DEBUG] XGB iter   0: tr-p-rmse: 2.202572	tr-a-peak@32: 0.972596	tr-rmse: 0.874590	tr-rmse: 0.874590
2024-04-29 04:25:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.272668	tr-a-peak@32: 0.000000	tr-rmse: 0.651579	tr-rmse: 0.651579
2024-04-29 04:25:56 [DEBUG] XGB iter  50: tr-p-rmse: 0.270649	tr-a-peak@32: 0.000000	tr-rmse: 0.651706	tr-rmse: 0.651706
2024-04-29 04:25:57 [DEBUG] XGB iter  75: tr-p-rmse: 0.270649	tr-a-peak@32: 0.000000	tr-rmse: 0.651706	tr-rmse: 0.651706
2024-04-29 04:25:57 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27064	tr-a-peak@32:0.00000	tr-rmse:0.65171	tr-rmse:0.65171 
2024-04-29 04:25:58 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 04:25:58 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |       960.8346 |       8.6678 |                8.6678 |    320 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8014
Total latency (us): 248.991

2024-04-29 04:25:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 04:26:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:26:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:27:27 [DEBUG] XGB validation: p-rmse: 0.274686	a-peak@32: 0.963153
2024-04-29 04:27:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.201886	tr-a-peak@32: 1.000000	tr-rmse: 0.873115	tr-rmse: 0.873115
2024-04-29 04:27:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.276293	tr-a-peak@32: 0.000000	tr-rmse: 0.651121	tr-rmse: 0.651121
2024-04-29 04:27:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.274428	tr-a-peak@32: 0.000000	tr-rmse: 0.651223	tr-rmse: 0.651223
2024-04-29 04:27:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.274428	tr-a-peak@32: 0.000000	tr-rmse: 0.651223	tr-rmse: 0.651223
2024-04-29 04:27:31 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27443	tr-a-peak@32:0.00000	tr-rmse:0.65122	tr-rmse:0.65122 
2024-04-29 04:27:31 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-04-29 04:27:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8078
Total latency (us): 247.574

2024-04-29 04:27:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:29:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:29:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:30:25 [DEBUG] XGB validation: p-rmse: 0.174564	a-peak@32: 0.974779
2024-04-29 04:30:25 [DEBUG] XGB iter   0: tr-p-rmse: 2.209535	tr-a-peak@32: 1.000000	tr-rmse: 0.880837	tr-rmse: 0.880837
2024-04-29 04:30:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.264992	tr-a-peak@32: 0.000000	tr-rmse: 0.655848	tr-rmse: 0.655848
2024-04-29 04:30:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.262062	tr-a-peak@32: 0.000000	tr-rmse: 0.655968	tr-rmse: 0.655968
2024-04-29 04:30:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.262062	tr-a-peak@32: 0.000000	tr-rmse: 0.655968	tr-rmse: 0.655968
2024-04-29 04:30:29 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26203	tr-a-peak@32:0.00000	tr-rmse:0.65598	tr-rmse:0.65598 
2024-04-29 04:30:29 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:30:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8142
Total latency (us): 247.574

2024-04-29 04:30:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-04-29 04:30:34 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 04:30:34 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 04:30:34 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-04-29 04:30:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1021 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8142
Total latency (us): 247.574

2024-04-29 04:30:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:30:59 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:31:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:32:03 [DEBUG] XGB validation: p-rmse: 0.030142	a-peak@32: 0.999874
2024-04-29 04:32:03 [DEBUG] XGB iter   0: tr-p-rmse: 2.206607	tr-a-peak@32: 1.000000	tr-rmse: 0.878927	tr-rmse: 0.878927
2024-04-29 04:32:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.261263	tr-a-peak@32: 0.156250	tr-rmse: 0.655098	tr-rmse: 0.655098
2024-04-29 04:32:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.259565	tr-a-peak@32: 0.125000	tr-rmse: 0.655260	tr-rmse: 0.655260
2024-04-29 04:32:07 [DEBUG] XGB iter  75: tr-p-rmse: 0.259565	tr-a-peak@32: 0.125000	tr-rmse: 0.655260	tr-rmse: 0.655260
2024-04-29 04:32:07 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.25950	tr-a-peak@32:0.12500	tr-rmse:0.65532	tr-rmse:0.65532 
2024-04-29 04:32:07 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:32:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1039.3398 |       6.0538 |                6.0538 |    192 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8206
Total latency (us): 247.574

2024-04-29 04:32:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 04:32:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:32:59 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:33:34 [DEBUG] XGB validation: p-rmse: 0.267261	a-peak@32: 0.840497
2024-04-29 04:33:34 [DEBUG] XGB iter   0: tr-p-rmse: 2.180751	tr-a-peak@32: 1.000000	tr-rmse: 0.877444	tr-rmse: 0.877444
2024-04-29 04:33:36 [DEBUG] XGB iter  25: tr-p-rmse: 0.270757	tr-a-peak@32: 0.000000	tr-rmse: 0.655020	tr-rmse: 0.655020
2024-04-29 04:33:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.268365	tr-a-peak@32: 0.000000	tr-rmse: 0.655177	tr-rmse: 0.655177
2024-04-29 04:33:37 [DEBUG] XGB iter  75: tr-p-rmse: 0.268365	tr-a-peak@32: 0.000000	tr-rmse: 0.655177	tr-rmse: 0.655177
2024-04-29 04:33:38 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26831	tr-a-peak@32:0.00000	tr-rmse:0.65520	tr-rmse:0.65520 
2024-04-29 04:33:38 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-04-29 04:33:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    255 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8270
Total latency (us): 246.332

2024-04-29 04:33:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 04:34:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:34:36 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:35:15 [DEBUG] XGB validation: p-rmse: 1.903944	a-peak@32: 0.366994
2024-04-29 04:35:16 [DEBUG] XGB iter   0: tr-p-rmse: 2.174945	tr-a-peak@32: 1.000000	tr-rmse: 0.877151	tr-rmse: 0.877151
2024-04-29 04:35:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.260759	tr-a-peak@32: 0.250000	tr-rmse: 0.654397	tr-rmse: 0.654397
2024-04-29 04:35:18 [DEBUG] XGB iter  50: tr-p-rmse: 0.257458	tr-a-peak@32: 0.281250	tr-rmse: 0.654545	tr-rmse: 0.654545
2024-04-29 04:35:19 [DEBUG] XGB iter  75: tr-p-rmse: 0.257458	tr-a-peak@32: 0.281250	tr-rmse: 0.654545	tr-rmse: 0.654545
2024-04-29 04:35:19 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25745	tr-a-peak@32:0.28125	tr-rmse:0.65455	tr-rmse:0.65455 
2024-04-29 04:35:19 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 04:35:19 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3303.8258 |      13.7250 |               27.4499 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8334
Total latency (us): 246.332

2024-04-29 04:35:19 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:37:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:37:43 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:38:21 [DEBUG] XGB validation: p-rmse: 0.326454	a-peak@32: 0.934646
2024-04-29 04:38:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.204341	tr-a-peak@32: 0.952634	tr-rmse: 0.882214	tr-rmse: 0.882214
2024-04-29 04:38:23 [DEBUG] XGB iter  25: tr-p-rmse: 0.259443	tr-a-peak@32: 0.031250	tr-rmse: 0.657688	tr-rmse: 0.657688
2024-04-29 04:38:24 [DEBUG] XGB iter  50: tr-p-rmse: 0.257410	tr-a-peak@32: 0.031250	tr-rmse: 0.657830	tr-rmse: 0.657830
2024-04-29 04:38:25 [DEBUG] XGB iter  75: tr-p-rmse: 0.257410	tr-a-peak@32: 0.031250	tr-rmse: 0.657830	tr-rmse: 0.657830
2024-04-29 04:38:25 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.25739	tr-a-peak@32:0.03125	tr-rmse:0.65784	tr-rmse:0.65784 
2024-04-29 04:38:25 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:38:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2266.7824 |      13.4965 |               26.9929 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8398
Total latency (us): 246.322

2024-04-29 04:38:25 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:40:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:41:03 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:41:40 [DEBUG] XGB validation: p-rmse: 0.102962	a-peak@32: 0.976837
2024-04-29 04:41:40 [DEBUG] XGB iter   0: tr-p-rmse: 2.216627	tr-a-peak@32: 1.000000	tr-rmse: 0.889005	tr-rmse: 0.889005
2024-04-29 04:41:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.254379	tr-a-peak@32: 0.562500	tr-rmse: 0.662121	tr-rmse: 0.662121
2024-04-29 04:41:43 [DEBUG] XGB iter  50: tr-p-rmse: 0.252370	tr-a-peak@32: 0.468750	tr-rmse: 0.662275	tr-rmse: 0.662275
2024-04-29 04:41:44 [DEBUG] XGB iter  75: tr-p-rmse: 0.252370	tr-a-peak@32: 0.468750	tr-rmse: 0.662275	tr-rmse: 0.662275
2024-04-29 04:41:44 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25236	tr-a-peak@32:0.46875	tr-rmse:0.66228	tr-rmse:0.66228 
2024-04-29 04:41:44 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 04:41:44 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1022.0322 |       5.8889 |                5.8889 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8462
Total latency (us): 246.301

2024-04-29 04:41:44 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 04:42:12 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 04:42:34 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 04:43:10 [DEBUG] XGB validation: p-rmse: 0.595791	a-peak@32: 0.751304
2024-04-29 04:43:10 [DEBUG] XGB iter   0: tr-p-rmse: 2.189753	tr-a-peak@32: 1.000000	tr-rmse: 0.887414	tr-rmse: 0.887414
2024-04-29 04:43:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.257278	tr-a-peak@32: 0.406250	tr-rmse: 0.661479	tr-rmse: 0.661479
2024-04-29 04:43:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.255194	tr-a-peak@32: 0.281250	tr-rmse: 0.661637	tr-rmse: 0.661637
2024-04-29 04:43:14 [DEBUG] XGB iter  75: tr-p-rmse: 0.255194	tr-a-peak@32: 0.281250	tr-rmse: 0.661637	tr-rmse: 0.661637
2024-04-29 04:43:14 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.25515	tr-a-peak@32:0.28125	tr-rmse:0.66165	tr-rmse:0.66165 
2024-04-29 04:43:14 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 04:43:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1506.4171 |      12.0340 |               24.0680 |    831 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8525
Total latency (us): 246.112

2024-04-29 04:43:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 04:45:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:46:01 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:46:38 [DEBUG] XGB validation: p-rmse: 0.571379	a-peak@32: 0.983080
2024-04-29 04:46:38 [DEBUG] XGB iter   0: tr-p-rmse: 2.204368	tr-a-peak@32: 0.972596	tr-rmse: 0.887579	tr-rmse: 0.887579
2024-04-29 04:46:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.250609	tr-a-peak@32: 0.375000	tr-rmse: 0.661661	tr-rmse: 0.661661
2024-04-29 04:46:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.248658	tr-a-peak@32: 0.343750	tr-rmse: 0.661793	tr-rmse: 0.661793
2024-04-29 04:46:42 [DEBUG] XGB iter  75: tr-p-rmse: 0.248658	tr-a-peak@32: 0.343750	tr-rmse: 0.661793	tr-rmse: 0.661793
2024-04-29 04:46:42 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.24858	tr-a-peak@32:0.37500	tr-rmse:0.66186	tr-rmse:0.66186 
2024-04-29 04:46:42 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 04:46:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8589
Total latency (us): 245.342

2024-04-29 04:46:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 04:47:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:47:32 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:48:07 [DEBUG] XGB validation: p-rmse: 0.650276	a-peak@32: 0.884842
2024-04-29 04:48:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.190471	tr-a-peak@32: 1.000000	tr-rmse: 0.885962	tr-rmse: 0.885962
2024-04-29 04:48:09 [DEBUG] XGB iter  25: tr-p-rmse: 0.255615	tr-a-peak@32: 0.062500	tr-rmse: 0.661405	tr-rmse: 0.661405
2024-04-29 04:48:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.252743	tr-a-peak@32: 0.062500	tr-rmse: 0.661559	tr-rmse: 0.661559
2024-04-29 04:48:10 [DEBUG] XGB iter  75: tr-p-rmse: 0.252743	tr-a-peak@32: 0.062500	tr-rmse: 0.661559	tr-rmse: 0.661559
2024-04-29 04:48:10 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25273	tr-a-peak@32:0.06250	tr-rmse:0.66156	tr-rmse:0.66156 
2024-04-29 04:48:11 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-04-29 04:48:11 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1085 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8653
Total latency (us): 245.342

2024-04-29 04:48:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:48:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:49:01 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:49:07 [DEBUG] XGB validation: p-rmse: 1.355224	a-peak@32: 1.000000
2024-04-29 04:49:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.186217	tr-a-peak@32: 1.000000	tr-rmse: 0.885962	tr-rmse: 0.885962
2024-04-29 04:49:09 [DEBUG] XGB iter  25: tr-p-rmse: 0.271781	tr-a-peak@32: 0.000000	tr-rmse: 0.661405	tr-rmse: 0.661405
2024-04-29 04:49:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.269121	tr-a-peak@32: 0.000000	tr-rmse: 0.661559	tr-rmse: 0.661559
2024-04-29 04:49:11 [DEBUG] XGB iter  75: tr-p-rmse: 0.269121	tr-a-peak@32: 0.000000	tr-rmse: 0.661559	tr-rmse: 0.661559
2024-04-29 04:49:11 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26911	tr-a-peak@32:0.00000	tr-rmse:0.66156	tr-rmse:0.66156 
2024-04-29 04:49:11 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 04:49:11 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8717
Total latency (us): 245.342

2024-04-29 04:49:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 04:49:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:50:07 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:50:23 [DEBUG] XGB validation: p-rmse: 2.420421	a-peak@32: 0.000000
2024-04-29 04:50:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.178648	tr-a-peak@32: 1.000000	tr-rmse: 0.885778	tr-rmse: 0.885778
2024-04-29 04:50:26 [DEBUG] XGB iter  25: tr-p-rmse: 0.294602	tr-a-peak@32: 0.000000	tr-rmse: 0.661644	tr-rmse: 0.661644
2024-04-29 04:50:27 [DEBUG] XGB iter  50: tr-p-rmse: 0.290767	tr-a-peak@32: 0.000000	tr-rmse: 0.661757	tr-rmse: 0.661757
2024-04-29 04:50:27 [DEBUG] XGB iter  75: tr-p-rmse: 0.290767	tr-a-peak@32: 0.000000	tr-rmse: 0.661757	tr-rmse: 0.661757
2024-04-29 04:50:28 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.29077	tr-a-peak@32:0.00000	tr-rmse:0.66176	tr-rmse:0.66176 
2024-04-29 04:50:28 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-04-29 04:50:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    896 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8781
Total latency (us): 245.342

2024-04-29 04:50:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:52:25 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:53:15 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:53:53 [DEBUG] XGB validation: p-rmse: 0.151421	a-peak@32: 0.954550
2024-04-29 04:53:54 [DEBUG] XGB iter   0: tr-p-rmse: 2.190515	tr-a-peak@32: 0.952634	tr-rmse: 0.891209	tr-rmse: 0.891209
2024-04-29 04:53:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.282525	tr-a-peak@32: 0.000000	tr-rmse: 0.664961	tr-rmse: 0.664961
2024-04-29 04:53:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.279511	tr-a-peak@32: 0.000000	tr-rmse: 0.665078	tr-rmse: 0.665078
2024-04-29 04:53:58 [DEBUG] XGB iter  75: tr-p-rmse: 0.279511	tr-a-peak@32: 0.000000	tr-rmse: 0.665078	tr-rmse: 0.665078
2024-04-29 04:53:58 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.27949	tr-a-peak@32:0.00000	tr-rmse:0.66509	tr-rmse:0.66509 
2024-04-29 04:53:58 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 04:53:58 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8845
Total latency (us): 245.342

2024-04-29 04:53:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-04-29 04:54:03 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 04:54:03 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 04:54:03 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-04-29 04:54:03 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8845
Total latency (us): 245.342

2024-04-29 04:54:03 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:56:07 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 04:56:48 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 04:57:27 [DEBUG] XGB validation: p-rmse: 0.354039	a-peak@32: 0.923239
2024-04-29 04:57:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.203056	tr-a-peak@32: 0.976317	tr-rmse: 0.895138	tr-rmse: 0.895138
2024-04-29 04:57:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.287116	tr-a-peak@32: 0.000000	tr-rmse: 0.667121	tr-rmse: 0.667121
2024-04-29 04:57:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.285409	tr-a-peak@32: 0.000000	tr-rmse: 0.667246	tr-rmse: 0.667246
2024-04-29 04:57:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.285409	tr-a-peak@32: 0.000000	tr-rmse: 0.667246	tr-rmse: 0.667246
2024-04-29 04:57:31 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.28541	tr-a-peak@32:0.00000	tr-rmse:0.66725	tr-rmse:0.66725 
2024-04-29 04:57:31 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 04:57:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8909
Total latency (us): 245.342

2024-04-29 04:57:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #10: "fused_nn_max_pool2d_1"
2024-04-29 04:57:39 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-04-29 04:57:39 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-04-29 04:57:39 [INFO] [task_scheduler.cc:237] [Updated] Task #10: "fused_nn_max_pool2d_1"
2024-04-29 04:57:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    895 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8909
Total latency (us): 245.342

2024-04-29 04:57:39 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 04:59:50 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:00:14 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:00:53 [DEBUG] XGB validation: p-rmse: 0.213045	a-peak@32: 0.979642
2024-04-29 05:00:53 [DEBUG] XGB iter   0: tr-p-rmse: 2.211508	tr-a-peak@32: 0.976317	tr-rmse: 0.900446	tr-rmse: 0.900446
2024-04-29 05:00:55 [DEBUG] XGB iter  25: tr-p-rmse: 0.274846	tr-a-peak@32: 0.000000	tr-rmse: 0.669845	tr-rmse: 0.669845
2024-04-29 05:00:56 [DEBUG] XGB iter  50: tr-p-rmse: 0.273378	tr-a-peak@32: 0.000000	tr-rmse: 0.669993	tr-rmse: 0.669993
2024-04-29 05:00:57 [DEBUG] XGB iter  75: tr-p-rmse: 0.273378	tr-a-peak@32: 0.000000	tr-rmse: 0.669993	tr-rmse: 0.669993
2024-04-29 05:00:57 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27335	tr-a-peak@32:0.00000	tr-rmse:0.67002	tr-rmse:0.67002 
2024-04-29 05:00:57 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-04-29 05:00:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2268.5522 |      13.4859 |               26.9719 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8973
Total latency (us): 245.342

2024-04-29 05:00:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 05:03:28 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:04:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:04:39 [DEBUG] XGB validation: p-rmse: 0.318120	a-peak@32: 0.888278
2024-04-29 05:04:39 [DEBUG] XGB iter   0: tr-p-rmse: 2.230956	tr-a-peak@32: 1.000000	tr-rmse: 0.903119	tr-rmse: 0.903119
2024-04-29 05:04:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.270388	tr-a-peak@32: 0.000000	tr-rmse: 0.670462	tr-rmse: 0.670462
2024-04-29 05:04:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.269010	tr-a-peak@32: 0.000000	tr-rmse: 0.670629	tr-rmse: 0.670629
2024-04-29 05:04:42 [DEBUG] XGB iter  75: tr-p-rmse: 0.269010	tr-a-peak@32: 0.000000	tr-rmse: 0.670629	tr-rmse: 0.670629
2024-04-29 05:04:43 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.26896	tr-a-peak@32:0.00000	tr-rmse:0.67065	tr-rmse:0.67065 
2024-04-29 05:04:43 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 05:04:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1085.4374 |       5.1816 |               10.3632 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9037
Total latency (us): 245.011

2024-04-29 05:04:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 05:05:07 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:05:30 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:06:05 [DEBUG] XGB validation: p-rmse: 0.429849	a-peak@32: 0.821800
2024-04-29 05:06:05 [DEBUG] XGB iter   0: tr-p-rmse: 2.205913	tr-a-peak@32: 1.000000	tr-rmse: 0.901130	tr-rmse: 0.901130
2024-04-29 05:06:07 [DEBUG] XGB iter  25: tr-p-rmse: 0.273365	tr-a-peak@32: 0.000000	tr-rmse: 0.669904	tr-rmse: 0.669904
2024-04-29 05:06:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.271695	tr-a-peak@32: 0.000000	tr-rmse: 0.670055	tr-rmse: 0.670055
2024-04-29 05:06:09 [DEBUG] XGB iter  75: tr-p-rmse: 0.271695	tr-a-peak@32: 0.000000	tr-rmse: 0.670055	tr-rmse: 0.670055
2024-04-29 05:06:09 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27169	tr-a-peak@32:0.00000	tr-rmse:0.67006	tr-rmse:0.67006 
2024-04-29 05:06:09 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-04-29 05:06:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9101
Total latency (us): 244.141

2024-04-29 05:06:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 05:06:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:06:59 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:07:36 [DEBUG] XGB validation: p-rmse: 0.510945	a-peak@32: 0.922935
2024-04-29 05:07:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.195507	tr-a-peak@32: 1.000000	tr-rmse: 0.899370	tr-rmse: 0.899370
2024-04-29 05:07:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.279766	tr-a-peak@32: 0.000000	tr-rmse: 0.669792	tr-rmse: 0.669792
2024-04-29 05:07:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.277737	tr-a-peak@32: 0.000000	tr-rmse: 0.669954	tr-rmse: 0.669954
2024-04-29 05:07:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.277737	tr-a-peak@32: 0.000000	tr-rmse: 0.669954	tr-rmse: 0.669954
2024-04-29 05:07:40 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27771	tr-a-peak@32:0.00000	tr-rmse:0.66997	tr-rmse:0.66997 
2024-04-29 05:07:41 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-04-29 05:07:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9165
Total latency (us): 244.141

2024-04-29 05:07:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 05:07:47 [INFO] [task_scheduler.cc:193] Sending 36 sample(s) to builder
2024-04-29 05:08:01 [INFO] [task_scheduler.cc:195] Sending 36 sample(s) to runner
2024-04-29 05:08:21 [DEBUG] XGB validation: p-rmse: 0.039393	a-peak@32: 0.999342
2024-04-29 05:08:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.194167	tr-a-peak@32: 1.000000	tr-rmse: 0.899124	tr-rmse: 0.899124
2024-04-29 05:08:24 [DEBUG] XGB iter  25: tr-p-rmse: 0.284260	tr-a-peak@32: 0.000000	tr-rmse: 0.669653	tr-rmse: 0.669653
2024-04-29 05:08:25 [DEBUG] XGB iter  50: tr-p-rmse: 0.281575	tr-a-peak@32: 0.000000	tr-rmse: 0.669747	tr-rmse: 0.669747
2024-04-29 05:08:26 [DEBUG] XGB iter  75: tr-p-rmse: 0.281575	tr-a-peak@32: 0.000000	tr-rmse: 0.669747	tr-rmse: 0.669747
2024-04-29 05:08:26 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.28156	tr-a-peak@32:0.00000	tr-rmse:0.66975	tr-rmse:0.66975 
2024-04-29 05:08:26 [INFO] [task_scheduler.cc:237] [Updated] Task #25: "fused_nn_global_avg_pool2d"
2024-04-29 05:08:26 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5440.2266 |      31.8726 |               31.8726 |   1149 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9201
Total latency (us): 244.141

2024-04-29 05:08:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:08:51 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-04-29 05:09:17 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-04-29 05:09:57 [DEBUG] XGB validation: p-rmse: 0.443552	a-peak@32: 0.942934
2024-04-29 05:09:57 [DEBUG] XGB iter   0: tr-p-rmse: 2.203526	tr-a-peak@32: 0.976317	tr-rmse: 0.897134	tr-rmse: 0.897134
2024-04-29 05:09:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.267609	tr-a-peak@32: 0.000000	tr-rmse: 0.667152	tr-rmse: 0.667152
2024-04-29 05:10:00 [DEBUG] XGB iter  50: tr-p-rmse: 0.265289	tr-a-peak@32: 0.000000	tr-rmse: 0.667292	tr-rmse: 0.667292
2024-04-29 05:10:01 [DEBUG] XGB iter  75: tr-p-rmse: 0.265289	tr-a-peak@32: 0.000000	tr-rmse: 0.667292	tr-rmse: 0.667292
2024-04-29 05:10:01 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26528	tr-a-peak@32:0.00000	tr-rmse:0.66729	tr-rmse:0.66729 
2024-04-29 05:10:01 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:10:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1212 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    125 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9264
Total latency (us): 243.154

2024-04-29 05:10:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #27: "fused_nn_softmax"
2024-04-29 05:10:10 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-04-29 05:10:33 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-04-29 05:11:09 [DEBUG] XGB validation: p-rmse: 0.035777	a-peak@32: 1.000000
2024-04-29 05:11:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.198890	tr-a-peak@32: 0.976317	tr-rmse: 0.896748	tr-rmse: 0.896748
2024-04-29 05:11:11 [DEBUG] XGB iter  25: tr-p-rmse: 0.269254	tr-a-peak@32: 0.000000	tr-rmse: 0.666859	tr-rmse: 0.666859
2024-04-29 05:11:12 [DEBUG] XGB iter  50: tr-p-rmse: 0.267139	tr-a-peak@32: 0.000000	tr-rmse: 0.667029	tr-rmse: 0.667029
2024-04-29 05:11:13 [DEBUG] XGB iter  75: tr-p-rmse: 0.267139	tr-a-peak@32: 0.000000	tr-rmse: 0.667029	tr-rmse: 0.667029
2024-04-29 05:11:13 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.26714	tr-a-peak@32:0.00000	tr-rmse:0.66703	tr-rmse:0.66703 
2024-04-29 05:11:13 [INFO] [task_scheduler.cc:237] [Updated] Task #27: "fused_nn_softmax"
2024-04-29 05:11:13 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2783.3408 |      12.7582 |               25.5165 |    960 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1212 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9326
Total latency (us): 243.154

2024-04-29 05:11:13 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 05:13:15 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:13:38 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:14:17 [DEBUG] XGB validation: p-rmse: 0.142579	a-peak@32: 0.969370
2024-04-29 05:14:17 [DEBUG] XGB iter   0: tr-p-rmse: 2.214607	tr-a-peak@32: 1.000000	tr-rmse: 0.898280	tr-rmse: 0.898280
2024-04-29 05:14:19 [DEBUG] XGB iter  25: tr-p-rmse: 0.256607	tr-a-peak@32: 0.000000	tr-rmse: 0.666807	tr-rmse: 0.666807
2024-04-29 05:14:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.254406	tr-a-peak@32: 0.000000	tr-rmse: 0.666966	tr-rmse: 0.666966
2024-04-29 05:14:21 [DEBUG] XGB iter  75: tr-p-rmse: 0.254406	tr-a-peak@32: 0.000000	tr-rmse: 0.666966	tr-rmse: 0.666966
2024-04-29 05:14:21 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25440	tr-a-peak@32:0.00000	tr-rmse:0.66697	tr-rmse:0.66697 
2024-04-29 05:14:21 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-04-29 05:14:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1212 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9390
Total latency (us): 242.622

2024-04-29 05:14:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 05:16:27 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:16:50 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:17:28 [DEBUG] XGB validation: p-rmse: 0.158635	a-peak@32: 0.941713
2024-04-29 05:17:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.217005	tr-a-peak@32: 1.000000	tr-rmse: 0.903488	tr-rmse: 0.903488
2024-04-29 05:17:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.262438	tr-a-peak@32: 0.000000	tr-rmse: 0.670450	tr-rmse: 0.670450
2024-04-29 05:17:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.260227	tr-a-peak@32: 0.000000	tr-rmse: 0.670591	tr-rmse: 0.670591
2024-04-29 05:17:32 [DEBUG] XGB iter  75: tr-p-rmse: 0.260227	tr-a-peak@32: 0.000000	tr-rmse: 0.670591	tr-rmse: 0.670591
2024-04-29 05:17:32 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26020	tr-a-peak@32:0.00000	tr-rmse:0.67060	tr-rmse:0.67060 
2024-04-29 05:17:32 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 05:17:32 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1326.4086 |       8.3664 |                8.3664 |    320 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1212 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9454
Total latency (us): 242.622

2024-04-29 05:17:32 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 05:17:59 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:18:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:18:58 [DEBUG] XGB validation: p-rmse: 0.149729	a-peak@32: 0.962147
2024-04-29 05:18:58 [DEBUG] XGB iter   0: tr-p-rmse: 2.197777	tr-a-peak@32: 1.000000	tr-rmse: 0.901815	tr-rmse: 0.901815
2024-04-29 05:19:00 [DEBUG] XGB iter  25: tr-p-rmse: 0.264761	tr-a-peak@32: 0.000000	tr-rmse: 0.670146	tr-rmse: 0.670146
2024-04-29 05:19:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.262012	tr-a-peak@32: 0.000000	tr-rmse: 0.670294	tr-rmse: 0.670294
2024-04-29 05:19:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.262012	tr-a-peak@32: 0.000000	tr-rmse: 0.670294	tr-rmse: 0.670294
2024-04-29 05:19:02 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26199	tr-a-peak@32:0.00000	tr-rmse:0.67030	tr-rmse:0.67030 
2024-04-29 05:19:02 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-04-29 05:19:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1212 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9518
Total latency (us): 242.599

2024-04-29 05:19:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:19:27 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:19:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:20:31 [DEBUG] XGB validation: p-rmse: 0.216233	a-peak@32: 0.902007
2024-04-29 05:20:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.196446	tr-a-peak@32: 1.000000	tr-rmse: 0.900087	tr-rmse: 0.900087
2024-04-29 05:20:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.252985	tr-a-peak@32: 0.000000	tr-rmse: 0.669955	tr-rmse: 0.669955
2024-04-29 05:20:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.251134	tr-a-peak@32: 0.000000	tr-rmse: 0.670078	tr-rmse: 0.670078
2024-04-29 05:20:35 [DEBUG] XGB iter  75: tr-p-rmse: 0.251134	tr-a-peak@32: 0.000000	tr-rmse: 0.670078	tr-rmse: 0.670078
2024-04-29 05:20:35 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25112	tr-a-peak@32:0.00000	tr-rmse:0.67009	tr-rmse:0.67009 
2024-04-29 05:20:35 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:20:35 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1055.8495 |       5.7003 |                5.7003 |    255 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9582
Total latency (us): 242.599

2024-04-29 05:20:35 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 05:21:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:21:24 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:22:00 [DEBUG] XGB validation: p-rmse: 0.390185	a-peak@32: 0.867913
2024-04-29 05:22:00 [DEBUG] XGB iter   0: tr-p-rmse: 2.188704	tr-a-peak@32: 1.000000	tr-rmse: 0.898480	tr-rmse: 0.898480
2024-04-29 05:22:02 [DEBUG] XGB iter  25: tr-p-rmse: 0.258732	tr-a-peak@32: 0.000000	tr-rmse: 0.670251	tr-rmse: 0.670251
2024-04-29 05:22:03 [DEBUG] XGB iter  50: tr-p-rmse: 0.256656	tr-a-peak@32: 0.000000	tr-rmse: 0.670381	tr-rmse: 0.670381
2024-04-29 05:22:04 [DEBUG] XGB iter  75: tr-p-rmse: 0.256656	tr-a-peak@32: 0.000000	tr-rmse: 0.670381	tr-rmse: 0.670381
2024-04-29 05:22:04 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.25662	tr-a-peak@32:0.00000	tr-rmse:0.67041	tr-rmse:0.67041 
2024-04-29 05:22:04 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-04-29 05:22:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1023 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9646
Total latency (us): 242.537

2024-04-29 05:22:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 05:24:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:24:44 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:25:23 [DEBUG] XGB validation: p-rmse: 0.413670	a-peak@32: 0.740612
2024-04-29 05:25:23 [DEBUG] XGB iter   0: tr-p-rmse: 2.197673	tr-a-peak@32: 0.968837	tr-rmse: 0.903132	tr-rmse: 0.903132
2024-04-29 05:25:25 [DEBUG] XGB iter  25: tr-p-rmse: 0.253282	tr-a-peak@32: 0.000000	tr-rmse: 0.673580	tr-rmse: 0.673580
2024-04-29 05:25:26 [DEBUG] XGB iter  50: tr-p-rmse: 0.251226	tr-a-peak@32: 0.000000	tr-rmse: 0.673738	tr-rmse: 0.673738
2024-04-29 05:25:27 [DEBUG] XGB iter  75: tr-p-rmse: 0.251226	tr-a-peak@32: 0.000000	tr-rmse: 0.673738	tr-rmse: 0.673738
2024-04-29 05:25:27 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25121	tr-a-peak@32:0.00000	tr-rmse:0.67375	tr-rmse:0.67375 
2024-04-29 05:25:27 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-04-29 05:25:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       877.2624 |       7.1202 |                7.1202 |    319 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9710
Total latency (us): 242.537

2024-04-29 05:25:27 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 05:25:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:26:18 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:26:55 [DEBUG] XGB validation: p-rmse: 0.232985	a-peak@32: 0.996056
2024-04-29 05:26:55 [DEBUG] XGB iter   0: tr-p-rmse: 2.206703	tr-a-peak@32: 0.882951	tr-rmse: 0.901892	tr-rmse: 0.901892
2024-04-29 05:26:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.270122	tr-a-peak@32: 0.000000	tr-rmse: 0.674990	tr-rmse: 0.674990
2024-04-29 05:26:58 [DEBUG] XGB iter  50: tr-p-rmse: 0.266550	tr-a-peak@32: 0.000000	tr-rmse: 0.675098	tr-rmse: 0.675098
2024-04-29 05:26:59 [DEBUG] XGB iter  75: tr-p-rmse: 0.266550	tr-a-peak@32: 0.000000	tr-rmse: 0.675098	tr-rmse: 0.675098
2024-04-29 05:26:59 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26654	tr-a-peak@32:0.00000	tr-rmse:0.67510	tr-rmse:0.67510 
2024-04-29 05:26:59 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-04-29 05:26:59 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:26:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:27:24 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-04-29 05:27:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-04-29 05:28:27 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 27
2024-04-29 05:28:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:27 [INFO] [task_scheduler.cc:260] Task #1 has finished. Remaining task(s): 26
2024-04-29 05:28:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #2 has finished. Remaining task(s): 25
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #3 has finished. Remaining task(s): 24
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #4 has finished. Remaining task(s): 23
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #5 has finished. Remaining task(s): 22
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #6 has finished. Remaining task(s): 21
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #7 has finished. Remaining task(s): 20
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #8 has finished. Remaining task(s): 19
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #9 has finished. Remaining task(s): 18
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #10 has finished. Remaining task(s): 17
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #11 has finished. Remaining task(s): 16
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #12 has finished. Remaining task(s): 15
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #13 has finished. Remaining task(s): 14
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #14 has finished. Remaining task(s): 13
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #15 has finished. Remaining task(s): 12
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #16 has finished. Remaining task(s): 11
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #17 has finished. Remaining task(s): 10
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #18 has finished. Remaining task(s): 9
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #19 has finished. Remaining task(s): 8
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #20 has finished. Remaining task(s): 7
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #21 has finished. Remaining task(s): 6
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #22 has finished. Remaining task(s): 5
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [INFO] [task_scheduler.cc:260] Task #23 has finished. Remaining task(s): 4
2024-04-29 05:28:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1276 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9774
Total latency (us): 242.316

2024-04-29 05:28:28 [DEBUG] XGB validation: p-rmse: 0.138957	a-peak@32: 0.969412
2024-04-29 05:28:29 [DEBUG] XGB iter   0: tr-p-rmse: 2.198338	tr-a-peak@32: 0.867418	tr-rmse: 0.900306	tr-rmse: 0.900306
2024-04-29 05:28:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.264935	tr-a-peak@32: 0.000000	tr-rmse: 0.674785	tr-rmse: 0.674785
2024-04-29 05:28:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.260372	tr-a-peak@32: 0.000000	tr-rmse: 0.674902	tr-rmse: 0.674902
2024-04-29 05:28:33 [DEBUG] XGB iter  75: tr-p-rmse: 0.260372	tr-a-peak@32: 0.000000	tr-rmse: 0.674902	tr-rmse: 0.674902
2024-04-29 05:28:33 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.26035	tr-a-peak@32:0.00000	tr-rmse:0.67491	tr-rmse:0.67491 
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1340 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9838
Total latency (us): 242.316

2024-04-29 05:28:33 [INFO] [task_scheduler.cc:260] Task #24 has finished. Remaining task(s): 3
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1340 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9838
Total latency (us): 242.316

2024-04-29 05:28:33 [INFO] [task_scheduler.cc:260] Task #25 has finished. Remaining task(s): 2
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1340 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9838
Total latency (us): 242.316

2024-04-29 05:28:33 [INFO] [task_scheduler.cc:260] Task #26 has finished. Remaining task(s): 1
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1340 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |    Y 
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9838
Total latency (us): 242.316

2024-04-29 05:28:33 [INFO] [task_scheduler.cc:260] Task #27 has finished. Remaining task(s): 0
2024-04-29 05:28:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2296.7366 |      13.3204 |               26.6409 |   1087 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1556.2063 |      11.6490 |               23.2980 |    959 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2842.6689 |      12.4920 |               24.9839 |   1024 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3305.0295 |      13.7200 |               27.4399 |   1087 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4712.2317 |       9.3710 |                9.3710 |    384 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |     61 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1307.5604 |       4.8120 |                4.8120 |    256 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1775.2927 |       7.0339 |                7.0339 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       233.0168 |       3.6041 |                3.6041 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1067.5627 |       5.6377 |                5.6377 |    319 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1509.2474 |       7.9447 |                7.9447 |    319 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1468.8104 |       4.1929 |                8.3858 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0003 |       3.0413 |                6.0826 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       124.3400 |       3.1315 |                3.1315 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       690.1928 |       6.0412 |                6.0412 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       905.3825 |       6.8990 |                6.8990 |    383 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |     64 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1148.6092 |       7.2508 |                7.2508 |    384 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |      1330.0122 |       8.3437 |                8.3437 |    384 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1184.8915 |       4.7467 |                9.4934 |    448 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.7780 |                5.5560 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5614.0558 |      30.8857 |               30.8857 |   1340 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        47.9728 |       3.5437 |                3.5437 |    160 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.4346 |                2.4346 |      5 |    Y 
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.1424 |       3.5014 |                3.5014 |    187 |    Y 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9838
Total latency (us): 242.316

