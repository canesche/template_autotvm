2024-04-27 23:39:01 [INFO] [task_scheduler.cc:160] Initializing Task #1: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu"
2024-04-27 23:39:01 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4), T.int64(3), T.int64(11), T.int64(11)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-27 23:39:01 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-27 23:39:01 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0 in T.grid(T.int64(1), T.int64(4), T.int64(55), T.int64(5)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(51), T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), oh_0 * T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ow_0 * T.int64(44) + ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(11), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(55), oh_0 + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(11) + ow_1 * T.int64(11) + ow_2 * T.int64(11) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[55, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[5, 1, 1, 11])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-27 23:39:01 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
            for n_0, oc_chunk_0 in T.grid(T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(227), T.int64(227), T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(55), T.int64(5), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(11), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), oh_0 + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(11) + ow_1 * T.int64(11) + ow_2 * T.int64(11) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(55), oh_0 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(55), ow_0 * T.int64(11) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[55, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[5, 1, 1, 11])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-27 23:39:01 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(4), T.int64(55), T.int64(5), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(51), T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), oh_0 * T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ow_0 * T.int64(44) + ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(11), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(55), oh_0 + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(11) + ow_1 * T.int64(11) + ow_2 * T.int64(11) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(11), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), oh_0 + ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), ow_0 * T.int64(11) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[55, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[5, 1, 1, 11])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-27 23:39:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-27 23:39:52 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-27 23:39:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-27 23:39:57 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-27 23:40:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-27 23:40:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-27 23:40:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-27 23:40:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-27 23:40:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9991  0.9990  0.9981  0.9974  0.9974  0.9967  0.9966  0.9963  0.9959  0.9956  0.9953  0.9950  0.9946  0.9931  0.9920  0.9920
[17 : 32]:	0.9920  0.9918  0.9911  0.9893  0.9890  0.9885  0.9883  0.9873  0.9870  0.9870  0.9868  0.9862  0.9861  0.9855  0.9853  0.9852
[33 : 48]:	0.9851  0.9832  0.9830  0.9827  0.9822  0.9806  0.9804  0.9802  0.9791  0.9788  0.9780  0.9780  0.9762  0.9762  0.9762  0.9761
[49 : 64]:	0.9752  0.9745  0.9744  0.9735  0.9735  0.9731  0.9724  0.9721  0.9720  0.9719  0.9711  0.9706  0.9705  0.9694  0.9687  0.9687
2024-04-27 23:40:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-27 23:40:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1: GFLOPs: 102.0155. Time: 1381.5630 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #2: GFLOPs: 9.3939. Time: 15003.3940 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #3: GFLOPs: 45.4945. Time: 3097.9776 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #4: GFLOPs: 1.9276. Time: 73118.8653 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #5: GFLOPs: 41.1737. Time: 3423.0771 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #6: GFLOPs: 37.5168. Time: 3756.7358 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #7: GFLOPs: 16.7885. Time: 8395.0727 us. Best GFLOPs: 102.0155
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #8: GFLOPs: 123.3541. Time: 1142.5706 us. Best GFLOPs: 123.3541
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #9: GFLOPs: 183.1384. Time: 769.5863 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #10: GFLOPs: 3.3610. Time: 41934.0853 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #11: GFLOPs: 4.0343. Time: 34935.2450 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #12: GFLOPs: 45.4396. Time: 3101.7165 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #13: GFLOPs: 85.7359. Time: 1643.8945 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #14: GFLOPs: 105.5106. Time: 1335.7973 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #15: GFLOPs: 86.8000. Time: 1623.7417 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #16: GFLOPs: 6.7416. Time: 20906.0538 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #17: GFLOPs: 17.8049. Time: 7915.8348 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #18: GFLOPs: 16.6708. Time: 8454.3655 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #19: GFLOPs: 1.5995. Time: 88113.8970 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #20: GFLOPs: 58.4792. Time: 2410.1010 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #21: GFLOPs: 53.9914. Time: 2610.4319 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #22: GFLOPs: 30.0530. Time: 4689.7339 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #23: GFLOPs: 103.6888. Time: 1359.2680 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #24: GFLOPs: 50.6564. Time: 2782.2921 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #25: GFLOPs: 174.9901. Time: 805.4216 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #26: GFLOPs: 6.1495. Time: 22919.2326 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #27: GFLOPs: 26.6120. Time: 5296.1317 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #28: GFLOPs: 73.9389. Time: 1906.1789 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #29: GFLOPs: 4.1386. Time: 34055.4730 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #30: GFLOPs: 38.6870. Time: 3643.1085 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #31: GFLOPs: 21.5998. Time: 6525.1073 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #32: GFLOPs: 26.3811. Time: 5342.4899 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #33: GFLOPs: 7.3681. Time: 19128.4043 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #34: GFLOPs: 2.0575. Time: 68501.3997 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #35: GFLOPs: 70.7493. Time: 1992.1170 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #36: GFLOPs: 21.7203. Time: 6488.8948 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #37: GFLOPs: 12.6986. Time: 11098.9319 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #38: GFLOPs: 19.2789. Time: 7310.6424 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #39: GFLOPs: 19.5667. Time: 7203.0796 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #40: GFLOPs: 37.7791. Time: 3730.6590 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #41: GFLOPs: 30.7321. Time: 4586.1058 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #42: GFLOPs: 101.1218. Time: 1393.7721 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #43: GFLOPs: 14.8939. Time: 9462.9865 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #44: GFLOPs: 9.8567. Time: 14298.9389 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #45: GFLOPs: 79.7398. Time: 1767.5089 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #46: GFLOPs: 24.6905. Time: 5708.2938 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #47: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(20), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(227), T.int64(51)):
                for ax4_fused in T.vectorized(T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), ax2)
                        v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(5) * T.int64(44) + ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(5), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(5) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(5) * T.int64(11) + ow_1 * T.int64(11) + ow_2_init * T.int64(11) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(11), T.int64(11), T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(5) * T.int64(4) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(5) * T.int64(11) + ow_1 * T.int64(11) + ow_2 * T.int64(11) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3025)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12100))
                    v_ax2 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12100) // T.int64(220))
                    v_ax3 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(220) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[5, 1, 1, 11])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 2, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b67)
l79 = sch.fuse(l70, l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136 = sch.get_loops(block=b113)
b137 = sch.decompose_reduction(block=b113, loop=l121)
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #48: GFLOPs: 11.3663. Time: 12399.8368 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #49: GFLOPs: 51.8716. Time: 2717.1068 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #50: GFLOPs: 117.9130. Time: 1195.2953 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #51: GFLOPs: 4.8947. Time: 28794.3660 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #52: GFLOPs: 8.5746. Time: 16436.9160 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #53: GFLOPs: 33.2902. Time: 4233.7017 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #54: GFLOPs: 94.8025. Time: 1486.6781 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #55: GFLOPs: 122.3782. Time: 1151.6824 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #56: GFLOPs: 41.0065. Time: 3437.0394 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #57: GFLOPs: 62.4210. Time: 2257.9082 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #58: GFLOPs: 15.6996. Time: 8977.3779 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #59: GFLOPs: 82.5007. Time: 1708.3582 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #60: GFLOPs: 58.8168. Time: 2396.2679 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #61: GFLOPs: 6.6249. Time: 21274.4364 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #62: GFLOPs: 8.6003. Time: 16387.9151 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #63: GFLOPs: 77.9120. Time: 1808.9731 us. Best GFLOPs: 183.1384
2024-04-28 00:09:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #64: GFLOPs: 52.2593. Time: 2696.9517 us. Best GFLOPs: 183.1384
2024-04-28 00:22:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:22:26 [INFO] [evolutionary_search.cc:715] Picked top 63 candidate(s) from database
2024-04-28 00:22:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:22:31 [INFO] [evolutionary_search.cc:723] Sampled 449 candidate(s)
2024-04-28 00:22:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:22:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:23:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:23:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:23:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9988  0.9988  0.9369  0.9334  0.9223  0.9222  0.9221  0.9079  0.9018  0.9018  0.8889  0.8868  0.8731  0.8727  0.8359  0.8342
[17 : 32]:	0.8340  0.8303  0.8294  0.8246  0.8236  0.8204  0.8137  0.8125  0.8090  0.8090  0.8090  0.8018  0.8018  0.8003  0.7945  0.7943
[33 : 48]:	0.7929  0.7915  0.7905  0.7900  0.7850  0.7823  0.7810  0.7810  0.7810  0.7794  0.7794  0.7780  0.7762  0.7743  0.7740  0.7740
[49 : 64]:	0.7738  0.7733  0.7732  0.7690  0.7690  0.7663  0.7663  0.7632  0.7630  0.7619  0.7543  0.7542  0.7526  0.7515  0.7504  0.7482
2024-04-28 00:23:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:23:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #65: GFLOPs: 179.9008. Time: 783.4362 us. Best GFLOPs: 183.1384
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #66: GFLOPs: 250.7253. Time: 562.1322 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #67: GFLOPs: 179.5496. Time: 784.9685 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #68: GFLOPs: 224.5959. Time: 627.5306 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #69: GFLOPs: 139.5971. Time: 1009.6257 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #70: GFLOPs: 51.2219. Time: 2751.5722 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #71: GFLOPs: 196.3011. Time: 717.9827 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #72: GFLOPs: 75.0727. Time: 1877.3912 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #73: GFLOPs: 197.5369. Time: 713.4911 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #74: GFLOPs: 205.1883. Time: 686.8853 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #75: GFLOPs: 145.5421. Time: 968.3853 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #76: GFLOPs: 139.4591. Time: 1010.6246 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #77: GFLOPs: 101.8671. Time: 1383.5753 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #78: GFLOPs: 133.5542. Time: 1055.3079 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #79: GFLOPs: 65.1238. Time: 2164.1989 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #80: GFLOPs: 74.0469. Time: 1903.3978 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #81: GFLOPs: 37.5799. Time: 3750.4320 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #82: GFLOPs: 62.3830. Time: 2259.2818 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #83: GFLOPs: 54.0431. Time: 2607.9351 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #84: GFLOPs: 48.9829. Time: 2877.3446 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #85: GFLOPs: 82.8046. Time: 1702.0891 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #86: GFLOPs: 74.0272. Time: 1903.9048 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #87: GFLOPs: 122.8474. Time: 1147.2831 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #88: GFLOPs: 71.5762. Time: 1969.1021 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #89: GFLOPs: 149.4323. Time: 943.1748 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #90: GFLOPs: 126.8323. Time: 1111.2374 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #91: GFLOPs: 112.0206. Time: 1258.1684 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #92: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(55) + oh_2_init * T.int64(11) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(227), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(11), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(55) + oh_2 * T.int64(11) + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 * T.int64(11) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 5, 11])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 11])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #93: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(55) + oh_2_init * T.int64(11) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(227), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(55) + oh_2 * T.int64(11) + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 5, 11])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #94: GFLOPs: 110.3652. Time: 1277.0397 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #95: GFLOPs: 17.2028. Time: 8192.9204 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #96: GFLOPs: 78.5345. Time: 1794.6363 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #97: GFLOPs: 154.6438. Time: 911.3898 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #98: GFLOPs: 179.2188. Time: 786.4174 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #99: GFLOPs: 110.7087. Time: 1273.0775 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #100: GFLOPs: 93.5109. Time: 1507.2121 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #101: GFLOPs: 100.8899. Time: 1396.9763 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #102: GFLOPs: 92.6040. Time: 1521.9735 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #103: GFLOPs: 219.7794. Time: 641.2830 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #104: GFLOPs: 235.8170. Time: 597.6703 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #105: GFLOPs: 195.8423. Time: 719.6647 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #106: GFLOPs: 29.9791. Time: 4701.3096 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #107: GFLOPs: 58.8626. Time: 2394.4034 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #108: GFLOPs: 44.3353. Time: 3178.9732 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #109: GFLOPs: 71.6452. Time: 1967.2046 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #110: GFLOPs: 189.6251. Time: 743.2604 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #111: GFLOPs: 65.9407. Time: 2137.3856 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #112: GFLOPs: 75.9924. Time: 1854.6708 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #113: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(3), T.int64(11)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(41), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(11), T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #114: GFLOPs: 120.5275. Time: 1169.3665 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #115: GFLOPs: 64.5023. Time: 2185.0513 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #116: GFLOPs: 109.0976. Time: 1291.8781 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #117: GFLOPs: 113.2817. Time: 1244.1619 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #118: GFLOPs: 45.1661. Time: 3120.5023 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #119: GFLOPs: 64.8817. Time: 2172.2721 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #120: GFLOPs: 34.9171. Time: 4036.4455 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #121: GFLOPs: 77.5817. Time: 1816.6766 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #122: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init * T.int64(11) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 * T.int64(11) + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 1, 11])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #123: GFLOPs: 67.4865. Time: 2088.4310 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #124: GFLOPs: 67.4844. Time: 2088.4951 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #125: GFLOPs: 99.9197. Time: 1410.5408 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #126: GFLOPs: 2.2392. Time: 62942.8630 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #127: GFLOPs: 38.0851. Time: 3700.6842 us. Best GFLOPs: 250.7253
2024-04-28 00:24:46 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #128: GFLOPs: 13.6836. Time: 10299.9894 us. Best GFLOPs: 250.7253
2024-04-28 00:45:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:46:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 00:46:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:46:04 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 00:46:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:46:31 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:46:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:46:55 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 00:47:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8538  0.8538  0.8538  0.8196  0.8177  0.8143  0.8105  0.7985  0.7967  0.7967  0.7967  0.7967  0.7967  0.7870  0.7774  0.7701
[17 : 32]:	0.7666  0.7542  0.7530  0.7467  0.7467  0.7467  0.7467  0.7467  0.7467  0.7467  0.7350  0.7350  0.7350  0.7350  0.7329  0.7329
[33 : 48]:	0.7318  0.7256  0.7226  0.7201  0.7201  0.7201  0.7146  0.7085  0.7018  0.6983  0.6983  0.6931  0.6930  0.6855  0.6807  0.6797
[49 : 64]:	0.6797  0.6797  0.6797  0.6797  0.6753  0.6753  0.6753  0.6753  0.6727  0.6712  0.6650  0.6650  0.6546  0.6545  0.6545  0.6477
2024-04-28 00:47:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:47:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #129: GFLOPs: 121.4880. Time: 1160.1209 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #130: GFLOPs: 203.6626. Time: 692.0309 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #131: GFLOPs: 157.2853. Time: 896.0835 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #132: GFLOPs: 170.4546. Time: 826.8523 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #133: GFLOPs: 85.5902. Time: 1646.6926 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #134: GFLOPs: 209.5831. Time: 672.4818 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #135: GFLOPs: 120.7161. Time: 1167.5392 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #136: GFLOPs: 141.2797. Time: 997.6009 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #137: GFLOPs: 161.4975. Time: 872.7121 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #138: GFLOPs: 170.6575. Time: 825.8691 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #139: GFLOPs: 72.5139. Time: 1943.6393 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #140: GFLOPs: 149.1698. Time: 944.8348 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #141: GFLOPs: 150.1120. Time: 938.9045 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #142: GFLOPs: 237.2955. Time: 593.9464 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #143: GFLOPs: 212.8030. Time: 662.3066 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #144: GFLOPs: 137.0261. Time: 1028.5691 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #145: GFLOPs: 170.0527. Time: 828.8067 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #146: GFLOPs: 188.3088. Time: 748.4557 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #147: GFLOPs: 109.9474. Time: 1281.8930 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #148: GFLOPs: 171.1241. Time: 823.6174 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #149: GFLOPs: 176.7330. Time: 797.4785 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #150: GFLOPs: 180.5066. Time: 780.8068 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #151: GFLOPs: 79.9246. Time: 1763.4211 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #152: GFLOPs: 79.2565. Time: 1778.2859 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #153: GFLOPs: 226.9995. Time: 620.8858 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #154: GFLOPs: 162.6733. Time: 866.4041 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #155: GFLOPs: 206.8847. Time: 681.2528 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #156: GFLOPs: 126.3955. Time: 1115.0774 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #157: GFLOPs: 88.5939. Time: 1590.8641 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #158: GFLOPs: 166.6349. Time: 845.8061 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #159: GFLOPs: 154.7062. Time: 911.0222 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #160: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(5), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(4), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b70)
l117 = sch.fuse(l115, l116, preserve_unit_iters=True)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b118)
b141 = sch.decompose_reduction(block=b118, loop=l125)
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #161: GFLOPs: 111.2620. Time: 1266.7472 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #162: GFLOPs: 170.3828. Time: 827.2006 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #163: GFLOPs: 113.6069. Time: 1240.6008 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #164: GFLOPs: 139.9841. Time: 1006.8347 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #165: GFLOPs: 118.4318. Time: 1190.0589 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #166: GFLOPs: 147.4307. Time: 955.9798 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #167: GFLOPs: 95.6588. Time: 1473.3697 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #168: GFLOPs: 156.8307. Time: 898.6809 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #169: GFLOPs: 156.9788. Time: 897.8332 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #170: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init * T.int64(11) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(11), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 * T.int64(11) + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 * T.int64(11) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 1, 11])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 11])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #171: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(11), T.int64(11), T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #172: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(11), T.int64(11), T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #173: GFLOPs: 106.2765. Time: 1326.1705 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #174: GFLOPs: 170.1605. Time: 828.2816 us. Best GFLOPs: 250.7253
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #175: GFLOPs: 281.7141. Time: 500.2973 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #176: GFLOPs: 131.8038. Time: 1069.3224 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #177: GFLOPs: 52.7932. Time: 2669.6764 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #178: GFLOPs: 116.4675. Time: 1210.1294 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #179: GFLOPs: 131.5962. Time: 1071.0100 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #180: GFLOPs: 127.2838. Time: 1107.2955 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #181: GFLOPs: 48.9618. Time: 2878.5885 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #182: GFLOPs: 48.9847. Time: 2877.2396 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #183: GFLOPs: 49.0201. Time: 2875.1633 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #184: GFLOPs: 62.7043. Time: 2247.7039 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #185: GFLOPs: 199.6254. Time: 706.0265 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #186: GFLOPs: 120.2136. Time: 1172.4195 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #187: GFLOPs: 216.9324. Time: 649.6991 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #188: GFLOPs: 228.2014. Time: 617.6159 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #189: GFLOPs: 143.5212. Time: 982.0210 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #190: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(11)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), oh_2_init * T.int64(5) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), ow_2_init * T.int64(11) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(3), T.int64(11)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(217), T.int64(227), T.int64(1)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), kh_0 + ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(11), T.int64(1), T.int64(1), T.int64(11), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(11)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), oh_2 * T.int64(5) + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), ow_2 * T.int64(11) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3025)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12100))
                    v_ax2 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12100) // T.int64(220))
                    v_ax3 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(220) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 11, 5])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 5, 11])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b67)
l87 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l107, l108, l109, l110, l111, preserve_unit_iters=True)
l113, l114 = sch.split(loop=l112, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #191: GFLOPs: 25.1754. Time: 5598.3593 us. Best GFLOPs: 281.7141
2024-04-28 00:48:21 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #192: GFLOPs: 114.7197. Time: 1228.5662 us. Best GFLOPs: 281.7141
2024-04-28 01:13:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:13:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:13:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:13:36 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 01:13:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:13:59 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:14:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:14:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:14:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8961  0.8471  0.8144  0.8027  0.8027  0.8027  0.7880  0.7802  0.7796  0.7784  0.7644  0.7644  0.7607  0.7502  0.7450  0.7373
[17 : 32]:	0.7337  0.7294  0.7284  0.7253  0.7250  0.7222  0.7222  0.7222  0.7222  0.7196  0.7196  0.7166  0.7166  0.7101  0.7044  0.7033
[33 : 48]:	0.7020  0.6989  0.6964  0.6937  0.6930  0.6927  0.6905  0.6902  0.6873  0.6867  0.6867  0.6825  0.6818  0.6818  0.6818  0.6811
[49 : 64]:	0.6751  0.6748  0.6717  0.6640  0.6623  0.6608  0.6536  0.6484  0.6484  0.6484  0.6484  0.6483  0.6469  0.6423  0.6423  0.6423
2024-04-28 01:14:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:14:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #193: GFLOPs: 76.3405. Time: 1846.2119 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #194: GFLOPs: 33.3330. Time: 4228.2650 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #195: GFLOPs: 116.6702. Time: 1208.0277 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #196: GFLOPs: 135.9378. Time: 1036.8039 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #197: GFLOPs: 114.1825. Time: 1234.3465 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #198: GFLOPs: 105.7643. Time: 1332.5930 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #199: GFLOPs: 180.2096. Time: 782.0937 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #200: GFLOPs: 150.2274. Time: 938.1828 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #201: GFLOPs: 84.8512. Time: 1661.0339 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #202: GFLOPs: 176.5394. Time: 798.3531 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #203: GFLOPs: 105.4641. Time: 1336.3863 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #204: GFLOPs: 132.8051. Time: 1061.2603 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #205: GFLOPs: 266.8625. Time: 528.1401 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #206: GFLOPs: 123.4722. Time: 1141.4777 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #207: GFLOPs: 218.3442. Time: 645.4983 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #208: GFLOPs: 84.4032. Time: 1669.8517 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #209: GFLOPs: 81.4402. Time: 1730.6043 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #210: GFLOPs: 85.0320. Time: 1657.5034 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #211: GFLOPs: 105.6265. Time: 1334.3317 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #212: GFLOPs: 92.2185. Time: 1528.3354 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #213: GFLOPs: 70.6889. Time: 1993.8183 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #214: GFLOPs: 211.5336. Time: 666.2810 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #215: GFLOPs: 227.8722. Time: 618.5081 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #216: GFLOPs: 185.3810. Time: 760.2763 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #217: GFLOPs: 190.9148. Time: 738.2393 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #218: GFLOPs: 95.1714. Time: 1480.9160 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #219: GFLOPs: 44.5279. Time: 3165.2236 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #220: GFLOPs: 209.2650. Time: 673.5040 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #221: GFLOPs: 182.8804. Time: 770.6718 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #222: GFLOPs: 153.3681. Time: 918.9709 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #223: GFLOPs: 274.9485. Time: 512.6080 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #224: GFLOPs: 39.7646. Time: 3544.3817 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #225: GFLOPs: 224.3134. Time: 628.3208 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #226: GFLOPs: 121.5417. Time: 1159.6088 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #227: GFLOPs: 222.9922. Time: 632.0435 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #228: GFLOPs: 78.4343. Time: 1796.9278 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #229: GFLOPs: 195.9946. Time: 719.1057 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #230: GFLOPs: 218.0310. Time: 646.4256 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #231: GFLOPs: 70.9723. Time: 1985.8556 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #232: GFLOPs: 74.0399. Time: 1903.5788 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #233: GFLOPs: 137.1016. Time: 1028.0024 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #234: GFLOPs: 166.1604. Time: 848.2216 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #235: GFLOPs: 168.2432. Time: 837.7209 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #236: GFLOPs: 152.5674. Time: 923.7935 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #237: GFLOPs: 137.9478. Time: 1021.6967 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #238: GFLOPs: 155.9454. Time: 903.7831 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #239: GFLOPs: 200.4954. Time: 702.9627 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #240: GFLOPs: 65.3858. Time: 2155.5273 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #241: GFLOPs: 140.7656. Time: 1001.2448 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #242: GFLOPs: 80.8237. Time: 1743.8056 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #243: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init * T.int64(11) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ic_0 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(11), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 * T.int64(11) + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 1, 11])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b70)
l118 = sch.fuse(l116, l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #244: GFLOPs: 50.5659. Time: 2787.2681 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #245: GFLOPs: 120.3429. Time: 1171.1598 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #246: GFLOPs: 49.6954. Time: 2836.0930 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #247: GFLOPs: 107.0179. Time: 1316.9829 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #248: GFLOPs: 156.6406. Time: 899.7720 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #249: GFLOPs: 163.1902. Time: 863.6597 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #250: GFLOPs: 228.3708. Time: 617.1577 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #251: GFLOPs: 154.5873. Time: 911.7230 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #252: GFLOPs: 79.2209. Time: 1779.0861 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #253: GFLOPs: 176.9638. Time: 796.4388 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #254: GFLOPs: 25.1610. Time: 5601.5504 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #255: GFLOPs: 36.4060. Time: 3871.3569 us. Best GFLOPs: 281.7141
2024-04-28 01:15:52 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #256: GFLOPs: 95.8745. Time: 1470.0557 us. Best GFLOPs: 281.7141
2024-04-28 01:19:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:20:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:20:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:20:04 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 01:20:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:20:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:20:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:20:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:20:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8337  0.8337  0.8285  0.7546  0.7546  0.7467  0.7415  0.7415  0.7387  0.7387  0.7387  0.7237  0.7202  0.7153  0.7080  0.7080
[17 : 32]:	0.7080  0.7063  0.6947  0.6868  0.6867  0.6842  0.6809  0.6784  0.6771  0.6670  0.6656  0.6596  0.6596  0.6539  0.6489  0.6414
[33 : 48]:	0.6414  0.6414  0.6407  0.6407  0.6407  0.6407  0.6396  0.6377  0.6367  0.6364  0.6364  0.6364  0.6294  0.6177  0.6155  0.6155
[49 : 64]:	0.6155  0.6130  0.6130  0.6130  0.6130  0.6130  0.6104  0.6101  0.6088  0.6088  0.6088  0.6088  0.6088  0.6063  0.6043  0.6014
2024-04-28 01:20:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:20:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #257: GFLOPs: 161.7096. Time: 871.5671 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #258: GFLOPs: 185.9899. Time: 757.7875 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #259: GFLOPs: 200.0214. Time: 704.6288 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #260: GFLOPs: 172.9714. Time: 814.8214 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #261: GFLOPs: 169.7081. Time: 830.4893 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #262: GFLOPs: 157.5313. Time: 894.6843 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #263: GFLOPs: 131.8136. Time: 1069.2429 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #264: GFLOPs: 134.4908. Time: 1047.9586 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #265: GFLOPs: 198.9521. Time: 708.4158 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #266: GFLOPs: 156.6590. Time: 899.6661 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #267: GFLOPs: 187.2171. Time: 752.8203 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #268: GFLOPs: 182.8147. Time: 770.9489 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #269: GFLOPs: 184.9550. Time: 762.0277 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #270: GFLOPs: 173.2765. Time: 813.3868 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #271: GFLOPs: 181.6433. Time: 775.9209 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #272: GFLOPs: 157.5802. Time: 894.4070 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #273: GFLOPs: 163.0376. Time: 864.4679 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #274: GFLOPs: 162.8469. Time: 865.4806 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #275: GFLOPs: 112.0325. Time: 1258.0354 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #276: GFLOPs: 134.8977. Time: 1044.7979 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #277: GFLOPs: 173.8876. Time: 810.5284 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #278: GFLOPs: 171.4642. Time: 821.9838 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #279: GFLOPs: 120.6508. Time: 1168.1709 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #280: GFLOPs: 197.1160. Time: 715.0146 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #281: GFLOPs: 156.8824. Time: 898.3849 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #282: GFLOPs: 145.6188. Time: 967.8753 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #283: GFLOPs: 168.1197. Time: 838.3361 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #284: GFLOPs: 116.4150. Time: 1210.6760 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #285: GFLOPs: 81.9030. Time: 1720.8268 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #286: GFLOPs: 187.3539. Time: 752.2705 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #287: GFLOPs: 187.3991. Time: 752.0891 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #288: GFLOPs: 233.2100. Time: 604.3515 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #289: GFLOPs: 232.2726. Time: 606.7905 us. Best GFLOPs: 281.7141
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #290: GFLOPs: 335.1879. Time: 420.4829 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #291: GFLOPs: 198.5353. Time: 709.9031 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #292: GFLOPs: 199.1132. Time: 707.8427 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #293: GFLOPs: 130.2442. Time: 1082.1273 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #294: GFLOPs: 83.4513. Time: 1688.8984 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #295: GFLOPs: 112.7083. Time: 1250.4919 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #296: GFLOPs: 150.1740. Time: 938.5164 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #297: GFLOPs: 207.6222. Time: 678.8330 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #298: GFLOPs: 208.6660. Time: 675.4375 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #299: GFLOPs: 153.5113. Time: 918.1135 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #300: GFLOPs: 208.9046. Time: 674.6658 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #301: GFLOPs: 111.7782. Time: 1260.8974 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #302: GFLOPs: 75.0456. Time: 1878.0676 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #303: GFLOPs: 190.1282. Time: 741.2934 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #304: GFLOPs: 192.9512. Time: 730.4478 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #305: GFLOPs: 183.3619. Time: 768.6483 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #306: GFLOPs: 217.0749. Time: 649.2725 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #307: GFLOPs: 217.3129. Time: 648.5615 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #308: GFLOPs: 171.7289. Time: 820.7167 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #309: GFLOPs: 171.9328. Time: 819.7435 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #310: GFLOPs: 85.7713. Time: 1643.2155 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #311: GFLOPs: 92.8531. Time: 1517.8896 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #312: GFLOPs: 205.2932. Time: 686.5343 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #313: GFLOPs: 163.4661. Time: 862.2018 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #314: GFLOPs: 182.9996. Time: 770.1701 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #315: GFLOPs: 110.0733. Time: 1280.4270 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #316: GFLOPs: 99.3474. Time: 1418.6665 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #317: GFLOPs: 174.2052. Time: 809.0505 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #318: GFLOPs: 58.8229. Time: 2396.0210 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #319: GFLOPs: 6.3213. Time: 22296.2804 us. Best GFLOPs: 335.1879
2024-04-28 01:22:17 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #320: GFLOPs: 42.4355. Time: 3321.2941 us. Best GFLOPs: 335.1879
2024-04-28 01:58:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:58:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:58:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:58:27 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 01:58:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:58:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:59:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:59:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 01:59:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7396  0.7396  0.6427  0.6427  0.6424  0.6424  0.6424  0.6424  0.6424  0.6424  0.6424  0.6219  0.6218  0.6184  0.6042  0.6026
[17 : 32]:	0.6026  0.6013  0.5961  0.5942  0.5897  0.5897  0.5882  0.5882  0.5882  0.5882  0.5882  0.5882  0.5855  0.5839  0.5754  0.5732
[33 : 48]:	0.5732  0.5729  0.5729  0.5729  0.5729  0.5710  0.5656  0.5627  0.5626  0.5622  0.5602  0.5597  0.5597  0.5597  0.5597  0.5597
[49 : 64]:	0.5557  0.5557  0.5557  0.5550  0.5550  0.5550  0.5532  0.5514  0.5484  0.5484  0.5465  0.5465  0.5452  0.5452  0.5452  0.5444
2024-04-28 01:59:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:59:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #321: GFLOPs: 118.4451. Time: 1189.9253 us. Best GFLOPs: 335.1879
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #322: GFLOPs: 229.0291. Time: 615.3839 us. Best GFLOPs: 335.1879
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #323: GFLOPs: 83.7651. Time: 1682.5712 us. Best GFLOPs: 335.1879
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #324: GFLOPs: 66.8397. Time: 2108.6376 us. Best GFLOPs: 335.1879
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #325: GFLOPs: 123.5575. Time: 1140.6898 us. Best GFLOPs: 335.1879
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #326: GFLOPs: 413.3258. Time: 340.9920 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #327: GFLOPs: 134.8960. Time: 1044.8106 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #328: GFLOPs: 200.9709. Time: 701.2997 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #329: GFLOPs: 101.7237. Time: 1385.5254 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #330: GFLOPs: 182.7358. Time: 771.2816 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #331: GFLOPs: 166.1999. Time: 848.0199 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #332: GFLOPs: 205.6824. Time: 685.2350 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #333: GFLOPs: 162.6488. Time: 866.5345 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #334: GFLOPs: 224.6028. Time: 627.5114 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #335: GFLOPs: 222.3189. Time: 633.9579 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #336: GFLOPs: 149.9385. Time: 939.9910 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #337: GFLOPs: 125.6425. Time: 1121.7607 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #338: GFLOPs: 205.8912. Time: 684.5401 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #339: GFLOPs: 205.4081. Time: 686.1501 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #340: GFLOPs: 229.8547. Time: 613.1734 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #341: GFLOPs: 114.9678. Time: 1225.9154 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #342: GFLOPs: 187.5498. Time: 751.4846 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #343: GFLOPs: 136.4977. Time: 1032.5505 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #344: GFLOPs: 165.1348. Time: 853.4896 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #345: GFLOPs: 105.3846. Time: 1337.3945 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #346: GFLOPs: 265.0915. Time: 531.6685 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #347: GFLOPs: 226.9422. Time: 621.0428 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #348: GFLOPs: 227.5118. Time: 619.4880 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #349: GFLOPs: 223.3764. Time: 630.9564 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #350: GFLOPs: 265.8218. Time: 530.2079 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #351: GFLOPs: 204.1347. Time: 690.4304 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #352: GFLOPs: 165.7982. Time: 850.0742 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #353: GFLOPs: 164.0074. Time: 859.3564 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #354: GFLOPs: 148.4294. Time: 949.5476 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #355: GFLOPs: 180.0259. Time: 782.8917 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #356: GFLOPs: 206.8937. Time: 681.2231 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #357: GFLOPs: 217.3044. Time: 648.5871 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #358: GFLOPs: 209.3621. Time: 673.1916 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #359: GFLOPs: 153.6544. Time: 917.2586 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #360: GFLOPs: 191.8019. Time: 734.8248 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #361: GFLOPs: 195.3658. Time: 721.4200 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #362: GFLOPs: 230.3842. Time: 611.7642 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #363: GFLOPs: 181.0358. Time: 778.5245 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #364: GFLOPs: 172.3783. Time: 817.6249 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #365: GFLOPs: 189.9984. Time: 741.8000 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #366: GFLOPs: 178.4931. Time: 789.6150 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #367: GFLOPs: 178.0532. Time: 791.5658 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #368: GFLOPs: 162.4118. Time: 867.7988 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #369: GFLOPs: 187.0295. Time: 753.5753 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #370: GFLOPs: 108.4689. Time: 1299.3664 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #371: GFLOPs: 186.7522. Time: 754.6941 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #372: GFLOPs: 215.4099. Time: 654.2912 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #373: GFLOPs: 212.2821. Time: 663.9317 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #374: GFLOPs: 164.1997. Time: 858.3500 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #375: GFLOPs: 140.4451. Time: 1003.5293 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #376: GFLOPs: 217.1265. Time: 649.1184 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #377: GFLOPs: 199.8513. Time: 705.2284 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #378: GFLOPs: 226.4884. Time: 622.2870 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #379: GFLOPs: 133.6479. Time: 1054.5676 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #380: GFLOPs: 173.3336. Time: 813.1186 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #381: GFLOPs: 122.4260. Time: 1151.2330 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #382: GFLOPs: 40.8672. Time: 3448.7501 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #383: GFLOPs: 81.6953. Time: 1725.2001 us. Best GFLOPs: 413.3258
2024-04-28 02:00:48 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #384: GFLOPs: 4.2752. Time: 32966.9728 us. Best GFLOPs: 413.3258
2024-04-28 02:36:17 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 02:36:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 02:36:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:36:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 02:36:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:36:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:36:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:37:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:37:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6267  0.6267  0.6084  0.6047  0.5829  0.5741  0.5734  0.5723  0.5683  0.5564  0.5440  0.5434  0.5429  0.5363  0.5328  0.5276
[17 : 32]:	0.5235  0.5235  0.5234  0.5214  0.5214  0.5205  0.5151  0.5151  0.5126  0.5126  0.5126  0.5057  0.5029  0.4990  0.4980  0.4980
[33 : 48]:	0.4980  0.4978  0.4975  0.4973  0.4968  0.4966  0.4965  0.4965  0.4941  0.4930  0.4930  0.4930  0.4930  0.4930  0.4900  0.4884
[49 : 64]:	0.4883  0.4883  0.4880  0.4862  0.4862  0.4862  0.4861  0.4854  0.4815  0.4796  0.4787  0.4773  0.4773  0.4773  0.4766  0.4734
2024-04-28 02:37:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 02:37:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:38:50 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #385: GFLOPs: 229.5403. Time: 614.0134 us. Best GFLOPs: 413.3258
2024-04-28 02:38:50 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #386: GFLOPs: 166.3429. Time: 847.2910 us. Best GFLOPs: 413.3258
2024-04-28 02:38:50 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #387: GFLOPs: 260.3321. Time: 541.3884 us. Best GFLOPs: 413.3258
2024-04-28 02:38:50 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #388: GFLOPs: 226.4962. Time: 622.2656 us. Best GFLOPs: 413.3258
2024-04-28 02:38:50 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #389: GFLOPs: 207.9758. Time: 677.6787 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #390: GFLOPs: 224.5060. Time: 627.7818 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #391: GFLOPs: 109.9261. Time: 1282.1413 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #392: GFLOPs: 113.2157. Time: 1244.8878 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #393: GFLOPs: 152.6044. Time: 923.5696 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #394: GFLOPs: 87.7489. Time: 1606.1824 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #395: GFLOPs: 205.1513. Time: 687.0090 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #396: GFLOPs: 20.8257. Time: 6767.6285 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #397: GFLOPs: 147.4082. Time: 956.1259 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #398: GFLOPs: 161.7373. Time: 871.4178 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #399: GFLOPs: 177.0662. Time: 795.9779 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #400: GFLOPs: 181.2870. Time: 777.4457 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #401: GFLOPs: 176.4369. Time: 798.8171 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #402: GFLOPs: 170.2037. Time: 828.0713 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #403: GFLOPs: 125.3414. Time: 1124.4557 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #404: GFLOPs: 121.6451. Time: 1158.6225 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #405: GFLOPs: 163.6334. Time: 861.3205 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #406: GFLOPs: 153.7428. Time: 916.7308 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #407: GFLOPs: 139.4699. Time: 1010.5463 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #408: GFLOPs: 162.2092. Time: 868.8831 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #409: GFLOPs: 104.9571. Time: 1342.8422 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #410: GFLOPs: 168.0043. Time: 838.9120 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #411: GFLOPs: 95.6554. Time: 1473.4228 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #412: GFLOPs: 84.8692. Time: 1660.6823 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #413: GFLOPs: 128.3495. Time: 1098.1014 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #414: GFLOPs: 213.4110. Time: 660.4196 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #415: GFLOPs: 137.8351. Time: 1022.5317 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #416: GFLOPs: 211.3623. Time: 666.8209 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #417: GFLOPs: 110.9517. Time: 1270.2901 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #418: GFLOPs: 207.3901. Time: 679.5927 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #419: GFLOPs: 387.5643. Time: 363.6579 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #420: GFLOPs: 218.8916. Time: 643.8841 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #421: GFLOPs: 135.7173. Time: 1038.4879 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #422: GFLOPs: 154.9866. Time: 909.3740 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #423: GFLOPs: 126.5351. Time: 1113.8474 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #424: GFLOPs: 275.2683. Time: 512.0124 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #425: GFLOPs: 219.7318. Time: 641.4221 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #426: GFLOPs: 201.9707. Time: 697.8279 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #427: GFLOPs: 408.2318. Time: 345.2470 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #428: GFLOPs: 233.0307. Time: 604.8164 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #429: GFLOPs: 229.9506. Time: 612.9178 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #430: GFLOPs: 166.1725. Time: 848.1596 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #431: GFLOPs: 60.6030. Time: 2325.6389 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #432: GFLOPs: 135.7692. Time: 1038.0911 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #433: GFLOPs: 131.2090. Time: 1074.1702 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #434: GFLOPs: 114.3967. Time: 1232.0361 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #435: GFLOPs: 207.5494. Time: 679.0711 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #436: GFLOPs: 214.6714. Time: 656.5421 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #437: GFLOPs: 189.1242. Time: 745.2289 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #438: GFLOPs: 114.2678. Time: 1233.4251 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #439: GFLOPs: 43.8838. Time: 3211.6806 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #440: GFLOPs: 89.3324. Time: 1577.7126 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #441: GFLOPs: 198.3183. Time: 710.6798 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #442: GFLOPs: 122.6046. Time: 1149.5555 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #443: GFLOPs: 193.5236. Time: 728.2875 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #444: GFLOPs: 166.0629. Time: 848.7193 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #445: GFLOPs: 180.0496. Time: 782.7888 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #446: GFLOPs: 87.6283. Time: 1608.3942 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #447: GFLOPs: 109.7693. Time: 1283.9732 us. Best GFLOPs: 413.3258
2024-04-28 02:38:51 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #448: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(176), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(55), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), ow_1 * T.int64(55) + ow_2_init * T.int64(55) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0 in T.grid(T.int64(1), T.int64(11)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(227)):
                        for ax4_fused in T.vectorized(T.int64(3)):
                            with T.block("data_pad"):
                                v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                                v_i2 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + oh_1 * T.int64(4) + kh_0 + ax2)
                                v_i3 = T.axis.spatial(T.int64(228), ax3)
                                v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                    for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(55), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), ow_1 * T.int64(55) + ow_2 * T.int64(55) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(55)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[16, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[11, 5, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 55])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.annotate(block_or_loop=l112, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l112, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-28 02:43:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 02:43:26 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 02:43:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:43:30 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 02:43:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:43:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:44:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:44:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 02:44:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7852  0.7321  0.7321  0.7180  0.7077  0.7077  0.6787  0.6543  0.6543  0.6040  0.6025  0.5953  0.5654  0.5584  0.5560  0.5560
[17 : 32]:	0.5469  0.5455  0.5408  0.5406  0.5371  0.5357  0.5357  0.5357  0.5357  0.5271  0.5267  0.5244  0.5241  0.5218  0.5218  0.5216
[33 : 48]:	0.5207  0.5207  0.5207  0.5192  0.5144  0.5125  0.5125  0.5109  0.5102  0.5090  0.5075  0.5056  0.5056  0.5055  0.5055  0.5051
[49 : 64]:	0.5029  0.4950  0.4940  0.4922  0.4904  0.4897  0.4895  0.4891  0.4883  0.4868  0.4868  0.4868  0.4868  0.4868  0.4865  0.4865
2024-04-28 02:44:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 02:44:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #449: GFLOPs: 70.0331. Time: 2012.4887 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #450: GFLOPs: 37.4958. Time: 3758.8469 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #451: GFLOPs: 66.7218. Time: 2112.3638 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #452: GFLOPs: 94.3737. Time: 1493.4333 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #453: GFLOPs: 60.1132. Time: 2344.5910 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #454: GFLOPs: 56.3845. Time: 2499.6355 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #455: GFLOPs: 115.2752. Time: 1222.6466 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #456: GFLOPs: 206.9614. Time: 681.0006 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #457: GFLOPs: 207.0096. Time: 680.8420 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #458: GFLOPs: 117.8808. Time: 1195.6211 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #459: GFLOPs: 81.5024. Time: 1729.2843 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #460: GFLOPs: 127.3954. Time: 1106.3253 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #461: GFLOPs: 59.8689. Time: 2354.1574 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #462: GFLOPs: 121.9486. Time: 1155.7390 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #463: GFLOPs: 193.4639. Time: 728.5122 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #464: GFLOPs: 202.7098. Time: 695.2836 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #465: GFLOPs: 146.2412. Time: 963.7561 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #466: GFLOPs: 169.8182. Time: 829.9512 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #467: GFLOPs: 144.6766. Time: 974.1785 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #468: GFLOPs: 170.8168. Time: 825.0993 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #469: GFLOPs: 197.6742. Time: 712.9954 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #470: GFLOPs: 156.4679. Time: 900.7652 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #471: GFLOPs: 228.9598. Time: 615.5701 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #472: GFLOPs: 178.5848. Time: 789.2093 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #473: GFLOPs: 186.9641. Time: 753.8388 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #474: GFLOPs: 95.6841. Time: 1472.9809 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #475: GFLOPs: 265.8764. Time: 530.0990 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #476: GFLOPs: 140.9031. Time: 1000.2673 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #477: GFLOPs: 207.9745. Time: 677.6832 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #478: GFLOPs: 208.2899. Time: 676.6568 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #479: GFLOPs: 225.2548. Time: 625.6950 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #480: GFLOPs: 272.1057. Time: 517.9634 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #481: GFLOPs: 175.4978. Time: 803.0916 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #482: GFLOPs: 181.5091. Time: 776.4942 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #483: GFLOPs: 183.1812. Time: 769.4064 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #484: GFLOPs: 99.4270. Time: 1417.5301 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #485: GFLOPs: 84.2715. Time: 1672.4603 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #486: GFLOPs: 153.2226. Time: 919.8436 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #487: GFLOPs: 165.3177. Time: 852.5451 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #488: GFLOPs: 134.1589. Time: 1050.5511 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #489: GFLOPs: 174.3941. Time: 808.1739 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #490: GFLOPs: 193.7512. Time: 727.4318 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #491: GFLOPs: 221.8369. Time: 635.3353 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #492: GFLOPs: 260.7983. Time: 540.4206 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #493: GFLOPs: 267.4307. Time: 527.0180 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #494: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(88), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(55)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(27)):
                    for ax4_fused in T.vectorized(T.int64(3)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(2), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(2) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 55, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #495: GFLOPs: 194.2052. Time: 725.7312 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #496: GFLOPs: 126.7446. Time: 1112.0061 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #497: GFLOPs: 84.3136. Time: 1671.6269 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #498: GFLOPs: 206.7531. Time: 681.6866 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #499: GFLOPs: 224.0161. Time: 629.1548 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #500: GFLOPs: 271.3778. Time: 519.3527 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #501: GFLOPs: 172.3975. Time: 817.5337 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #502: GFLOPs: 200.9537. Time: 701.3596 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #503: GFLOPs: 205.2684. Time: 686.6173 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #504: GFLOPs: 164.7019. Time: 855.7328 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #505: GFLOPs: 132.7109. Time: 1062.0139 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #506: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(55)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(27)):
                    for ax4_fused in T.vectorized(T.int64(3)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(4) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(11), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 55, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #507: GFLOPs: 202.8214. Time: 694.9010 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #508: GFLOPs: 184.4140. Time: 764.2631 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #509: GFLOPs: 194.1120. Time: 726.0797 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #510: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(227), T.int64(227)):
                for ax4_fused in T.vectorized(T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(11), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(5), T.int64(55), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), oh_0 * T.int64(55) + oh_1 * T.int64(5) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(55) + ow_1 * T.int64(55) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(55), T.int64(2), T.int64(1), T.int64(11), T.int64(11), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_fused_fused * T.int64(8) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(55), oh_0 * T.int64(55) + oh_1 * T.int64(5) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(55) + ow_1 * T.int64(55) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                        v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                        v_kw = T.axis.reduce(T.int64(11), kw_0 * T.int64(11) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3025)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12100))
                    v_ax2 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12100) // T.int64(220))
                    v_ax3 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(220) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 11, 5, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 55, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 11])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #511: GFLOPs: 67.4420. Time: 2089.8070 us. Best GFLOPs: 413.3258
2024-04-28 02:45:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #512: GFLOPs: 47.9540. Time: 2939.0843 us. Best GFLOPs: 413.3258
2024-04-28 03:22:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 03:22:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 03:22:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 03:22:11 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 03:22:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 03:22:35 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 03:22:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 03:22:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 03:23:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8890  0.7878  0.7565  0.6499  0.6499  0.6499  0.5912  0.5912  0.5870  0.5539  0.5539  0.5539  0.5539  0.5539  0.5539  0.5539
[17 : 32]:	0.5539  0.5519  0.5509  0.5386  0.5383  0.5340  0.5339  0.5284  0.5274  0.5274  0.5261  0.5253  0.5251  0.5251  0.5206  0.5201
[33 : 48]:	0.5133  0.5133  0.5133  0.5126  0.4961  0.4960  0.4950  0.4950  0.4904  0.4879  0.4879  0.4853  0.4853  0.4849  0.4830  0.4800
[49 : 64]:	0.4799  0.4794  0.4775  0.4768  0.4763  0.4756  0.4752  0.4744  0.4744  0.4744  0.4744  0.4738  0.4738  0.4738  0.4736  0.4736
2024-04-28 03:23:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 03:23:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #513: GFLOPs: 194.0703. Time: 726.2358 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #514: GFLOPs: 160.6278. Time: 877.4372 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #515: GFLOPs: 387.0990. Time: 364.0950 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #516: GFLOPs: 137.3394. Time: 1026.2228 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #517: GFLOPs: 389.5171. Time: 361.8347 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #518: GFLOPs: 191.2640. Time: 736.8912 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #519: GFLOPs: 254.6243. Time: 553.5245 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #520: GFLOPs: 264.5693. Time: 532.7178 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #521: GFLOPs: 142.8057. Time: 986.9409 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #522: GFLOPs: 106.0088. Time: 1329.5203 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #523: GFLOPs: 226.9809. Time: 620.9368 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #524: GFLOPs: 182.4022. Time: 772.6925 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #525: GFLOPs: 183.0129. Time: 770.1141 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #526: GFLOPs: 201.8831. Time: 698.1306 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #527: GFLOPs: 182.5313. Time: 772.1461 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #528: GFLOPs: 155.3040. Time: 907.5155 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #529: GFLOPs: 202.6934. Time: 695.3397 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #530: GFLOPs: 118.6318. Time: 1188.0526 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #531: GFLOPs: 276.7238. Time: 509.3194 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #532: GFLOPs: 155.2203. Time: 908.0050 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #533: GFLOPs: 153.2162. Time: 919.8819 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #534: GFLOPs: 133.8339. Time: 1053.1026 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #535: GFLOPs: 212.8963. Time: 662.0161 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #536: GFLOPs: 228.3936. Time: 617.0962 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #537: GFLOPs: 205.0761. Time: 687.2608 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #538: GFLOPs: 205.2093. Time: 686.8150 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #539: GFLOPs: 269.1719. Time: 523.6089 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #540: GFLOPs: 171.8712. Time: 820.0372 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #541: GFLOPs: 187.0632. Time: 753.4395 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #542: GFLOPs: 213.3898. Time: 660.4853 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #543: GFLOPs: 114.7876. Time: 1227.8397 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #544: GFLOPs: 157.3307. Time: 895.8252 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #545: GFLOPs: 119.7708. Time: 1176.7546 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #546: GFLOPs: 171.8425. Time: 820.1741 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #547: GFLOPs: 159.8262. Time: 881.8380 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #548: GFLOPs: 202.4126. Time: 696.3043 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #549: GFLOPs: 241.1852. Time: 584.3674 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #550: GFLOPs: 118.3401. Time: 1190.9808 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #551: GFLOPs: 211.7536. Time: 665.5887 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #552: GFLOPs: 209.1630. Time: 673.8324 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #553: GFLOPs: 103.3160. Time: 1364.1716 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #554: GFLOPs: 225.9276. Time: 623.8317 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #555: GFLOPs: 199.7894. Time: 705.4469 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #556: GFLOPs: 117.3428. Time: 1201.1034 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #557: GFLOPs: 167.1842. Time: 843.0270 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #558: GFLOPs: 156.9640. Time: 897.9178 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #559: GFLOPs: 139.8739. Time: 1007.6276 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #560: GFLOPs: 200.8737. Time: 701.6389 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #561: GFLOPs: 216.5790. Time: 650.7594 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #562: GFLOPs: 164.1873. Time: 858.4147 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #563: GFLOPs: 199.8415. Time: 705.2630 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #564: GFLOPs: 230.9940. Time: 610.1493 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #565: GFLOPs: 216.7082. Time: 650.3713 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #566: GFLOPs: 213.5656. Time: 659.9416 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #567: GFLOPs: 178.6765. Time: 788.8043 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #568: GFLOPs: 240.2517. Time: 586.6381 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #569: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(27), T.int64(227)):
                for ax4_fused in T.vectorized(T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(11) * T.int64(20) + ax2)
                        v_i3 = T.axis.spatial(T.int64(228), ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(5), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(11) * T.int64(5) + oh_1 * T.int64(5) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(55) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(5), T.int64(1), T.int64(1), T.int64(3), T.int64(11), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(11) * T.int64(5) + oh_1 * T.int64(5) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), ow_0 * T.int64(55) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(5), T.int64(55)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(11) * T.int64(5) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[11, 1, 5, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 11, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78 = sch.get_loops(block=b68)
l79 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l79)
l80 = sch.fuse(l78, preserve_unit_iters=True)
sch.vectorize(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b116)
b141 = sch.decompose_reduction(block=b116, loop=l125)
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #570: GFLOPs: 198.2017. Time: 711.0979 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #571: GFLOPs: 152.6508. Time: 923.2887 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #572: GFLOPs: 182.1797. Time: 773.6359 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #573: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(44), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(5)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(51), T.int64(27)):
                    for ax4_fused in T.vectorized(T.int64(3)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), oh_1 * T.int64(44) + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2_init * T.int64(5) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(11), T.int64(1), T.int64(1), T.int64(3), T.int64(11), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(5)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(55), oh_1 * T.int64(11) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 * T.int64(5) + ow_2 * T.int64(5) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                                v_kh = T.axis.reduce(T.int64(11), kh_0 * T.int64(11) + kh_1)
                                v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(55)):
                for ax3_ax4_fused in T.vectorized(T.int64(20)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(11) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(55), ax2)
                        v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 1, 1, 5])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 11])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=44)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #574: GFLOPs: 136.6612. Time: 1031.3154 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #575: GFLOPs: 114.9210. Time: 1226.4142 us. Best GFLOPs: 413.3258
2024-04-28 03:24:35 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #576: GFLOPs: 45.5531. Time: 3093.9905 us. Best GFLOPs: 413.3258
2024-04-28 04:10:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:10:40 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:10:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:10:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 04:10:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:11:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:11:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:11:33 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:11:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9187  0.8928  0.8497  0.8293  0.8020  0.7988  0.7763  0.7391  0.7071  0.7071  0.6389  0.6387  0.6344  0.6317  0.6255  0.6104
[17 : 32]:	0.5941  0.5834  0.5749  0.5686  0.5640  0.5632  0.5632  0.5615  0.5604  0.5488  0.5465  0.5421  0.5417  0.5407  0.5370  0.5360
[33 : 48]:	0.5299  0.5261  0.5259  0.5210  0.5195  0.5170  0.5170  0.5132  0.5100  0.5086  0.5041  0.5015  0.4983  0.4962  0.4942  0.4942
[49 : 64]:	0.4937  0.4936  0.4934  0.4930  0.4918  0.4918  0.4914  0.4894  0.4894  0.4869  0.4852  0.4848  0.4828  0.4827  0.4821  0.4821
2024-04-28 04:11:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:11:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #577: GFLOPs: 169.7795. Time: 830.1405 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #578: GFLOPs: 144.4669. Time: 975.5924 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #579: GFLOPs: 412.8441. Time: 341.3899 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #580: GFLOPs: 170.3906. Time: 827.1632 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #581: GFLOPs: 168.4264. Time: 836.8097 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #582: GFLOPs: 171.0853. Time: 823.8043 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #583: GFLOPs: 134.4104. Time: 1048.5858 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #584: GFLOPs: 388.9560. Time: 362.3567 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #585: GFLOPs: 307.5749. Time: 458.2324 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #586: GFLOPs: 309.6293. Time: 455.1920 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #587: GFLOPs: 187.9314. Time: 749.9586 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #588: GFLOPs: 129.1133. Time: 1091.6060 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #589: GFLOPs: 171.1979. Time: 823.2624 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #590: GFLOPs: 406.8765. Time: 346.3970 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #591: GFLOPs: 263.8668. Time: 534.1362 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #592: GFLOPs: 86.3649. Time: 1631.9218 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #593: GFLOPs: 243.5152. Time: 578.7761 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #594: GFLOPs: 388.6907. Time: 362.6040 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #595: GFLOPs: 385.9055. Time: 365.2210 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #596: GFLOPs: 204.5450. Time: 689.0453 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #597: GFLOPs: 41.1305. Time: 3426.6760 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #598: GFLOPs: 188.8322. Time: 746.3811 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #599: GFLOPs: 176.7273. Time: 797.5042 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #600: GFLOPs: 105.2027. Time: 1339.7065 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #601: GFLOPs: 159.1591. Time: 885.5338 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #602: GFLOPs: 117.2099. Time: 1202.4650 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #603: GFLOPs: 84.0286. Time: 1677.2950 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #604: GFLOPs: 358.3494. Time: 393.3055 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #605: GFLOPs: 139.5445. Time: 1010.0059 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #606: GFLOPs: 110.2206. Time: 1278.7159 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #607: GFLOPs: 241.5174. Time: 583.5636 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #608: GFLOPs: 58.3017. Time: 2417.4398 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #609: GFLOPs: 217.2697. Time: 648.6906 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #610: GFLOPs: 283.1487. Time: 497.7624 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #611: GFLOPs: 302.2506. Time: 466.3045 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #612: GFLOPs: 177.3846. Time: 794.5494 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #613: GFLOPs: 152.5998. Time: 923.5975 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #614: GFLOPs: 173.8332. Time: 810.7820 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #615: GFLOPs: 173.8783. Time: 810.5717 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #616: GFLOPs: 343.8522. Time: 409.8878 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #617: GFLOPs: 198.6927. Time: 709.3404 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #618: GFLOPs: 166.8612. Time: 844.6590 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #619: GFLOPs: 175.9376. Time: 801.0840 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #620: GFLOPs: 177.3202. Time: 794.8376 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #621: GFLOPs: 218.1049. Time: 646.2064 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #622: GFLOPs: 307.2148. Time: 458.7695 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #623: GFLOPs: 198.8869. Time: 708.6480 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #624: GFLOPs: 200.9998. Time: 701.1988 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #625: GFLOPs: 217.7759. Time: 647.1826 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #626: GFLOPs: 224.6146. Time: 627.4782 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #627: GFLOPs: 170.6791. Time: 825.7647 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #628: GFLOPs: 206.0826. Time: 683.9043 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #629: GFLOPs: 206.2756. Time: 683.2646 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #630: GFLOPs: 207.1488. Time: 680.3845 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #631: GFLOPs: 236.4867. Time: 595.9777 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #632: GFLOPs: 217.1201. Time: 649.1374 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #633: GFLOPs: 232.5334. Time: 606.1098 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #634: GFLOPs: 226.2198. Time: 623.0258 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #635: GFLOPs: 215.8619. Time: 652.9212 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #636: GFLOPs: 146.3605. Time: 962.9703 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #637: GFLOPs: 49.3381. Time: 2856.6312 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #638: GFLOPs: 2.4355. Time: 57868.5557 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #639: GFLOPs: 32.6562. Time: 4315.8910 us. Best GFLOPs: 413.3258
2024-04-28 04:13:00 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #640: GFLOPs: 99.9031. Time: 1410.7751 us. Best GFLOPs: 413.3258
2024-04-28 04:32:20 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:32:21 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:32:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:32:26 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 04:32:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:32:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:33:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:33:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:33:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9052  0.8551  0.8551  0.8551  0.8452  0.8364  0.7854  0.7789  0.7789  0.7445  0.7427  0.7403  0.7171  0.7099  0.6927  0.6920
[17 : 32]:	0.6380  0.6264  0.6198  0.6126  0.6110  0.6108  0.6033  0.6033  0.6000  0.5971  0.5860  0.5820  0.5816  0.5816  0.5731  0.5706
[33 : 48]:	0.5662  0.5650  0.5650  0.5646  0.5521  0.5510  0.5482  0.5428  0.5411  0.5402  0.5402  0.5402  0.5372  0.5361  0.5339  0.5336
[49 : 64]:	0.5336  0.5334  0.5334  0.5334  0.5334  0.5322  0.5302  0.5289  0.5287  0.5287  0.5287  0.5287  0.5287  0.5287  0.5264  0.5264
2024-04-28 04:33:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:33:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #641: GFLOPs: 200.9440. Time: 701.3935 us. Best GFLOPs: 413.3258
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #642: GFLOPs: 419.4642. Time: 336.0020 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #643: GFLOPs: 412.8608. Time: 341.3761 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #644: GFLOPs: 387.3189. Time: 363.8883 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #645: GFLOPs: 315.2455. Time: 447.0826 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #646: GFLOPs: 180.9179. Time: 779.0318 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #647: GFLOPs: 362.8912. Time: 388.3831 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #648: GFLOPs: 253.6250. Time: 555.7055 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #649: GFLOPs: 401.7211. Time: 350.8424 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #650: GFLOPs: 234.4765. Time: 601.0872 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #651: GFLOPs: 192.0316. Time: 733.9458 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #652: GFLOPs: 185.0462. Time: 761.6519 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #653: GFLOPs: 394.0049. Time: 357.7133 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #654: GFLOPs: 388.9914. Time: 362.3237 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #655: GFLOPs: 32.1995. Time: 4377.1087 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #656: GFLOPs: 125.4164. Time: 1123.7829 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #657: GFLOPs: 298.0094. Time: 472.9407 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #658: GFLOPs: 127.0945. Time: 1108.9449 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #659: GFLOPs: 108.0468. Time: 1304.4427 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #660: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(121), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(27), T.int64(27)):
                for ax4_fused in T.vectorized(T.int64(3)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(11) * T.int64(20) + ax2)
                        v_i3 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(11) * T.int64(20) + ax3)
                        v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(5), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(16), T.int64(5), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(11) * T.int64(5) + oh_1 * T.int64(5) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(11), T.int64(11), T.int64(1), T.int64(16), T.int64(5), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(11) * T.int64(5) + oh_1 * T.int64(5) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(11) * T.int64(5) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(16), T.int64(5)):
                    for ax3_ax4_fused in T.vectorized(T.int64(20)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(11) * T.int64(5) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(11) * T.int64(5) + ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[11, 1, 5, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[11, 5, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 4, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[3, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[11, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l111, l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #661: GFLOPs: 287.5827. Time: 490.0879 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #662: GFLOPs: 276.7313. Time: 509.3056 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #663: GFLOPs: 92.3833. Time: 1525.6089 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #664: GFLOPs: 217.0007. Time: 649.4946 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #665: GFLOPs: 200.2718. Time: 703.7476 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #666: GFLOPs: 92.7846. Time: 1519.0112 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #667: GFLOPs: 170.3911. Time: 827.1607 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #668: GFLOPs: 149.2447. Time: 944.3607 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #669: GFLOPs: 135.9560. Time: 1036.6648 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #670: GFLOPs: 127.3495. Time: 1106.7244 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #671: GFLOPs: 179.6141. Time: 784.6868 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #672: GFLOPs: 157.3046. Time: 895.9740 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #673: GFLOPs: 313.0483. Time: 450.2206 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #674: GFLOPs: 134.6489. Time: 1046.7284 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #675: GFLOPs: 127.4572. Time: 1105.7891 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #676: GFLOPs: 289.2079. Time: 487.3338 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #677: GFLOPs: 160.1490. Time: 880.0602 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #678: GFLOPs: 293.1762. Time: 480.7376 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #679: GFLOPs: 155.2555. Time: 907.7991 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #680: GFLOPs: 286.7840. Time: 491.4528 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #681: GFLOPs: 138.8248. Time: 1015.2420 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #682: GFLOPs: 222.2187. Time: 634.2437 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #683: GFLOPs: 230.6464. Time: 611.0687 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #684: GFLOPs: 183.8361. Time: 766.6656 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #685: GFLOPs: 82.2001. Time: 1714.6064 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #686: GFLOPs: 142.9426. Time: 985.9958 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #687: GFLOPs: 169.5903. Time: 831.0664 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #688: GFLOPs: 148.9660. Time: 946.1272 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #689: GFLOPs: 369.7746. Time: 381.1533 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #690: GFLOPs: 153.0889. Time: 920.6470 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #691: GFLOPs: 162.9064. Time: 865.1645 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #692: GFLOPs: 165.8369. Time: 849.8762 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #693: GFLOPs: 149.6037. Time: 942.0944 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #694: GFLOPs: 396.0561. Time: 355.8607 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #695: GFLOPs: 116.8569. Time: 1206.0971 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #696: GFLOPs: 197.0407. Time: 715.2876 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #697: GFLOPs: 192.5711. Time: 731.8898 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #698: GFLOPs: 234.0477. Time: 602.1884 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #699: GFLOPs: 303.1470. Time: 464.9257 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #700: GFLOPs: 224.5511. Time: 627.6559 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #701: GFLOPs: 220.8443. Time: 638.1907 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #702: GFLOPs: 6.8303. Time: 20634.6752 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #703: GFLOPs: 48.5946. Time: 2900.3362 us. Best GFLOPs: 419.4642
2024-04-28 04:34:49 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #704: GFLOPs: 29.2526. Time: 4818.0649 us. Best GFLOPs: 419.4642
2024-04-28 04:54:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:54:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:54:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:54:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 04:54:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:55:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:55:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:55:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 04:55:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0444  1.0444  1.0444  0.9653  0.9592  0.9592  0.9417  0.9417  0.9404  0.9260  0.9260  0.8971  0.8793  0.8686  0.8631  0.8510
[17 : 32]:	0.8413  0.8413  0.8413  0.8111  0.7699  0.7625  0.7614  0.7614  0.7614  0.7614  0.7614  0.7613  0.7607  0.7549  0.7549  0.7506
[33 : 48]:	0.7472  0.7371  0.7371  0.7371  0.7354  0.7255  0.7255  0.7255  0.7187  0.7114  0.7109  0.7054  0.7048  0.6916  0.6852  0.6720
[49 : 64]:	0.6576  0.6576  0.6544  0.6539  0.6539  0.6538  0.6414  0.6399  0.6323  0.6319  0.6286  0.6188  0.6160  0.6090  0.5878  0.5877
2024-04-28 04:55:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:55:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #705: GFLOPs: 383.7513. Time: 367.2712 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #706: GFLOPs: 414.2887. Time: 340.1995 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #707: GFLOPs: 331.9541. Time: 424.5791 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #708: GFLOPs: 132.0089. Time: 1067.6609 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #709: GFLOPs: 165.7452. Time: 850.3463 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #710: GFLOPs: 90.2728. Time: 1561.2767 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #711: GFLOPs: 392.9764. Time: 358.6495 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #712: GFLOPs: 402.6992. Time: 349.9903 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #713: GFLOPs: 399.0674. Time: 353.1754 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #714: GFLOPs: 406.7990. Time: 346.4630 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #715: GFLOPs: 355.9881. Time: 395.9143 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #716: GFLOPs: 142.6541. Time: 987.9897 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #717: GFLOPs: 106.8861. Time: 1318.6068 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #718: GFLOPs: 401.0250. Time: 351.4514 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #719: GFLOPs: 360.8880. Time: 390.5389 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #720: GFLOPs: 204.3924. Time: 689.5599 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #721: GFLOPs: 380.3419. Time: 370.5634 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #722: GFLOPs: 388.8128. Time: 362.4901 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #723: GFLOPs: 386.8121. Time: 364.3651 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #724: GFLOPs: 78.7707. Time: 1789.2543 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #725: GFLOPs: 364.3506. Time: 386.8275 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #726: GFLOPs: 156.0994. Time: 902.8913 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #727: GFLOPs: 173.3403. Time: 813.0874 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #728: GFLOPs: 312.6184. Time: 450.8398 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #729: GFLOPs: 165.9982. Time: 849.0504 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #730: GFLOPs: 229.3803. Time: 614.4417 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #731: GFLOPs: 218.6146. Time: 644.6999 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #732: GFLOPs: 384.7281. Time: 366.3387 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #733: GFLOPs: 322.2157. Time: 437.4114 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #734: GFLOPs: 67.1261. Time: 2099.6436 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #735: GFLOPs: 150.4830. Time: 936.5892 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #736: GFLOPs: 126.7100. Time: 1112.3100 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #737: GFLOPs: 323.3027. Time: 435.9406 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #738: GFLOPs: 216.3533. Time: 651.4383 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #739: GFLOPs: 231.2311. Time: 609.5234 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #740: GFLOPs: 301.3641. Time: 467.6761 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #741: GFLOPs: 361.7491. Time: 389.6093 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #742: GFLOPs: 321.0125. Time: 439.0508 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #743: GFLOPs: 232.9092. Time: 605.1320 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #744: GFLOPs: 209.1030. Time: 674.0257 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #745: GFLOPs: 190.8742. Time: 738.3962 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #746: GFLOPs: 200.2388. Time: 703.8637 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #747: GFLOPs: 320.6916. Time: 439.4901 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #748: GFLOPs: 325.1925. Time: 433.4072 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #749: GFLOPs: 188.8067. Time: 746.4819 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #750: GFLOPs: 158.2958. Time: 890.3637 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #751: GFLOPs: 267.0039. Time: 527.8605 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #752: GFLOPs: 106.3695. Time: 1325.0113 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #753: GFLOPs: 221.8918. Time: 635.1782 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #754: GFLOPs: 209.7740. Time: 671.8696 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #755: GFLOPs: 236.6082. Time: 595.6718 us. Best GFLOPs: 419.4642
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #756: GFLOPs: 446.4732. Time: 315.6758 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #757: GFLOPs: 263.5461. Time: 534.7861 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #758: GFLOPs: 187.3459. Time: 752.3025 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #759: GFLOPs: 390.4955. Time: 360.9281 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #760: GFLOPs: 38.6863. Time: 3643.1715 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #761: GFLOPs: 268.0896. Time: 525.7227 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #762: GFLOPs: 30.7349. Time: 4585.6934 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #763: GFLOPs: 42.1290. Time: 3345.4588 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #764: GFLOPs: 96.5794. Time: 1459.3258 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #765: GFLOPs: 92.4160. Time: 1525.0696 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #766: GFLOPs: 84.2264. Time: 1673.3559 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #767: GFLOPs: 63.7622. Time: 2210.4130 us. Best GFLOPs: 446.4732
2024-04-28 04:57:10 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #768: GFLOPs: 133.1554. Time: 1058.4688 us. Best GFLOPs: 446.4732
2024-04-28 05:28:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 05:28:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 05:28:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:28:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 05:28:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:29:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:29:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:29:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:29:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9052  0.8917  0.8917  0.8917  0.8749  0.8693  0.8617  0.8549  0.8407  0.8347  0.8347  0.8178  0.8103  0.8058  0.8052  0.7858
[17 : 32]:	0.7848  0.7797  0.7754  0.7715  0.7648  0.7545  0.7526  0.7511  0.7508  0.7435  0.7386  0.7310  0.7194  0.7003  0.6986  0.6986
[33 : 48]:	0.6982  0.6907  0.6864  0.6864  0.6810  0.6804  0.6800  0.6800  0.6670  0.6571  0.6560  0.6530  0.6523  0.6500  0.6460  0.6449
[49 : 64]:	0.6436  0.6401  0.6318  0.6241  0.6229  0.6227  0.6226  0.6159  0.6082  0.6056  0.6053  0.6041  0.5992  0.5911  0.5911  0.5905
2024-04-28 05:29:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 05:29:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #769: GFLOPs: 391.2544. Time: 360.2280 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #770: GFLOPs: 397.3648. Time: 354.6887 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #771: GFLOPs: 171.4269. Time: 822.1625 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #772: GFLOPs: 116.3203. Time: 1211.6615 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #773: GFLOPs: 364.2233. Time: 386.9626 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #774: GFLOPs: 200.1117. Time: 704.3108 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #775: GFLOPs: 389.3716. Time: 361.9699 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #776: GFLOPs: 88.2349. Time: 1597.3370 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #777: GFLOPs: 392.2715. Time: 359.2940 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #778: GFLOPs: 390.0092. Time: 361.3782 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #779: GFLOPs: 399.4779. Time: 352.8125 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #780: GFLOPs: 392.2089. Time: 359.3514 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #781: GFLOPs: 169.8697. Time: 829.6996 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #782: GFLOPs: 151.2292. Time: 931.9680 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #783: GFLOPs: 400.1476. Time: 352.2220 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #784: GFLOPs: 382.1905. Time: 368.7711 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #785: GFLOPs: 404.9978. Time: 348.0039 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #786: GFLOPs: 399.9352. Time: 352.4091 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #787: GFLOPs: 409.1354. Time: 344.4845 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #788: GFLOPs: 196.7503. Time: 716.3437 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #789: GFLOPs: 387.0453. Time: 364.1455 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #790: GFLOPs: 62.2007. Time: 2265.9044 us. Best GFLOPs: 446.4732
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #791: GFLOPs: 456.7723. Time: 308.5581 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #792: GFLOPs: 421.6021. Time: 334.2982 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #793: GFLOPs: 444.1154. Time: 317.3518 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #794: GFLOPs: 133.3992. Time: 1056.5343 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #795: GFLOPs: 285.7066. Time: 493.3060 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #796: GFLOPs: 134.6250. Time: 1046.9140 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #797: GFLOPs: 306.0886. Time: 460.4576 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #798: GFLOPs: 117.6258. Time: 1198.2136 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #799: GFLOPs: 335.0730. Time: 420.6272 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #800: GFLOPs: 112.8894. Time: 1248.4852 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #801: GFLOPs: 124.3138. Time: 1133.7500 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #802: GFLOPs: 417.3831. Time: 337.6773 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #803: GFLOPs: 390.2127. Time: 361.1897 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #804: GFLOPs: 252.2372. Time: 558.7630 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #805: GFLOPs: 392.4988. Time: 359.0859 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #806: GFLOPs: 136.3178. Time: 1033.9130 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #807: GFLOPs: 207.1960. Time: 680.2294 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #808: GFLOPs: 122.1613. Time: 1153.7272 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #809: GFLOPs: 253.9873. Time: 554.9127 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #810: GFLOPs: 123.4142. Time: 1142.0147 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #811: GFLOPs: 136.4215. Time: 1033.1273 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #812: GFLOPs: 266.8317. Time: 528.2010 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #813: GFLOPs: 280.8897. Time: 501.7657 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #814: GFLOPs: 275.2264. Time: 512.0905 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #815: GFLOPs: 87.6084. Time: 1608.7585 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #816: GFLOPs: 431.3474. Time: 326.7455 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #817: GFLOPs: 125.1262. Time: 1126.3889 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #818: GFLOPs: 440.2670. Time: 320.1258 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #819: GFLOPs: 58.2950. Time: 2417.7171 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #820: GFLOPs: 222.5156. Time: 633.3974 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #821: GFLOPs: 216.8177. Time: 650.0428 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #822: GFLOPs: 141.6933. Time: 994.6891 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #823: GFLOPs: 193.0921. Time: 729.9149 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #824: GFLOPs: 130.8013. Time: 1077.5180 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #825: GFLOPs: 186.0589. Time: 757.5065 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #826: GFLOPs: 325.1015. Time: 433.5286 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #827: GFLOPs: 76.2229. Time: 1849.0610 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #828: GFLOPs: 442.7005. Time: 318.3660 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #829: GFLOPs: 64.1616. Time: 2196.6550 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #830: GFLOPs: 108.8923. Time: 1294.3133 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #831: GFLOPs: 1.6237. Time: 86799.5727 us. Best GFLOPs: 456.7723
2024-04-28 05:30:56 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #832: GFLOPs: 64.3256. Time: 2191.0516 us. Best GFLOPs: 456.7723
2024-04-28 05:45:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 05:45:36 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 05:45:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:45:41 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 05:45:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:46:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:46:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:46:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 05:46:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9199  0.9122  0.8860  0.8722  0.8548  0.8381  0.8213  0.8162  0.8162  0.8151  0.8151  0.8030  0.8003  0.7943  0.7943  0.7749
[17 : 32]:	0.7729  0.7670  0.7650  0.7607  0.7587  0.7517  0.7517  0.7514  0.7505  0.7423  0.7383  0.7383  0.7383  0.7343  0.7337  0.7303
[33 : 48]:	0.7286  0.7236  0.7185  0.7062  0.6910  0.6888  0.6851  0.6795  0.6777  0.6725  0.6713  0.6670  0.6655  0.6646  0.6641  0.6623
[49 : 64]:	0.6597  0.6592  0.6574  0.6518  0.6499  0.6491  0.6491  0.6488  0.6485  0.6470  0.6435  0.6404  0.6370  0.6302  0.6286  0.6281
2024-04-28 05:46:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 05:46:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #833: GFLOPs: 443.1435. Time: 318.0478 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #834: GFLOPs: 443.7983. Time: 317.5785 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #835: GFLOPs: 425.7047. Time: 331.0764 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #836: GFLOPs: 442.4742. Time: 318.5289 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #837: GFLOPs: 392.9249. Time: 358.6965 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #838: GFLOPs: 342.9518. Time: 410.9639 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #839: GFLOPs: 363.6014. Time: 387.6245 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #840: GFLOPs: 178.7709. Time: 788.3879 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #841: GFLOPs: 387.6489. Time: 363.5785 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #842: GFLOPs: 178.8712. Time: 787.9457 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #843: GFLOPs: 188.2631. Time: 748.6372 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #844: GFLOPs: 91.2969. Time: 1543.7640 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #845: GFLOPs: 203.5191. Time: 692.5188 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #846: GFLOPs: 177.1134. Time: 795.7658 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #847: GFLOPs: 177.5090. Time: 793.9925 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #848: GFLOPs: 388.0884. Time: 363.1668 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #849: GFLOPs: 155.5148. Time: 906.2854 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #850: GFLOPs: 343.5566. Time: 410.2405 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #851: GFLOPs: 180.8112. Time: 779.4914 us. Best GFLOPs: 456.7723
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #852: GFLOPs: 458.7962. Time: 307.1969 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #853: GFLOPs: 117.2036. Time: 1202.5299 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #854: GFLOPs: 214.9335. Time: 655.7415 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #855: GFLOPs: 161.8820. Time: 870.6390 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #856: GFLOPs: 382.4612. Time: 368.5101 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #857: GFLOPs: 372.2288. Time: 378.6402 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #858: GFLOPs: 388.5395. Time: 362.7451 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #859: GFLOPs: 123.2207. Time: 1143.8083 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #860: GFLOPs: 207.4326. Time: 679.4534 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #861: GFLOPs: 284.8566. Time: 494.7781 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #862: GFLOPs: 179.3613. Time: 785.7927 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #863: GFLOPs: 151.2776. Time: 931.6699 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #864: GFLOPs: 350.8417. Time: 401.7219 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #865: GFLOPs: 126.2464. Time: 1116.3944 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #866: GFLOPs: 429.4929. Time: 328.1563 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #867: GFLOPs: 142.0803. Time: 991.9802 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #868: GFLOPs: 367.8523. Time: 383.1451 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #869: GFLOPs: 111.4179. Time: 1264.9741 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #870: GFLOPs: 340.8585. Time: 413.4877 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #871: GFLOPs: 105.0191. Time: 1342.0488 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #872: GFLOPs: 166.2103. Time: 847.9667 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #873: GFLOPs: 438.1939. Time: 321.6403 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #874: GFLOPs: 99.3420. Time: 1418.7434 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #875: GFLOPs: 343.9386. Time: 409.7847 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #876: GFLOPs: 99.0953. Time: 1422.2754 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #877: GFLOPs: 18.9806. Time: 7425.5189 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #878: GFLOPs: 118.6113. Time: 1188.2577 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #879: GFLOPs: 394.1107. Time: 357.6173 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #880: GFLOPs: 363.9728. Time: 387.2289 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #881: GFLOPs: 240.5844. Time: 585.8268 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #882: GFLOPs: 162.9803. Time: 864.7718 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #883: GFLOPs: 134.5026. Time: 1047.8665 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #884: GFLOPs: 210.5364. Time: 669.4367 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #885: GFLOPs: 53.1780. Time: 2650.3604 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #886: GFLOPs: 283.2664. Time: 497.5556 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #887: GFLOPs: 164.9346. Time: 854.5254 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #888: GFLOPs: 286.0384. Time: 492.7338 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #889: GFLOPs: 368.1812. Time: 382.8028 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #890: GFLOPs: 405.5624. Time: 347.5194 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #891: GFLOPs: 84.9116. Time: 1659.8530 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #892: GFLOPs: 89.8641. Time: 1568.3771 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #893: GFLOPs: 97.5688. Time: 1444.5279 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #894: GFLOPs: 93.7067. Time: 1504.0634 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #895: GFLOPs: 80.4243. Time: 1752.4657 us. Best GFLOPs: 458.7962
2024-04-28 05:48:16 [INFO] [task_scheduler.cc:121] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #896: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(224), T.int64(224), T.int64(3)), "float32"), p1: T.Buffer((T.int64(16), T.int64(1), T.int64(11), T.int64(11), T.int64(3), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(228), T.int64(228), T.int64(3)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(55), T.int64(55), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(10), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(55)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(5) * T.int64(8) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(5) * T.int64(11) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(55), ow_2_init * T.int64(55) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(1), T.int64(11)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(41), T.int64(227)):
                    for ax4_fused in T.vectorized(T.int64(3)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(228), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(5) * T.int64(44) + kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(228), ax3)
                            v_i4 = T.axis.spatial(T.int64(3), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(2) <= v_i2 and v_i2 < T.int64(226) and T.int64(2) <= v_i3 and v_i3 < T.int64(226), p0[v_i0, v_i1, v_i2 - T.int64(2), v_i3 - T.int64(2), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(11), T.int64(1), T.int64(2), T.int64(3), T.int64(1), T.int64(11), T.int64(1), T.int64(8), T.int64(1), T.int64(55)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(5) * T.int64(8) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(55), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(5) * T.int64(11) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(55), ow_2 * T.int64(55) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(3), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(11), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(11), kw_0 * T.int64(11) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)], p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(3), v_oh * T.int64(4) + v_kh, v_ow * T.int64(4) + v_kw, v_ic % T.int64(3)] * p1[v_oc_chunk, v_ic // T.int64(3), v_kh, v_kw, v_ic % T.int64(3), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3025)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(12100))
                    v_ax2 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(12100) // T.int64(220))
                    v_ax3 = T.axis.spatial(T.int64(55), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(220) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 5, 11, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 55])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[11, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 11])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b67)
l87 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b68)
l106 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l106)
l107 = sch.fuse(l105, preserve_unit_iters=True)
sch.vectorize(loop=l107)
sch.annotate(block_or_loop=l106, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l106, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112 = sch.get_loops(block=b69)
l113 = sch.fuse(l108, l109, l110, l111, l112, preserve_unit_iters=True)
l114, l115 = sch.split(loop=l113, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l114)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-28 06:15:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 06:15:19 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 06:15:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 06:15:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 06:15:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 06:15:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 06:15:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 06:16:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 06:16:19 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0530  1.0499  0.9703  0.9452  0.9305  0.9210  0.9062  0.9004  0.8948  0.8827  0.8758  0.8715  0.8710  0.8710  0.8462  0.8448
[17 : 32]:	0.8402  0.8388  0.8375  0.8375  0.8223  0.8168  0.8093  0.7991  0.7990  0.7909  0.7880  0.7869  0.7832  0.7764  0.7764  0.7740
[33 : 48]:	0.7696  0.7528  0.7445  0.7360  0.7343  0.7343  0.7310  0.7300  0.7289  0.7226  0.7217  0.7213  0.7213  0.7211  0.7186  0.7186
[49 : 64]:	0.7145  0.7123  0.7059  0.7029  0.6938  0.6930  0.6930  0.6846  0.6846  0.6824  0.6813  0.6791  0.6790  0.6707  0.6666  0.6649
2024-04-28 06:16:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 06:16:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #897: GFLOPs: 454.9642. Time: 309.7843 us. Best GFLOPs: 458.7962
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #898: GFLOPs: 453.9677. Time: 310.4644 us. Best GFLOPs: 458.7962
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #899: GFLOPs: 472.6243. Time: 298.2089 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #900: GFLOPs: 219.5740. Time: 641.8830 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #901: GFLOPs: 218.0317. Time: 646.4235 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #902: GFLOPs: 428.1158. Time: 329.2118 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #903: GFLOPs: 440.5847. Time: 319.8949 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #904: GFLOPs: 393.9210. Time: 357.7895 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #905: GFLOPs: 352.5859. Time: 399.7347 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #906: GFLOPs: 402.2660. Time: 350.3671 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #907: GFLOPs: 186.0748. Time: 757.4416 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #908: GFLOPs: 84.7748. Time: 1662.5315 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #909: GFLOPs: 218.6065. Time: 644.7236 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #910: GFLOPs: 383.4378. Time: 367.5715 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #911: GFLOPs: 388.1951. Time: 363.0669 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #912: GFLOPs: 433.9811. Time: 324.7625 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #913: GFLOPs: 426.6949. Time: 330.3082 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #914: GFLOPs: 417.3254. Time: 337.7240 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #915: GFLOPs: 120.9920. Time: 1164.8766 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #916: GFLOPs: 148.2047. Time: 950.9873 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #917: GFLOPs: 313.6921. Time: 449.2966 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #918: GFLOPs: 399.3501. Time: 352.9254 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #919: GFLOPs: 318.3078. Time: 442.7815 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #920: GFLOPs: 344.3352. Time: 409.3127 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #921: GFLOPs: 405.1552. Time: 347.8687 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #922: GFLOPs: 413.0540. Time: 341.2164 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #923: GFLOPs: 398.0557. Time: 354.0730 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #924: GFLOPs: 388.7002. Time: 362.5951 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #925: GFLOPs: 429.0425. Time: 328.5008 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #926: GFLOPs: 156.3354. Time: 901.5282 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #927: GFLOPs: 363.4506. Time: 387.7853 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #928: GFLOPs: 401.6698. Time: 350.8872 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #929: GFLOPs: 368.9497. Time: 382.0055 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #930: GFLOPs: 389.5359. Time: 361.8173 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #931: GFLOPs: 386.4961. Time: 364.6630 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #932: GFLOPs: 191.4500. Time: 736.1756 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #933: GFLOPs: 167.8274. Time: 839.7961 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #934: GFLOPs: 197.3530. Time: 714.1558 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #935: GFLOPs: 396.5783. Time: 355.3921 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #936: GFLOPs: 247.4950. Time: 569.4692 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #937: GFLOPs: 367.3050. Time: 383.7160 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #938: GFLOPs: 381.7056. Time: 369.2395 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #939: GFLOPs: 434.7621. Time: 324.1791 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #940: GFLOPs: 388.6169. Time: 362.6729 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #941: GFLOPs: 389.5617. Time: 361.7932 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #942: GFLOPs: 336.0490. Time: 419.4055 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #943: GFLOPs: 169.1979. Time: 832.9936 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #944: GFLOPs: 427.6632. Time: 329.5603 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #945: GFLOPs: 425.2480. Time: 331.4320 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #946: GFLOPs: 183.1116. Time: 769.6991 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #947: GFLOPs: 423.6773. Time: 332.6608 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #948: GFLOPs: 199.5743. Time: 706.2072 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #949: GFLOPs: 188.5738. Time: 747.4039 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #950: GFLOPs: 223.2272. Time: 631.3781 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #951: GFLOPs: 231.0129. Time: 610.0992 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #952: GFLOPs: 373.0054. Time: 377.8519 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #953: GFLOPs: 375.1331. Time: 375.7088 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #954: GFLOPs: 107.7491. Time: 1308.0457 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #955: GFLOPs: 457.0155. Time: 308.3939 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #956: GFLOPs: 135.9494. Time: 1036.7153 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #957: GFLOPs: 376.6844. Time: 374.1615 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #958: GFLOPs: 67.7955. Time: 2078.9116 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #959: GFLOPs: 30.0923. Time: 4683.6145 us. Best GFLOPs: 472.6243
2024-04-28 06:17:40 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #960: GFLOPs: 99.7880. Time: 1412.4018 us. Best GFLOPs: 472.6243
2024-04-28 07:09:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:09:49 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 07:09:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 07:09:54 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 07:10:06 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 07:10:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 07:10:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 07:10:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3f59fc8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3f785e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x34efad8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x32cef48)]: 0 failure(s)
2024-04-28 07:10:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9711  0.9468  0.9438  0.9347  0.9345  0.9244  0.9206  0.8874  0.8816  0.8612  0.8575  0.8488  0.8394  0.8356  0.8341  0.8249
[17 : 32]:	0.8227  0.8216  0.8199  0.8123  0.8107  0.8074  0.7979  0.7943  0.7940  0.7908  0.7906  0.7808  0.7777  0.7737  0.7735  0.7688
[33 : 48]:	0.7590  0.7471  0.7459  0.7331  0.7287  0.7265  0.7248  0.7217  0.7181  0.7164  0.7112  0.7106  0.7106  0.7106  0.7106  0.7031
[49 : 64]:	0.6935  0.6814  0.6809  0.6809  0.6809  0.6757  0.6713  0.6701  0.6684  0.6684  0.6684  0.6630  0.6582  0.6557  0.6522  0.6522
2024-04-28 07:10:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:10:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #961: GFLOPs: 467.7278. Time: 301.3308 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #962: GFLOPs: 439.2514. Time: 320.8659 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #963: GFLOPs: 418.8468. Time: 336.4973 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #964: GFLOPs: 399.3605. Time: 352.9162 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #965: GFLOPs: 455.0398. Time: 309.7329 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #966: GFLOPs: 239.3072. Time: 588.9535 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #967: GFLOPs: 453.5360. Time: 310.7599 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #968: GFLOPs: 443.3746. Time: 317.8820 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #969: GFLOPs: 226.4272. Time: 622.4554 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #970: GFLOPs: 398.3013. Time: 353.8548 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #971: GFLOPs: 408.8286. Time: 344.7430 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #972: GFLOPs: 456.6169. Time: 308.6631 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #973: GFLOPs: 395.6293. Time: 356.2446 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #974: GFLOPs: 383.3884. Time: 367.6188 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #975: GFLOPs: 385.7527. Time: 365.3657 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #976: GFLOPs: 393.0137. Time: 358.6155 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #977: GFLOPs: 401.6192. Time: 350.9314 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #978: GFLOPs: 378.8653. Time: 372.0077 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #979: GFLOPs: 381.8194. Time: 369.1294 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #980: GFLOPs: 377.8171. Time: 373.0397 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #981: GFLOPs: 400.7522. Time: 351.6906 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #982: GFLOPs: 392.8574. Time: 358.7581 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #983: GFLOPs: 324.0614. Time: 434.9200 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #984: GFLOPs: 141.2449. Time: 997.8469 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #985: GFLOPs: 397.3593. Time: 354.6936 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #986: GFLOPs: 193.4824. Time: 728.4426 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #987: GFLOPs: 150.6410. Time: 935.6074 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #988: GFLOPs: 335.4486. Time: 420.1562 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #989: GFLOPs: 429.1705. Time: 328.4028 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #990: GFLOPs: 130.5799. Time: 1079.3451 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #991: GFLOPs: 374.4872. Time: 376.3568 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #992: GFLOPs: 336.4040. Time: 418.9630 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #993: GFLOPs: 213.3630. Time: 660.5682 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #994: GFLOPs: 196.6769. Time: 716.6108 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #995: GFLOPs: 226.1453. Time: 623.2312 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #996: GFLOPs: 376.2327. Time: 374.6107 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #997: GFLOPs: 350.8299. Time: 401.7354 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #998: GFLOPs: 399.5285. Time: 352.7678 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #999: GFLOPs: 425.4754. Time: 331.2549 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1000: GFLOPs: 401.9221. Time: 350.6670 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1001: GFLOPs: 143.1678. Time: 984.4446 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1002: GFLOPs: 210.9221. Time: 668.2127 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1003: GFLOPs: 255.5683. Time: 551.4801 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1004: GFLOPs: 180.1002. Time: 782.5687 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1005: GFLOPs: 145.9177. Time: 965.8925 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1006: GFLOPs: 223.3604. Time: 631.0018 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1007: GFLOPs: 233.9104. Time: 602.5418 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1008: GFLOPs: 161.9750. Time: 870.1393 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1009: GFLOPs: 202.6866. Time: 695.3631 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1010: GFLOPs: 357.5067. Time: 394.2326 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1011: GFLOPs: 205.9740. Time: 684.2650 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1012: GFLOPs: 101.4456. Time: 1389.3237 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1013: GFLOPs: 197.4008. Time: 713.9828 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1014: GFLOPs: 175.9420. Time: 801.0638 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1015: GFLOPs: 360.2201. Time: 391.2630 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1016: GFLOPs: 85.8526. Time: 1641.6603 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1017: GFLOPs: 179.3162. Time: 785.9903 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1018: GFLOPs: 106.9005. Time: 1318.4294 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1019: GFLOPs: 166.8045. Time: 844.9458 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1020: GFLOPs: 131.8350. Time: 1069.0697 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1021: GFLOPs: 248.9961. Time: 566.0362 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1022: GFLOPs: 77.5059. Time: 1818.4518 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1023: GFLOPs: 66.8753. Time: 2107.5156 us. Best GFLOPs: 472.6243
2024-04-28 07:12:13 [INFO] [task_scheduler.cc:131] [Task #1: fused_nn_contrib_conv2d_NCHWc_add_nn_relu] Trial #1024: GFLOPs: 12.1901. Time: 11561.9466 us. Best GFLOPs: 472.6243
