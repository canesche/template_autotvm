2024-04-27 23:39:15 [INFO] [task_scheduler.cc:160] Initializing Task #5: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2"
2024-04-27 23:39:15 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4), T.int64(192), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-27 23:39:15 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-27 23:39:15 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
            for n_0, oc_chunk_0 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(24), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(48) + oc_chunk_1 * T.int64(48) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[24, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-27 23:39:15 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(24), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(48) + oc_chunk_1 * T.int64(48) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(14) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(14), p0[v_n, v_ic // T.int64(4), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(4)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(1), T.int64(13), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(48) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), oh_0 + ax2)
                        v_ax3 = T.axis.spatial(T.int64(13), ax3)
                        v_ax4 = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[24, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-27 23:39:15 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(24)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(15), T.int64(4)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(48), ic_0 * T.int64(2) + ax1)
                            v_i2 = T.axis.spatial(T.int64(15), oh_0 + ax2)
                            v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(48) + oc_chunk_1 * T.int64(48) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(48), T.int64(1), T.int64(13), T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(48) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), oh_0 + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[24, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-27 23:46:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-27 23:46:06 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-27 23:46:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 13 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-27 23:46:11 [INFO] [evolutionary_search.cc:723] Sampled 499 candidate(s)
2024-04-27 23:46:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-27 23:46:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-27 23:46:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-27 23:46:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-27 23:46:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9999  0.9996  0.9993  0.9991  0.9990  0.9982  0.9977  0.9971  0.9968  0.9961  0.9956  0.9951  0.9950  0.9949  0.9949  0.9949
[17 : 32]:	0.9946  0.9942  0.9937  0.9936  0.9936  0.9934  0.9933  0.9931  0.9926  0.9916  0.9908  0.9890  0.9885  0.9882  0.9882  0.9879
[33 : 48]:	0.9872  0.9872  0.9870  0.9867  0.9864  0.9863  0.9852  0.9843  0.9843  0.9836  0.9836  0.9835  0.9832  0.9830  0.9826  0.9821
[49 : 64]:	0.9821  0.9814  0.9808  0.9804  0.9796  0.9791  0.9788  0.9788  0.9785  0.9785  0.9773  0.9763  0.9757  0.9751  0.9739  0.9727
2024-04-27 23:46:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-27 23:46:33 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1: GFLOPs: 14.6550. Time: 15312.8713 us. Best GFLOPs: 14.6550
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #2: GFLOPs: 119.8042. Time: 1873.1423 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #3: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0 in T.serial(T.int64(1), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(4)):
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                        for ax3_ax4_fused in T.vectorized(T.int64(60)):
                            with T.block("data_pad"):
                                v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                                v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                                v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                        for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(24), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(13), T.int64(13), T.int64(1)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(96) + oc_chunk_1 * T.int64(24) + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(96), T.int64(3), T.int64(3), T.int64(1), T.int64(24), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13), T.int64(1)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(96), oc_chunk_0 * T.int64(96) + oc_chunk_1 * T.int64(24) + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                                v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(96), T.int64(13)):
                    for ax3_ax4_fused in T.vectorized(T.int64(52)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                            v_ax3 = T.axis.spatial(T.int64(13), ax3_ax4_fused // T.int64(4))
                            v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 4, 24, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 2, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l81, l82, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
sch.annotate(block_or_loop=l84, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l84, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b70)
l120 = sch.fuse(l118, l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147 = sch.get_loops(block=b121)
b148 = sch.decompose_reduction(block=b121, loop=l132)
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #4: GFLOPs: 47.0920. Time: 4765.3597 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #5: GFLOPs: 2.6205. Time: 85637.0640 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #6: GFLOPs: 17.7254. Time: 12660.4034 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #7: GFLOPs: 1.1896. Time: 188647.1917 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #8: GFLOPs: 56.9208. Time: 3942.5042 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #9: GFLOPs: 4.6610. Time: 48146.6207 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #10: GFLOPs: 2.4490. Time: 91632.0173 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #11: GFLOPs: 23.1813. Time: 9680.6443 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #12: GFLOPs: 63.3052. Time: 3544.8939 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #13: GFLOPs: 32.8317. Time: 6835.1745 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #14: GFLOPs: 0.2857. Time: 785552.5930 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #15: GFLOPs: 40.9229. Time: 5483.7299 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #16: GFLOPs: 82.9224. Time: 2706.2694 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #17: GFLOPs: 76.9384. Time: 2916.7540 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #18: GFLOPs: 6.4058. Time: 35032.1977 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #19: GFLOPs: 2.8634. Time: 78373.3253 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #20: GFLOPs: 19.7392. Time: 11368.7762 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #21: GFLOPs: 46.1060. Time: 4867.2754 us. Best GFLOPs: 119.8042
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #22: GFLOPs: 177.1132. Time: 1267.0448 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #23: GFLOPs: 66.9807. Time: 3350.3715 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #24: GFLOPs: 72.0460. Time: 3114.8188 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #25: GFLOPs: 18.9168. Time: 11863.0269 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #26: GFLOPs: 49.7697. Time: 4508.9791 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #27: GFLOPs: 3.7254. Time: 60237.9227 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #28: GFLOPs: 4.4132. Time: 50849.6437 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #29: GFLOPs: 109.8593. Time: 2042.7062 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #30: GFLOPs: 34.8621. Time: 6437.0941 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #31: GFLOPs: 30.9522. Time: 7250.2236 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #32: GFLOPs: 31.4285. Time: 7140.3492 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #33: GFLOPs: 6.6711. Time: 33639.0070 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #34: GFLOPs: 34.2687. Time: 6548.5524 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #35: GFLOPs: 11.9584. Time: 18765.8738 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #36: GFLOPs: 4.5895. Time: 48896.7870 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #37: GFLOPs: 13.7776. Time: 16288.0296 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #38: GFLOPs: 40.0390. Time: 5604.7961 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #39: GFLOPs: 23.9252. Time: 9379.6591 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #40: GFLOPs: 57.8207. Time: 3881.1420 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #41: GFLOPs: 79.5185. Time: 2822.1158 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #42: GFLOPs: 127.6837. Time: 1757.5489 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #43: GFLOPs: 22.2650. Time: 10079.0789 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #44: GFLOPs: 7.8614. Time: 28545.9075 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #45: GFLOPs: 123.4239. Time: 1818.2090 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #46: GFLOPs: 0.0922. Time: 2433311.3020 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #47: GFLOPs: 8.1440. Time: 27555.3280 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #48: GFLOPs: 75.9927. Time: 2953.0504 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #49: GFLOPs: 36.6993. Time: 6114.8431 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #50: GFLOPs: 10.6081. Time: 21154.7230 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #51: GFLOPs: 57.7055. Time: 3888.8875 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #52: GFLOPs: 19.5645. Time: 11470.2934 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #53: GFLOPs: 59.7392. Time: 3756.5037 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #54: GFLOPs: 62.2817. Time: 3603.1515 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #55: GFLOPs: 50.3259. Time: 4459.1460 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #56: GFLOPs: 8.2404. Time: 27233.0175 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #57: GFLOPs: 2.3929. Time: 93780.6113 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #58: GFLOPs: 5.6557. Time: 39678.2843 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #59: GFLOPs: 87.3561. Time: 2568.9161 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #60: GFLOPs: 2.6397. Time: 85013.3237 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #61: GFLOPs: 26.7590. Time: 8386.3506 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #62: GFLOPs: 42.1806. Time: 5320.2323 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #63: GFLOPs: 19.9605. Time: 11242.7389 us. Best GFLOPs: 177.1132
2024-04-28 00:09:58 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #64: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(2), T.int64(13)):
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(3)):
                    for ax3_ax4_fused in T.vectorized(T.int64(60)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(15), oh_1 + ax2)
                            v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                            v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(13), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + oc_chunk_1 * T.int64(12) + oc_chunk_2_init * T.int64(3) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(13), ow_1 + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(3), T.int64(1), T.int64(3), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + oc_chunk_1 * T.int64(12) + oc_chunk_2 * T.int64(3) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(13), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(24), T.int64(13)):
                for ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), ax2)
                        v_ax3 = T.axis.spatial(T.int64(13), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 4, 3])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l82, l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l114, l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 00:17:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:17:22 [INFO] [evolutionary_search.cc:715] Picked top 62 candidate(s) from database
2024-04-28 00:17:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 8 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:17:27 [INFO] [evolutionary_search.cc:723] Sampled 442 candidate(s)
2024-04-28 00:17:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:17:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:17:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:18:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:18:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0019  1.0019  1.0019  1.0019  1.0019  0.9911  0.9256  0.9256  0.9207  0.9064  0.9064  0.8665  0.8567  0.8473  0.8095  0.7860
[17 : 32]:	0.7590  0.7541  0.7541  0.7239  0.7113  0.7093  0.7069  0.6996  0.6968  0.6968  0.6957  0.6932  0.6930  0.6830  0.6830  0.6775
[33 : 48]:	0.6765  0.6765  0.6754  0.6700  0.6700  0.6683  0.6683  0.6683  0.6655  0.6655  0.6655  0.6630  0.6630  0.6630  0.6614  0.6614
[49 : 64]:	0.6551  0.6551  0.6525  0.6518  0.6509  0.6488  0.6467  0.6454  0.6390  0.6390  0.6377  0.6371  0.6366  0.6359  0.6354  0.6345
2024-04-28 00:18:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:18:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #65: GFLOPs: 92.9425. Time: 2414.5073 us. Best GFLOPs: 177.1132
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #66: GFLOPs: 89.3849. Time: 2510.6060 us. Best GFLOPs: 177.1132
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #67: GFLOPs: 179.5707. Time: 1249.7050 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #68: GFLOPs: 165.1078. Time: 1359.1746 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #69: GFLOPs: 170.8871. Time: 1313.2085 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #70: GFLOPs: 145.4867. Time: 1542.4801 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #71: GFLOPs: 157.2888. Time: 1426.7410 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #72: GFLOPs: 162.7407. Time: 1378.9445 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #73: GFLOPs: 171.5561. Time: 1308.0871 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #74: GFLOPs: 163.1737. Time: 1375.2851 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #75: GFLOPs: 156.4784. Time: 1434.1302 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #76: GFLOPs: 155.5085. Time: 1443.0747 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #77: GFLOPs: 115.0610. Time: 1950.3593 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #78: GFLOPs: 155.9114. Time: 1439.3454 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #79: GFLOPs: 119.9944. Time: 1870.1744 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #80: GFLOPs: 94.7794. Time: 2367.7120 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #81: GFLOPs: 103.4194. Time: 2169.9052 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #82: GFLOPs: 85.8785. Time: 2613.1132 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #83: GFLOPs: 85.2786. Time: 2631.4956 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #84: GFLOPs: 163.8020. Time: 1370.0102 us. Best GFLOPs: 179.5707
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #85: GFLOPs: 187.0785. Time: 1199.5517 us. Best GFLOPs: 187.0785
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #86: GFLOPs: 189.0296. Time: 1187.1708 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #87: GFLOPs: 74.2707. Time: 3021.5177 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #88: GFLOPs: 64.8821. Time: 3458.7403 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #89: GFLOPs: 87.6595. Time: 2560.0241 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #90: GFLOPs: 87.6798. Time: 2559.4316 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #91: GFLOPs: 94.7205. Time: 2369.1840 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #92: GFLOPs: 95.0750. Time: 2360.3513 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #93: GFLOPs: 132.1123. Time: 1698.6331 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #94: GFLOPs: 63.1982. Time: 3550.8991 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #95: GFLOPs: 61.1652. Time: 3668.9214 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #96: GFLOPs: 76.1275. Time: 2947.8208 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #97: GFLOPs: 104.4776. Time: 2147.9276 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #98: GFLOPs: 105.5850. Time: 2125.3999 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #99: GFLOPs: 80.4434. Time: 2789.6669 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #100: GFLOPs: 111.4385. Time: 2013.7603 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #101: GFLOPs: 79.0756. Time: 2837.9214 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #102: GFLOPs: 119.6523. Time: 1875.5214 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #103: GFLOPs: 127.4152. Time: 1761.2524 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #104: GFLOPs: 155.1097. Time: 1446.7846 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #105: GFLOPs: 75.9038. Time: 2956.5109 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #106: GFLOPs: 68.3442. Time: 3283.5330 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #107: GFLOPs: 108.6438. Time: 2065.5617 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #108: GFLOPs: 76.5840. Time: 2930.2527 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #109: GFLOPs: 82.0716. Time: 2734.3241 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #110: GFLOPs: 112.6172. Time: 1992.6833 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #111: GFLOPs: 50.1496. Time: 4474.8214 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #112: GFLOPs: 23.8956. Time: 9391.2699 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #113: GFLOPs: 40.8857. Time: 5488.7187 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #114: GFLOPs: 45.0680. Time: 4979.3673 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #115: GFLOPs: 57.5213. Time: 3901.3414 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #116: GFLOPs: 153.5060. Time: 1461.9001 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #117: GFLOPs: 100.5666. Time: 2231.4597 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #118: GFLOPs: 130.0989. Time: 1724.9209 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #119: GFLOPs: 58.1235. Time: 3860.9201 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #120: GFLOPs: 4.3231. Time: 51910.0340 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #121: GFLOPs: 183.2903. Time: 1224.3438 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #122: GFLOPs: 161.0705. Time: 1393.2430 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #123: GFLOPs: 90.9711. Time: 2466.8307 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #124: GFLOPs: 79.4324. Time: 2825.1731 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #125: GFLOPs: 14.0668. Time: 15953.1891 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #126: GFLOPs: 47.9926. Time: 4675.9400 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #127: GFLOPs: 11.6707. Time: 19228.5348 us. Best GFLOPs: 189.0296
2024-04-28 00:19:40 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #128: GFLOPs: 5.5616. Time: 40349.6590 us. Best GFLOPs: 189.0296
2024-04-28 00:24:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:24:47 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 00:24:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 8 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:24:51 [INFO] [evolutionary_search.cc:723] Sampled 402 candidate(s)
2024-04-28 00:25:01 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 4 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:25:11 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:25:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:25:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:25:36 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9475  0.9475  0.9475  0.9475  0.9475  0.9475  0.9475  0.9475  0.9475  0.9289  0.9090  0.9090  0.9090  0.9090  0.9090  0.9090
[17 : 32]:	0.9090  0.9090  0.9090  0.9090  0.9090  0.9064  0.9055  0.9027  0.8940  0.8940  0.8940  0.8804  0.8776  0.8736  0.8736  0.8736
[33 : 48]:	0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736  0.8736
[49 : 64]:	0.8736  0.8736  0.8731  0.8731  0.8731  0.8725  0.8716  0.8716  0.8689  0.8627  0.8627  0.8610  0.8595  0.8595  0.8595  0.8595
2024-04-28 00:25:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:25:37 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #129: GFLOPs: 193.4909. Time: 1159.7983 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #130: GFLOPs: 92.1113. Time: 2436.2954 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #131: GFLOPs: 172.0369. Time: 1304.4318 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #132: GFLOPs: 88.4088. Time: 2538.3269 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #133: GFLOPs: 118.8205. Time: 1888.6498 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #134: GFLOPs: 95.2397. Time: 2356.2687 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #135: GFLOPs: 143.3075. Time: 1565.9363 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #136: GFLOPs: 164.6898. Time: 1362.6248 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #137: GFLOPs: 188.5707. Time: 1190.0598 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #138: GFLOPs: 169.8513. Time: 1321.2169 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #139: GFLOPs: 77.7176. Time: 2887.5085 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #140: GFLOPs: 121.5653. Time: 1846.0067 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #141: GFLOPs: 164.6474. Time: 1362.9752 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #142: GFLOPs: 162.4243. Time: 1381.6301 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #143: GFLOPs: 159.4081. Time: 1407.7724 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #144: GFLOPs: 66.0409. Time: 3398.0498 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #145: GFLOPs: 92.3365. Time: 2430.3528 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #146: GFLOPs: 65.9409. Time: 3403.2059 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #147: GFLOPs: 83.1546. Time: 2698.7138 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #148: GFLOPs: 65.0078. Time: 3452.0532 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #149: GFLOPs: 95.8843. Time: 2340.4298 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #150: GFLOPs: 66.6768. Time: 3365.6419 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #151: GFLOPs: 114.7213. Time: 1956.1344 us. Best GFLOPs: 193.4909
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #152: GFLOPs: 197.6341. Time: 1135.4842 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #153: GFLOPs: 165.2998. Time: 1357.5963 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #154: GFLOPs: 111.7189. Time: 2008.7054 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #155: GFLOPs: 165.7910. Time: 1353.5736 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #156: GFLOPs: 79.7611. Time: 2813.5301 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #157: GFLOPs: 173.3751. Time: 1294.3634 us. Best GFLOPs: 197.6341
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #158: GFLOPs: 197.7645. Time: 1134.7356 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #159: GFLOPs: 193.5002. Time: 1159.7425 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #160: GFLOPs: 189.3436. Time: 1185.2017 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #161: GFLOPs: 188.0692. Time: 1193.2329 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #162: GFLOPs: 139.7137. Time: 1606.2159 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #163: GFLOPs: 162.1677. Time: 1383.8170 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #164: GFLOPs: 142.3961. Time: 1575.9585 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #165: GFLOPs: 190.8952. Time: 1175.5684 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #166: GFLOPs: 175.3236. Time: 1279.9781 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #167: GFLOPs: 122.4055. Time: 1833.3354 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #168: GFLOPs: 153.0288. Time: 1466.4580 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #169: GFLOPs: 195.8935. Time: 1145.5734 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #170: GFLOPs: 130.8495. Time: 1715.0263 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #171: GFLOPs: 196.1165. Time: 1144.2708 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #172: GFLOPs: 185.1720. Time: 1211.9026 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #173: GFLOPs: 108.9457. Time: 2059.8365 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #174: GFLOPs: 187.6621. Time: 1195.8217 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #175: GFLOPs: 113.9258. Time: 1969.7933 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #176: GFLOPs: 194.0301. Time: 1156.5749 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #177: GFLOPs: 134.1583. Time: 1672.7279 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #178: GFLOPs: 193.3666. Time: 1160.5435 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #179: GFLOPs: 157.0804. Time: 1428.6336 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #180: GFLOPs: 78.3030. Time: 2865.9225 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #181: GFLOPs: 158.8701. Time: 1412.5400 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #182: GFLOPs: 171.3851. Time: 1309.3927 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #183: GFLOPs: 196.8958. Time: 1139.7418 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #184: GFLOPs: 174.7680. Time: 1284.0469 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #185: GFLOPs: 89.2742. Time: 2513.7197 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #186: GFLOPs: 96.6018. Time: 2323.0466 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #187: GFLOPs: 96.4041. Time: 2327.8087 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #188: GFLOPs: 173.3846. Time: 1294.2924 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #189: GFLOPs: 174.6711. Time: 1284.7597 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #190: GFLOPs: 72.5272. Time: 3094.1545 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #191: GFLOPs: 63.7693. Time: 3519.0971 us. Best GFLOPs: 197.7645
2024-04-28 00:26:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #192: GFLOPs: 158.8452. Time: 1412.7612 us. Best GFLOPs: 197.7645
2024-04-28 00:36:57 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:36:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 00:37:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:37:02 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 00:37:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:37:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:37:31 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:37:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:37:46 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9275  0.9275  0.9275  0.9275  0.9240  0.9178  0.9178  0.9178  0.9098  0.9098  0.9098  0.9098  0.9098  0.9049  0.8828  0.8764
[17 : 32]:	0.8696  0.8696  0.8696  0.8696  0.8693  0.8688  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570
[33 : 48]:	0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8570  0.8554  0.8554
[49 : 64]:	0.8554  0.8488  0.8479  0.8370  0.8268  0.8241  0.8241  0.8121  0.8121  0.8105  0.8099  0.8038  0.7995  0.7958  0.7958  0.7958
2024-04-28 00:37:46 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:37:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #193: GFLOPs: 246.6117. Time: 909.9746 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #194: GFLOPs: 190.3572. Time: 1178.8907 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #195: GFLOPs: 192.5142. Time: 1165.6821 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #196: GFLOPs: 197.3501. Time: 1137.1182 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #197: GFLOPs: 192.3566. Time: 1166.6371 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #198: GFLOPs: 192.4942. Time: 1165.8031 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #199: GFLOPs: 196.6548. Time: 1141.1388 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #200: GFLOPs: 183.0181. Time: 1226.1647 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #201: GFLOPs: 190.0663. Time: 1180.6951 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #202: GFLOPs: 189.6954. Time: 1183.0039 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #203: GFLOPs: 190.0326. Time: 1180.9048 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #204: GFLOPs: 182.6578. Time: 1228.5838 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #205: GFLOPs: 186.5495. Time: 1202.9537 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #206: GFLOPs: 136.3933. Time: 1645.3186 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #207: GFLOPs: 85.4498. Time: 2626.2244 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #208: GFLOPs: 178.9207. Time: 1254.2445 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #209: GFLOPs: 195.2688. Time: 1149.2383 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #210: GFLOPs: 194.6506. Time: 1152.8882 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #211: GFLOPs: 171.0702. Time: 1311.8029 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #212: GFLOPs: 197.4992. Time: 1136.2596 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #213: GFLOPs: 202.9230. Time: 1105.8891 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #214: GFLOPs: 164.7276. Time: 1362.3115 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #215: GFLOPs: 197.9606. Time: 1133.6110 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #216: GFLOPs: 105.3589. Time: 2129.9611 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #217: GFLOPs: 194.4015. Time: 1154.3652 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #218: GFLOPs: 189.3201. Time: 1185.3490 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #219: GFLOPs: 157.2099. Time: 1427.4567 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #220: GFLOPs: 160.2271. Time: 1400.5766 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #221: GFLOPs: 157.2347. Time: 1427.2317 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #222: GFLOPs: 233.5813. Time: 960.7376 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #223: GFLOPs: 185.0337. Time: 1212.8082 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #224: GFLOPs: 179.2310. Time: 1252.0731 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #225: GFLOPs: 195.0060. Time: 1150.7869 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #226: GFLOPs: 134.1179. Time: 1673.2323 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #227: GFLOPs: 201.8916. Time: 1111.5390 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #228: GFLOPs: 208.7111. Time: 1075.2201 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #229: GFLOPs: 196.1651. Time: 1143.9875 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #230: GFLOPs: 87.0162. Time: 2578.9483 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #231: GFLOPs: 178.8998. Time: 1254.3911 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #232: GFLOPs: 107.3943. Time: 2089.5927 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #233: GFLOPs: 189.2492. Time: 1185.7932 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #234: GFLOPs: 143.3660. Time: 1565.2970 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #235: GFLOPs: 141.8590. Time: 1581.9254 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #236: GFLOPs: 97.6218. Time: 2298.7730 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #237: GFLOPs: 193.0572. Time: 1162.4037 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #238: GFLOPs: 101.4783. Time: 2211.4114 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #239: GFLOPs: 189.8693. Time: 1181.9201 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #240: GFLOPs: 188.0910. Time: 1193.0947 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #241: GFLOPs: 186.7914. Time: 1201.3956 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #242: GFLOPs: 148.6417. Time: 1509.7401 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #243: GFLOPs: 164.6149. Time: 1363.2446 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #244: GFLOPs: 175.5838. Time: 1278.0813 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #245: GFLOPs: 172.9164. Time: 1297.7966 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #246: GFLOPs: 185.0333. Time: 1212.8104 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #247: GFLOPs: 205.9710. Time: 1089.5241 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #248: GFLOPs: 176.3485. Time: 1272.5390 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #249: GFLOPs: 175.1010. Time: 1281.6053 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #250: GFLOPs: 156.7032. Time: 1432.0725 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #251: GFLOPs: 172.0213. Time: 1304.5499 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #252: GFLOPs: 161.3048. Time: 1391.2193 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #253: GFLOPs: 145.3344. Time: 1544.0969 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #254: GFLOPs: 8.4512. Time: 26553.5278 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #255: GFLOPs: 35.7615. Time: 6275.1901 us. Best GFLOPs: 246.6117
2024-04-28 00:38:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #256: GFLOPs: 3.7440. Time: 59939.3237 us. Best GFLOPs: 246.6117
2024-04-28 00:48:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 00:48:22 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 00:48:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 14 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:48:26 [INFO] [evolutionary_search.cc:723] Sampled 396 candidate(s)
2024-04-28 00:48:36 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:48:45 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:48:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:49:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 00:49:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8323  0.8106  0.8106  0.8106  0.8106  0.8106  0.8020  0.7882  0.7729  0.7729  0.7680  0.7680  0.7680  0.7680  0.7680  0.7500
[17 : 32]:	0.7500  0.7500  0.7500  0.7500  0.7500  0.7500  0.7500  0.7481  0.7481  0.7481  0.7481  0.7447  0.7447  0.7447  0.7447  0.7447
[33 : 48]:	0.7447  0.7447  0.7447  0.7447  0.7438  0.7438  0.7438  0.7434  0.7240  0.7240  0.7240  0.7229  0.7222  0.7222  0.7198  0.7128
[49 : 64]:	0.7076  0.7076  0.7076  0.7076  0.7076  0.7076  0.7070  0.6986  0.6977  0.6977  0.6977  0.6977  0.6977  0.6977  0.6977  0.6977
2024-04-28 00:49:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 00:49:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #257: GFLOPs: 100.0420. Time: 2243.1617 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #258: GFLOPs: 141.8356. Time: 1582.1867 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #259: GFLOPs: 192.9704. Time: 1162.9262 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #260: GFLOPs: 192.6922. Time: 1164.6055 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #261: GFLOPs: 156.6765. Time: 1432.3164 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #262: GFLOPs: 191.3137. Time: 1172.9969 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #263: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[32, 3, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l80, l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #264: GFLOPs: 143.9046. Time: 1559.4380 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #265: GFLOPs: 99.8933. Time: 2246.4997 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #266: GFLOPs: 129.7602. Time: 1729.4244 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #267: GFLOPs: 169.9449. Time: 1320.4892 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #268: GFLOPs: 138.3257. Time: 1622.3334 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #269: GFLOPs: 150.2084. Time: 1493.9937 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #270: GFLOPs: 143.6960. Time: 1561.7024 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #271: GFLOPs: 182.5078. Time: 1229.5933 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #272: GFLOPs: 63.9706. Time: 3508.0238 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #273: GFLOPs: 188.9002. Time: 1187.9839 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #274: GFLOPs: 137.4703. Time: 1632.4279 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #275: GFLOPs: 134.5659. Time: 1667.6621 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #276: GFLOPs: 88.5536. Time: 2534.1761 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #277: GFLOPs: 127.3577. Time: 1762.0481 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #278: GFLOPs: 141.4821. Time: 1586.1395 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #279: GFLOPs: 155.6291. Time: 1441.9565 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #280: GFLOPs: 117.9705. Time: 1902.2584 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #281: GFLOPs: 120.8565. Time: 1856.8340 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #282: GFLOPs: 104.2838. Time: 2151.9191 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #283: GFLOPs: 175.9805. Time: 1275.2000 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #284: GFLOPs: 74.6585. Time: 3005.8252 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #285: GFLOPs: 55.9364. Time: 4011.8828 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #286: GFLOPs: 96.0632. Time: 2336.0711 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #287: GFLOPs: 103.1675. Time: 2175.2040 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #288: GFLOPs: 189.4492. Time: 1184.5412 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #289: GFLOPs: 189.5240. Time: 1184.0736 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #290: GFLOPs: 151.1226. Time: 1484.9552 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #291: GFLOPs: 122.6425. Time: 1829.7933 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #292: GFLOPs: 78.2091. Time: 2869.3633 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #293: GFLOPs: 158.4518. Time: 1416.2689 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #294: GFLOPs: 170.4883. Time: 1316.2804 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #295: GFLOPs: 193.0646. Time: 1162.3588 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #296: GFLOPs: 197.7470. Time: 1134.8357 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #297: GFLOPs: 175.8911. Time: 1275.8480 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #298: GFLOPs: 176.6481. Time: 1270.3812 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #299: GFLOPs: 180.2738. Time: 1244.8306 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #300: GFLOPs: 148.3604. Time: 1512.6032 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #301: GFLOPs: 179.2008. Time: 1252.2846 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #302: GFLOPs: 158.6532. Time: 1414.4714 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #303: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_i2_fused in T.parallel(T.int64(720)):
            for i3_i4_fused in T.vectorized(T.int64(60)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(48), i0_i1_i2_fused // T.int64(15))
                    v_i2 = T.axis.spatial(T.int64(15), i0_i1_i2_fused % T.int64(15))
                    v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                    v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(26), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(48) + oc_chunk_2_init * T.int64(12) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(3), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(48) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1 in T.grid(T.int64(1), T.int64(48)):
                for ax2_ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13))
                        v_ax3 = T.axis.spatial(T.int64(13), ax2_ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax2_ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 4, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l74, l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l109, l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #304: GFLOPs: 161.9731. Time: 1385.4790 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #305: GFLOPs: 182.7991. Time: 1227.6337 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #306: GFLOPs: 175.3880. Time: 1279.5081 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #307: GFLOPs: 169.9928. Time: 1320.1165 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #308: GFLOPs: 171.0556. Time: 1311.9149 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #309: GFLOPs: 186.3111. Time: 1204.4925 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #310: GFLOPs: 176.5175. Time: 1271.3206 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #311: GFLOPs: 147.4229. Time: 1522.2221 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #312: GFLOPs: 179.2411. Time: 1252.0032 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #313: GFLOPs: 188.7185. Time: 1189.1275 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #314: GFLOPs: 188.6248. Time: 1189.7179 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #315: GFLOPs: 188.9891. Time: 1187.4249 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #316: GFLOPs: 192.7938. Time: 1163.9919 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #317: GFLOPs: 143.2409. Time: 1566.6641 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #318: GFLOPs: 44.7679. Time: 5012.7497 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #319: GFLOPs: 148.9481. Time: 1506.6343 us. Best GFLOPs: 246.6117
2024-04-28 00:50:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #320: GFLOPs: 74.4045. Time: 3016.0846 us. Best GFLOPs: 246.6117
2024-04-28 01:05:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:05:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:05:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:05:06 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 01:05:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 3 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:05:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:05:36 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:05:45 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:05:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7423  0.7355  0.7355  0.7326  0.7326  0.7326  0.7326  0.7225  0.7225  0.7225  0.7175  0.7161  0.7119  0.7119  0.7119  0.7092
[17 : 32]:	0.7092  0.7092  0.7092  0.7092  0.7079  0.7079  0.7079  0.7079  0.7070  0.7055  0.7055  0.7011  0.6971  0.6959  0.6959  0.6959
[33 : 48]:	0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959  0.6959
[49 : 64]:	0.6959  0.6896  0.6874  0.6874  0.6834  0.6834  0.6734  0.6734  0.6734  0.6734  0.6734  0.6734  0.6734  0.6710  0.6710  0.6678
2024-04-28 01:05:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:05:51 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #321: GFLOPs: 80.1527. Time: 2799.7842 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #322: GFLOPs: 242.9476. Time: 923.6988 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #323: GFLOPs: 193.6095. Time: 1159.0876 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #324: GFLOPs: 186.1543. Time: 1205.5075 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #325: GFLOPs: 171.7654. Time: 1306.4932 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #326: GFLOPs: 207.1853. Time: 1083.1384 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #327: GFLOPs: 146.7761. Time: 1528.9300 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #328: GFLOPs: 175.6160. Time: 1277.8469 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #329: GFLOPs: 197.7603. Time: 1134.7596 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #330: GFLOPs: 203.6416. Time: 1101.9869 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #331: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[12, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l80, l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #332: GFLOPs: 159.3849. Time: 1407.9775 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #333: GFLOPs: 162.8494. Time: 1378.0239 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #334: GFLOPs: 189.3703. Time: 1185.0345 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #335: GFLOPs: 190.6752. Time: 1176.9245 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #336: GFLOPs: 133.6297. Time: 1679.3450 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #337: GFLOPs: 133.5208. Time: 1680.7152 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #338: GFLOPs: 170.0454. Time: 1319.7087 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #339: GFLOPs: 231.2924. Time: 970.2452 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #340: GFLOPs: 133.3076. Time: 1683.4032 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #341: GFLOPs: 162.0556. Time: 1384.7736 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #342: GFLOPs: 161.0234. Time: 1393.6506 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #343: GFLOPs: 170.8222. Time: 1313.7076 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #344: GFLOPs: 177.1104. Time: 1267.0646 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #345: GFLOPs: 172.2186. Time: 1303.0554 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #346: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_i2_fused in T.parallel(T.int64(720)):
            for i3_i4_fused in T.vectorized(T.int64(60)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(48), i0_i1_i2_fused // T.int64(15))
                    v_i2 = T.axis.spatial(T.int64(15), i0_i1_i2_fused % T.int64(15))
                    v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                    v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(26), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(12) + oc_chunk_2_init * T.int64(12) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(3), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(12) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1 in T.grid(T.int64(1), T.int64(48)):
                for ax2_ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13))
                        v_ax3 = T.axis.spatial(T.int64(13), ax2_ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax2_ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l74, l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l109, l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #347: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_i2_fused in T.parallel(T.int64(720)):
            for i3_i4_fused in T.vectorized(T.int64(60)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(48), i0_i1_i2_fused // T.int64(15))
                    v_i2 = T.axis.spatial(T.int64(15), i0_i1_i2_fused % T.int64(15))
                    v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                    v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(26), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(12) + oc_chunk_2_init * T.int64(12) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(3), T.int64(1), T.int64(12), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + oc_chunk_1 * T.int64(12) + oc_chunk_2 * T.int64(12) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1 in T.grid(T.int64(1), T.int64(48)):
                for ax2_ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(13) * T.int64(48) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(13))
                        v_ax3 = T.axis.spatial(T.int64(13), ax2_ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax2_ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 4, 1, 12])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l74, l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b70)
l112 = sch.fuse(l109, l110, l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #348: GFLOPs: 91.0542. Time: 2464.5795 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #349: GFLOPs: 134.3244. Time: 1670.6603 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #350: GFLOPs: 119.7578. Time: 1873.8678 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #351: GFLOPs: 179.0634. Time: 1253.2450 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #352: GFLOPs: 144.7626. Time: 1550.1958 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #353: GFLOPs: 186.0833. Time: 1205.9673 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #354: GFLOPs: 119.4750. Time: 1878.3035 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #355: GFLOPs: 132.3248. Time: 1695.9055 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #356: GFLOPs: 186.8274. Time: 1201.1638 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #357: GFLOPs: 188.8234. Time: 1188.4672 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #358: GFLOPs: 144.7193. Time: 1550.6596 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #359: GFLOPs: 122.1738. Time: 1836.8129 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #360: GFLOPs: 189.4532. Time: 1184.5160 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #361: GFLOPs: 185.0160. Time: 1212.9243 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #362: GFLOPs: 131.4075. Time: 1707.7442 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #363: GFLOPs: 86.9229. Time: 2581.7176 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #364: GFLOPs: 193.5883. Time: 1159.2147 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #365: GFLOPs: 131.8199. Time: 1702.4009 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #366: GFLOPs: 137.2949. Time: 1634.5130 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #367: GFLOPs: 131.6361. Time: 1704.7777 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #368: GFLOPs: 149.0960. Time: 1505.1404 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #369: GFLOPs: 194.2914. Time: 1155.0198 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #370: GFLOPs: 96.6567. Time: 2321.7248 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #371: GFLOPs: 176.5599. Time: 1271.0152 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #372: GFLOPs: 186.7335. Time: 1201.7678 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #373: GFLOPs: 134.4319. Time: 1669.3239 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #374: GFLOPs: 91.8464. Time: 2443.3233 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #375: GFLOPs: 198.9994. Time: 1127.6937 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #376: GFLOPs: 161.4212. Time: 1390.2163 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #377: GFLOPs: 191.5335. Time: 1171.6510 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #378: GFLOPs: 195.0009. Time: 1150.8170 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #379: GFLOPs: 167.6862. Time: 1338.2759 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #380: GFLOPs: 160.1407. Time: 1401.3325 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #381: GFLOPs: 197.0419. Time: 1138.8965 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #382: GFLOPs: 1.9418. Time: 115570.0393 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #383: GFLOPs: 43.2095. Time: 5193.5397 us. Best GFLOPs: 246.6117
2024-04-28 01:07:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #384: GFLOPs: 68.2014. Time: 3290.4054 us. Best GFLOPs: 246.6117
2024-04-28 01:11:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:11:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:11:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:11:29 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 01:11:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:11:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:11:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:12:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:12:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8949  0.8949  0.8645  0.8050  0.7863  0.7863  0.7580  0.7580  0.7488  0.7488  0.7469  0.7469  0.7469  0.7469  0.7464  0.7464
[17 : 32]:	0.7464  0.7464  0.7331  0.7331  0.7331  0.7331  0.7331  0.7273  0.7273  0.7184  0.7147  0.7147  0.7147  0.7147  0.7147  0.7142
[33 : 48]:	0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142  0.7142
[49 : 64]:	0.7142  0.7099  0.7099  0.7068  0.7068  0.7068  0.7068  0.7027  0.7027  0.7027  0.7027  0.7027  0.7027  0.7010  0.6952  0.6924
2024-04-28 01:12:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:12:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #385: GFLOPs: 96.7571. Time: 2319.3167 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #386: GFLOPs: 132.9946. Time: 1687.3641 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #387: GFLOPs: 174.8197. Time: 1283.6677 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #388: GFLOPs: 124.4416. Time: 1803.3390 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #389: GFLOPs: 174.7980. Time: 1283.8272 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #390: GFLOPs: 224.1307. Time: 1001.2478 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #391: GFLOPs: 165.8241. Time: 1353.3037 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #392: GFLOPs: 123.7499. Time: 1813.4184 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #393: GFLOPs: 195.8707. Time: 1145.7068 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #394: GFLOPs: 177.9462. Time: 1261.1134 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #395: GFLOPs: 194.2211. Time: 1155.4377 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #396: GFLOPs: 194.0818. Time: 1156.2672 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #397: GFLOPs: 199.8905. Time: 1122.6666 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #398: GFLOPs: 194.2047. Time: 1155.5350 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #399: GFLOPs: 75.5858. Time: 2968.9474 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #400: GFLOPs: 192.6363. Time: 1164.9434 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #401: GFLOPs: 159.6514. Time: 1405.6269 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #402: GFLOPs: 193.1579. Time: 1161.7977 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #403: GFLOPs: 218.2913. Time: 1028.0317 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #404: GFLOPs: 191.3269. Time: 1172.9161 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #405: GFLOPs: 170.4992. Time: 1316.1960 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #406: GFLOPs: 188.2731. Time: 1191.9407 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #407: GFLOPs: 188.2126. Time: 1192.3240 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #408: GFLOPs: 179.5052. Time: 1250.1607 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #409: GFLOPs: 200.8249. Time: 1117.4429 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #410: GFLOPs: 185.4145. Time: 1210.3172 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #411: GFLOPs: 141.5986. Time: 1584.8352 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #412: GFLOPs: 94.9072. Time: 2364.5236 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #413: GFLOPs: 63.9633. Time: 3508.4212 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #414: GFLOPs: 172.1538. Time: 1303.5460 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #415: GFLOPs: 107.5073. Time: 2087.3966 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #416: GFLOPs: 179.5188. Time: 1250.0658 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #417: GFLOPs: 95.4974. Time: 2349.9104 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #418: GFLOPs: 98.7041. Time: 2273.5676 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #419: GFLOPs: 181.9349. Time: 1233.4651 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #420: GFLOPs: 116.9636. Time: 1918.6346 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #421: GFLOPs: 191.8271. Time: 1169.8573 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #422: GFLOPs: 191.1424. Time: 1174.0478 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #423: GFLOPs: 154.0268. Time: 1456.9565 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #424: GFLOPs: 160.6662. Time: 1396.7492 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #425: GFLOPs: 186.1201. Time: 1205.7286 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #426: GFLOPs: 189.5066. Time: 1184.1825 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #427: GFLOPs: 168.4546. Time: 1332.1708 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #428: GFLOPs: 191.0286. Time: 1174.7477 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #429: GFLOPs: 162.0215. Time: 1385.0654 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #430: GFLOPs: 162.1271. Time: 1384.1630 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #431: GFLOPs: 161.7052. Time: 1387.7742 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #432: GFLOPs: 158.2214. Time: 1418.3316 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #433: GFLOPs: 143.4501. Time: 1564.3794 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #434: GFLOPs: 157.7770. Time: 1422.3267 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #435: GFLOPs: 170.7079. Time: 1314.5867 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #436: GFLOPs: 165.1306. Time: 1358.9874 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #437: GFLOPs: 152.4713. Time: 1471.8202 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #438: GFLOPs: 152.5565. Time: 1470.9982 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #439: GFLOPs: 182.3919. Time: 1230.3747 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #440: GFLOPs: 175.7018. Time: 1277.2228 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #441: GFLOPs: 162.9653. Time: 1377.0439 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #442: GFLOPs: 174.9579. Time: 1282.6538 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #443: GFLOPs: 188.0663. Time: 1193.2517 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #444: GFLOPs: 166.3191. Time: 1349.2762 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #445: GFLOPs: 177.9801. Time: 1260.8732 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #446: GFLOPs: 23.3272. Time: 9620.0994 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #447: GFLOPs: 4.8553. Time: 46219.5277 us. Best GFLOPs: 246.6117
2024-04-28 01:13:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #448: GFLOPs: 93.0617. Time: 2411.4162 us. Best GFLOPs: 246.6117
2024-04-28 01:36:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:36:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:36:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 13 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:36:43 [INFO] [evolutionary_search.cc:723] Sampled 397 candidate(s)
2024-04-28 01:36:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:37:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:37:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:37:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:37:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7906  0.7868  0.7868  0.7679  0.7679  0.7679  0.7679  0.7679  0.7679  0.7679  0.7679  0.7679  0.7679  0.7451  0.7451  0.7451
[17 : 32]:	0.7451  0.7451  0.7451  0.7451  0.7451  0.7438  0.7324  0.7185  0.7185  0.7092  0.7092  0.7092  0.7023  0.7023  0.6950  0.6950
[33 : 48]:	0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950  0.6950
[49 : 64]:	0.6950  0.6901  0.6900  0.6900  0.6900  0.6879  0.6829  0.6829  0.6829  0.6829  0.6829  0.6829  0.6829  0.6829  0.6829  0.6829
2024-04-28 01:37:27 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:37:27 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #449: GFLOPs: 115.2564. Time: 1947.0541 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #450: GFLOPs: 171.0395. Time: 1312.0379 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #451: GFLOPs: 86.4845. Time: 2594.8060 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #452: GFLOPs: 66.1515. Time: 3392.3702 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #453: GFLOPs: 162.6630. Time: 1379.6031 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #454: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[96, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #455: GFLOPs: 188.2235. Time: 1192.2551 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #456: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[96, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #457: GFLOPs: 139.8193. Time: 1605.0029 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #458: GFLOPs: 205.4799. Time: 1092.1283 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #459: GFLOPs: 140.2674. Time: 1599.8757 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #460: GFLOPs: 141.9506. Time: 1580.9050 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #461: GFLOPs: 205.4562. Time: 1092.2542 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #462: GFLOPs: 163.0571. Time: 1376.2685 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #463: GFLOPs: 159.7621. Time: 1404.6538 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #464: GFLOPs: 158.0662. Time: 1419.7236 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #465: GFLOPs: 210.3197. Time: 1066.9964 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #466: GFLOPs: 172.3424. Time: 1302.1193 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #467: GFLOPs: 215.5106. Time: 1041.2963 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #468: GFLOPs: 174.6094. Time: 1285.2136 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #469: GFLOPs: 175.5951. Time: 1277.9988 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #470: GFLOPs: 77.7726. Time: 2885.4670 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #471: GFLOPs: 135.5196. Time: 1655.9254 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #472: GFLOPs: 187.3062. Time: 1198.0939 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #473: GFLOPs: 184.8653. Time: 1213.9130 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #474: GFLOPs: 190.9375. Time: 1175.3083 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #475: GFLOPs: 132.6704. Time: 1691.4883 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #476: GFLOPs: 132.4197. Time: 1694.6904 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #477: GFLOPs: 138.8770. Time: 1615.8935 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #478: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 96, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l80, l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #479: GFLOPs: 175.5943. Time: 1278.0047 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #480: GFLOPs: 132.9699. Time: 1687.6781 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #481: GFLOPs: 177.2123. Time: 1266.3363 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #482: GFLOPs: 211.3888. Time: 1061.6000 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #483: GFLOPs: 196.5769. Time: 1141.5907 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #484: GFLOPs: 244.8135. Time: 916.6586 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #485: GFLOPs: 190.6443. Time: 1177.1155 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #486: GFLOPs: 166.9268. Time: 1344.3638 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #487: GFLOPs: 171.0828. Time: 1311.7059 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #488: GFLOPs: 213.7337. Time: 1049.9531 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #489: GFLOPs: 189.8226. Time: 1182.2111 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #490: GFLOPs: 180.8925. Time: 1240.5731 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #491: GFLOPs: 221.1473. Time: 1014.7552 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #492: GFLOPs: 243.2441. Time: 922.5728 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #493: GFLOPs: 149.9450. Time: 1496.6183 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #494: GFLOPs: 178.4296. Time: 1257.6968 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #495: GFLOPs: 193.4270. Time: 1160.1809 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #496: GFLOPs: 194.2129. Time: 1155.4865 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #497: GFLOPs: 190.0629. Time: 1180.7161 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #498: GFLOPs: 191.4067. Time: 1172.4270 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #499: GFLOPs: 137.4777. Time: 1632.3400 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #500: GFLOPs: 143.7702. Time: 1560.8961 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #501: GFLOPs: 143.7040. Time: 1561.6156 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #502: GFLOPs: 179.9488. Time: 1247.0789 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #503: GFLOPs: 83.8830. Time: 2675.2774 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #504: GFLOPs: 112.6855. Time: 1991.4753 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #505: GFLOPs: 233.7344. Time: 960.1085 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #506: GFLOPs: 196.9001. Time: 1139.7171 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #507: GFLOPs: 168.1601. Time: 1334.5041 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #508: GFLOPs: 185.3308. Time: 1210.8637 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #509: GFLOPs: 188.9852. Time: 1187.4493 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #510: GFLOPs: 50.3425. Time: 4457.6732 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #511: GFLOPs: 54.2607. Time: 4135.7815 us. Best GFLOPs: 246.6117
2024-04-28 01:38:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #512: GFLOPs: 62.8857. Time: 3568.5459 us. Best GFLOPs: 246.6117
2024-04-28 01:49:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:49:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:49:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 8 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:49:17 [INFO] [evolutionary_search.cc:723] Sampled 402 candidate(s)
2024-04-28 01:49:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:49:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:49:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:49:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:50:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7621  0.7414  0.7414  0.7414  0.7414  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297  0.7297
[17 : 32]:	0.7297  0.7297  0.7287  0.7287  0.7239  0.7239  0.7239  0.7207  0.7207  0.7069  0.7059  0.6881  0.6881  0.6838  0.6838  0.6838
[33 : 48]:	0.6838  0.6838  0.6838  0.6838  0.6838  0.6838  0.6838  0.6838  0.6838  0.6740  0.6740  0.6740  0.6735  0.6735  0.6735  0.6712
[49 : 64]:	0.6644  0.6644  0.6644  0.6644  0.6644  0.6644  0.6644  0.6644  0.6644  0.6644  0.6615  0.6615  0.6594  0.6594  0.6548  0.6548
2024-04-28 01:50:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:50:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #513: GFLOPs: 195.2979. Time: 1149.0671 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #514: GFLOPs: 170.8457. Time: 1313.5265 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #515: GFLOPs: 103.7105. Time: 2163.8163 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #516: GFLOPs: 195.7609. Time: 1146.3493 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #517: GFLOPs: 182.0900. Time: 1232.4144 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #518: GFLOPs: 199.3073. Time: 1125.9517 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #519: GFLOPs: 198.4057. Time: 1131.0679 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #520: GFLOPs: 161.4508. Time: 1389.9616 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #521: GFLOPs: 92.2810. Time: 2431.8149 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #522: GFLOPs: 141.9404. Time: 1581.0184 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #523: GFLOPs: 124.3070. Time: 1805.2920 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #524: GFLOPs: 131.6602. Time: 1704.4658 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #525: GFLOPs: 132.3847. Time: 1695.1388 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #526: GFLOPs: 141.7259. Time: 1583.4115 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #527: GFLOPs: 182.0895. Time: 1232.4181 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #528: GFLOPs: 182.8323. Time: 1227.4106 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #529: GFLOPs: 174.4773. Time: 1286.1867 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #530: GFLOPs: 141.2041. Time: 1589.2619 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #531: GFLOPs: 66.2308. Time: 3388.3088 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #532: GFLOPs: 149.3731. Time: 1502.3475 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #533: GFLOPs: 175.9113. Time: 1275.7017 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #534: GFLOPs: 194.5713. Time: 1153.3582 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #535: GFLOPs: 201.7817. Time: 1112.1442 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #536: GFLOPs: 183.8676. Time: 1220.5000 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #537: GFLOPs: 180.9183. Time: 1240.3963 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #538: GFLOPs: 156.5076. Time: 1433.8628 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #539: GFLOPs: 186.2612. Time: 1204.8153 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #540: GFLOPs: 158.5677. Time: 1415.2338 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #541: GFLOPs: 166.1727. Time: 1350.4644 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #542: GFLOPs: 72.7478. Time: 3084.7732 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #543: GFLOPs: 96.5467. Time: 2324.3715 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #544: GFLOPs: 184.9341. Time: 1213.4612 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #545: GFLOPs: 179.5269. Time: 1250.0096 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #546: GFLOPs: 189.3172. Time: 1185.3669 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #547: GFLOPs: 125.3947. Time: 1789.6319 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #548: GFLOPs: 126.2662. Time: 1777.2805 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #549: GFLOPs: 73.7331. Time: 3043.5482 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #550: GFLOPs: 182.2128. Time: 1231.5843 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #551: GFLOPs: 186.0464. Time: 1206.2068 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #552: GFLOPs: 126.5480. Time: 1773.3215 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #553: GFLOPs: 189.1746. Time: 1186.2608 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #554: GFLOPs: 207.5215. Time: 1081.3836 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #555: GFLOPs: 185.5870. Time: 1209.1920 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #556: GFLOPs: 193.1987. Time: 1161.5522 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #557: GFLOPs: 66.7381. Time: 3362.5510 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #558: GFLOPs: 131.2471. Time: 1709.8307 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #559: GFLOPs: 118.5084. Time: 1893.6243 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #560: GFLOPs: 202.1916. Time: 1109.8897 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #561: GFLOPs: 185.2047. Time: 1211.6883 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #562: GFLOPs: 187.2626. Time: 1198.3726 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #563: GFLOPs: 175.3792. Time: 1279.5721 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #564: GFLOPs: 157.0457. Time: 1428.9495 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #565: GFLOPs: 183.0146. Time: 1226.1886 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #566: GFLOPs: 183.3618. Time: 1223.8662 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #567: GFLOPs: 135.1078. Time: 1660.9733 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #568: GFLOPs: 124.6269. Time: 1800.6569 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #569: GFLOPs: 198.8510. Time: 1128.5355 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #570: GFLOPs: 138.4266. Time: 1621.1510 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #571: GFLOPs: 147.5601. Time: 1520.8063 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #572: GFLOPs: 162.2886. Time: 1382.7857 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #573: GFLOPs: 170.5084. Time: 1316.1251 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #574: GFLOPs: 3.8651. Time: 58060.6537 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #575: GFLOPs: 37.0526. Time: 6056.5379 us. Best GFLOPs: 246.6117
2024-04-28 01:51:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #576: GFLOPs: 60.7312. Time: 3695.1443 us. Best GFLOPs: 246.6117
2024-04-28 01:56:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 01:56:05 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 01:56:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 6 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:56:09 [INFO] [evolutionary_search.cc:723] Sampled 404 candidate(s)
2024-04-28 01:56:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:56:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:56:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:56:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 01:56:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7653  0.7653  0.7653  0.7653  0.7653  0.7481  0.7335  0.7335  0.7335  0.7321  0.7321  0.7276  0.7190  0.7181  0.7181  0.7181
[17 : 32]:	0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7181  0.7082
[33 : 48]:	0.7082  0.7082  0.7082  0.6926  0.6926  0.6926  0.6926  0.6926  0.6926  0.6926  0.6926  0.6823  0.6823  0.6792  0.6792  0.6792
[49 : 64]:	0.6792  0.6792  0.6792  0.6792  0.6792  0.6792  0.6792  0.6792  0.6759  0.6734  0.6734  0.6734  0.6709  0.6709  0.6668  0.6668
2024-04-28 01:56:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 01:56:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #577: GFLOPs: 247.3671. Time: 907.1956 us. Best GFLOPs: 247.3671
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #578: GFLOPs: 180.6464. Time: 1242.2632 us. Best GFLOPs: 247.3671
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #579: GFLOPs: 196.7644. Time: 1140.5029 us. Best GFLOPs: 247.3671
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #580: GFLOPs: 201.5914. Time: 1113.1939 us. Best GFLOPs: 247.3671
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #581: GFLOPs: 262.3468. Time: 855.3960 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #582: GFLOPs: 203.3926. Time: 1103.3358 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #583: GFLOPs: 160.7684. Time: 1395.8608 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #584: GFLOPs: 183.6465. Time: 1221.9692 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #585: GFLOPs: 226.6173. Time: 990.2614 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #586: GFLOPs: 189.0279. Time: 1187.1815 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #587: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 32, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l80, l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #588: GFLOPs: 194.0840. Time: 1156.2538 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #589: GFLOPs: 193.4578. Time: 1159.9967 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #590: GFLOPs: 121.9748. Time: 1839.8093 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #591: GFLOPs: 238.1531. Time: 942.2945 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #592: GFLOPs: 200.7717. Time: 1117.7388 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #593: GFLOPs: 149.4187. Time: 1501.8894 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #594: GFLOPs: 170.5087. Time: 1316.1231 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #595: GFLOPs: 184.0861. Time: 1219.0510 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #596: GFLOPs: 175.2853. Time: 1280.2578 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #597: GFLOPs: 143.5773. Time: 1562.9932 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #598: GFLOPs: 114.2148. Time: 1964.8106 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #599: GFLOPs: 177.6334. Time: 1263.3344 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #600: GFLOPs: 170.2766. Time: 1317.9165 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #601: GFLOPs: 187.6215. Time: 1196.0803 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #602: GFLOPs: 178.5404. Time: 1256.9166 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #603: GFLOPs: 195.2870. Time: 1149.1310 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #604: GFLOPs: 187.4549. Time: 1197.1430 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #605: GFLOPs: 169.0207. Time: 1327.7090 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #606: GFLOPs: 188.7665. Time: 1188.8253 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #607: GFLOPs: 200.6724. Time: 1118.2920 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #608: GFLOPs: 68.2050. Time: 3290.2314 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #609: GFLOPs: 133.3704. Time: 1682.6106 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #610: GFLOPs: 164.6167. Time: 1363.2294 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #611: GFLOPs: 119.2014. Time: 1882.6157 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #612: GFLOPs: 213.5073. Time: 1051.0663 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #613: GFLOPs: 187.6189. Time: 1196.0970 us. Best GFLOPs: 262.3468
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #614: GFLOPs: 341.2755. Time: 657.5636 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #615: GFLOPs: 233.2123. Time: 962.2578 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #616: GFLOPs: 183.7971. Time: 1220.9679 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #617: GFLOPs: 190.2255. Time: 1179.7073 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #618: GFLOPs: 226.9709. Time: 988.7188 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #619: GFLOPs: 104.4421. Time: 2148.6586 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #620: GFLOPs: 134.3188. Time: 1670.7297 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #621: GFLOPs: 194.8969. Time: 1151.4312 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #622: GFLOPs: 188.8883. Time: 1188.0584 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #623: GFLOPs: 235.9940. Time: 950.9157 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #624: GFLOPs: 142.7441. Time: 1572.1165 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #625: GFLOPs: 148.9356. Time: 1506.7616 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #626: GFLOPs: 188.1696. Time: 1192.5966 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #627: GFLOPs: 145.0909. Time: 1546.6884 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #628: GFLOPs: 83.5324. Time: 2686.5053 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #629: GFLOPs: 178.7464. Time: 1255.4680 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #630: GFLOPs: 191.3804. Time: 1172.5879 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #631: GFLOPs: 188.5880. Time: 1189.9505 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #632: GFLOPs: 187.8014. Time: 1194.9344 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #633: GFLOPs: 188.3891. Time: 1191.2070 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #634: GFLOPs: 196.7788. Time: 1140.4194 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #635: GFLOPs: 196.5495. Time: 1141.7497 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #636: GFLOPs: 153.6574. Time: 1460.4590 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #637: GFLOPs: 177.0233. Time: 1267.6884 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #638: GFLOPs: 60.3714. Time: 3717.1654 us. Best GFLOPs: 341.2755
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #639: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(13), T.int64(13), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + oc_chunk_1 * T.int64(3) + oc_chunk_2_init * T.int64(3) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(16)):
                    for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(3), T.int64(3)):
                        for ax3_ax4_fused in T.vectorized(T.int64(12)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(48), ic_0 * T.int64(3) + ax1)
                                v_i2 = T.axis.spatial(T.int64(15), oh_1 + ax2)
                                v_i3 = T.axis.spatial(T.int64(15), ow_1 + ax3_ax4_fused // T.int64(4))
                                v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(12), T.int64(1), T.int64(3), T.int64(1), T.int64(3), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + oc_chunk_1 * T.int64(3) + oc_chunk_2 * T.int64(3) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(13), ow_1 + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(12) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(24), T.int64(13)):
                for ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(24) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), ax2)
                        v_ax3 = T.axis.spatial(T.int64(13), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 8, 1, 3])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 12])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b68)
l87 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88 = sch.fuse(l85, l86, preserve_unit_iters=True)
sch.vectorize(loop=l88)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l89, preserve_unit_iters=True)
sch.parallel(loop=l111)
l112 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l112)
sch.annotate(block_or_loop=l111, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l111, ann_key="pragma_unroll_explicit", ann_val=1)
l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b70)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b120)
b143 = sch.decompose_reduction(block=b120, loop=l127)
2024-04-28 01:58:21 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #640: GFLOPs: 15.3933. Time: 14578.4277 us. Best GFLOPs: 341.2755
2024-04-28 02:10:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 02:10:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 02:10:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 9 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:10:08 [INFO] [evolutionary_search.cc:723] Sampled 401 candidate(s)
2024-04-28 02:10:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:10:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:10:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:10:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:10:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6633  0.6581
[17 : 32]:	0.6581  0.6436  0.6436  0.6436  0.6436  0.6381  0.6320  0.6320  0.6261  0.6226  0.6123  0.6097  0.6097  0.6097  0.6083  0.6083
[33 : 48]:	0.6083  0.6075  0.5956  0.5956  0.5956  0.5883  0.5869  0.5869  0.5838  0.5819  0.5734  0.5734  0.5672  0.5668  0.5668  0.5668
[49 : 64]:	0.5394  0.5394  0.5385  0.5373  0.5364  0.5364  0.5294  0.5294  0.5257  0.5238  0.5218  0.5218  0.5218  0.5218  0.5218  0.5218
2024-04-28 02:10:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 02:10:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #641: GFLOPs: 230.9051. Time: 971.8726 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #642: GFLOPs: 183.9727. Time: 1219.8025 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #643: GFLOPs: 193.3175. Time: 1160.8385 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #644: GFLOPs: 159.5595. Time: 1406.4368 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #645: GFLOPs: 172.6967. Time: 1299.4477 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #646: GFLOPs: 196.0377. Time: 1144.7304 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #647: GFLOPs: 190.8427. Time: 1175.8920 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #648: GFLOPs: 163.5016. Time: 1372.5267 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #649: GFLOPs: 203.2701. Time: 1104.0011 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #650: GFLOPs: 245.3407. Time: 914.6889 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #651: GFLOPs: 243.7594. Time: 920.6225 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #652: GFLOPs: 204.3125. Time: 1098.3685 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #653: GFLOPs: 200.9536. Time: 1116.7275 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #654: GFLOPs: 204.5761. Time: 1096.9533 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #655: GFLOPs: 204.3221. Time: 1098.3169 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #656: GFLOPs: 169.2421. Time: 1325.9723 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #657: GFLOPs: 184.5635. Time: 1215.8978 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #658: GFLOPs: 178.4989. Time: 1257.2088 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #659: GFLOPs: 163.4414. Time: 1373.0327 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #660: GFLOPs: 237.1849. Time: 946.1410 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #661: GFLOPs: 162.3252. Time: 1382.4740 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #662: GFLOPs: 220.2966. Time: 1018.6737 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #663: GFLOPs: 148.9280. Time: 1506.8379 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #664: GFLOPs: 158.1939. Time: 1418.5783 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #665: GFLOPs: 163.3703. Time: 1373.6304 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #666: GFLOPs: 144.3561. Time: 1554.5614 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #667: GFLOPs: 226.7304. Time: 989.7673 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #668: GFLOPs: 180.7401. Time: 1241.6194 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #669: GFLOPs: 180.7199. Time: 1241.7578 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #670: GFLOPs: 188.4436. Time: 1190.8623 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #671: GFLOPs: 187.9330. Time: 1194.0980 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #672: GFLOPs: 93.9298. Time: 2389.1291 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #673: GFLOPs: 158.7539. Time: 1413.5741 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #674: GFLOPs: 201.0161. Time: 1116.3799 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #675: GFLOPs: 176.2458. Time: 1273.2809 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #676: GFLOPs: 171.9532. Time: 1305.0668 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #677: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #678: GFLOPs: 140.5553. Time: 1596.5988 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #679: GFLOPs: 205.6924. Time: 1090.9997 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #680: GFLOPs: 224.4888. Time: 999.6508 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #681: GFLOPs: 168.7403. Time: 1329.9155 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #682: GFLOPs: 169.2273. Time: 1326.0884 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #683: GFLOPs: 186.3523. Time: 1204.2263 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #684: GFLOPs: 196.1114. Time: 1144.3006 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #685: GFLOPs: 187.3085. Time: 1198.0791 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #686: GFLOPs: 156.9885. Time: 1429.4705 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #687: GFLOPs: 213.2590. Time: 1052.2901 us. Best GFLOPs: 341.2755
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #688: GFLOPs: 384.6791. Time: 583.3703 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #689: GFLOPs: 194.7857. Time: 1152.0886 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #690: GFLOPs: 195.1135. Time: 1150.1527 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #691: GFLOPs: 243.6294. Time: 921.1137 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #692: GFLOPs: 74.4039. Time: 3016.1097 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #693: GFLOPs: 240.7995. Time: 931.9387 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #694: GFLOPs: 195.4441. Time: 1148.2072 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #695: GFLOPs: 144.6543. Time: 1551.3562 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #696: GFLOPs: 195.9328. Time: 1145.3435 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #697: GFLOPs: 128.9349. Time: 1740.4939 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #698: GFLOPs: 178.1352. Time: 1259.7753 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #699: GFLOPs: 171.9208. Time: 1305.3125 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #700: GFLOPs: 181.3255. Time: 1237.6105 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #701: GFLOPs: 155.6832. Time: 1441.4556 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #702: GFLOPs: 75.4890. Time: 2972.7566 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #703: GFLOPs: 137.1785. Time: 1635.9008 us. Best GFLOPs: 384.6791
2024-04-28 02:12:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #704: GFLOPs: 11.0648. Time: 20281.5460 us. Best GFLOPs: 384.6791
2024-04-28 02:22:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 02:22:38 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 02:22:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:22:41 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 02:22:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:23:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:23:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:23:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:23:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7383  0.7383  0.7383  0.7383  0.7383  0.6928  0.6928  0.6928  0.6563  0.6288  0.6214  0.6214  0.6214  0.6214  0.6107  0.6107
[17 : 32]:	0.6107  0.6107  0.6107  0.6107  0.6107  0.6025  0.5920  0.5830  0.5741  0.5626  0.5602  0.5602  0.5571  0.5560  0.5560  0.5535
[33 : 48]:	0.5535  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443
[49 : 64]:	0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5443  0.5441  0.5440  0.5430  0.5406  0.5406  0.5406
2024-04-28 02:23:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 02:23:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #705: GFLOPs: 101.6638. Time: 2207.3774 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #706: GFLOPs: 169.9183. Time: 1320.6957 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #707: GFLOPs: 255.0264. Time: 879.9495 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #708: GFLOPs: 179.8868. Time: 1247.5091 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #709: GFLOPs: 243.5230. Time: 921.5160 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #710: GFLOPs: 96.6629. Time: 2321.5765 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #711: GFLOPs: 201.5279. Time: 1113.5451 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #712: GFLOPs: 150.0317. Time: 1495.7527 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #713: GFLOPs: 211.6506. Time: 1060.2868 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #714: GFLOPs: 105.5618. Time: 2125.8676 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #715: GFLOPs: 210.6607. Time: 1065.2691 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #716: GFLOPs: 201.1436. Time: 1115.6727 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #717: GFLOPs: 196.2367. Time: 1143.5697 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #718: GFLOPs: 184.8952. Time: 1213.7166 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #719: GFLOPs: 150.8822. Time: 1487.3215 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #720: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #721: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #722: GFLOPs: 186.3224. Time: 1204.4194 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #723: GFLOPs: 206.7560. Time: 1085.3873 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #724: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #725: GFLOPs: 239.0109. Time: 938.9127 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #726: GFLOPs: 59.0259. Time: 3801.8955 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #727: GFLOPs: 101.2145. Time: 2217.1772 us. Best GFLOPs: 384.6791
2024-04-28 02:24:52 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #728: GFLOPs: 110.4572. Time: 2031.6502 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #729: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(13), oh_2_init * T.int64(13) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(13), ow_2_init * T.int64(13) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(48)):
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(1), T.int64(15)):
                    for ax3_ax4_fused in T.vectorized(T.int64(60)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(48), ic_0 + ax1)
                            v_i2 = T.axis.spatial(T.int64(15), ax2)
                            v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                            v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l84, l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l107, l108, l109, l110, l111, preserve_unit_iters=True)
l113, l114 = sch.split(loop=l112, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #730: GFLOPs: 55.5012. Time: 4043.3436 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #731: GFLOPs: 138.1482. Time: 1624.4170 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #732: GFLOPs: 205.5054. Time: 1091.9927 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #733: GFLOPs: 88.8811. Time: 2524.8370 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #734: GFLOPs: 155.3319. Time: 1444.7151 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #735: GFLOPs: 134.8544. Time: 1664.0939 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #736: GFLOPs: 90.3528. Time: 2483.7128 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #737: GFLOPs: 98.5837. Time: 2276.3433 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #738: GFLOPs: 179.0111. Time: 1253.6114 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #739: GFLOPs: 194.2540. Time: 1155.2422 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #740: GFLOPs: 190.1760. Time: 1180.0138 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #741: GFLOPs: 168.8126. Time: 1329.3464 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #742: GFLOPs: 250.1976. Time: 896.9327 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #743: GFLOPs: 153.8210. Time: 1458.9061 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #744: GFLOPs: 205.8454. Time: 1090.1888 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #745: GFLOPs: 195.8737. Time: 1145.6890 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #746: GFLOPs: 186.1588. Time: 1205.4783 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #747: GFLOPs: 217.3703. Time: 1032.3876 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #748: GFLOPs: 207.7816. Time: 1080.0299 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #749: GFLOPs: 156.3093. Time: 1435.6816 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #750: GFLOPs: 210.7886. Time: 1064.6227 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #751: GFLOPs: 256.6191. Time: 874.4882 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #752: GFLOPs: 205.5354. Time: 1091.8334 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #753: GFLOPs: 194.2639. Time: 1155.1829 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #754: GFLOPs: 168.0979. Time: 1334.9977 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #755: GFLOPs: 182.6939. Time: 1228.3409 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #756: GFLOPs: 188.5216. Time: 1190.3696 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #757: GFLOPs: 169.6314. Time: 1322.9291 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #758: GFLOPs: 140.3386. Time: 1599.0636 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #759: GFLOPs: 184.1321. Time: 1218.7466 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #760: GFLOPs: 182.9377. Time: 1226.7038 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #761: GFLOPs: 194.4608. Time: 1154.0136 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #762: GFLOPs: 168.1218. Time: 1334.8083 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #763: GFLOPs: 180.8251. Time: 1241.0358 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #764: GFLOPs: 258.6765. Time: 867.5330 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #765: GFLOPs: 81.0482. Time: 2768.8496 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #766: GFLOPs: 79.1017. Time: 2836.9844 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #767: GFLOPs: 13.9048. Time: 16139.0639 us. Best GFLOPs: 384.6791
2024-04-28 02:24:53 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #768: GFLOPs: 23.7932. Time: 9431.7043 us. Best GFLOPs: 384.6791
2024-04-28 02:27:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 02:27:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 02:27:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 6 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:27:08 [INFO] [evolutionary_search.cc:723] Sampled 404 candidate(s)
2024-04-28 02:27:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:27:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:27:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:27:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 02:27:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5994  0.5994  0.5994  0.5994  0.5933  0.5481  0.5410  0.5400  0.5400  0.5400  0.5400  0.5392  0.5392  0.5392  0.5392  0.5392
[17 : 32]:	0.5392  0.5392  0.5392  0.5392  0.5392  0.5392  0.5392  0.5392  0.5392  0.5337  0.5337  0.5337  0.5337  0.5318  0.5318  0.5318
[33 : 48]:	0.5304  0.5304  0.5304  0.5304  0.5298  0.5298  0.5298  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262
[49 : 64]:	0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262  0.5262
2024-04-28 02:27:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 02:27:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #769: GFLOPs: 193.2188. Time: 1161.4313 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #770: GFLOPs: 232.2592. Time: 966.2066 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #771: GFLOPs: 187.5878. Time: 1196.2949 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #772: GFLOPs: 218.0400. Time: 1029.2167 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #773: GFLOPs: 202.1291. Time: 1110.2326 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #774: GFLOPs: 177.8401. Time: 1261.8661 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #775: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #776: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #777: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #778: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #779: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #780: GFLOPs: 168.1243. Time: 1334.7885 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #781: GFLOPs: 384.1746. Time: 584.1364 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #782: GFLOPs: 237.6186. Time: 944.4141 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #783: GFLOPs: 369.3555. Time: 607.5728 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #784: GFLOPs: 193.8439. Time: 1157.6863 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #785: GFLOPs: 182.1231. Time: 1232.1907 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #786: GFLOPs: 137.5034. Time: 1632.0347 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #787: GFLOPs: 152.0405. Time: 1475.9912 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #788: GFLOPs: 136.0123. Time: 1649.9268 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #789: GFLOPs: 193.1993. Time: 1161.5483 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #790: GFLOPs: 168.9237. Time: 1328.4716 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #791: GFLOPs: 193.9712. Time: 1156.9263 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #792: GFLOPs: 176.9468. Time: 1268.2363 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #793: GFLOPs: 157.5569. Time: 1424.3128 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #794: GFLOPs: 177.9352. Time: 1261.1912 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #795: GFLOPs: 192.8954. Time: 1163.3785 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #796: GFLOPs: 209.1499. Time: 1072.9642 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #797: GFLOPs: 212.7622. Time: 1054.7471 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #798: GFLOPs: 199.0510. Time: 1127.4011 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #799: GFLOPs: 227.5962. Time: 986.0024 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #800: GFLOPs: 171.2863. Time: 1310.1476 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #801: GFLOPs: 232.1869. Time: 966.5074 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #802: GFLOPs: 183.6910. Time: 1221.6731 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #803: GFLOPs: 176.9615. Time: 1268.1308 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #804: GFLOPs: 200.3130. Time: 1120.2988 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #805: GFLOPs: 200.9397. Time: 1116.8046 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #806: GFLOPs: 237.5563. Time: 944.6616 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #807: GFLOPs: 215.9402. Time: 1039.2247 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #808: GFLOPs: 159.5717. Time: 1406.3297 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #809: GFLOPs: 199.9748. Time: 1122.1934 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #810: GFLOPs: 193.0222. Time: 1162.6145 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #811: GFLOPs: 177.6358. Time: 1263.3169 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #812: GFLOPs: 219.4191. Time: 1022.7476 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #813: GFLOPs: 189.0549. Time: 1187.0117 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #814: GFLOPs: 207.6967. Time: 1080.4713 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #815: GFLOPs: 119.7106. Time: 1874.6074 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #816: GFLOPs: 183.3093. Time: 1224.2172 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #817: GFLOPs: 156.8392. Time: 1430.8312 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #818: GFLOPs: 146.6690. Time: 1530.0460 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #819: GFLOPs: 166.4980. Time: 1347.8263 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #820: GFLOPs: 183.3153. Time: 1224.1769 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #821: GFLOPs: 216.2107. Time: 1037.9247 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #822: GFLOPs: 188.9769. Time: 1187.5017 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #823: GFLOPs: 218.4001. Time: 1027.5194 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #824: GFLOPs: 141.8353. Time: 1582.1902 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #825: GFLOPs: 182.4183. Time: 1230.1968 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #826: GFLOPs: 342.0106. Time: 656.1504 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #827: GFLOPs: 246.1405. Time: 911.7167 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #828: GFLOPs: 190.3541. Time: 1178.9099 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #829: GFLOPs: 201.8395. Time: 1111.8260 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #830: GFLOPs: 14.0834. Time: 15934.3890 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #831: GFLOPs: 25.0490. Time: 8958.8527 us. Best GFLOPs: 384.6791
2024-04-28 02:29:16 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #832: GFLOPs: 22.7946. Time: 9844.9033 us. Best GFLOPs: 384.6791
2024-04-28 03:19:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 03:19:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 03:19:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:19:47 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 03:19:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:20:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:20:16 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:20:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 3 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:20:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5892  0.5892  0.5892  0.5892  0.5892  0.5892  0.5849  0.5849  0.5849  0.5849  0.5849  0.5849  0.5849  0.5833  0.5833  0.5833
[17 : 32]:	0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833
[33 : 48]:	0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5833  0.5400  0.5400  0.5391  0.5361
[49 : 64]:	0.5294  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280  0.5263  0.5263  0.5263  0.5263  0.5263  0.5263
2024-04-28 03:20:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 03:20:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #833: GFLOPs: 384.3128. Time: 583.9264 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #834: GFLOPs: 252.8717. Time: 887.4476 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #835: GFLOPs: 253.3765. Time: 885.6795 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #836: GFLOPs: 212.5601. Time: 1055.7504 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #837: GFLOPs: 226.6038. Time: 990.3204 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #838: GFLOPs: 201.3732. Time: 1114.4006 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #839: GFLOPs: 239.6094. Time: 936.5674 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #840: GFLOPs: 187.0871. Time: 1199.4968 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #841: GFLOPs: 153.7803. Time: 1459.2924 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #842: GFLOPs: 252.5839. Time: 888.4587 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #843: GFLOPs: 189.3054. Time: 1185.4407 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #844: GFLOPs: 176.8661. Time: 1268.8150 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #845: GFLOPs: 238.2531. Time: 941.8991 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #846: GFLOPs: 193.2831. Time: 1161.0448 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #847: GFLOPs: 183.4025. Time: 1223.5951 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #848: GFLOPs: 184.4873. Time: 1216.4003 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #849: GFLOPs: 217.4004. Time: 1032.2443 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #850: GFLOPs: 231.6501. Time: 968.7469 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #851: GFLOPs: 253.5389. Time: 885.1120 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #852: GFLOPs: 207.3578. Time: 1082.2376 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #853: GFLOPs: 219.3327. Time: 1023.1507 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #854: GFLOPs: 220.1384. Time: 1019.4056 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #855: GFLOPs: 230.1150. Time: 975.2097 us. Best GFLOPs: 384.6791
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #856: GFLOPs: 385.4617. Time: 582.1859 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #857: GFLOPs: 239.2950. Time: 937.7981 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #858: GFLOPs: 239.5074. Time: 936.9662 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #859: GFLOPs: 198.9256. Time: 1128.1120 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #860: GFLOPs: 218.1416. Time: 1028.7370 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #861: GFLOPs: 253.9255. Time: 883.7647 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #862: GFLOPs: 244.3499. Time: 918.3978 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #863: GFLOPs: 240.4453. Time: 933.3115 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #864: GFLOPs: 166.4684. Time: 1348.0658 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #865: GFLOPs: 120.9423. Time: 1855.5160 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #866: GFLOPs: 118.4217. Time: 1895.0111 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #867: GFLOPs: 199.1986. Time: 1126.5660 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #868: GFLOPs: 246.2713. Time: 911.2323 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #869: GFLOPs: 240.7750. Time: 932.0334 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #870: GFLOPs: 194.7424. Time: 1152.3445 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #871: GFLOPs: 182.4369. Time: 1230.0709 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #872: GFLOPs: 195.6172. Time: 1147.1914 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #873: GFLOPs: 149.9062. Time: 1497.0054 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #874: GFLOPs: 201.5668. Time: 1113.3302 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #875: GFLOPs: 186.4248. Time: 1203.7582 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #876: GFLOPs: 241.2241. Time: 930.2982 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #877: GFLOPs: 186.2146. Time: 1205.1170 us. Best GFLOPs: 385.4617
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #878: GFLOPs: 389.7392. Time: 575.7962 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #879: GFLOPs: 208.1854. Time: 1077.9354 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #880: GFLOPs: 191.5842. Time: 1171.3405 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #881: GFLOPs: 138.1462. Time: 1624.4413 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #882: GFLOPs: 183.0502. Time: 1225.9501 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #883: GFLOPs: 166.9673. Time: 1344.0378 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #884: GFLOPs: 178.1953. Time: 1259.3510 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #885: GFLOPs: 180.9640. Time: 1240.0827 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #886: GFLOPs: 203.1571. Time: 1104.6150 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #887: GFLOPs: 179.1108. Time: 1252.9138 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #888: GFLOPs: 179.1757. Time: 1252.4598 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #889: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #890: GFLOPs: 190.3228. Time: 1179.1040 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #891: GFLOPs: 112.0948. Time: 2001.9694 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #892: GFLOPs: 188.2859. Time: 1191.8595 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #893: GFLOPs: 170.8290. Time: 1313.6549 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #894: GFLOPs: 16.1829. Time: 13867.1707 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #895: GFLOPs: 22.6456. Time: 9909.6806 us. Best GFLOPs: 389.7392
2024-04-28 03:22:05 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #896: GFLOPs: 75.0664. Time: 2989.4932 us. Best GFLOPs: 389.7392
2024-04-28 03:52:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 03:52:47 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 03:52:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:52:50 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 03:53:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:53:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:53:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:53:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 03:53:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8092  0.7584  0.5820  0.5746  0.5721  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718
[17 : 32]:	0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718  0.5718
[33 : 48]:	0.5718  0.5718  0.5718  0.5548  0.5548  0.5548  0.5539  0.5486  0.5382  0.5382  0.5355  0.5355  0.5355  0.5355  0.5355  0.5325
[49 : 64]:	0.5325  0.5325  0.5325  0.5325  0.5310  0.5310  0.5310  0.5310  0.5310  0.5213  0.5171  0.5171  0.5171  0.5171  0.5171  0.5171
2024-04-28 03:53:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 03:53:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #897: GFLOPs: 96.2670. Time: 2331.1244 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #898: GFLOPs: 86.8932. Time: 2582.5985 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #899: GFLOPs: 261.9556. Time: 856.6731 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #900: GFLOPs: 166.0683. Time: 1351.3134 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #901: GFLOPs: 214.8547. Time: 1044.4752 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #902: GFLOPs: 195.8377. Time: 1145.8994 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #903: GFLOPs: 195.6807. Time: 1146.8191 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #904: GFLOPs: 198.7322. Time: 1129.2100 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #905: GFLOPs: 369.3736. Time: 607.5431 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #906: GFLOPs: 238.2998. Time: 941.7145 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #907: GFLOPs: 239.8590. Time: 935.5928 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #908: GFLOPs: 175.1571. Time: 1281.1952 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #909: GFLOPs: 214.4443. Time: 1046.4737 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #910: GFLOPs: 200.4521. Time: 1119.5211 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #911: GFLOPs: 198.5893. Time: 1130.0226 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #912: GFLOPs: 237.0007. Time: 946.8764 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #913: GFLOPs: 192.0761. Time: 1168.3406 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #914: GFLOPs: 144.4852. Time: 1553.1718 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #915: GFLOPs: 161.1289. Time: 1392.7380 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #916: GFLOPs: 168.4300. Time: 1332.3660 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #917: GFLOPs: 196.3865. Time: 1142.6978 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #918: GFLOPs: 157.1538. Time: 1427.9665 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #919: GFLOPs: 196.5174. Time: 1141.9363 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #920: GFLOPs: 154.7923. Time: 1449.7519 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #921: GFLOPs: 168.0719. Time: 1335.2048 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #922: GFLOPs: 176.0402. Time: 1274.7674 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #923: GFLOPs: 225.8802. Time: 993.4927 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #924: GFLOPs: 203.6477. Time: 1101.9538 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #925: GFLOPs: 201.4687. Time: 1113.8721 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #926: GFLOPs: 254.8070. Time: 880.7074 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #927: GFLOPs: 192.8256. Time: 1163.7994 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #928: GFLOPs: 143.3059. Time: 1565.9535 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #929: GFLOPs: 119.0689. Time: 1884.7094 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #930: GFLOPs: 209.6645. Time: 1070.3307 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #931: GFLOPs: 199.7205. Time: 1123.6220 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #932: GFLOPs: 223.7769. Time: 1002.8306 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #933: GFLOPs: 222.4780. Time: 1008.6856 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #934: GFLOPs: 182.7203. Time: 1228.1632 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #935: GFLOPs: 212.6210. Time: 1055.4477 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #936: GFLOPs: 199.8440. Time: 1122.9279 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #937: GFLOPs: 145.0589. Time: 1547.0296 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #938: GFLOPs: 166.4157. Time: 1348.4928 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #939: GFLOPs: 179.0204. Time: 1253.5461 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #940: GFLOPs: 262.3578. Time: 855.3601 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #941: GFLOPs: 190.9848. Time: 1175.0166 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #942: GFLOPs: 159.1856. Time: 1409.7401 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #943: GFLOPs: 174.1727. Time: 1288.4360 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #944: GFLOPs: 183.0765. Time: 1225.7734 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #945: GFLOPs: 208.0836. Time: 1078.4624 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #946: GFLOPs: 177.8503. Time: 1261.7934 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #947: GFLOPs: 179.5417. Time: 1249.9065 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #948: GFLOPs: 172.6659. Time: 1299.6798 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #949: GFLOPs: 162.7702. Time: 1378.6948 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #950: GFLOPs: 155.2868. Time: 1445.1347 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #951: GFLOPs: 158.3378. Time: 1417.2891 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #952: GFLOPs: 152.0286. Time: 1476.1062 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #953: GFLOPs: 185.6971. Time: 1208.4756 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #954: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(13), oh_2_init * T.int64(13) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(13), ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0 in range(T.int64(96)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(15), T.int64(15)):
                    for ax4_fused in T.vectorized(T.int64(2)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(48), ic_0 // T.int64(2) + ax1)
                            v_i2, v_i3 = T.axis.remap("SS", [ax2, ax3])
                            v_i4 = T.axis.spatial(T.int64(4), ic_0 % T.int64(2) * T.int64(2) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[12, 8, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b68)
l105 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111 = sch.get_loops(block=b69)
l112 = sch.fuse(l107, l108, l109, l110, l111, preserve_unit_iters=True)
l113, l114 = sch.split(loop=l112, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l113)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b115)
b133 = sch.decompose_reduction(block=b115, loop=l117)
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #955: GFLOPs: 213.8941. Time: 1049.1660 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #956: GFLOPs: 170.6934. Time: 1314.6982 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #957: GFLOPs: 179.4111. Time: 1250.8162 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #958: GFLOPs: 46.7588. Time: 4799.3198 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #959: GFLOPs: 42.9679. Time: 5222.7450 us. Best GFLOPs: 389.7392
2024-04-28 03:55:07 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #960: GFLOPs: 65.2001. Time: 3441.8730 us. Best GFLOPs: 389.7392
2024-04-28 04:00:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:00:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:00:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:00:08 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 04:00:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:00:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:00:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:00:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:00:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6740  0.6574  0.6574  0.6156  0.6156  0.6075  0.6075  0.5794  0.5703  0.5600  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589
[17 : 32]:	0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589  0.5589
[33 : 48]:	0.5589  0.5589  0.5463  0.5463  0.5463  0.5463  0.5463  0.5463  0.5463  0.5304  0.5284  0.5223  0.5204  0.5204  0.5169  0.5168
[49 : 64]:	0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156  0.5156
2024-04-28 04:00:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:00:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #961: GFLOPs: 109.8740. Time: 2042.4343 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #962: GFLOPs: 148.4459. Time: 1511.7313 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #963: GFLOPs: 106.9729. Time: 2097.8249 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #964: GFLOPs: 83.8264. Time: 2677.0840 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #965: GFLOPs: 83.8059. Time: 2677.7379 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #966: GFLOPs: 98.9135. Time: 2268.7544 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #967: GFLOPs: 98.8751. Time: 2269.6342 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #968: GFLOPs: 232.9920. Time: 963.1676 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #969: GFLOPs: 84.5206. Time: 2655.0962 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #970: GFLOPs: 258.4515. Time: 868.2881 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #971: GFLOPs: 199.6389. Time: 1124.0814 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #972: GFLOPs: 209.1646. Time: 1072.8887 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #973: GFLOPs: 200.2614. Time: 1120.5874 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #974: GFLOPs: 181.4827. Time: 1236.5384 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #975: GFLOPs: 154.3765. Time: 1453.6563 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #976: GFLOPs: 168.6109. Time: 1330.9361 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #977: GFLOPs: 168.6161. Time: 1330.8954 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #978: GFLOPs: 185.5297. Time: 1209.5660 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #979: GFLOPs: 245.6139. Time: 913.6713 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #980: GFLOPs: 161.0828. Time: 1393.1365 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #981: GFLOPs: 192.2762. Time: 1167.1247 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #982: GFLOPs: 172.3551. Time: 1302.0232 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #983: GFLOPs: 186.6976. Time: 1201.9995 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #984: GFLOPs: 196.0925. Time: 1144.4105 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #985: GFLOPs: 186.4540. Time: 1203.5693 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #986: GFLOPs: 148.1932. Time: 1514.3097 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #987: GFLOPs: 151.8903. Time: 1477.4500 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #988: GFLOPs: 239.9039. Time: 935.4177 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #989: GFLOPs: 241.9004. Time: 927.6973 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #990: GFLOPs: 148.6529. Time: 1509.6270 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #991: GFLOPs: 152.0214. Time: 1476.1759 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #992: GFLOPs: 193.5684. Time: 1159.3334 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #993: GFLOPs: 218.3385. Time: 1027.8094 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #994: GFLOPs: 204.8745. Time: 1095.3553 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #995: GFLOPs: 215.2015. Time: 1042.7916 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #996: GFLOPs: 241.9189. Time: 927.6266 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #997: GFLOPs: 186.9290. Time: 1200.5110 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #998: GFLOPs: 213.3625. Time: 1051.7798 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #999: GFLOPs: 173.6372. Time: 1292.4097 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1000: GFLOPs: 194.4087. Time: 1154.3226 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1001: GFLOPs: 241.7721. Time: 928.1895 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1002: GFLOPs: 182.3860. Time: 1230.4146 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1003: GFLOPs: 58.5358. Time: 3833.7283 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1004: GFLOPs: 147.9286. Time: 1517.0182 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1005: GFLOPs: 188.0244. Time: 1193.5176 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1006: GFLOPs: 150.7669. Time: 1488.4587 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1007: GFLOPs: 253.5617. Time: 885.0328 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1008: GFLOPs: 137.5956. Time: 1630.9417 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1009: GFLOPs: 248.3247. Time: 903.6975 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1010: GFLOPs: 139.3291. Time: 1610.6496 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1011: GFLOPs: 204.0333. Time: 1099.8712 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1012: GFLOPs: 182.8633. Time: 1227.2026 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1013: GFLOPs: 201.5965. Time: 1113.1660 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1014: GFLOPs: 210.6067. Time: 1065.5426 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1015: GFLOPs: 196.6888. Time: 1140.9412 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1016: GFLOPs: 120.6453. Time: 1860.0832 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1017: GFLOPs: 192.2339. Time: 1167.3817 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1018: GFLOPs: 200.0161. Time: 1121.9613 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1019: GFLOPs: 161.6171. Time: 1388.5310 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1020: GFLOPs: 176.8777. Time: 1268.7318 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1021: GFLOPs: 150.3095. Time: 1492.9891 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1022: GFLOPs: 11.9164. Time: 18832.1065 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1023: GFLOPs: 4.2806. Time: 52425.5650 us. Best GFLOPs: 389.7392
2024-04-28 04:02:18 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1024: GFLOPs: 42.0458. Time: 5337.2872 us. Best GFLOPs: 389.7392
2024-04-28 04:18:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:18:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:18:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 12 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:18:32 [INFO] [evolutionary_search.cc:723] Sampled 398 candidate(s)
2024-04-28 04:18:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:18:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:19:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:19:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:19:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5479  0.5467  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446
[17 : 32]:	0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5446  0.5444  0.5444  0.5444  0.5444  0.5444  0.5444  0.5444  0.5444
[33 : 48]:	0.5255  0.5240  0.5227  0.5178  0.5128  0.5128  0.5108  0.5104  0.5096  0.5096  0.5096  0.5096  0.5084  0.5084  0.5084  0.5084
[49 : 64]:	0.5084  0.5084  0.5084  0.5084  0.5084  0.5084  0.5072  0.5072  0.5072  0.5072  0.5072  0.5072  0.5072  0.5062  0.5062  0.5062
2024-04-28 04:19:16 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:19:16 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1025: GFLOPs: 105.2991. Time: 2131.1718 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1026: GFLOPs: 206.6783. Time: 1085.7954 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1027: GFLOPs: 253.6896. Time: 884.5863 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1028: GFLOPs: 240.0995. Time: 934.6555 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1029: GFLOPs: 171.1932. Time: 1310.8600 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1030: GFLOPs: 252.9348. Time: 887.2261 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1031: GFLOPs: 247.0081. Time: 908.5141 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1032: GFLOPs: 241.4674. Time: 929.3609 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1033: GFLOPs: 202.0787. Time: 1110.5097 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1034: GFLOPs: 214.8284. Time: 1044.6027 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1035: GFLOPs: 206.1411. Time: 1088.6248 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1036: GFLOPs: 217.9763. Time: 1029.5174 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1037: GFLOPs: 193.2732. Time: 1161.1047 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1038: GFLOPs: 70.8745. Time: 3166.3076 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1039: GFLOPs: 195.6476. Time: 1147.0131 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1040: GFLOPs: 219.5064. Time: 1022.3407 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1041: GFLOPs: 240.1831. Time: 934.3305 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1042: GFLOPs: 202.8966. Time: 1106.0333 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1043: GFLOPs: 196.3149. Time: 1143.1142 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1044: GFLOPs: 92.6296. Time: 2422.6640 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1045: GFLOPs: 196.6879. Time: 1140.9464 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1046: GFLOPs: 196.5955. Time: 1141.4825 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1047: GFLOPs: 121.7233. Time: 1843.6114 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1048: GFLOPs: 195.3466. Time: 1148.7802 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1049: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1050: GFLOPs: 169.3341. Time: 1325.2520 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1051: GFLOPs: 206.1020. Time: 1088.8315 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1052: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1053: GFLOPs: 194.7375. Time: 1152.3739 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1054: GFLOPs: 180.7999. Time: 1241.2084 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1055: GFLOPs: 191.6219. Time: 1171.1103 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1056: GFLOPs: 165.4295. Time: 1356.5317 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1057: GFLOPs: 249.3241. Time: 900.0747 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1058: GFLOPs: 191.7783. Time: 1170.1550 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1059: GFLOPs: 194.4341. Time: 1154.1719 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1060: GFLOPs: 180.9910. Time: 1239.8980 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1061: GFLOPs: 154.8333. Time: 1449.3676 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1062: GFLOPs: 184.0050. Time: 1219.5881 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1063: GFLOPs: 149.7611. Time: 1498.4554 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1064: GFLOPs: 138.9618. Time: 1614.9064 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1065: GFLOPs: 205.1911. Time: 1093.6655 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1066: GFLOPs: 183.0909. Time: 1225.6775 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1067: GFLOPs: 175.4123. Time: 1279.3305 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1068: GFLOPs: 223.4600. Time: 1004.2529 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1069: GFLOPs: 143.7340. Time: 1561.2897 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1070: GFLOPs: 161.3157. Time: 1391.1256 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1071: GFLOPs: 154.6744. Time: 1450.8563 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1072: GFLOPs: 188.5537. Time: 1190.1670 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1073: GFLOPs: 187.3514. Time: 1197.8046 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1074: GFLOPs: 168.4276. Time: 1332.3849 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1075: GFLOPs: 195.3365. Time: 1148.8398 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1076: GFLOPs: 150.1948. Time: 1494.1290 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1077: GFLOPs: 171.7194. Time: 1306.8435 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1078: GFLOPs: 160.3521. Time: 1399.4854 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1079: GFLOPs: 172.2283. Time: 1302.9817 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1080: GFLOPs: 187.4287. Time: 1197.3104 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1081: GFLOPs: 141.0044. Time: 1591.5133 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1082: GFLOPs: 150.7888. Time: 1488.2427 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1083: GFLOPs: 185.7011. Time: 1208.4490 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1084: GFLOPs: 87.5286. Time: 2563.8515 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1085: GFLOPs: 166.6172. Time: 1346.8622 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1086: GFLOPs: 48.2665. Time: 4649.4021 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1087: GFLOPs: 25.3336. Time: 8858.2139 us. Best GFLOPs: 389.7392
2024-04-28 04:20:47 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1088: GFLOPs: 13.1102. Time: 17117.2872 us. Best GFLOPs: 389.7392
2024-04-28 04:34:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:34:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:34:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:34:54 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 04:35:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:35:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:35:24 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:35:33 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:35:38 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5813  0.5813  0.5813  0.5759  0.5664  0.5664  0.5656  0.5440  0.5412  0.5412  0.5412  0.5412  0.5412  0.5412  0.5412  0.5412
[17 : 32]:	0.5412  0.5412  0.5398  0.5380  0.5351  0.5281  0.5281  0.5281  0.5281  0.5281  0.5281  0.5223  0.5156  0.5156  0.5113  0.5093
[33 : 48]:	0.5093  0.5047  0.5047  0.5045  0.5045  0.5045  0.5042  0.5042  0.5042  0.5042  0.5042  0.5042  0.5042  0.5042  0.5042  0.5042
[49 : 64]:	0.5042  0.5012  0.4937  0.4937  0.4910  0.4910  0.4902  0.4902  0.4900  0.4900  0.4887  0.4887  0.4874  0.4848  0.4848  0.4848
2024-04-28 04:35:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:35:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1089: GFLOPs: 130.0377. Time: 1725.7333 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1090: GFLOPs: 78.1580. Time: 2871.2417 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1091: GFLOPs: 80.1170. Time: 2801.0348 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1092: GFLOPs: 193.1204. Time: 1162.0232 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1093: GFLOPs: 226.1214. Time: 992.4331 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1094: GFLOPs: 199.0526. Time: 1127.3924 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1095: GFLOPs: 277.2843. Time: 809.3151 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1096: GFLOPs: 185.7096. Time: 1208.3938 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1097: GFLOPs: 192.4896. Time: 1165.8312 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1098: GFLOPs: 188.0191. Time: 1193.5508 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1099: GFLOPs: 192.5414. Time: 1165.5176 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1100: GFLOPs: 196.3488. Time: 1142.9171 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1101: GFLOPs: 175.0392. Time: 1282.0575 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1102: GFLOPs: 171.0400. Time: 1312.0348 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1103: GFLOPs: 163.3834. Time: 1373.5197 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1104: GFLOPs: 197.5527. Time: 1135.9521 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1105: GFLOPs: 127.8484. Time: 1755.2849 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1106: GFLOPs: 196.0747. Time: 1144.5148 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1107: GFLOPs: 199.6400. Time: 1124.0754 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1108: GFLOPs: 268.3846. Time: 836.1523 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1109: GFLOPs: 123.8640. Time: 1811.7475 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1110: GFLOPs: 182.2910. Time: 1231.0557 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1111: GFLOPs: 205.4991. Time: 1092.0262 us. Best GFLOPs: 389.7392
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1112: GFLOPs: 397.5131. Time: 564.5358 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1113: GFLOPs: 208.6817. Time: 1075.3716 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1114: GFLOPs: 227.6341. Time: 985.8382 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1115: GFLOPs: 250.0752. Time: 897.3716 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1116: GFLOPs: 253.1105. Time: 886.6103 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1117: GFLOPs: 238.2242. Time: 942.0133 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1118: GFLOPs: 237.9582. Time: 943.0661 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1119: GFLOPs: 132.1546. Time: 1698.0891 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1120: GFLOPs: 170.7886. Time: 1313.9655 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1121: GFLOPs: 113.5850. Time: 1975.7046 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1122: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(96)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(15), T.int64(15)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(48), ic_0 // T.int64(2) + ax1)
                                v_i2, v_i3 = T.axis.remap("SS", [ax2, ax3])
                                v_i4 = T.axis.spatial(T.int64(4), ic_0 % T.int64(2) * T.int64(2) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                                v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[96, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b68)
l113 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l113)
l114 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l114)
sch.annotate(block_or_loop=l113, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l113, ann_key="pragma_unroll_explicit", ann_val=1)
l115, l116, l117, l118, l119 = sch.get_loops(block=b69)
l120 = sch.fuse(l115, l116, l117, l118, l119, preserve_unit_iters=True)
l121, l122 = sch.split(loop=l120, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l121)
sch.vectorize(loop=l122)
b123 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148 = sch.get_loops(block=b123)
b149 = sch.decompose_reduction(block=b123, loop=l133)
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1123: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0 in range(T.int64(96)):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(15), T.int64(15)):
                        for ax4_fused in T.vectorized(T.int64(2)):
                            with T.block("data_pad"):
                                v_i0 = T.axis.spatial(T.int64(1), ax0)
                                v_i1 = T.axis.spatial(T.int64(48), ic_0 // T.int64(2) + ax1)
                                v_i2, v_i3 = T.axis.remap("SS", [ax2, ax3])
                                v_i4 = T.axis.spatial(T.int64(4), ic_0 % T.int64(2) * T.int64(2) + ax4_fused)
                                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                                v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 24, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=10)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b67)
l86 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87 = sch.fuse(l85, preserve_unit_iters=True)
sch.vectorize(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b68)
l108 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114 = sch.get_loops(block=b69)
l115 = sch.fuse(l110, l111, l112, l113, l114, preserve_unit_iters=True)
l116, l117 = sch.split(loop=l115, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l116)
sch.vectorize(loop=l117)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b118)
b139 = sch.decompose_reduction(block=b118, loop=l123)
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1124: GFLOPs: 192.6050. Time: 1165.1328 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1125: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1126: GFLOPs: 172.7100. Time: 1299.3478 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1127: GFLOPs: 217.9819. Time: 1029.4908 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1128: GFLOPs: 316.1193. Time: 709.8914 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1129: GFLOPs: 243.9660. Time: 919.8429 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1130: GFLOPs: 221.7057. Time: 1012.1992 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1131: GFLOPs: 182.9984. Time: 1226.2972 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1132: GFLOPs: 226.4471. Time: 991.0057 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1133: GFLOPs: 222.3877. Time: 1009.0952 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1134: GFLOPs: 186.9922. Time: 1200.1054 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1135: GFLOPs: 156.1076. Time: 1437.5366 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1136: GFLOPs: 160.8174. Time: 1395.4358 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1137: GFLOPs: 194.9058. Time: 1151.3784 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1138: GFLOPs: 194.0210. Time: 1156.6290 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1139: GFLOPs: 66.7142. Time: 3363.7562 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1140: GFLOPs: 242.5532. Time: 925.2005 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1141: GFLOPs: 195.1764. Time: 1149.7826 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1142: GFLOPs: 154.7213. Time: 1450.4164 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1143: GFLOPs: 201.1079. Time: 1115.8706 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1144: GFLOPs: 174.4143. Time: 1286.6515 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1145: GFLOPs: 190.8556. Time: 1175.8126 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1146: GFLOPs: 180.7830. Time: 1241.3248 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1147: GFLOPs: 200.4528. Time: 1119.5170 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1148: GFLOPs: 243.3256. Time: 922.2638 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1149: GFLOPs: 95.4699. Time: 2350.5877 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1150: GFLOPs: 33.9549. Time: 6609.0711 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1151: GFLOPs: 138.9722. Time: 1614.7860 us. Best GFLOPs: 397.5131
2024-04-28 04:37:10 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1152: GFLOPs: 120.9810. Time: 1854.9219 us. Best GFLOPs: 397.5131
2024-04-28 04:49:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:49:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:49:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 14 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:49:36 [INFO] [evolutionary_search.cc:723] Sampled 396 candidate(s)
2024-04-28 04:49:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:49:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:50:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:50:15 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:50:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6285  0.5803  0.5803  0.5591  0.5591  0.5549  0.5549  0.5439  0.5439  0.5327  0.5246  0.5184  0.5140  0.5121  0.5062  0.5017
[17 : 32]:	0.5017  0.5017  0.5005  0.5004  0.5004  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000  0.5000
[33 : 48]:	0.4985  0.4974  0.4974  0.4974  0.4974  0.4943  0.4941  0.4940  0.4939  0.4939  0.4939  0.4918  0.4918  0.4905  0.4891  0.4891
[49 : 64]:	0.4891  0.4858  0.4831  0.4830  0.4830  0.4830  0.4830  0.4830  0.4811  0.4811  0.4811  0.4811  0.4811  0.4811  0.4811  0.4778
2024-04-28 04:50:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:50:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1153: GFLOPs: 132.9764. Time: 1687.5957 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1154: GFLOPs: 201.4756. Time: 1113.8342 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1155: GFLOPs: 108.9656. Time: 2059.4603 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1156: GFLOPs: 249.2535. Time: 900.3297 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1157: GFLOPs: 249.1367. Time: 900.7520 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1158: GFLOPs: 104.6523. Time: 2144.3424 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1159: GFLOPs: 104.7012. Time: 2143.3405 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1160: GFLOPs: 221.5282. Time: 1013.0104 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1161: GFLOPs: 192.1003. Time: 1168.1936 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1162: GFLOPs: 68.8777. Time: 3258.1003 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1163: GFLOPs: 224.1039. Time: 1001.3675 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1164: GFLOPs: 193.6322. Time: 1158.9517 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1165: GFLOPs: 218.6098. Time: 1026.5337 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1166: GFLOPs: 71.4021. Time: 3142.9078 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1167: GFLOPs: 187.6543. Time: 1195.8709 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1168: GFLOPs: 203.1637. Time: 1104.5790 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1169: GFLOPs: 195.9852. Time: 1145.0371 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1170: GFLOPs: 175.0124. Time: 1282.2540 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1171: GFLOPs: 184.0156. Time: 1219.5185 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1172: GFLOPs: 204.0494. Time: 1099.7843 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1173: GFLOPs: 204.2109. Time: 1098.9146 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1174: GFLOPs: 206.8961. Time: 1084.6524 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1175: GFLOPs: 171.0494. Time: 1311.9625 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1176: GFLOPs: 195.3734. Time: 1148.6227 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1177: GFLOPs: 137.4641. Time: 1632.5013 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1178: GFLOPs: 137.0071. Time: 1637.9471 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1179: GFLOPs: 160.4294. Time: 1398.8106 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1180: GFLOPs: 194.9612. Time: 1151.0513 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1181: GFLOPs: 182.6922. Time: 1228.3520 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1182: GFLOPs: 192.0498. Time: 1168.5012 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1183: GFLOPs: 158.8144. Time: 1413.0352 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1184: GFLOPs: 188.3387. Time: 1191.5257 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1185: GFLOPs: 289.5614. Time: 775.0011 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1186: GFLOPs: 101.3988. Time: 2213.1459 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1187: GFLOPs: 249.5463. Time: 899.2735 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1188: GFLOPs: 92.7609. Time: 2419.2350 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1189: GFLOPs: 212.8441. Time: 1054.3416 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1190: GFLOPs: 207.4681. Time: 1081.6619 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1191: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(96), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[6, 8, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l80, l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1192: GFLOPs: 187.9491. Time: 1193.9955 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1193: GFLOPs: 196.6431. Time: 1141.2064 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1194: GFLOPs: 148.0836. Time: 1515.4305 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1195: GFLOPs: 170.1488. Time: 1318.9064 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1196: GFLOPs: 238.3724. Time: 941.4278 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1197: GFLOPs: 175.4238. Time: 1279.2469 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1198: GFLOPs: 161.2422. Time: 1391.7595 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1199: GFLOPs: 120.7984. Time: 1857.7268 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1200: GFLOPs: 113.5666. Time: 1976.0238 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1201: GFLOPs: 131.7746. Time: 1702.9859 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1202: GFLOPs: 220.0211. Time: 1019.9495 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1203: GFLOPs: 87.9563. Time: 2551.3856 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1204: GFLOPs: 179.2963. Time: 1251.6174 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1205: GFLOPs: 154.7216. Time: 1450.4143 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1206: GFLOPs: 193.4541. Time: 1160.0187 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1207: GFLOPs: 182.0833. Time: 1232.4601 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1208: GFLOPs: 214.9552. Time: 1043.9869 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1209: GFLOPs: 169.5775. Time: 1323.3503 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1210: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1211: GFLOPs: 201.6412. Time: 1112.9195 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1212: GFLOPs: 179.8320. Time: 1247.8890 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1213: GFLOPs: 201.7035. Time: 1112.5754 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1214: GFLOPs: 16.0689. Time: 13965.4778 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1215: GFLOPs: 78.5244. Time: 2857.8412 us. Best GFLOPs: 397.5131
2024-04-28 04:51:58 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1216: GFLOPs: 41.7869. Time: 5370.3583 us. Best GFLOPs: 397.5131
2024-04-28 04:57:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 04:57:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 04:57:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:57:15 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 04:57:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:57:34 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:57:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:57:54 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 04:57:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7436  0.7154  0.7154  0.7154  0.6843  0.6843  0.6603  0.6476  0.5658  0.5602  0.5537  0.5521  0.5436  0.5436  0.5425  0.5425
[17 : 32]:	0.5425  0.5425  0.5413  0.5413  0.5387  0.5379  0.5379  0.5379  0.5370  0.5369  0.5369  0.5334  0.5281  0.5281  0.5281  0.5271
[33 : 48]:	0.5271  0.5266  0.5197  0.5197  0.5187  0.5187  0.5187  0.5136  0.5136  0.5062  0.5035  0.4985  0.4984  0.4982  0.4959  0.4959
[49 : 64]:	0.4959  0.4927  0.4888  0.4886  0.4885  0.4866  0.4866  0.4861  0.4861  0.4861  0.4827  0.4825  0.4817  0.4797  0.4797  0.4797
2024-04-28 04:57:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 04:58:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1217: GFLOPs: 404.8210. Time: 554.3446 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1218: GFLOPs: 231.9012. Time: 967.6983 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1219: GFLOPs: 111.2620. Time: 2016.9535 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1220: GFLOPs: 139.8896. Time: 1604.1960 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1221: GFLOPs: 195.3325. Time: 1148.8632 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1222: GFLOPs: 389.0967. Time: 576.7470 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1223: GFLOPs: 90.7293. Time: 2473.4050 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1224: GFLOPs: 128.1474. Time: 1751.1897 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1225: GFLOPs: 136.4893. Time: 1644.1606 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1226: GFLOPs: 112.1622. Time: 2000.7662 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1227: GFLOPs: 176.0798. Time: 1274.4809 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1228: GFLOPs: 93.4780. Time: 2400.6760 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1229: GFLOPs: 201.6064. Time: 1113.1116 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1230: GFLOPs: 189.6646. Time: 1183.1958 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1231: GFLOPs: 197.3765. Time: 1136.9660 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1232: GFLOPs: 173.4312. Time: 1293.9446 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1233: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1234: GFLOPs: 214.7944. Time: 1044.7682 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1235: GFLOPs: 56.5983. Time: 3964.9660 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1236: GFLOPs: 216.6092. Time: 1036.0148 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1237: GFLOPs: 119.2878. Time: 1881.2523 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1238: GFLOPs: 109.8580. Time: 2042.7308 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1239: GFLOPs: 120.3871. Time: 1864.0739 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1240: GFLOPs: 109.0413. Time: 2058.0305 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1241: GFLOPs: 133.4413. Time: 1681.7156 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1242: GFLOPs: 82.7357. Time: 2712.3758 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1243: GFLOPs: 109.5418. Time: 2048.6285 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1244: GFLOPs: 391.1143. Time: 573.7718 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1245: GFLOPs: 187.3376. Time: 1197.8926 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1246: GFLOPs: 254.6628. Time: 881.2059 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1247: GFLOPs: 246.6510. Time: 909.8296 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1248: GFLOPs: 37.5808. Time: 5971.4122 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1249: GFLOPs: 152.2642. Time: 1473.8225 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1250: GFLOPs: 215.8683. Time: 1039.5710 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1251: GFLOPs: 207.6007. Time: 1080.9712 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1252: GFLOPs: 207.0889. Time: 1083.6426 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1253: GFLOPs: 245.3563. Time: 914.6306 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1254: GFLOPs: 176.5428. Time: 1271.1383 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1255: GFLOPs: 199.9092. Time: 1122.5617 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1256: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(96), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1257: GFLOPs: 153.6345. Time: 1460.6767 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1258: GFLOPs: 167.7802. Time: 1337.5262 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1259: GFLOPs: 145.0095. Time: 1547.5566 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1260: GFLOPs: 179.8785. Time: 1247.5662 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1261: GFLOPs: 185.6424. Time: 1208.8311 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1262: GFLOPs: 168.3292. Time: 1333.1634 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1263: GFLOPs: 180.3961. Time: 1243.9870 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1264: GFLOPs: 188.2458. Time: 1192.1132 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1265: GFLOPs: 171.3806. Time: 1309.4267 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1266: GFLOPs: 54.4329. Time: 4122.6950 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1267: GFLOPs: 172.3163. Time: 1302.3167 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1268: GFLOPs: 253.4558. Time: 885.4025 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1269: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(96), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[96, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1270: GFLOPs: 92.7849. Time: 2418.6095 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1271: GFLOPs: 93.0006. Time: 2412.9979 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1272: GFLOPs: 228.7992. Time: 980.8180 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1273: GFLOPs: 105.0542. Time: 2136.1396 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1274: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(48), T.int64(15)):
                for ax3_ax4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76 = sch.get_loops(block=b67)
l77 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78 = sch.fuse(l75, l76, preserve_unit_iters=True)
sch.vectorize(loop=l78)
l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l79, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b114)
b140 = sch.decompose_reduction(block=b114, loop=l124)
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1275: GFLOPs: 141.7545. Time: 1583.0911 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1276: GFLOPs: 182.3650. Time: 1230.5562 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1277: GFLOPs: 114.2382. Time: 1964.4077 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1278: GFLOPs: 16.4011. Time: 13682.5997 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1279: GFLOPs: 35.5839. Time: 6306.5055 us. Best GFLOPs: 404.8210
2024-04-28 04:59:36 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1280: GFLOPs: 65.0628. Time: 3449.1340 us. Best GFLOPs: 404.8210
2024-04-28 05:14:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 05:14:51 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 05:14:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:14:55 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 05:15:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:15:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:15:24 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:15:33 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:15:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9330  0.9330  0.9330  0.9330  0.8233  0.7604  0.7316  0.7316  0.7316  0.7316  0.7316  0.7316  0.7278  0.6988  0.6974  0.6969
[17 : 32]:	0.6781  0.6781  0.6781  0.6539  0.6373  0.6373  0.6339  0.6339  0.5981  0.5961  0.5961  0.5961  0.5836  0.5832  0.5796  0.5796
[33 : 48]:	0.5793  0.5714  0.5713  0.5684  0.5643  0.5643  0.5609  0.5536  0.5501  0.5401  0.5320  0.5308  0.5308  0.5288  0.5239  0.5204
[49 : 64]:	0.5202  0.5202  0.5183  0.5183  0.5183  0.5143  0.5143  0.5095  0.5088  0.5088  0.5088  0.5082  0.5053  0.4977  0.4973  0.4969
2024-04-28 05:15:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 05:15:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1281: GFLOPs: 258.4275. Time: 868.3689 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1282: GFLOPs: 260.9978. Time: 859.8172 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1283: GFLOPs: 160.7700. Time: 1395.8472 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1284: GFLOPs: 100.6621. Time: 2229.3426 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1285: GFLOPs: 252.2474. Time: 889.6441 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1286: GFLOPs: 146.7411. Time: 1529.2945 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1287: GFLOPs: 375.0096. Time: 598.4123 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1288: GFLOPs: 246.5841. Time: 910.0764 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1289: GFLOPs: 220.4049. Time: 1018.1732 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1290: GFLOPs: 245.1206. Time: 915.5099 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1291: GFLOPs: 222.5168. Time: 1008.5097 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1292: GFLOPs: 186.1580. Time: 1205.4836 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1293: GFLOPs: 158.6012. Time: 1414.9350 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1294: GFLOPs: 184.7912. Time: 1214.3999 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1295: GFLOPs: 197.3612. Time: 1137.0541 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1296: GFLOPs: 239.3478. Time: 937.5913 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1297: GFLOPs: 191.3539. Time: 1172.7504 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1298: GFLOPs: 211.2583. Time: 1062.2557 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1299: GFLOPs: 262.3423. Time: 855.4106 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1300: GFLOPs: 123.7893. Time: 1812.8412 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1301: GFLOPs: 159.9699. Time: 1402.8283 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1302: GFLOPs: 197.4483. Time: 1136.5527 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1303: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1304: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1305: GFLOPs: 165.1263. Time: 1359.0224 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1306: GFLOPs: 227.8049. Time: 985.0991 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1307: GFLOPs: 228.1646. Time: 983.5460 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1308: GFLOPs: 80.8760. Time: 2774.7465 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1309: GFLOPs: 193.7058. Time: 1158.5113 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1310: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1311: GFLOPs: 197.3668. Time: 1137.0218 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1312: GFLOPs: 206.8875. Time: 1084.6977 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1313: GFLOPs: 42.4894. Time: 5281.5571 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1314: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1315: GFLOPs: 79.3210. Time: 2829.1411 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1316: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1317: GFLOPs: 111.3451. Time: 2015.4488 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1318: GFLOPs: 163.6067. Time: 1371.6451 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1319: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(3), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(32) + oc_chunk_1 * T.int64(32) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(32) + oc_chunk_1 * T.int64(32) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[3, 1, 32, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1320: GFLOPs: 82.2158. Time: 2729.5301 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1321: GFLOPs: 201.2376. Time: 1115.1513 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1322: GFLOPs: 277.9522. Time: 807.3702 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1323: GFLOPs: 234.0033. Time: 959.0052 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1324: GFLOPs: 245.9704. Time: 912.3471 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1325: GFLOPs: 249.6489. Time: 898.9038 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1326: GFLOPs: 230.4122. Time: 973.9518 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1327: GFLOPs: 81.0779. Time: 2767.8351 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1328: GFLOPs: 97.5218. Time: 2301.1307 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1329: GFLOPs: 74.9006. Time: 2996.1097 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1330: GFLOPs: 74.9000. Time: 2996.1324 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1331: GFLOPs: 118.3012. Time: 1896.9413 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1332: GFLOPs: 116.5851. Time: 1924.8628 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1333: GFLOPs: 118.3359. Time: 1896.3845 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1334: GFLOPs: 136.3116. Time: 1646.3045 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1335: GFLOPs: 128.4122. Time: 1747.5787 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1336: GFLOPs: 89.2256. Time: 2515.0902 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1337: GFLOPs: 208.5734. Time: 1075.9299 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1338: GFLOPs: 211.2427. Time: 1062.3345 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1339: GFLOPs: 172.6952. Time: 1299.4589 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1340: GFLOPs: 124.7538. Time: 1798.8259 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1341: GFLOPs: 107.4384. Time: 2088.7344 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1342: GFLOPs: 0.9201. Time: 243909.1610 us. Best GFLOPs: 404.8210
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1343: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(12), T.int64(13), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused * T.int64(12) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(13), oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(13), ow_2_init * T.int64(13) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(4), oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(4), T.int64(3)):
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(12), T.int64(13)):
                    for ax3_ax4_fused in T.vectorized(T.int64(60)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(48), ic_0 * T.int64(12) + ax1)
                            v_i2 = T.axis.spatial(T.int64(15), kh_0 + ax2)
                            v_i3 = T.axis.spatial(T.int64(15), ax3_ax4_fused // T.int64(4))
                            v_i4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(3), T.int64(1), T.int64(12), T.int64(13), T.int64(1), T.int64(2), T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused * T.int64(12) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(48) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
            for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(12), T.int64(13)):
                for ax3_ax4_fused in T.vectorized(T.int64(52)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused * T.int64(12) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(13), ax2)
                        v_ax3 = T.axis.spatial(T.int64(13), ax3_ax4_fused // T.int64(4))
                        v_ax4 = T.axis.spatial(T.int64(4), ax3_ax4_fused % T.int64(4))
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[4, 2, 12, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 2, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 48])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b68)
l88 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l86, l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l113, l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-28 05:17:12 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1344: GFLOPs: 59.8985. Time: 3746.5114 us. Best GFLOPs: 404.8210
2024-04-28 05:40:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 05:41:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 05:41:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:41:04 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 05:41:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:41:23 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:41:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:41:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:41:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7022  0.7022  0.7022  0.7022  0.7022  0.7022  0.7022  0.7022  0.6184  0.6184  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099
[17 : 32]:	0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6099  0.6061  0.5705  0.5684
[33 : 48]:	0.5684  0.5674  0.5565  0.5512  0.5498  0.5498  0.5469  0.5466  0.5464  0.5439  0.5367  0.5335  0.5335  0.5298  0.5298  0.5290
[49 : 64]:	0.5278  0.5266  0.5253  0.5232  0.5232  0.5232  0.5232  0.5232  0.5232  0.5214  0.5214  0.5214  0.5212  0.5212  0.5183  0.5179
2024-04-28 05:41:49 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 05:41:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1345: GFLOPs: 264.8289. Time: 847.3787 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1346: GFLOPs: 387.3107. Time: 579.4065 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1347: GFLOPs: 255.1310. Time: 879.5889 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1348: GFLOPs: 250.3845. Time: 896.2631 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1349: GFLOPs: 164.2199. Time: 1366.5232 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1350: GFLOPs: 192.0601. Time: 1168.4382 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1351: GFLOPs: 220.2930. Time: 1018.6906 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1352: GFLOPs: 241.1279. Time: 930.6696 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1353: GFLOPs: 243.1154. Time: 923.0612 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1354: GFLOPs: 402.4921. Time: 557.5522 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1355: GFLOPs: 227.8553. Time: 984.8810 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1356: GFLOPs: 228.8459. Time: 980.6178 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1357: GFLOPs: 223.2641. Time: 1005.1340 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1358: GFLOPs: 190.5284. Time: 1177.8315 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1359: GFLOPs: 163.6677. Time: 1371.1345 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1360: GFLOPs: 227.7626. Time: 985.2818 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1361: GFLOPs: 197.4576. Time: 1136.4991 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1362: GFLOPs: 217.5036. Time: 1031.7548 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1363: GFLOPs: 221.1726. Time: 1014.6391 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1364: GFLOPs: 177.0308. Time: 1267.6344 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1365: GFLOPs: 246.1320. Time: 911.7481 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1366: GFLOPs: 161.0759. Time: 1393.1967 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1367: GFLOPs: 221.0985. Time: 1014.9793 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1368: GFLOPs: 256.8433. Time: 873.7247 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1369: GFLOPs: 208.1138. Time: 1078.3062 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1370: GFLOPs: 182.1063. Time: 1232.3046 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1371: GFLOPs: 212.7754. Time: 1054.6817 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1372: GFLOPs: 216.5299. Time: 1036.3943 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1373: GFLOPs: 198.3478. Time: 1131.3983 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1374: GFLOPs: 193.0948. Time: 1162.1769 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1375: GFLOPs: 111.0195. Time: 2021.3603 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1376: GFLOPs: 238.0723. Time: 942.6145 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1377: GFLOPs: 209.7244. Time: 1070.0252 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1378: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1379: GFLOPs: 238.8156. Time: 939.6806 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1380: GFLOPs: 181.5122. Time: 1236.3375 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1381: GFLOPs: 188.1702. Time: 1192.5923 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1382: GFLOPs: 210.0271. Time: 1068.4829 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1383: GFLOPs: 131.0961. Time: 1711.8003 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1384: GFLOPs: 206.6018. Time: 1086.1977 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1385: GFLOPs: 113.2624. Time: 1981.3313 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1386: GFLOPs: 187.5655. Time: 1196.4376 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1387: GFLOPs: 103.0900. Time: 2176.8387 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1388: GFLOPs: 171.3583. Time: 1309.5972 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1389: GFLOPs: 138.4252. Time: 1621.1672 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1390: GFLOPs: 174.2683. Time: 1287.7294 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1391: GFLOPs: 146.6622. Time: 1530.1173 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1392: GFLOPs: 97.7560. Time: 2295.6169 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1393: GFLOPs: 137.0326. Time: 1637.6419 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1394: GFLOPs: 172.7764. Time: 1298.8482 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1395: GFLOPs: 209.9039. Time: 1069.1102 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1396: GFLOPs: 111.2348. Time: 2017.4471 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1397: GFLOPs: 234.9357. Time: 955.1992 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1398: GFLOPs: 137.8149. Time: 1628.3462 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1399: GFLOPs: 237.5121. Time: 944.8375 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1400: GFLOPs: 135.7802. Time: 1652.7479 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1401: GFLOPs: 100.2080. Time: 2239.4462 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1402: GFLOPs: 196.6284. Time: 1141.2919 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1403: GFLOPs: 195.7648. Time: 1146.3267 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1404: GFLOPs: 112.1885. Time: 2000.2968 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1405: GFLOPs: 97.9081. Time: 2292.0501 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1406: GFLOPs: 73.2569. Time: 3063.3326 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1407: GFLOPs: 62.2699. Time: 3603.8316 us. Best GFLOPs: 404.8210
2024-04-28 05:43:22 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1408: GFLOPs: 16.1887. Time: 13862.1569 us. Best GFLOPs: 404.8210
2024-04-28 05:50:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 05:50:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 05:50:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 5 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:50:34 [INFO] [evolutionary_search.cc:723] Sampled 405 candidate(s)
2024-04-28 05:50:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:50:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:51:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:51:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 05:51:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6708  0.6708  0.6708  0.6708  0.6708  0.6655  0.6041  0.6041  0.6041  0.6041  0.6041  0.5974  0.5974  0.5925  0.5925  0.5752
[17 : 32]:	0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752
[33 : 48]:	0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5752  0.5673  0.5638  0.5589  0.5543  0.5543  0.5543  0.5543  0.5543
[49 : 64]:	0.5543  0.5520  0.5520  0.5449  0.5449  0.5430  0.5427  0.5389  0.5380  0.5380  0.5380  0.5380  0.5380  0.5380  0.5380  0.5380
2024-04-28 05:51:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 05:51:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1409: GFLOPs: 258.8608. Time: 866.9152 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1410: GFLOPs: 196.6969. Time: 1140.8941 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1411: GFLOPs: 204.0849. Time: 1099.5930 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1412: GFLOPs: 235.2672. Time: 953.8532 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1413: GFLOPs: 247.6630. Time: 906.1117 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1414: GFLOPs: 153.4716. Time: 1462.2274 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1415: GFLOPs: 210.8406. Time: 1064.3601 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1416: GFLOPs: 155.1510. Time: 1446.4000 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1417: GFLOPs: 200.7652. Time: 1117.7751 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1418: GFLOPs: 238.7363. Time: 939.9927 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1419: GFLOPs: 177.1609. Time: 1266.7038 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1420: GFLOPs: 114.5468. Time: 1959.1155 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1421: GFLOPs: 127.7431. Time: 1756.7321 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1422: GFLOPs: 247.0527. Time: 908.3501 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1423: GFLOPs: 199.3069. Time: 1125.9541 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1424: GFLOPs: 193.1624. Time: 1161.7706 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1425: GFLOPs: 211.4439. Time: 1061.3237 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1426: GFLOPs: 191.2188. Time: 1173.5792 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1427: GFLOPs: 202.6420. Time: 1107.4227 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1428: GFLOPs: 211.3829. Time: 1061.6296 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1429: GFLOPs: 192.0667. Time: 1168.3978 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1430: GFLOPs: 194.6276. Time: 1153.0243 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1431: GFLOPs: 182.8758. Time: 1227.1187 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1432: GFLOPs: 181.9558. Time: 1233.3238 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1433: GFLOPs: 174.9585. Time: 1282.6488 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1434: GFLOPs: 194.4357. Time: 1154.1623 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1435: GFLOPs: 216.3199. Time: 1037.4005 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1436: GFLOPs: 182.9821. Time: 1226.4060 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1437: GFLOPs: 200.9643. Time: 1116.6678 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1438: GFLOPs: 194.6027. Time: 1153.1722 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1439: GFLOPs: 206.9793. Time: 1084.2163 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1440: GFLOPs: 216.1039. Time: 1038.4375 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1441: GFLOPs: 124.6872. Time: 1799.7866 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1442: GFLOPs: 201.4724. Time: 1113.8518 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1443: GFLOPs: 175.6666. Time: 1277.4790 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1444: GFLOPs: 220.9238. Time: 1015.7816 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1445: GFLOPs: 213.6938. Time: 1050.1491 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1446: GFLOPs: 192.5821. Time: 1165.2713 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1447: GFLOPs: 183.2272. Time: 1224.7656 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1448: GFLOPs: 197.2024. Time: 1137.9696 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1449: GFLOPs: 200.2026. Time: 1120.9166 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1450: GFLOPs: 269.1739. Time: 833.7002 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1451: GFLOPs: 140.8201. Time: 1593.5964 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1452: GFLOPs: 190.4321. Time: 1178.4269 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1453: GFLOPs: 173.4497. Time: 1293.8063 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1454: GFLOPs: 216.8686. Time: 1034.7759 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1455: GFLOPs: 210.1213. Time: 1068.0038 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1456: GFLOPs: 110.6263. Time: 2028.5453 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1457: GFLOPs: 121.6107. Time: 1845.3174 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1458: GFLOPs: 234.7998. Time: 955.7518 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1459: GFLOPs: 119.2998. Time: 1881.0617 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1460: GFLOPs: 188.0745. Time: 1193.1992 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1461: GFLOPs: 217.1752. Time: 1033.3148 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1462: GFLOPs: 112.5747. Time: 1993.4350 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1463: GFLOPs: 203.5334. Time: 1102.5725 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1464: GFLOPs: 176.2599. Time: 1273.1787 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1465: GFLOPs: 176.7575. Time: 1269.5943 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1466: GFLOPs: 162.4159. Time: 1381.7018 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1467: GFLOPs: 238.9375. Time: 939.2013 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1468: GFLOPs: 240.7661. Time: 932.0679 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1469: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1470: GFLOPs: 4.7361. Time: 47382.9597 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1471: GFLOPs: 0.6786. Time: 330706.6827 us. Best GFLOPs: 404.8210
2024-04-28 05:53:01 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1472: GFLOPs: 27.9484. Time: 8029.4524 us. Best GFLOPs: 404.8210
2024-04-28 06:20:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 06:20:02 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 06:20:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 15 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:20:06 [INFO] [evolutionary_search.cc:723] Sampled 395 candidate(s)
2024-04-28 06:20:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:20:25 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:20:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:20:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:20:50 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6332  0.6307  0.6307  0.5697  0.5655  0.5655  0.5563  0.5563  0.5512  0.5512  0.5512  0.5512  0.5512  0.5512  0.5512  0.5369
[17 : 32]:	0.5369  0.5369  0.5321  0.5321  0.5321  0.5321  0.5321  0.5321  0.5321  0.5304  0.5296  0.5296  0.5264  0.5220  0.5207  0.5207
[33 : 48]:	0.5207  0.5204  0.5198  0.5198  0.5198  0.5198  0.5159  0.5159  0.5112  0.5112  0.5112  0.5112  0.5112  0.5112  0.5112  0.5079
[49 : 64]:	0.5072  0.5070  0.5067  0.5050  0.5032  0.5032  0.4997  0.4997  0.4997  0.4980  0.4965  0.4927  0.4925  0.4925  0.4904  0.4904
2024-04-28 06:20:50 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 06:20:50 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1473: GFLOPs: 210.3045. Time: 1067.0735 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1474: GFLOPs: 184.6526. Time: 1215.3112 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1475: GFLOPs: 171.6656. Time: 1307.2526 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1476: GFLOPs: 209.8896. Time: 1069.1827 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1477: GFLOPs: 194.2326. Time: 1155.3691 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1478: GFLOPs: 184.7276. Time: 1214.8176 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1479: GFLOPs: 238.8497. Time: 939.5465 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1480: GFLOPs: 244.1019. Time: 919.3308 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1481: GFLOPs: 219.7726. Time: 1021.1025 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1482: GFLOPs: 228.0560. Time: 984.0142 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1483: GFLOPs: 242.4660. Time: 925.5333 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1484: GFLOPs: 230.8693. Time: 972.0233 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1485: GFLOPs: 242.7000. Time: 924.6408 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1486: GFLOPs: 264.2238. Time: 849.3193 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1487: GFLOPs: 116.7403. Time: 1922.3042 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1488: GFLOPs: 399.9884. Time: 561.0422 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1489: GFLOPs: 198.8543. Time: 1128.5163 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1490: GFLOPs: 198.2768. Time: 1131.8032 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1491: GFLOPs: 237.6324. Time: 944.3593 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1492: GFLOPs: 176.1901. Time: 1273.6831 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1493: GFLOPs: 257.6956. Time: 870.8349 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1494: GFLOPs: 169.1865. Time: 1326.4080 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1495: GFLOPs: 193.9991. Time: 1156.7597 us. Best GFLOPs: 404.8210
2024-04-28 06:22:30 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1496: GFLOPs: 196.7951. Time: 1140.3250 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1497: GFLOPs: 208.8401. Time: 1074.5560 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1498: GFLOPs: 205.0123. Time: 1094.6190 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1499: GFLOPs: 169.5052. Time: 1323.9140 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1500: GFLOPs: 165.1775. Time: 1358.6011 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1501: GFLOPs: 193.0992. Time: 1162.1506 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1502: GFLOPs: 254.2403. Time: 882.6705 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1503: GFLOPs: 98.8459. Time: 2270.3044 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1504: GFLOPs: 129.1263. Time: 1737.9141 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1505: GFLOPs: 163.3320. Time: 1373.9523 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1506: GFLOPs: 171.5617. Time: 1308.0444 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1507: GFLOPs: 91.7064. Time: 2447.0512 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1508: GFLOPs: 140.9406. Time: 1592.2339 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1509: GFLOPs: 138.1437. Time: 1624.4709 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1510: GFLOPs: 191.3806. Time: 1172.5869 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1511: GFLOPs: 150.6691. Time: 1489.4251 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1512: GFLOPs: 150.5663. Time: 1490.4420 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1513: GFLOPs: 238.1478. Time: 942.3155 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1514: GFLOPs: 240.8894. Time: 931.5908 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1515: GFLOPs: 240.8730. Time: 931.6542 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1516: GFLOPs: 194.2613. Time: 1155.1983 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1517: GFLOPs: 235.4623. Time: 953.0630 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1518: GFLOPs: 214.4675. Time: 1046.3609 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1519: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1520: GFLOPs: 215.8702. Time: 1039.5618 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1521: GFLOPs: 168.0595. Time: 1335.3029 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1522: GFLOPs: 35.1950. Time: 6376.2036 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1523: GFLOPs: 208.9139. Time: 1074.1762 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1524: GFLOPs: 72.5924. Time: 3091.3769 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1525: GFLOPs: 144.6554. Time: 1551.3441 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1526: GFLOPs: 183.5405. Time: 1222.6748 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1527: GFLOPs: 121.1697. Time: 1852.0332 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1528: GFLOPs: 219.6879. Time: 1021.4964 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1529: GFLOPs: 202.9532. Time: 1105.7248 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1530: GFLOPs: 208.9930. Time: 1073.7700 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1531: GFLOPs: 165.1455. Time: 1358.8644 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1532: GFLOPs: 180.1698. Time: 1245.5494 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1533: GFLOPs: 160.8349. Time: 1395.2845 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1534: GFLOPs: 34.5267. Time: 6499.6113 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1535: GFLOPs: 34.1693. Time: 6567.6031 us. Best GFLOPs: 404.8210
2024-04-28 06:22:31 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1536: GFLOPs: 21.9771. Time: 10211.1029 us. Best GFLOPs: 404.8210
2024-04-28 06:37:49 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 06:37:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 06:37:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 7 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:37:54 [INFO] [evolutionary_search.cc:723] Sampled 403 candidate(s)
2024-04-28 06:38:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:38:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:38:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:38:32 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:38:38 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6181  0.5885  0.5803  0.5696  0.5696  0.5696  0.5517  0.5492  0.5305  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280  0.5280
[17 : 32]:	0.5280  0.5280  0.5187  0.5160  0.5160  0.5160  0.5160  0.5086  0.5081  0.4995  0.4995  0.4995  0.4978  0.4956  0.4956  0.4956
[33 : 48]:	0.4956  0.4956  0.4922  0.4907  0.4907  0.4907  0.4907  0.4893  0.4893  0.4886  0.4886  0.4886  0.4876  0.4853  0.4853  0.4853
[49 : 64]:	0.4853  0.4853  0.4853  0.4853  0.4793  0.4793  0.4793  0.4790  0.4778  0.4746  0.4746  0.4718  0.4710  0.4710  0.4710  0.4704
2024-04-28 06:38:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 06:38:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1537: GFLOPs: 202.3273. Time: 1109.1450 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1538: GFLOPs: 208.3061. Time: 1077.3105 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1539: GFLOPs: 160.7751. Time: 1395.8028 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1540: GFLOPs: 169.0292. Time: 1327.6427 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1541: GFLOPs: 211.9515. Time: 1058.7817 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1542: GFLOPs: 212.1833. Time: 1057.6253 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1543: GFLOPs: 260.1091. Time: 862.7547 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1544: GFLOPs: 197.7406. Time: 1134.8726 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1545: GFLOPs: 138.9152. Time: 1615.4486 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1546: GFLOPs: 93.4261. Time: 2402.0090 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1547: GFLOPs: 118.7072. Time: 1890.4524 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1548: GFLOPs: 125.7470. Time: 1784.6174 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1549: GFLOPs: 150.3799. Time: 1492.2901 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1550: GFLOPs: 137.9111. Time: 1627.2101 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1551: GFLOPs: 201.9934. Time: 1110.9789 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1552: GFLOPs: 232.3279. Time: 965.9208 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1553: GFLOPs: 233.9965. Time: 959.0332 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1554: GFLOPs: 223.5515. Time: 1003.8421 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1555: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1556: GFLOPs: 147.2875. Time: 1523.6213 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1557: GFLOPs: 222.5874. Time: 1008.1898 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1558: GFLOPs: 241.3838. Time: 929.6827 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1559: GFLOPs: 205.4262. Time: 1092.4137 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1560: GFLOPs: 183.8726. Time: 1220.4669 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1561: GFLOPs: 201.6848. Time: 1112.6788 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1562: GFLOPs: 322.8529. Time: 695.0855 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1563: GFLOPs: 201.8434. Time: 1111.8042 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1564: GFLOPs: 205.9849. Time: 1089.4504 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1565: GFLOPs: 96.4406. Time: 2326.9294 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1566: GFLOPs: 161.1894. Time: 1392.2155 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1567: GFLOPs: 211.7007. Time: 1060.0358 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1568: GFLOPs: 166.0013. Time: 1351.8587 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1569: GFLOPs: 186.6022. Time: 1202.6139 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1570: GFLOPs: 189.5118. Time: 1184.1497 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1571: GFLOPs: 211.8521. Time: 1059.2785 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1572: GFLOPs: 206.6714. Time: 1085.8319 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1573: GFLOPs: 256.0037. Time: 876.5904 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1574: GFLOPs: 210.5067. Time: 1066.0488 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1575: GFLOPs: 190.9415. Time: 1175.2835 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1576: GFLOPs: 246.4681. Time: 910.5046 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1577: GFLOPs: 249.3749. Time: 899.8914 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1578: GFLOPs: 160.7050. Time: 1396.4121 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1579: GFLOPs: 160.0094. Time: 1402.4824 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1580: GFLOPs: 202.9858. Time: 1105.5470 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1581: GFLOPs: 156.8427. Time: 1430.7992 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1582: GFLOPs: 165.4104. Time: 1356.6884 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1583: GFLOPs: 186.1337. Time: 1205.6410 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1584: GFLOPs: 158.7896. Time: 1413.2565 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1585: GFLOPs: 163.4173. Time: 1373.2348 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1586: GFLOPs: 201.4826. Time: 1113.7955 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1587: GFLOPs: 246.8675. Time: 909.0316 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1588: GFLOPs: 211.4395. Time: 1061.3453 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1589: GFLOPs: 132.6242. Time: 1692.0773 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1590: GFLOPs: 184.5593. Time: 1215.9253 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1591: GFLOPs: 209.4782. Time: 1071.2827 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1592: GFLOPs: 152.4318. Time: 1472.2020 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1593: GFLOPs: 46.3552. Time: 4841.1006 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1594: GFLOPs: 203.6361. Time: 1102.0165 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1595: GFLOPs: 149.5434. Time: 1500.6367 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1596: GFLOPs: 180.2872. Time: 1244.7381 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1597: GFLOPs: 201.7070. Time: 1112.5559 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1598: GFLOPs: 8.1037. Time: 27692.3150 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1599: GFLOPs: 18.4886. Time: 12137.7926 us. Best GFLOPs: 404.8210
2024-04-28 06:40:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1600: GFLOPs: 41.1989. Time: 5447.0007 us. Best GFLOPs: 404.8210
2024-04-28 06:47:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 06:47:52 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 06:47:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 10 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:47:56 [INFO] [evolutionary_search.cc:723] Sampled 400 candidate(s)
2024-04-28 06:48:06 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:48:15 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:48:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:48:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 06:48:40 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.5634  0.5634  0.5634  0.5634  0.5496  0.5356  0.5252  0.5252  0.5231  0.5231  0.5231  0.5231  0.5231  0.5231  0.5231  0.5231
[17 : 32]:	0.5231  0.5231  0.5231  0.5231  0.5231  0.5231  0.5231  0.5231  0.5136  0.5085  0.5042  0.5028  0.5028  0.4991  0.4991  0.4980
[33 : 48]:	0.4972  0.4895  0.4895  0.4895  0.4895  0.4888  0.4888  0.4880  0.4874  0.4874  0.4874  0.4874  0.4874  0.4859  0.4855  0.4855
[49 : 64]:	0.4842  0.4835  0.4830  0.4795  0.4795  0.4795  0.4788  0.4767  0.4766  0.4765  0.4762  0.4762  0.4760  0.4751  0.4750  0.4750
2024-04-28 06:48:40 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 06:48:40 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1601: GFLOPs: 100.0661. Time: 2242.6214 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1602: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(13), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 48, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, l79, l80, l81, l82, l83, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b113)
b134 = sch.decompose_reduction(block=b113, loop=l118)
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1603: GFLOPs: 240.2257. Time: 934.1649 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1604: GFLOPs: 221.2370. Time: 1014.3439 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1605: GFLOPs: 192.4431. Time: 1166.1129 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1606: GFLOPs: 109.7359. Time: 2045.0034 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1607: GFLOPs: 200.3845. Time: 1119.8986 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1608: GFLOPs: 173.2770. Time: 1295.0960 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1609: GFLOPs: 163.8993. Time: 1369.1969 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1610: GFLOPs: 242.4508. Time: 925.5914 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1611: GFLOPs: 220.1171. Time: 1019.5047 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1612: GFLOPs: 244.1605. Time: 919.1102 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1613: GFLOPs: 201.8471. Time: 1111.7837 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1614: GFLOPs: 183.7783. Time: 1221.0930 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1615: GFLOPs: 196.9625. Time: 1139.3557 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1616: GFLOPs: 183.0812. Time: 1225.7424 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1617: GFLOPs: 205.3695. Time: 1092.7152 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1618: GFLOPs: 193.1580. Time: 1161.7968 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1619: GFLOPs: 198.3407. Time: 1131.4391 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1620: GFLOPs: 207.6288. Time: 1080.8248 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1621: GFLOPs: 182.1669. Time: 1231.8946 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1622: GFLOPs: 220.4015. Time: 1018.1890 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1623: GFLOPs: 197.4154. Time: 1136.7422 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1624: GFLOPs: 216.2901. Time: 1037.5436 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1625: GFLOPs: 227.3774. Time: 986.9510 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1626: GFLOPs: 180.6288. Time: 1242.3845 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1627: GFLOPs: 156.1775. Time: 1436.8927 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1628: GFLOPs: 237.0305. Time: 946.7574 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1629: GFLOPs: 149.5524. Time: 1500.5471 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1630: GFLOPs: 64.0388. Time: 3504.2877 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1631: GFLOPs: 82.9892. Time: 2704.0924 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1632: GFLOPs: 245.6371. Time: 913.5849 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1633: GFLOPs: 404.3844. Time: 554.9432 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1634: GFLOPs: 244.9872. Time: 916.0084 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1635: GFLOPs: 175.5298. Time: 1278.4742 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1636: GFLOPs: 214.7764. Time: 1044.8559 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1637: GFLOPs: 245.1690. Time: 915.3292 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1638: GFLOPs: 101.4573. Time: 2211.8709 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1639: GFLOPs: 132.7000. Time: 1691.1109 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1640: GFLOPs: 190.9916. Time: 1174.9750 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1641: GFLOPs: 222.7432. Time: 1007.4845 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1642: GFLOPs: 219.5387. Time: 1022.1907 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1643: GFLOPs: 166.2810. Time: 1349.5853 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1644: GFLOPs: 240.7167. Time: 932.2592 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1645: GFLOPs: 177.3403. Time: 1265.4221 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1646: GFLOPs: 192.7590. Time: 1164.2020 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1647: GFLOPs: 217.5852. Time: 1031.3679 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1648: GFLOPs: 216.1704. Time: 1038.1180 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1649: GFLOPs: 143.2180. Time: 1566.9149 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1650: GFLOPs: 171.4315. Time: 1309.0381 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1651: GFLOPs: 169.0836. Time: 1327.2157 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1652: GFLOPs: 193.7668. Time: 1158.1468 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1653: GFLOPs: 199.8842. Time: 1122.7020 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1654: GFLOPs: 137.2039. Time: 1635.5973 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1655: GFLOPs: 199.7810. Time: 1123.2819 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1656: GFLOPs: 92.8887. Time: 2415.9072 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1657: GFLOPs: 136.2820. Time: 1646.6614 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1658: GFLOPs: 189.1820. Time: 1186.2140 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1659: GFLOPs: 224.2543. Time: 1000.6959 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1660: GFLOPs: 183.6857. Time: 1221.7083 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1661: GFLOPs: 218.5449. Time: 1026.8386 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1662: GFLOPs: 5.4568. Time: 41125.1540 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1663: GFLOPs: 75.0058. Time: 2991.9049 us. Best GFLOPs: 404.8210
2024-04-28 06:50:17 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1664: GFLOPs: 71.8884. Time: 3121.6471 us. Best GFLOPs: 404.8210
2024-04-28 07:12:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:12:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 07:12:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 16 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:12:18 [INFO] [evolutionary_search.cc:723] Sampled 394 candidate(s)
2024-04-28 07:12:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:12:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:12:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:12:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:13:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6186  0.6186  0.5619  0.5619  0.5619  0.5614  0.5531  0.5531  0.5508  0.5508  0.5479  0.5414  0.5353  0.5353  0.5341  0.5286
[17 : 32]:	0.5240  0.5240  0.5240  0.5240  0.5240  0.5190  0.5136  0.5100  0.5068  0.5048  0.5048  0.5037  0.5010  0.5010  0.5002  0.5002
[33 : 48]:	0.5002  0.4988  0.4966  0.4960  0.4960  0.4960  0.4960  0.4960  0.4960  0.4960  0.4960  0.4921  0.4921  0.4921  0.4919  0.4911
[49 : 64]:	0.4870  0.4864  0.4864  0.4857  0.4840  0.4826  0.4826  0.4821  0.4800  0.4800  0.4800  0.4800  0.4800  0.4800  0.4798  0.4798
2024-04-28 07:13:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:13:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1665: GFLOPs: 156.8601. Time: 1430.6400 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1666: GFLOPs: 133.6022. Time: 1679.6908 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1667: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(3) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[64, 3])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1668: GFLOPs: 141.4800. Time: 1586.1630 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1669: GFLOPs: 229.9348. Time: 975.9740 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1670: GFLOPs: 185.3758. Time: 1210.5698 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1671: GFLOPs: 187.3959. Time: 1197.5203 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1672: GFLOPs: 189.1838. Time: 1186.2029 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1673: GFLOPs: 127.0993. Time: 1765.6301 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1674: GFLOPs: 171.9540. Time: 1305.0602 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1675: GFLOPs: 174.5409. Time: 1285.7176 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1676: GFLOPs: 232.7897. Time: 964.0047 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1677: GFLOPs: 196.2384. Time: 1143.5599 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1678: GFLOPs: 245.1195. Time: 915.5142 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1679: GFLOPs: 241.9830. Time: 927.3806 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1680: GFLOPs: 70.7770. Time: 3170.6664 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1681: GFLOPs: 138.6420. Time: 1618.6317 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1682: GFLOPs: 200.7249. Time: 1117.9997 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1683: GFLOPs: 199.6013. Time: 1124.2932 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1684: GFLOPs: 212.2132. Time: 1057.4762 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1685: GFLOPs: 199.2804. Time: 1126.1035 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1686: GFLOPs: 181.2788. Time: 1237.9294 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1687: GFLOPs: 146.5419. Time: 1531.3736 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1688: GFLOPs: 168.6527. Time: 1330.6062 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1689: GFLOPs: 143.8432. Time: 1560.1039 us. Best GFLOPs: 404.8210
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1690: GFLOPs: 422.4359. Time: 531.2294 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1691: GFLOPs: 196.9006. Time: 1139.7139 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1692: GFLOPs: 259.5016. Time: 864.7743 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1693: GFLOPs: 255.7955. Time: 877.3037 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1694: GFLOPs: 165.0973. Time: 1359.2616 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1695: GFLOPs: 251.5479. Time: 892.1178 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1696: GFLOPs: 184.6188. Time: 1215.5335 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1697: GFLOPs: 215.2706. Time: 1042.4570 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1698: GFLOPs: 230.3293. Time: 974.3025 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1699: GFLOPs: 173.3047. Time: 1294.8891 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1700: GFLOPs: 149.6766. Time: 1499.3019 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1701: GFLOPs: 92.6032. Time: 2423.3545 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1702: GFLOPs: 182.9613. Time: 1226.5452 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1703: GFLOPs: 231.9720. Time: 967.4030 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1704: GFLOPs: 216.7685. Time: 1035.2537 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1705: GFLOPs: 115.4630. Time: 1943.5689 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1706: GFLOPs: 244.1287. Time: 919.2297 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1707: GFLOPs: 202.1010. Time: 1110.3871 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1708: GFLOPs: 198.9476. Time: 1127.9874 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1709: GFLOPs: 166.8204. Time: 1345.2217 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1710: GFLOPs: 190.9471. Time: 1175.2492 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1711: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(96), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[96, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1712: GFLOPs: 214.8813. Time: 1044.3460 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1713: GFLOPs: 208.7348. Time: 1075.0981 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1714: GFLOPs: 158.7937. Time: 1413.2194 us. Best GFLOPs: 422.4359
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1715: GFLOPs: 433.8092. Time: 517.3020 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1716: GFLOPs: 221.9434. Time: 1011.1151 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1717: GFLOPs: 180.5283. Time: 1243.0757 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1718: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1719: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(48), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(13), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[48, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1720: GFLOPs: 255.2464. Time: 879.1911 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1721: GFLOPs: 241.9773. Time: 927.4025 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1722: GFLOPs: 194.4404. Time: 1154.1346 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1723: GFLOPs: 200.6500. Time: 1118.4171 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1724: GFLOPs: 183.1215. Time: 1225.4723 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1725: GFLOPs: 169.2662. Time: 1325.7840 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1726: GFLOPs: 42.7655. Time: 5247.4567 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1727: GFLOPs: 43.5950. Time: 5147.6155 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1728: GFLOPs: 5.5655. Time: 40321.9310 us. Best GFLOPs: 433.8092
2024-04-28 07:14:43 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:14:44 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 07:14:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 9 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:14:48 [INFO] [evolutionary_search.cc:723] Sampled 401 candidate(s)
2024-04-28 07:14:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:15:07 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:15:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:15:27 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 2 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:15:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.6306  0.6306  0.5939  0.5501  0.5420  0.5271  0.5271  0.5271  0.5226  0.5220  0.5219  0.5219  0.5219  0.5149  0.5135  0.5135
[17 : 32]:	0.5135  0.5135  0.5109  0.5081  0.5076  0.4965  0.4888  0.4888  0.4871  0.4867  0.4867  0.4867  0.4867  0.4807  0.4807  0.4800
[33 : 48]:	0.4798  0.4798  0.4798  0.4739  0.4686  0.4667  0.4660  0.4635  0.4635  0.4635  0.4635  0.4635  0.4625  0.4621  0.4621  0.4621
[49 : 64]:	0.4613  0.4613  0.4613  0.4613  0.4613  0.4613  0.4613  0.4608  0.4599  0.4598  0.4598  0.4593  0.4578  0.4561  0.4551  0.4542
2024-04-28 07:15:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:15:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1729: GFLOPs: 242.0297. Time: 927.2018 us. Best GFLOPs: 433.8092
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1730: GFLOPs: 241.7532. Time: 928.2623 us. Best GFLOPs: 433.8092
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1731: GFLOPs: 166.4751. Time: 1348.0119 us. Best GFLOPs: 433.8092
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1732: GFLOPs: 159.0209. Time: 1411.2005 us. Best GFLOPs: 433.8092
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1733: GFLOPs: 438.8976. Time: 511.3047 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1734: GFLOPs: 151.5651. Time: 1480.6203 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1735: GFLOPs: 202.2372. Time: 1109.6394 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1736: GFLOPs: 254.9398. Time: 880.2483 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1737: GFLOPs: 217.0433. Time: 1033.9427 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1738: GFLOPs: 183.3645. Time: 1223.8486 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1739: GFLOPs: 243.4744. Time: 921.7002 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1740: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[13, 1, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1741: GFLOPs: 405.2820. Time: 553.7141 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1742: GFLOPs: 229.1882. Time: 979.1533 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1743: GFLOPs: 249.4908. Time: 899.4734 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1744: GFLOPs: 186.4216. Time: 1203.7788 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1745: GFLOPs: 188.9762. Time: 1187.5057 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1746: GFLOPs: 249.8792. Time: 898.0754 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1747: GFLOPs: 194.0952. Time: 1156.1869 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1748: GFLOPs: 185.0696. Time: 1212.5726 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1749: GFLOPs: 219.3471. Time: 1023.0835 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1750: GFLOPs: 196.7154. Time: 1140.7871 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1751: GFLOPs: 146.1655. Time: 1535.3175 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1752: GFLOPs: 154.7288. Time: 1450.3462 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1753: GFLOPs: 141.3710. Time: 1587.3866 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1754: GFLOPs: 187.6468. Time: 1195.9190 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1755: GFLOPs: 194.0715. Time: 1156.3284 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1756: GFLOPs: 170.5506. Time: 1315.7996 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1757: GFLOPs: 99.5686. Time: 2253.8265 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1758: GFLOPs: 182.4166. Time: 1230.2079 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1759: GFLOPs: 199.8036. Time: 1123.1548 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1760: GFLOPs: 180.7523. Time: 1241.5355 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1761: GFLOPs: 164.9371. Time: 1360.5812 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1762: GFLOPs: 122.6400. Time: 1829.8296 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1763: GFLOPs: 124.6677. Time: 1800.0682 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1764: GFLOPs: 215.0834. Time: 1043.3644 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1765: GFLOPs: 103.3895. Time: 2170.5332 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1766: GFLOPs: 147.0142. Time: 1526.4532 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1767: GFLOPs: 205.0810. Time: 1094.2524 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1768: GFLOPs: 182.0315. Time: 1232.8109 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1769: GFLOPs: 153.0894. Time: 1465.8784 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1770: GFLOPs: 155.7430. Time: 1440.9016 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1771: GFLOPs: 225.3702. Time: 995.7411 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1772: GFLOPs: 216.4308. Time: 1036.8691 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1773: GFLOPs: 197.4696. Time: 1136.4300 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1774: GFLOPs: 151.6234. Time: 1480.0513 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1775: GFLOPs: 193.7484. Time: 1158.2565 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1776: GFLOPs: 258.9715. Time: 866.5445 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1777: GFLOPs: 260.4204. Time: 861.7235 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1778: GFLOPs: 217.5159. Time: 1031.6966 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1779: GFLOPs: 189.9617. Time: 1181.3452 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1780: GFLOPs: 168.4019. Time: 1332.5885 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1781: GFLOPs: 201.2455. Time: 1115.1074 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1782: GFLOPs: 154.2300. Time: 1455.0369 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1783: GFLOPs: 197.4737. Time: 1136.4061 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1784: GFLOPs: 185.4133. Time: 1210.3254 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1785: GFLOPs: 127.8523. Time: 1755.2312 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1786: GFLOPs: 145.3141. Time: 1544.3124 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1787: GFLOPs: 151.3720. Time: 1482.5090 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1788: GFLOPs: 164.0832. Time: 1367.6621 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1789: GFLOPs: 139.6383. Time: 1607.0838 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1790: GFLOPs: 71.2067. Time: 3151.5325 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1791: GFLOPs: 105.2258. Time: 2132.6545 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1792: GFLOPs: 56.3329. Time: 3983.6434 us. Best GFLOPs: 438.8976
2024-04-28 07:17:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:17:16 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 07:17:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 11 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:17:20 [INFO] [evolutionary_search.cc:723] Sampled 399 candidate(s)
2024-04-28 07:17:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:17:39 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:17:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:17:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:18:03 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.8324  0.8324  0.8324  0.8324  0.8324  0.7793  0.7793  0.7793  0.7048  0.7048  0.6803  0.6667  0.6384  0.6362  0.6362  0.6313
[17 : 32]:	0.6313  0.5321  0.5321  0.5321  0.5321  0.5312  0.5197  0.5077  0.5077  0.4958  0.4944  0.4944  0.4944  0.4944  0.4944  0.4944
[33 : 48]:	0.4927  0.4850  0.4839  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4821  0.4807  0.4807
[49 : 64]:	0.4771  0.4725  0.4725  0.4725  0.4691  0.4633  0.4612  0.4600  0.4600  0.4600  0.4588  0.4588  0.4562  0.4544  0.4541  0.4539
2024-04-28 07:18:04 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:18:04 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1793: GFLOPs: 202.7879. Time: 1106.6262 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1794: GFLOPs: 135.0888. Time: 1661.2067 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1795: GFLOPs: 198.7834. Time: 1128.9189 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1796: GFLOPs: 161.1825. Time: 1392.2751 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1797: GFLOPs: 123.3711. Time: 1818.9871 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1798: GFLOPs: 221.4000. Time: 1013.5970 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1799: GFLOPs: 140.4098. Time: 1598.2530 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1800: GFLOPs: 409.6772. Time: 547.7736 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1801: GFLOPs: 91.7685. Time: 2445.3971 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1802: GFLOPs: 92.7872. Time: 2418.5482 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1803: GFLOPs: 173.8271. Time: 1290.9973 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1804: GFLOPs: 193.1482. Time: 1161.8557 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1805: GFLOPs: 187.6688. Time: 1195.7789 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1806: GFLOPs: 232.7124. Time: 964.3250 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1807: GFLOPs: 234.8930. Time: 955.3729 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1808: GFLOPs: 282.0537. Time: 795.6298 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1809: GFLOPs: 188.7413. Time: 1188.9838 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1810: GFLOPs: 189.4651. Time: 1184.4420 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1811: GFLOPs: 212.5788. Time: 1055.6574 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1812: GFLOPs: 214.5786. Time: 1045.8190 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1813: GFLOPs: 187.7594. Time: 1195.2017 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1814: GFLOPs: 241.1127. Time: 930.7281 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1815: GFLOPs: 195.5611. Time: 1147.5205 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1816: GFLOPs: 337.6272. Time: 664.6691 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1817: GFLOPs: 260.2112. Time: 862.4162 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1818: GFLOPs: 264.1594. Time: 849.5263 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1819: GFLOPs: 122.8008. Time: 1827.4337 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1820: GFLOPs: 122.8351. Time: 1826.9235 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1821: GFLOPs: 120.8248. Time: 1857.3206 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1822: GFLOPs: 100.8795. Time: 2224.5388 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1823: GFLOPs: 107.5635. Time: 2086.3054 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1824: GFLOPs: 63.8955. Time: 3512.1472 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1825: GFLOPs: 176.2849. Time: 1272.9982 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1826: GFLOPs: 224.3052. Time: 1000.4688 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1827: GFLOPs: 214.2278. Time: 1047.5316 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1828: GFLOPs: 152.4833. Time: 1471.7042 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1829: GFLOPs: 185.7958. Time: 1207.8336 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1830: GFLOPs: 202.5916. Time: 1107.6982 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1831: GFLOPs: 196.9697. Time: 1139.3139 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1832: GFLOPs: 202.3994. Time: 1108.7502 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1833: GFLOPs: 380.9755. Time: 589.0414 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1834: GFLOPs: 195.5812. Time: 1147.4023 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1835: GFLOPs: 224.3775. Time: 1000.1464 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1836: GFLOPs: 204.9644. Time: 1094.8749 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1837: GFLOPs: 238.6769. Time: 940.2266 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1838: GFLOPs: 374.6201. Time: 599.0346 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1839: GFLOPs: 209.2902. Time: 1072.2449 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1840: GFLOPs: 231.1727. Time: 970.7476 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1841: GFLOPs: 182.1526. Time: 1231.9912 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1842: GFLOPs: 27.1352. Time: 8270.0721 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1843: GFLOPs: 32.1884. Time: 6971.7864 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1844: GFLOPs: 27.1393. Time: 8268.8428 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1845: GFLOPs: 253.2371. Time: 886.1670 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1846: GFLOPs: 262.5379. Time: 854.7733 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1847: GFLOPs: 149.8480. Time: 1497.5866 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1848: GFLOPs: 193.9496. Time: 1157.0549 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1849: GFLOPs: 189.0342. Time: 1187.1413 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1850: GFLOPs: 182.5093. Time: 1229.5829 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1851: GFLOPs: 208.3704. Time: 1076.9781 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1852: GFLOPs: 179.6256. Time: 1249.3226 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1853: GFLOPs: 90.1387. Time: 2489.6130 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1854: GFLOPs: 23.4881. Time: 9554.2313 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1855: GFLOPs: 59.7768. Time: 3754.1361 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1856: GFLOPs: 4.8062. Time: 46691.4240 us. Best GFLOPs: 438.8976
2024-04-28 07:19:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 07:19:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 07:19:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 6 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:19:37 [INFO] [evolutionary_search.cc:723] Sampled 404 candidate(s)
2024-04-28 07:19:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:19:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 1 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:20:06 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:20:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31a9648)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x4b98708)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x35cbcd8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x35db6f8)]: 0 failure(s)
2024-04-28 07:20:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.7447  0.7358  0.7358  0.6216  0.5793  0.5793  0.5793  0.5793  0.5761  0.5713  0.5713  0.5528  0.5505  0.5362  0.5362  0.5333
[17 : 32]:	0.5333  0.5333  0.5302  0.5302  0.5302  0.5302  0.5118  0.5065  0.5054  0.5019  0.5014  0.4995  0.4995  0.4980  0.4979  0.4973
[33 : 48]:	0.4973  0.4944  0.4894  0.4894  0.4894  0.4892  0.4892  0.4780  0.4780  0.4742  0.4710  0.4708  0.4707  0.4707  0.4698  0.4698
[49 : 64]:	0.4698  0.4698  0.4663  0.4663  0.4614  0.4603  0.4602  0.4596  0.4584  0.4584  0.4584  0.4580  0.4576  0.4570  0.4570  0.4570
2024-04-28 07:20:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 07:20:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1857: GFLOPs: 97.0890. Time: 2311.3883 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1858: GFLOPs: 229.0558. Time: 979.7192 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1859: GFLOPs: 181.1236. Time: 1238.9900 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1860: GFLOPs: 212.4810. Time: 1056.1430 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1861: GFLOPs: 190.7246. Time: 1176.6198 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1862: GFLOPs: 189.7773. Time: 1182.4931 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1863: GFLOPs: 137.9192. Time: 1627.1147 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1864: GFLOPs: 139.1257. Time: 1613.0045 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1865: GFLOPs: 184.8020. Time: 1214.3286 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1866: GFLOPs: 75.1342. Time: 2986.7939 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1867: GFLOPs: 126.7328. Time: 1770.7357 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1868: GFLOPs: 126.7239. Time: 1770.8606 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1869: GFLOPs: 132.0426. Time: 1699.5299 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1870: GFLOPs: 155.2895. Time: 1445.1095 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1871: GFLOPs: 186.5333. Time: 1203.0579 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1872: GFLOPs: 172.4682. Time: 1301.1696 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1873: GFLOPs: 213.5017. Time: 1051.0940 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1874: GFLOPs: 207.9945. Time: 1078.9248 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1875: GFLOPs: 143.0439. Time: 1568.8219 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1876: GFLOPs: 168.5115. Time: 1331.7217 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1877: GFLOPs: 197.9411. Time: 1133.7228 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1878: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init * T.int64(13) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(6), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(13)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 * T.int64(13) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 * T.int64(6) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 13, 1, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 6])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1879: GFLOPs: 209.4251. Time: 1071.5541 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1880: GFLOPs: 138.7676. Time: 1617.1671 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1881: GFLOPs: 94.6584. Time: 2370.7381 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1882: GFLOPs: 83.7870. Time: 2678.3426 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1883: GFLOPs: 157.8801. Time: 1421.3971 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1884: GFLOPs: 196.8417. Time: 1140.0548 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1885: GFLOPs: 174.3817. Time: 1286.8920 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1886: GFLOPs: 136.7264. Time: 1641.3098 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1887: GFLOPs: 190.7396. Time: 1176.5274 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1888: GFLOPs: 182.3455. Time: 1230.6876 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1889: GFLOPs: 211.0664. Time: 1063.2215 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1890: GFLOPs: 202.2583. Time: 1109.5239 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1891: GFLOPs: 224.5212. Time: 999.5065 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1892: GFLOPs: 249.3386. Time: 900.0225 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1893: GFLOPs: 198.7009. Time: 1129.3877 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1894: GFLOPs: 172.2203. Time: 1303.0426 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1895: GFLOPs: 184.3263. Time: 1217.4622 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1896: GFLOPs: 158.4691. Time: 1416.1146 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1897: GFLOPs: 277.7191. Time: 808.0481 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1898: GFLOPs: 244.4985. Time: 917.8396 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1899: GFLOPs: 191.3661. Time: 1172.6759 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1900: GFLOPs: 203.5485. Time: 1102.4911 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1901: GFLOPs: 149.2708. Time: 1503.3771 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1902: GFLOPs: 185.3517. Time: 1210.7275 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1903: GFLOPs: 145.1427. Time: 1546.1361 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1904: GFLOPs: 206.4337. Time: 1087.0818 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1905: GFLOPs: 197.2866. Time: 1137.4842 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1906: GFLOPs: 196.7916. Time: 1140.3454 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1907: GFLOPs: 203.7552. Time: 1101.3726 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1908: GFLOPs: 251.5748. Time: 892.0226 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1909: GFLOPs: 211.8359. Time: 1059.3595 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1910: GFLOPs: 195.3608. Time: 1148.6971 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1911: GFLOPs: 162.8762. Time: 1377.7973 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1912: GFLOPs: 235.3070. Time: 953.6917 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1913: GFLOPs: 117.2746. Time: 1913.5460 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1914: GFLOPs: 240.0605. Time: 934.8076 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1915: GFLOPs: 214.0901. Time: 1048.2051 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1916: GFLOPs: 306.4844. Time: 732.2082 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:121] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1917: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32"), p1: T.Buffer((T.int64(96), T.int64(48), T.int64(3), T.int64(3), T.int64(4), T.int64(4)), "float32"), p2: T.Buffer((T.int64(1), T.int64(96), T.int64(1), T.int64(1), T.int64(4)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(15), T.int64(15), T.int64(4)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(96), T.int64(13), T.int64(13), T.int64(4)))
        for i0_i1_fused in T.parallel(T.int64(48)):
            for i2 in range(T.int64(15)):
                for i3_i4_fused in T.vectorized(T.int64(60)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1, v_i2 = T.axis.remap("SS", [i0_i1_fused, i2])
                        v_i3 = T.axis.spatial(T.int64(15), i3_i4_fused // T.int64(4))
                        v_i4 = T.axis.spatial(T.int64(4), i3_i4_fused % T.int64(4))
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(14) and T.int64(1) <= v_i3 and v_i3 < T.int64(14), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_fused in T.parallel(T.int64(48), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2_init * T.int64(13) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(192), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(13), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(96), n_0_oc_chunk_0_fused * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(13), oh_0 * T.int64(13) + oh_1 * T.int64(13) + oh_2 * T.int64(13) + oh_3)
                            v_ow = T.axis.spatial(T.int64(13), ow_0 * T.int64(13) + ow_1 * T.int64(13) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(4), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(192), ic_0 + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)], p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(4), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(4)] * p1[v_oc_chunk, v_ic // T.int64(4), v_kh, v_kw, v_ic % T.int64(4), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(1014)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(96), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(676))
                    v_ax2 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(676) // T.int64(52))
                    v_ax3 = T.axis.spatial(T.int64(13), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(52) // T.int64(4))
                    v_ax4 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(4))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[48, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 1, 13])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 13, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[192, 1])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=32)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74 = sch.get_loops(block=b67)
l75 = sch.fuse(l70, l71, preserve_unit_iters=True)
sch.parallel(loop=l75)
l76 = sch.fuse(l73, l74, preserve_unit_iters=True)
sch.vectorize(loop=l76)
l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102 = sch.get_loops(block=b68)
l103 = sch.fuse(l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l103)
l104 = sch.fuse(l102, preserve_unit_iters=True)
sch.vectorize(loop=l104)
sch.annotate(block_or_loop=l103, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l103, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b69)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b113)
b139 = sch.decompose_reduction(block=b113, loop=l123)
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1918: GFLOPs: 49.9310. Time: 4494.4089 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1919: GFLOPs: 52.6328. Time: 4263.6961 us. Best GFLOPs: 438.8976
2024-04-28 07:22:04 [INFO] [task_scheduler.cc:131] [Task #5: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_2] Trial #1920: GFLOPs: 1.5141. Time: 148211.7640 us. Best GFLOPs: 438.8976
