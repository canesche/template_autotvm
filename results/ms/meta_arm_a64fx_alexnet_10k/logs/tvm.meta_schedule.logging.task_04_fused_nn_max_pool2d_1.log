2024-04-27 23:39:13 [INFO] [task_scheduler.cc:160] Initializing Task #4: "fused_nn_max_pool2d_1"
2024-04-27 23:39:13 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(27), T.int64(27), T.int64(4)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3, ax4, rv0, rv1 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(3), T.int64(3)):
            with T.block("pool_max"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, v_rv0, v_rv1 = T.axis.remap("SSSSSRR", [ax0, ax1, ax2, ax3, ax4, rv0, rv1])
                T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
                T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.block_attr({"schedule_rule": "meta_schedule.pool_max"})
                with T.init():
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
2024-04-27 23:39:13 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-27 23:39:13 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(27), T.int64(27), T.int64(4)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            pool_max_rf = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(1)))
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(1), T.int64(9)):
                with T.block("pool_max_rf"):
                    vrv0_rv1_fused_0, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1 = T.axis.remap("SSSSSSR", [rv0_rv1_fused_0, ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_1])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) // T.int64(3), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) % T.int64(3), v_ax4])
                    T.writes(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
                    with T.init():
                        pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0] = T.float32(-3.4028234663852886e+38)
                    pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0] = T.max(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) // T.int64(3), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) % T.int64(3), v_ax4])
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(1)):
                with T.block("pool_max"):
                    vrv0_rv1_fused_0, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("RSSSSS", [rv0_rv1_fused_0, ax0, ax1, ax2, ax3, ax4])
                    T.reads(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.block_attr({"meta_schedule.random_compute_producer": 1})
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
l2, l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l7, l8, preserve_unit_iters=True)
v10, v11 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 9])
l12, l13 = sch.split(loop=l9, factors=[v10, v11], preserve_unit_iters=True)
b14 = sch.rfactor(loop=l12, factor_axis=5)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v15 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v15)
2024-04-27 23:39:13 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(27), T.int64(27), T.int64(4)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            pool_max_rf = T.alloc_buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(9)))
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(1), T.int64(9)):
                with T.block("pool_max_rf"):
                    vrv0_rv1_fused_1, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0 = T.axis.remap("SSSSSSR", [rv0_rv1_fused_1, ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) // T.int64(3), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) % T.int64(3), v_ax4])
                    T.writes(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
                    with T.init():
                        pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1] = T.float32(-3.4028234663852886e+38)
                    pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1] = T.max(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) // T.int64(3), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(9) + vrv0_rv1_fused_1) % T.int64(3), v_ax4])
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(9)):
                with T.block("pool_max"):
                    vrv0_rv1_fused_1, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("RSSSSS", [rv0_rv1_fused_1, ax0, ax1, ax2, ax3, ax4])
                    T.reads(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.block_attr({"meta_schedule.random_compute_producer": 1})
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
l2, l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l7, l8, preserve_unit_iters=True)
v10, v11 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 9])
l12, l13 = sch.split(loop=l9, factors=[v10, v11], preserve_unit_iters=True)
b14 = sch.rfactor(loop=l13, factor_axis=5)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v15 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v15)
2024-04-27 23:39:13 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(48), T.int64(27), T.int64(27), T.int64(4)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            for ax0, ax1, ax2, ax3, ax4, rv0, rv1 in T.grid(T.int64(1), T.int64(48), T.int64(13), T.int64(13), T.int64(4), T.int64(3), T.int64(3)):
                with T.block("pool_max"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, v_rv0, v_rv1 = T.axis.remap("SSSSSRR", [ax0, ax1, ax2, ax3, ax4, rv0, rv1])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
2024-04-27 23:44:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-27 23:44:53 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-27 23:44:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3543128)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x32309e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4b88c78)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x4bb1798)]: 0 failure(s)
2024-04-27 23:44:53 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-27 23:44:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3543128)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x32309e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4b88c78)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x4bb1798)]: 0 failure(s)
2024-04-27 23:44:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3543128)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x32309e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4b88c78)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x4bb1798)]: 0 failure(s)
2024-04-27 23:44:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3543128)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x32309e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4b88c78)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x4bb1798)]: 0 failure(s)
2024-04-27 23:44:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x3543128)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x32309e8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x4b88c78)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x4bb1798)]: 0 failure(s)
2024-04-27 23:44:59 [INFO] [evolutionary_search.cc:649] Scores of the best 60 candidates:
[1 : 16]:	0.9844  0.9383  0.9257  0.9072  0.9029  0.8769  0.8652  0.8446  0.8400  0.8242  0.7963  0.7857  0.7694  0.7395  0.7308  0.7107
[17 : 32]:	0.6836  0.6814  0.6748  0.6715  0.6513  0.6280  0.6234  0.5774  0.5539  0.5115  0.5039  0.4942  0.4737  0.4482  0.4371  0.4218
[33 : 48]:	0.4186  0.4144  0.4133  0.4093  0.3853  0.3519  0.3314  0.3038  0.3027  0.3014  0.2969  0.2705  0.2650  0.2066  0.2054  0.1945
[49 : 60]:	0.1813  0.1415  0.1257  0.1239  0.1018  0.1014  0.0973  0.0869  0.0583  0.0327  0.0322  0.0202
2024-04-27 23:44:59 [INFO] [evolutionary_search.cc:727] Got 60 candidate(s) with evolutionary search
2024-04-27 23:44:59 [INFO] [evolutionary_search.cc:730] Sending 60 candidates(s) for measurement
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #1: GFLOPs: 3.9669. Time: 73.6175 us. Best GFLOPs: 3.9669
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #2: GFLOPs: 9.3205. Time: 31.3322 us. Best GFLOPs: 9.3205
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #3: GFLOPs: 15.9143. Time: 18.3503 us. Best GFLOPs: 15.9143
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #4: GFLOPs: 21.5847. Time: 13.5296 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #5: GFLOPs: 10.1686. Time: 28.7189 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #6: GFLOPs: 5.0181. Time: 58.1952 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #7: GFLOPs: 10.0894. Time: 28.9443 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #8: GFLOPs: 5.9264. Time: 49.2765 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #9: GFLOPs: 9.2418. Time: 31.5991 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #10: GFLOPs: 7.2228. Time: 40.4317 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #11: GFLOPs: 8.9555. Time: 32.6093 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #12: GFLOPs: 11.9346. Time: 24.4693 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #13: GFLOPs: 7.6602. Time: 38.1231 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #14: GFLOPs: 12.0935. Time: 24.1478 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #15: GFLOPs: 12.0156. Time: 24.3045 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #16: GFLOPs: 10.0031. Time: 29.1940 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #17: GFLOPs: 7.9669. Time: 36.6554 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #18: GFLOPs: 16.6602. Time: 17.5287 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #19: GFLOPs: 7.6879. Time: 37.9858 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #20: GFLOPs: 5.7959. Time: 50.3860 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #21: GFLOPs: 5.9468. Time: 49.1077 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #22: GFLOPs: 9.2388. Time: 31.6094 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #23: GFLOPs: 8.4821. Time: 34.4293 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #24: GFLOPs: 5.9625. Time: 48.9781 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #25: GFLOPs: 4.9791. Time: 58.6521 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #26: GFLOPs: 8.5167. Time: 34.2894 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #27: GFLOPs: 6.8473. Time: 42.6493 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #28: GFLOPs: 8.9923. Time: 32.4759 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #29: GFLOPs: 9.1375. Time: 31.9599 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #30: GFLOPs: 6.1986. Time: 47.1125 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #31: GFLOPs: 7.9646. Time: 36.6661 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #32: GFLOPs: 3.5588. Time: 82.0602 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #33: GFLOPs: 8.3322. Time: 35.0486 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #34: GFLOPs: 7.0814. Time: 41.2396 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #35: GFLOPs: 11.5232. Time: 25.3430 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #36: GFLOPs: 7.9102. Time: 36.9186 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #37: GFLOPs: 10.6106. Time: 27.5227 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #38: GFLOPs: 11.3183. Time: 25.8017 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #39: GFLOPs: 7.7890. Time: 37.4931 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #40: GFLOPs: 9.7981. Time: 29.8050 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #41: GFLOPs: 14.8090. Time: 19.7199 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #42: GFLOPs: 7.8758. Time: 37.0798 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #43: GFLOPs: 6.0655. Time: 48.1463 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #44: GFLOPs: 5.9248. Time: 49.2895 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #45: GFLOPs: 14.7176. Time: 19.8423 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #46: GFLOPs: 9.9811. Time: 29.2584 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #47: GFLOPs: 9.1003. Time: 32.0902 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #48: GFLOPs: 20.0381. Time: 14.5739 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #49: GFLOPs: 7.8689. Time: 37.1122 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #50: GFLOPs: 7.7723. Time: 37.5735 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #51: GFLOPs: 5.4579. Time: 53.5066 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #52: GFLOPs: 14.0719. Time: 20.7529 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #53: GFLOPs: 5.5444. Time: 52.6719 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #54: GFLOPs: 7.7870. Time: 37.5024 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #55: GFLOPs: 9.1758. Time: 31.8263 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #56: GFLOPs: 8.7484. Time: 33.3811 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #57: GFLOPs: 7.8488. Time: 37.2070 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #58: GFLOPs: 2.4272. Time: 120.3167 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #59: GFLOPs: 9.6045. Time: 30.4058 us. Best GFLOPs: 21.5847
2024-04-28 00:09:56 [INFO] [task_scheduler.cc:131] [Task #4: fused_nn_max_pool2d_1] Trial #60: GFLOPs: 7.7926. Time: 37.4757 us. Best GFLOPs: 21.5847
