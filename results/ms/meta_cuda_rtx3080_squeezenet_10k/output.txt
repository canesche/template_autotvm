2024-03-23 01:28:29 [INFO] Logging directory: results/ms/meta_cuda_rtx3080_squeezenet_10k/logs
2024-03-23 01:28:34 [INFO] LocalBuilder: max_workers = 8
2024-03-23 01:28:34 [INFO] [task_scheduler.cc:159] Initializing Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 01:28:34 [INFO] [task_scheduler.cc:159] Initializing Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #5: "fused_nn_max_pool2d"
[01:28:35] /home/canesche/tvm-0.16.dev0/src/meta_schedule/schedule_rule/apply_custom_rule.cc:56: Warning: Unknown schedule rule "meta_schedule.pool_max" for target keys "["cuda", "gpu"]". Checked PackedFuncs:
  meta_schedule.cuda.meta_schedule.pool_max
  meta_schedule.gpu.meta_schedule.pool_max
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #9: "fused_concatenate"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #10: "fused_nn_max_pool2d_1"
[01:28:35] /home/canesche/tvm-0.16.dev0/src/meta_schedule/schedule_rule/apply_custom_rule.cc:56: Warning: Unknown schedule rule "meta_schedule.pool_max" for target keys "["cuda", "gpu"]". Checked PackedFuncs:
  meta_schedule.cuda.meta_schedule.pool_max
  meta_schedule.gpu.meta_schedule.pool_max
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #14: "fused_concatenate_1"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #15: "fused_nn_max_pool2d_2"
[01:28:35] /home/canesche/tvm-0.16.dev0/src/meta_schedule/schedule_rule/apply_custom_rule.cc:56: Warning: Unknown schedule rule "meta_schedule.pool_max" for target keys "["cuda", "gpu"]". Checked PackedFuncs:
  meta_schedule.cuda.meta_schedule.pool_max
  meta_schedule.gpu.meta_schedule.pool_max
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 01:28:35 [INFO] [task_scheduler.cc:159] Initializing Task #19: "fused_concatenate_2"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #23: "fused_concatenate_3"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #25: "fused_nn_global_avg_pool2d"
[01:28:36] /home/canesche/tvm-0.16.dev0/src/meta_schedule/schedule_rule/apply_custom_rule.cc:56: Warning: Unknown schedule rule "meta_schedule.adaptive_pool_avg" for target keys "["cuda", "gpu"]". Checked PackedFuncs:
  meta_schedule.cuda.meta_schedule.adaptive_pool_avg
  meta_schedule.gpu.meta_schedule.adaptive_pool_avg
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #26: "fused_nn_batch_flatten"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:159] Initializing Task #27: "fused_nn_softmax"
2024-03-23 01:28:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |            N/A |          N/A |                   N/A |      0 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |            N/A |          N/A |                   N/A |      0 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 0
Total latency (us): 0

2024-03-23 01:28:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 01:29:15 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:29:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:30:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 01:31:10 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:31:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:32:27 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 01:33:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:33:44 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:34:20 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 01:34:55 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:35:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:36:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 01:36:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:36:49 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:37:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #5: "fused_nn_max_pool2d"
2024-03-23 01:37:15 [INFO] [task_scheduler.cc:193] Sending 61 sample(s) to builder
2024-03-23 01:37:19 [INFO] [task_scheduler.cc:195] Sending 61 sample(s) to runner
2024-03-23 01:37:50 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 01:37:56 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 01:38:09 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 01:38:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 01:38:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:38:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:39:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 01:39:33 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:39:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:40:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #9: "fused_concatenate"
2024-03-23 01:40:13 [INFO] [task_scheduler.cc:193] Sending 1 sample(s) to builder
2024-03-23 01:40:13 [INFO] [task_scheduler.cc:195] Sending 1 sample(s) to runner
2024-03-23 01:40:13 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #10: "fused_nn_max_pool2d_1"
2024-03-23 01:40:15 [INFO] [task_scheduler.cc:193] Sending 61 sample(s) to builder
2024-03-23 01:40:18 [INFO] [task_scheduler.cc:195] Sending 61 sample(s) to runner
2024-03-23 01:40:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 01:40:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:41:14 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:41:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 01:41:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:42:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:42:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 01:42:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:43:10 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:43:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-03-23 01:43:43 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-03-23 01:43:44 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-03-23 01:43:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #15: "fused_nn_max_pool2d_2"
2024-03-23 01:43:49 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-03-23 01:43:52 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-03-23 01:44:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 01:44:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:44:43 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:45:18 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 01:45:25 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 01:45:33 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 01:46:08 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 01:46:14 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:46:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:46:54 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #19: "fused_concatenate_2"
2024-03-23 01:46:55 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-03-23 01:46:56 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-03-23 01:46:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 01:47:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:47:15 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:47:53 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-03-23 01:48:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:48:10 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:48:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 01:48:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:48:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:49:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-03-23 01:49:11 [INFO] [task_scheduler.cc:193] Sending 6 sample(s) to builder
2024-03-23 01:49:12 [INFO] [task_scheduler.cc:195] Sending 6 sample(s) to runner
2024-03-23 01:49:15 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:49:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:49:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:49:59 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #25: "fused_nn_global_avg_pool2d"
2024-03-23 01:50:01 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-03-23 01:50:05 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-03-23 01:50:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #26: "fused_nn_batch_flatten"
2024-03-23 01:50:38 [INFO] [task_scheduler.cc:193] Sending 5 sample(s) to builder
2024-03-23 01:50:39 [INFO] [task_scheduler.cc:195] Sending 5 sample(s) to runner
2024-03-23 01:50:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #27: "fused_nn_softmax"
2024-03-23 01:50:43 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:50:51 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:51:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.812706	tr-a-peak@32: 0.803589	tr-rmse: 0.908951	tr-rmse: 0.908951
2024-03-23 01:51:28 [DEBUG] XGB iter  25: tr-p-rmse: 0.059790	tr-a-peak@32: 1.000000	tr-rmse: 0.577420	tr-rmse: 0.577420
2024-03-23 01:51:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.058972	tr-a-peak@32: 1.000000	tr-rmse: 0.577930	tr-rmse: 0.577930
2024-03-23 01:51:28 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.05854	tr-a-peak@32:1.00000	tr-rmse:0.57857	tr-rmse:0.57857 
2024-03-23 01:51:29 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 01:51:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |            N/A |          N/A |                   N/A |      0 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 64
Total latency (us): 30.9469

2024-03-23 01:51:29 [DEBUG] XGB iter   0: tr-p-rmse: 2.868137	tr-a-peak@32: 0.770936	tr-rmse: 0.893422	tr-rmse: 0.893422
2024-03-23 01:51:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.043011	tr-a-peak@32: 1.000000	tr-rmse: 0.558352	tr-rmse: 0.558352
2024-03-23 01:51:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.041930	tr-a-peak@32: 1.000000	tr-rmse: 0.559023	tr-rmse: 0.559023
2024-03-23 01:51:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.041932	tr-a-peak@32: 1.000000	tr-rmse: 0.559021	tr-rmse: 0.559021
2024-03-23 01:51:29 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.04177	tr-a-peak@32:1.00000	tr-rmse:0.55936	tr-rmse:0.55936 
2024-03-23 01:51:29 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 01:51:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |            N/A |          N/A |                   N/A |      0 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 128
Total latency (us): 58.267

2024-03-23 01:51:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.850441	tr-a-peak@32: 0.780637	tr-rmse: 0.915860	tr-rmse: 0.915860
2024-03-23 01:51:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.053090	tr-a-peak@32: 1.000000	tr-rmse: 0.581292	tr-rmse: 0.581292
2024-03-23 01:51:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.052372	tr-a-peak@32: 1.000000	tr-rmse: 0.581954	tr-rmse: 0.581954
2024-03-23 01:51:30 [DEBUG] XGB iter  75: tr-p-rmse: 0.052374	tr-a-peak@32: 1.000000	tr-rmse: 0.581952	tr-rmse: 0.581952
2024-03-23 01:51:30 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.05231	tr-a-peak@32:1.00000	tr-rmse:0.58216	tr-rmse:0.58216 
2024-03-23 01:51:30 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 01:51:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |            N/A |          N/A |                   N/A |      0 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 192
Total latency (us): 84.6051

2024-03-23 01:51:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.874360	tr-a-peak@32: 0.963347	tr-rmse: 0.903548	tr-rmse: 0.903548
2024-03-23 01:51:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.049283	tr-a-peak@32: 1.000000	tr-rmse: 0.568182	tr-rmse: 0.568182
2024-03-23 01:51:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.048544	tr-a-peak@32: 1.000000	tr-rmse: 0.568853	tr-rmse: 0.568853
2024-03-23 01:51:30 [DEBUG] XGB iter  75: tr-p-rmse: 0.048545	tr-a-peak@32: 1.000000	tr-rmse: 0.568851	tr-rmse: 0.568851
2024-03-23 01:51:30 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.04850	tr-a-peak@32:1.00000	tr-rmse:0.56907	tr-rmse:0.56907 
2024-03-23 01:51:30 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 01:51:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |            N/A |          N/A |                   N/A |      0 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 256
Total latency (us): 107.498

2024-03-23 01:51:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.632658	tr-a-peak@32: 0.693924	tr-rmse: 0.877705	tr-rmse: 0.877705
2024-03-23 01:51:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.171662	tr-a-peak@32: 0.812500	tr-rmse: 0.565071	tr-rmse: 0.565071
2024-03-23 01:51:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.171068	tr-a-peak@32: 0.812500	tr-rmse: 0.565406	tr-rmse: 0.565406
2024-03-23 01:51:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.171068	tr-a-peak@32: 0.812500	tr-rmse: 0.565406	tr-rmse: 0.565406
2024-03-23 01:51:31 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.17103	tr-a-peak@32:0.81250	tr-rmse:0.56548	tr-rmse:0.56548 
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |            N/A |          N/A |                   N/A |      0 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 320
Total latency (us): 118.51

2024-03-23 01:51:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.597114	tr-a-peak@32: 0.679114	tr-rmse: 0.867550	tr-rmse: 0.867550
2024-03-23 01:51:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.171371	tr-a-peak@32: 0.843750	tr-rmse: 0.557330	tr-rmse: 0.557330
2024-03-23 01:51:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.168696	tr-a-peak@32: 0.843750	tr-rmse: 0.557602	tr-rmse: 0.557602
2024-03-23 01:51:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.168696	tr-a-peak@32: 0.843750	tr-rmse: 0.557602	tr-rmse: 0.557602
2024-03-23 01:51:31 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.16865	tr-a-peak@32:0.84375	tr-rmse:0.55771	tr-rmse:0.55771 
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:237] [Updated] Task #5: "fused_nn_max_pool2d"
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |            N/A |          N/A |                   N/A |      0 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 381
Total latency (us): 121.887

2024-03-23 01:51:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.458110	tr-a-peak@32: 1.000000	tr-rmse: 0.851059	tr-rmse: 0.851059
2024-03-23 01:51:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.222206	tr-a-peak@32: 0.750000	tr-rmse: 0.556902	tr-rmse: 0.556902
2024-03-23 01:51:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.222112	tr-a-peak@32: 0.750000	tr-rmse: 0.557017	tr-rmse: 0.557017
2024-03-23 01:51:31 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.22168	tr-a-peak@32:0.75000	tr-rmse:0.55770	tr-rmse:0.55770 
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 01:51:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |            N/A |          N/A |                   N/A |      0 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 444
Total latency (us): 126.406

2024-03-23 01:51:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.314404	tr-a-peak@32: 0.904498	tr-rmse: 0.827521	tr-rmse: 0.827521
2024-03-23 01:51:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.176145	tr-a-peak@32: 0.968750	tr-rmse: 0.547748	tr-rmse: 0.547748
2024-03-23 01:51:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.176091	tr-a-peak@32: 0.968750	tr-rmse: 0.547812	tr-rmse: 0.547812
2024-03-23 01:51:32 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.17567	tr-a-peak@32:0.96875	tr-rmse:0.54848	tr-rmse:0.54848 
2024-03-23 01:51:32 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 01:51:32 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |            N/A |          N/A |                   N/A |      0 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 508
Total latency (us): 133.663

2024-03-23 01:51:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.246164	tr-a-peak@32: 0.939004	tr-rmse: 0.822359	tr-rmse: 0.822359
2024-03-23 01:51:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.270523	tr-a-peak@32: 0.562500	tr-rmse: 0.547669	tr-rmse: 0.547669
2024-03-23 01:51:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.270469	tr-a-peak@32: 0.562500	tr-rmse: 0.547718	tr-rmse: 0.547718
2024-03-23 01:51:32 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.27004	tr-a-peak@32:0.56250	tr-rmse:0.54818	tr-rmse:0.54818 
2024-03-23 01:51:32 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 01:51:32 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 572
Total latency (us): 142.95

2024-03-23 01:51:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.245839	tr-a-peak@32: 0.939004	tr-rmse: 0.822034	tr-rmse: 0.822034
2024-03-23 01:51:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.258129	tr-a-peak@32: 0.593750	tr-rmse: 0.547276	tr-rmse: 0.547276
2024-03-23 01:51:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.258056	tr-a-peak@32: 0.593750	tr-rmse: 0.547337	tr-rmse: 0.547337
2024-03-23 01:51:33 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.25775	tr-a-peak@32:0.59375	tr-rmse:0.54778	tr-rmse:0.54778 
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:237] [Updated] Task #9: "fused_concatenate"
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |            N/A |          N/A |                   N/A |      0 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 572
Total latency (us): 142.95

2024-03-23 01:51:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.223104	tr-a-peak@32: 0.965367	tr-rmse: 0.813574	tr-rmse: 0.813574
2024-03-23 01:51:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.253918	tr-a-peak@32: 0.562500	tr-rmse: 0.539855	tr-rmse: 0.539855
2024-03-23 01:51:33 [DEBUG] XGB iter  50: tr-p-rmse: 0.253850	tr-a-peak@32: 0.562500	tr-rmse: 0.539899	tr-rmse: 0.539899
2024-03-23 01:51:33 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.25340	tr-a-peak@32:0.56250	tr-rmse:0.54038	tr-rmse:0.54038 
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:237] [Updated] Task #10: "fused_nn_max_pool2d_1"
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |            N/A |          N/A |                   N/A |      0 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 633
Total latency (us): 145.377

2024-03-23 01:51:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.082627	tr-a-peak@32: 0.968750	tr-rmse: 0.791295	tr-rmse: 0.791295
2024-03-23 01:51:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.272119	tr-a-peak@32: 0.375000	tr-rmse: 0.537031	tr-rmse: 0.537031
2024-03-23 01:51:33 [DEBUG] XGB iter  50: tr-p-rmse: 0.272107	tr-a-peak@32: 0.375000	tr-rmse: 0.537041	tr-rmse: 0.537041
2024-03-23 01:51:33 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.27190	tr-a-peak@32:0.37500	tr-rmse:0.53724	tr-rmse:0.53724 
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 01:51:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |            N/A |          N/A |                   N/A |      0 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 697
Total latency (us): 154.312

2024-03-23 01:51:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.068411	tr-a-peak@32: 0.878249	tr-rmse: 0.776513	tr-rmse: 0.776513
2024-03-23 01:51:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.277846	tr-a-peak@32: 0.562500	tr-rmse: 0.532203	tr-rmse: 0.532203
2024-03-23 01:51:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.277835	tr-a-peak@32: 0.562500	tr-rmse: 0.532212	tr-rmse: 0.532212
2024-03-23 01:51:34 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.27756	tr-a-peak@32:0.56250	tr-rmse:0.53271	tr-rmse:0.53271 
2024-03-23 01:51:34 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 01:51:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |            N/A |          N/A |                   N/A |      0 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 761
Total latency (us): 162.619

2024-03-23 01:51:34 [DEBUG] XGB iter   0: tr-p-rmse: 1.960046	tr-a-peak@32: 0.765370	tr-rmse: 0.760331	tr-rmse: 0.760331
2024-03-23 01:51:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.240305	tr-a-peak@32: 0.593750	tr-rmse: 0.529908	tr-rmse: 0.529908
2024-03-23 01:51:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.240301	tr-a-peak@32: 0.593750	tr-rmse: 0.529911	tr-rmse: 0.529911
2024-03-23 01:51:34 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.24006	tr-a-peak@32:0.59375	tr-rmse:0.53043	tr-rmse:0.53043 
2024-03-23 01:51:34 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 01:51:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 825
Total latency (us): 171.076

2024-03-23 01:51:34 [DEBUG] XGB iter   0: tr-p-rmse: 1.958208	tr-a-peak@32: 0.795856	tr-rmse: 0.758838	tr-rmse: 0.758838
2024-03-23 01:51:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.269116	tr-a-peak@32: 0.468750	tr-rmse: 0.526301	tr-rmse: 0.526301
2024-03-23 01:51:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.269112	tr-a-peak@32: 0.468750	tr-rmse: 0.526304	tr-rmse: 0.526304
2024-03-23 01:51:35 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.26891	tr-a-peak@32:0.46875	tr-rmse:0.52649	tr-rmse:0.52649 
2024-03-23 01:51:35 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-03-23 01:51:35 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |            N/A |          N/A |                   N/A |      0 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 831
Total latency (us): 175.625

2024-03-23 01:51:35 [DEBUG] XGB iter   0: tr-p-rmse: 1.913458	tr-a-peak@32: 0.837217	tr-rmse: 0.750275	tr-rmse: 0.750275
2024-03-23 01:51:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.247156	tr-a-peak@32: 0.687500	tr-rmse: 0.521322	tr-rmse: 0.521322
2024-03-23 01:51:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.247153	tr-a-peak@32: 0.687500	tr-rmse: 0.521324	tr-rmse: 0.521324
2024-03-23 01:51:35 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.24696	tr-a-peak@32:0.68750	tr-rmse:0.52148	tr-rmse:0.52148 
2024-03-23 01:51:35 [INFO] [task_scheduler.cc:237] [Updated] Task #15: "fused_nn_max_pool2d_2"
2024-03-23 01:51:35 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |            N/A |          N/A |                   N/A |      0 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 893
Total latency (us): 177.883

2024-03-23 01:51:35 [DEBUG] XGB iter   0: tr-p-rmse: 1.883064	tr-a-peak@32: 0.737188	tr-rmse: 0.734162	tr-rmse: 0.734162
2024-03-23 01:51:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.231343	tr-a-peak@32: 0.656250	tr-rmse: 0.512508	tr-rmse: 0.512508
2024-03-23 01:51:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.231339	tr-a-peak@32: 0.656250	tr-rmse: 0.512511	tr-rmse: 0.512511
2024-03-23 01:51:36 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.23117	tr-a-peak@32:0.65625	tr-rmse:0.51265	tr-rmse:0.51265 
2024-03-23 01:51:36 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 01:51:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |            N/A |          N/A |                   N/A |      0 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 957
Total latency (us): 183.369

2024-03-23 01:51:36 [DEBUG] XGB iter   0: tr-p-rmse: 1.829836	tr-a-peak@32: 0.536151	tr-rmse: 0.719769	tr-rmse: 0.719769
2024-03-23 01:51:36 [DEBUG] XGB iter  25: tr-p-rmse: 0.249035	tr-a-peak@32: 0.593750	tr-rmse: 0.507770	tr-rmse: 0.507770
2024-03-23 01:51:36 [DEBUG] XGB iter  50: tr-p-rmse: 0.249033	tr-a-peak@32: 0.593750	tr-rmse: 0.507771	tr-rmse: 0.507771
2024-03-23 01:51:36 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.24884	tr-a-peak@32:0.59375	tr-rmse:0.50791	tr-rmse:0.50791 
2024-03-23 01:51:36 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 01:51:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |            N/A |          N/A |                   N/A |      0 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1020
Total latency (us): 190.827

2024-03-23 01:51:36 [DEBUG] XGB iter   0: tr-p-rmse: 1.782731	tr-a-peak@32: 0.755592	tr-rmse: 0.710317	tr-rmse: 0.710317
2024-03-23 01:51:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.251741	tr-a-peak@32: 0.375000	tr-rmse: 0.506579	tr-rmse: 0.506579
2024-03-23 01:51:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.251741	tr-a-peak@32: 0.375000	tr-rmse: 0.506579	tr-rmse: 0.506579
2024-03-23 01:51:37 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.25156	tr-a-peak@32:0.37500	tr-rmse:0.50699	tr-rmse:0.50699 
2024-03-23 01:51:37 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 01:51:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1084
Total latency (us): 201.176

2024-03-23 01:51:37 [DEBUG] XGB iter   0: tr-p-rmse: 1.791502	tr-a-peak@32: 0.749827	tr-rmse: 0.709355	tr-rmse: 0.709355
2024-03-23 01:51:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.245363	tr-a-peak@32: 0.500000	tr-rmse: 0.505891	tr-rmse: 0.505891
2024-03-23 01:51:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.245360	tr-a-peak@32: 0.500000	tr-rmse: 0.505893	tr-rmse: 0.505893
2024-03-23 01:51:37 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.24526	tr-a-peak@32:0.53125	tr-rmse:0.50612	tr-rmse:0.50612 
2024-03-23 01:51:37 [INFO] [task_scheduler.cc:237] [Updated] Task #19: "fused_concatenate_2"
2024-03-23 01:51:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |            N/A |          N/A |                   N/A |      0 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1090
Total latency (us): 205.772

2024-03-23 01:51:37 [DEBUG] XGB iter   0: tr-p-rmse: 1.742005	tr-a-peak@32: 0.794069	tr-rmse: 0.696990	tr-rmse: 0.696990
2024-03-23 01:51:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.224185	tr-a-peak@32: 0.593750	tr-rmse: 0.500150	tr-rmse: 0.500150
2024-03-23 01:51:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.224187	tr-a-peak@32: 0.593750	tr-rmse: 0.500148	tr-rmse: 0.500148
2024-03-23 01:51:38 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.22415	tr-a-peak@32:0.59375	tr-rmse:0.50024	tr-rmse:0.50024 
2024-03-23 01:51:38 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 01:51:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |      0 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1154
Total latency (us): 213.245

2024-03-23 01:51:38 [DEBUG] XGB iter   0: tr-p-rmse: 1.729084	tr-a-peak@32: 0.968750	tr-rmse: 0.700046	tr-rmse: 0.700046
2024-03-23 01:51:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.202136	tr-a-peak@32: 0.875000	tr-rmse: 0.550317	tr-rmse: 0.550317
2024-03-23 01:51:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.202136	tr-a-peak@32: 0.875000	tr-rmse: 0.550317	tr-rmse: 0.550317
2024-03-23 01:51:38 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.20207	tr-a-peak@32:0.87500	tr-rmse:0.55038	tr-rmse:0.55038 
2024-03-23 01:51:38 [INFO] [task_scheduler.cc:237] [Updated] Task #21: "fused_nn_conv2d_add_nn_relu_11"
2024-03-23 01:51:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |            N/A |          N/A |                   N/A |      0 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1154
Total latency (us): 213.245

2024-03-23 01:51:39 [DEBUG] XGB iter   0: tr-p-rmse: 1.655033	tr-a-peak@32: 0.881942	tr-rmse: 0.694661	tr-rmse: 0.694661
2024-03-23 01:51:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.208727	tr-a-peak@32: 0.906250	tr-rmse: 0.547911	tr-rmse: 0.547911
2024-03-23 01:51:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.208726	tr-a-peak@32: 0.906250	tr-rmse: 0.547912	tr-rmse: 0.547912
2024-03-23 01:51:39 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.20865	tr-a-peak@32:0.90625	tr-rmse:0.54819	tr-rmse:0.54819 
2024-03-23 01:51:39 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 01:51:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |            N/A |          N/A |                   N/A |      0 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1218
Total latency (us): 222.947

2024-03-23 01:51:39 [DEBUG] XGB iter   0: tr-p-rmse: 1.631728	tr-a-peak@32: 1.000000	tr-rmse: 0.693628	tr-rmse: 0.693628
2024-03-23 01:51:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.225367	tr-a-peak@32: 0.750000	tr-rmse: 0.548584	tr-rmse: 0.548584
2024-03-23 01:51:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.225368	tr-a-peak@32: 0.750000	tr-rmse: 0.548584	tr-rmse: 0.548584
2024-03-23 01:51:39 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.22532	tr-a-peak@32:0.75000	tr-rmse:0.54862	tr-rmse:0.54862 
2024-03-23 01:51:39 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-03-23 01:51:39 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1224
Total latency (us): 227.437

2024-03-23 01:51:40 [DEBUG] XGB iter   0: tr-p-rmse: 1.581510	tr-a-peak@32: 0.924064	tr-rmse: 0.695302	tr-rmse: 0.695302
2024-03-23 01:51:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.238583	tr-a-peak@32: 0.500000	tr-rmse: 0.548310	tr-rmse: 0.548310
2024-03-23 01:51:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.238583	tr-a-peak@32: 0.500000	tr-rmse: 0.548310	tr-rmse: 0.548310
2024-03-23 01:51:40 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.23855	tr-a-peak@32:0.50000	tr-rmse:0.54846	tr-rmse:0.54846 
2024-03-23 01:51:40 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:51:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3717.9751 |      46.6367 |               46.6367 |     64 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |            N/A |          N/A |                   N/A |      0 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1288
Total latency (us): 274.074

2024-03-23 01:51:40 [DEBUG] XGB iter   0: tr-p-rmse: 1.560501	tr-a-peak@32: 0.997811	tr-rmse: 0.682110	tr-rmse: 0.682110
2024-03-23 01:51:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.237784	tr-a-peak@32: 0.625000	tr-rmse: 0.545290	tr-rmse: 0.545290
2024-03-23 01:51:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.237785	tr-a-peak@32: 0.625000	tr-rmse: 0.545289	tr-rmse: 0.545289
2024-03-23 01:51:41 [DEBUG] XGB stopped. Best iteration: [18] tr-p-rmse:0.23755	tr-a-peak@32:0.62500	tr-rmse:0.54550	tr-rmse:0.54550 
2024-03-23 01:51:41 [INFO] [task_scheduler.cc:237] [Updated] Task #25: "fused_nn_global_avg_pool2d"
2024-03-23 01:51:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3717.9751 |      46.6367 |               46.6367 |     64 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |            N/A |          N/A |                   N/A |      0 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1350
Total latency (us): 276.374

2024-03-23 01:51:41 [DEBUG] XGB iter   0: tr-p-rmse: 1.559756	tr-a-peak@32: 0.995577	tr-rmse: 0.681347	tr-rmse: 0.681347
2024-03-23 01:51:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.238494	tr-a-peak@32: 0.656250	tr-rmse: 0.544214	tr-rmse: 0.544214
2024-03-23 01:51:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.238494	tr-a-peak@32: 0.656250	tr-rmse: 0.544213	tr-rmse: 0.544213
2024-03-23 01:51:41 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.23845	tr-a-peak@32:0.65625	tr-rmse:0.54425	tr-rmse:0.54425 
2024-03-23 01:51:41 [INFO] [task_scheduler.cc:237] [Updated] Task #26: "fused_nn_batch_flatten"
2024-03-23 01:51:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3717.9751 |      46.6367 |               46.6367 |     64 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |            N/A |          N/A |                   N/A |      0 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1355
Total latency (us): 278.653

2024-03-23 01:51:41 [DEBUG] XGB iter   0: tr-p-rmse: 1.532854	tr-a-peak@32: 0.995577	tr-rmse: 0.677733	tr-rmse: 0.677733
2024-03-23 01:51:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.229093	tr-a-peak@32: 0.593750	tr-rmse: 0.543123	tr-rmse: 0.543123
2024-03-23 01:51:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.229093	tr-a-peak@32: 0.593750	tr-rmse: 0.543123	tr-rmse: 0.543123
2024-03-23 01:51:42 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.22909	tr-a-peak@32:0.59375	tr-rmse:0.54313	tr-rmse:0.54313 
2024-03-23 01:51:42 [INFO] [task_scheduler.cc:237] [Updated] Task #27: "fused_nn_softmax"
2024-03-23 01:51:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      3717.9751 |      46.6367 |               46.6367 |     64 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1419
Total latency (us): 280.937

2024-03-23 01:51:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:51:53 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 01:52:04 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 01:52:40 [DEBUG] XGB validation: p-rmse: 1.069681	a-peak@32: 0.807466
2024-03-23 01:52:40 [DEBUG] XGB iter   0: tr-p-rmse: 1.529894	tr-a-peak@32: 0.995622	tr-rmse: 0.661670	tr-rmse: 0.661670
2024-03-23 01:52:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.232450	tr-a-peak@32: 0.625000	tr-rmse: 0.539002	tr-rmse: 0.539002
2024-03-23 01:52:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.232450	tr-a-peak@32: 0.625000	tr-rmse: 0.539002	tr-rmse: 0.539002
2024-03-23 01:52:40 [DEBUG] XGB stopped. Best iteration: [23] tr-p-rmse:0.23245	tr-a-peak@32:0.62500	tr-rmse:0.53901	tr-rmse:0.53901 
2024-03-23 01:52:40 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:52:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      1977.1618 |      15.4735 |               30.9469 |     64 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4765.3743 |      36.3862 |               36.3862 |    127 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1482
Total latency (us): 270.687

2024-03-23 01:52:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 01:53:32 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:53:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:54:22 [DEBUG] XGB validation: p-rmse: 1.682927	a-peak@32: 0.792900
2024-03-23 01:54:22 [DEBUG] XGB iter   0: tr-p-rmse: 1.647548	tr-a-peak@32: 0.992137	tr-rmse: 0.652493	tr-rmse: 0.652493
2024-03-23 01:54:22 [DEBUG] XGB iter  25: tr-p-rmse: 0.251397	tr-a-peak@32: 0.437500	tr-rmse: 0.521276	tr-rmse: 0.521276
2024-03-23 01:54:23 [DEBUG] XGB iter  50: tr-p-rmse: 0.251397	tr-a-peak@32: 0.437500	tr-rmse: 0.521276	tr-rmse: 0.521276
2024-03-23 01:54:23 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.25136	tr-a-peak@32:0.43750	tr-rmse:0.52130	tr-rmse:0.52130 
2024-03-23 01:54:23 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 01:54:23 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |     64 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4765.3743 |      36.3862 |               36.3862 |    127 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1546
Total latency (us): 261.659

2024-03-23 01:54:23 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 01:55:14 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:55:27 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:56:05 [DEBUG] XGB validation: p-rmse: 1.530891	a-peak@32: 0.664568
2024-03-23 01:56:05 [DEBUG] XGB iter   0: tr-p-rmse: 1.762921	tr-a-peak@32: 0.959995	tr-rmse: 0.681455	tr-rmse: 0.681455
2024-03-23 01:56:06 [DEBUG] XGB iter  25: tr-p-rmse: 0.234028	tr-a-peak@32: 0.593750	tr-rmse: 0.528930	tr-rmse: 0.528930
2024-03-23 01:56:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.234028	tr-a-peak@32: 0.593750	tr-rmse: 0.528930	tr-rmse: 0.528930
2024-03-23 01:56:06 [DEBUG] XGB stopped. Best iteration: [20] tr-p-rmse:0.23398	tr-a-peak@32:0.59375	tr-rmse:0.52898	tr-rmse:0.52898 
2024-03-23 01:56:06 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 01:56:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |     64 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4765.3743 |      36.3862 |               36.3862 |    127 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1610
Total latency (us): 261.659

2024-03-23 01:56:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 01:56:55 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:57:19 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:57:56 [DEBUG] XGB validation: p-rmse: 1.259088	a-peak@32: 0.865591
2024-03-23 01:57:56 [DEBUG] XGB iter   0: tr-p-rmse: 1.909335	tr-a-peak@32: 0.968750	tr-rmse: 0.730583	tr-rmse: 0.730583
2024-03-23 01:57:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.218580	tr-a-peak@32: 0.593750	tr-rmse: 0.544088	tr-rmse: 0.544088
2024-03-23 01:57:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.218576	tr-a-peak@32: 0.593750	tr-rmse: 0.544092	tr-rmse: 0.544092
2024-03-23 01:57:57 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.21852	tr-a-peak@32:0.59375	tr-rmse:0.54414	tr-rmse:0.54414 
2024-03-23 01:57:57 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 01:57:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3961.4058 |      11.4467 |               22.8933 |     64 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4765.3743 |      36.3862 |               36.3862 |    127 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1674
Total latency (us): 261.659

2024-03-23 01:57:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 01:58:44 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 01:59:03 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 01:59:41 [DEBUG] XGB validation: p-rmse: 0.712988	a-peak@32: 0.706999
2024-03-23 01:59:41 [DEBUG] XGB iter   0: tr-p-rmse: 1.972369	tr-a-peak@32: 1.000000	tr-rmse: 0.754348	tr-rmse: 0.754348
2024-03-23 01:59:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.186401	tr-a-peak@32: 0.687283	tr-rmse: 0.549101	tr-rmse: 0.549101
2024-03-23 01:59:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.186388	tr-a-peak@32: 0.687283	tr-rmse: 0.549112	tr-rmse: 0.549112
2024-03-23 01:59:41 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.18635	tr-a-peak@32:0.68728	tr-rmse:0.54914	tr-rmse:0.54914 
2024-03-23 01:59:41 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 01:59:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4765.3743 |      36.3862 |               36.3862 |    127 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1738
Total latency (us): 261.627

2024-03-23 01:59:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 01:59:52 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:00:04 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:00:39 [DEBUG] XGB validation: p-rmse: 0.861660	a-peak@32: 0.655922
2024-03-23 02:00:39 [DEBUG] XGB iter   0: tr-p-rmse: 1.941981	tr-a-peak@32: 1.000000	tr-rmse: 0.742451	tr-rmse: 0.742451
2024-03-23 02:00:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.197159	tr-a-peak@32: 0.812500	tr-rmse: 0.546139	tr-rmse: 0.546139
2024-03-23 02:00:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.197148	tr-a-peak@32: 0.812500	tr-rmse: 0.546149	tr-rmse: 0.546149
2024-03-23 02:00:40 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.19713	tr-a-peak@32:0.81250	tr-rmse:0.54619	tr-rmse:0.54619 
2024-03-23 02:00:40 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:00:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1327.1003 |      13.6600 |               27.3201 |    128 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    191 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1802
Total latency (us): 260.785

2024-03-23 02:00:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:01:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:01:50 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:02:27 [DEBUG] XGB validation: p-rmse: 1.043520	a-peak@32: 0.808710
2024-03-23 02:02:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.023641	tr-a-peak@32: 0.995577	tr-rmse: 0.760669	tr-rmse: 0.760669
2024-03-23 02:02:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.213677	tr-a-peak@32: 0.593576	tr-rmse: 0.550715	tr-rmse: 0.550715
2024-03-23 02:02:27 [DEBUG] XGB iter  50: tr-p-rmse: 0.213658	tr-a-peak@32: 0.593576	tr-rmse: 0.550735	tr-rmse: 0.550735
2024-03-23 02:02:28 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21361	tr-a-peak@32:0.59358	tr-rmse:0.55079	tr-rmse:0.55079 
2024-03-23 02:02:28 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:02:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    128 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    191 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1866
Total latency (us): 256.152

2024-03-23 02:02:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:03:17 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:03:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:04:13 [DEBUG] XGB validation: p-rmse: 1.051625	a-peak@32: 0.862051
2024-03-23 02:04:13 [DEBUG] XGB iter   0: tr-p-rmse: 2.043233	tr-a-peak@32: 0.997811	tr-rmse: 0.766903	tr-rmse: 0.766903
2024-03-23 02:04:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.213349	tr-a-peak@32: 0.156250	tr-rmse: 0.550052	tr-rmse: 0.550052
2024-03-23 02:04:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.213329	tr-a-peak@32: 0.156250	tr-rmse: 0.550072	tr-rmse: 0.550072
2024-03-23 02:04:14 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21328	tr-a-peak@32:0.15625	tr-rmse:0.55012	tr-rmse:0.55012 
2024-03-23 02:04:14 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:04:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    191 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1930
Total latency (us): 256.152

2024-03-23 02:04:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:04:25 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:04:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:05:00 [DEBUG] XGB validation: p-rmse: 1.149539	a-peak@32: 0.654528
2024-03-23 02:05:00 [DEBUG] XGB iter   0: tr-p-rmse: 2.044211	tr-a-peak@32: 0.995577	tr-rmse: 0.762348	tr-rmse: 0.762348
2024-03-23 02:05:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.215031	tr-a-peak@32: 0.249870	tr-rmse: 0.547293	tr-rmse: 0.547293
2024-03-23 02:05:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.215017	tr-a-peak@32: 0.249870	tr-rmse: 0.547307	tr-rmse: 0.547307
2024-03-23 02:05:01 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21498	tr-a-peak@32:0.24987	tr-rmse:0.54734	tr-rmse:0.54734 
2024-03-23 02:05:01 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:05:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    128 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    255 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 1994
Total latency (us): 256.152

2024-03-23 02:05:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:05:49 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:06:09 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:06:45 [DEBUG] XGB validation: p-rmse: 1.482926	a-peak@32: 0.406670
2024-03-23 02:06:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.091224	tr-a-peak@32: 0.995577	tr-rmse: 0.763307	tr-rmse: 0.763307
2024-03-23 02:06:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.205269	tr-a-peak@32: 0.437500	tr-rmse: 0.540609	tr-rmse: 0.540609
2024-03-23 02:06:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.205205	tr-a-peak@32: 0.437500	tr-rmse: 0.540656	tr-rmse: 0.540656
2024-03-23 02:06:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.205205	tr-a-peak@32: 0.437500	tr-rmse: 0.540656	tr-rmse: 0.540656
2024-03-23 02:06:46 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20518	tr-a-peak@32:0.43750	tr-rmse:0.54068	tr-rmse:0.54068 
2024-03-23 02:06:46 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:06:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |     64 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    255 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2058
Total latency (us): 256.152

2024-03-23 02:06:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:06:57 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:07:09 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:07:30 [DEBUG] XGB validation: p-rmse: 1.802374	a-peak@32: 0.454387
2024-03-23 02:07:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.053682	tr-a-peak@32: 0.995421	tr-rmse: 0.760298	tr-rmse: 0.760298
2024-03-23 02:07:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.199519	tr-a-peak@32: 0.656250	tr-rmse: 0.539906	tr-rmse: 0.539906
2024-03-23 02:07:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.199482	tr-a-peak@32: 0.656250	tr-rmse: 0.539934	tr-rmse: 0.539934
2024-03-23 02:07:31 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.19939	tr-a-peak@32:0.65625	tr-rmse:0.54000	tr-rmse:0.54000 
2024-03-23 02:07:31 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:07:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2791.4558 |      10.9597 |               21.9194 |    128 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    255 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2122
Total latency (us): 256.152

2024-03-23 02:07:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:08:25 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:08:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:09:21 [DEBUG] XGB validation: p-rmse: 1.128375	a-peak@32: 0.696576
2024-03-23 02:09:21 [DEBUG] XGB iter   0: tr-p-rmse: 2.121411	tr-a-peak@32: 1.000000	tr-rmse: 0.776194	tr-rmse: 0.776194
2024-03-23 02:09:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.206995	tr-a-peak@32: 0.437500	tr-rmse: 0.547691	tr-rmse: 0.547691
2024-03-23 02:09:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.206463	tr-a-peak@32: 0.437500	tr-rmse: 0.547716	tr-rmse: 0.547716
2024-03-23 02:09:22 [DEBUG] XGB iter  75: tr-p-rmse: 0.206463	tr-a-peak@32: 0.437500	tr-rmse: 0.547716	tr-rmse: 0.547716
2024-03-23 02:09:22 [DEBUG] XGB stopped. Best iteration: [27] tr-p-rmse:0.20646	tr-a-peak@32:0.43750	tr-rmse:0.54772	tr-rmse:0.54772 
2024-03-23 02:09:22 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:09:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |       614.5772 |       5.1741 |               10.3483 |     64 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    255 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2186
Total latency (us): 256.044

2024-03-23 02:09:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 02:09:32 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:09:42 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:10:13 [DEBUG] XGB validation: p-rmse: 0.641033	a-peak@32: 0.983995
2024-03-23 02:10:13 [DEBUG] XGB iter   0: tr-p-rmse: 2.138193	tr-a-peak@32: 1.000000	tr-rmse: 0.770428	tr-rmse: 0.770428
2024-03-23 02:10:14 [DEBUG] XGB iter  25: tr-p-rmse: 0.194585	tr-a-peak@32: 0.656250	tr-rmse: 0.548449	tr-rmse: 0.548449
2024-03-23 02:10:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.194502	tr-a-peak@32: 0.656250	tr-rmse: 0.548501	tr-rmse: 0.548501
2024-03-23 02:10:14 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.19431	tr-a-peak@32:0.65625	tr-rmse:0.54863	tr-rmse:0.54863 
2024-03-23 02:10:14 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 02:10:14 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      4878.2442 |      35.5443 |               35.5443 |    255 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2250
Total latency (us): 251.554

2024-03-23 02:10:14 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:10:25 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:10:32 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:11:09 [DEBUG] XGB validation: p-rmse: 0.235508	a-peak@32: 0.949153
2024-03-23 02:11:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.124445	tr-a-peak@32: 0.995577	tr-rmse: 0.763951	tr-rmse: 0.763951
2024-03-23 02:11:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.192279	tr-a-peak@32: 0.750000	tr-rmse: 0.552163	tr-rmse: 0.552163
2024-03-23 02:11:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.191888	tr-a-peak@32: 0.750000	tr-rmse: 0.552244	tr-rmse: 0.552244
2024-03-23 02:11:10 [DEBUG] XGB iter  75: tr-p-rmse: 0.191888	tr-a-peak@32: 0.750000	tr-rmse: 0.552244	tr-rmse: 0.552244
2024-03-23 02:11:10 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.19186	tr-a-peak@32:0.75000	tr-rmse:0.55228	tr-rmse:0.55228 
2024-03-23 02:11:10 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:11:10 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |     64 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2314
Total latency (us): 248.47

2024-03-23 02:11:10 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 02:11:20 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:11:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:11:35 [DEBUG] XGB validation: p-rmse: 1.298640	a-peak@32: 0.965122
2024-03-23 02:11:35 [DEBUG] XGB iter   0: tr-p-rmse: 2.099016	tr-a-peak@32: 0.997811	tr-rmse: 0.761303	tr-rmse: 0.761303
2024-03-23 02:11:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.187066	tr-a-peak@32: 0.624913	tr-rmse: 0.551705	tr-rmse: 0.551705
2024-03-23 02:11:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.187027	tr-a-peak@32: 0.624913	tr-rmse: 0.551733	tr-rmse: 0.551733
2024-03-23 02:11:35 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.18693	tr-a-peak@32:0.62491	tr-rmse:0.55180	tr-rmse:0.55180 
2024-03-23 02:11:36 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 02:11:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1417.4694 |       4.6438 |                9.2875 |     64 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2378
Total latency (us): 248.47

2024-03-23 02:11:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 02:11:45 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:11:58 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:12:28 [DEBUG] XGB validation: p-rmse: 0.874866	a-peak@32: 0.551450
2024-03-23 02:12:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.074066	tr-a-peak@32: 1.000000	tr-rmse: 0.757057	tr-rmse: 0.757057
2024-03-23 02:12:28 [DEBUG] XGB iter  25: tr-p-rmse: 0.200944	tr-a-peak@32: 0.593750	tr-rmse: 0.550024	tr-rmse: 0.550024
2024-03-23 02:12:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.200883	tr-a-peak@32: 0.593750	tr-rmse: 0.550062	tr-rmse: 0.550062
2024-03-23 02:12:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.200883	tr-a-peak@32: 0.593750	tr-rmse: 0.550062	tr-rmse: 0.550062
2024-03-23 02:12:29 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20086	tr-a-peak@32:0.59375	tr-rmse:0.55008	tr-rmse:0.55008 
2024-03-23 02:12:29 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 02:12:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |       673.6313 |       8.9346 |                8.9346 |     64 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2442
Total latency (us): 247.168

2024-03-23 02:12:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 02:12:40 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:12:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:13:27 [DEBUG] XGB validation: p-rmse: 0.254364	a-peak@32: 0.886135
2024-03-23 02:13:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.074766	tr-a-peak@32: 0.997535	tr-rmse: 0.751181	tr-rmse: 0.751181
2024-03-23 02:13:28 [DEBUG] XGB iter  25: tr-p-rmse: 0.201299	tr-a-peak@32: 0.562500	tr-rmse: 0.550894	tr-rmse: 0.550894
2024-03-23 02:13:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.201251	tr-a-peak@32: 0.562500	tr-rmse: 0.550927	tr-rmse: 0.550927
2024-03-23 02:13:28 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.20112	tr-a-peak@32:0.56250	tr-rmse:0.55102	tr-rmse:0.55102 
2024-03-23 02:13:28 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 02:13:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      2696.5169 |      13.1690 |               26.3381 |    192 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2506
Total latency (us): 243.668

2024-03-23 02:13:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:14:20 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:14:33 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:15:10 [DEBUG] XGB validation: p-rmse: 0.666518	a-peak@32: 0.664955
2024-03-23 02:15:10 [DEBUG] XGB iter   0: tr-p-rmse: 2.093017	tr-a-peak@32: 0.995123	tr-rmse: 0.742642	tr-rmse: 0.742642
2024-03-23 02:15:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.200533	tr-a-peak@32: 0.593707	tr-rmse: 0.538764	tr-rmse: 0.538764
2024-03-23 02:15:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.200424	tr-a-peak@32: 0.593707	tr-rmse: 0.538832	tr-rmse: 0.538832
2024-03-23 02:15:11 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.20025	tr-a-peak@32:0.59371	tr-rmse:0.53899	tr-rmse:0.53899 
2024-03-23 02:15:11 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:15:11 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1456.3518 |       4.2288 |                8.4576 |     64 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2570
Total latency (us): 239.086

2024-03-23 02:15:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 02:15:21 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:15:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:16:00 [DEBUG] XGB validation: p-rmse: 0.654538	a-peak@32: 0.954065
2024-03-23 02:16:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.083837	tr-a-peak@32: 0.997811	tr-rmse: 0.735837	tr-rmse: 0.735837
2024-03-23 02:16:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.209239	tr-a-peak@32: 0.249913	tr-rmse: 0.537434	tr-rmse: 0.537434
2024-03-23 02:16:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.209160	tr-a-peak@32: 0.249913	tr-rmse: 0.537490	tr-rmse: 0.537490
2024-03-23 02:16:01 [DEBUG] XGB iter  75: tr-p-rmse: 0.209160	tr-a-peak@32: 0.249913	tr-rmse: 0.537490	tr-rmse: 0.537490
2024-03-23 02:16:01 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20913	tr-a-peak@32:0.24991	tr-rmse:0.53751	tr-rmse:0.53751 
2024-03-23 02:16:01 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 02:16:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1443.3936 |       8.3072 |                8.3072 |     64 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2634
Total latency (us): 237.487

2024-03-23 02:16:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 02:16:13 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:16:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:16:57 [DEBUG] XGB validation: p-rmse: 0.569277	a-peak@32: 0.940483
2024-03-23 02:16:57 [DEBUG] XGB iter   0: tr-p-rmse: 2.053260	tr-a-peak@32: 1.000000	tr-rmse: 0.730863	tr-rmse: 0.730863
2024-03-23 02:16:58 [DEBUG] XGB iter  25: tr-p-rmse: 0.199651	tr-a-peak@32: 0.780171	tr-rmse: 0.540556	tr-rmse: 0.540556
2024-03-23 02:16:58 [DEBUG] XGB iter  50: tr-p-rmse: 0.199599	tr-a-peak@32: 0.780171	tr-rmse: 0.540594	tr-rmse: 0.540594
2024-03-23 02:16:58 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.19945	tr-a-peak@32:0.78017	tr-rmse:0.54070	tr-rmse:0.54070 
2024-03-23 02:16:58 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 02:16:58 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      3966.9239 |      11.4307 |               22.8615 |    192 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2698
Total latency (us): 237.172

2024-03-23 02:16:58 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:17:46 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:18:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:19:06 [DEBUG] XGB validation: p-rmse: 1.083996	a-peak@32: 0.320451
2024-03-23 02:19:06 [DEBUG] XGB iter   0: tr-p-rmse: 2.096466	tr-a-peak@32: 1.000000	tr-rmse: 0.739061	tr-rmse: 0.739061
2024-03-23 02:19:06 [DEBUG] XGB iter  25: tr-p-rmse: 0.199660	tr-a-peak@32: 0.840442	tr-rmse: 0.542338	tr-rmse: 0.542338
2024-03-23 02:19:07 [DEBUG] XGB iter  50: tr-p-rmse: 0.199550	tr-a-peak@32: 0.840442	tr-rmse: 0.542418	tr-rmse: 0.542418
2024-03-23 02:19:07 [DEBUG] XGB iter  75: tr-p-rmse: 0.199550	tr-a-peak@32: 0.840442	tr-rmse: 0.542418	tr-rmse: 0.542418
2024-03-23 02:19:07 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.19951	tr-a-peak@32:0.84044	tr-rmse:0.54245	tr-rmse:0.54245 
2024-03-23 02:19:07 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:19:07 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    192 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2762
Total latency (us): 236.832

2024-03-23 02:19:07 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:20:05 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:20:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:20:59 [DEBUG] XGB validation: p-rmse: 0.873057	a-peak@32: 0.835202
2024-03-23 02:20:59 [DEBUG] XGB iter   0: tr-p-rmse: 2.094195	tr-a-peak@32: 0.975440	tr-rmse: 0.751365	tr-rmse: 0.751365
2024-03-23 02:21:00 [DEBUG] XGB iter  25: tr-p-rmse: 0.186907	tr-a-peak@32: 0.779596	tr-rmse: 0.548047	tr-rmse: 0.548047
2024-03-23 02:21:00 [DEBUG] XGB iter  50: tr-p-rmse: 0.186823	tr-a-peak@32: 0.779596	tr-rmse: 0.548114	tr-rmse: 0.548114
2024-03-23 02:21:00 [DEBUG] XGB iter  75: tr-p-rmse: 0.186823	tr-a-peak@32: 0.779596	tr-rmse: 0.548114	tr-rmse: 0.548114
2024-03-23 02:21:00 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.18679	tr-a-peak@32:0.77960	tr-rmse:0.54814	tr-rmse:0.54814 
2024-03-23 02:21:00 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:21:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |     64 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2826
Total latency (us): 236.832

2024-03-23 02:21:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 02:21:10 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 02:21:26 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 02:21:39 [DEBUG] XGB validation: p-rmse: 1.712881	a-peak@32: 0.321195
2024-03-23 02:21:40 [DEBUG] XGB iter   0: tr-p-rmse: 2.078455	tr-a-peak@32: 1.000000	tr-rmse: 0.751207	tr-rmse: 0.751207
2024-03-23 02:21:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.204721	tr-a-peak@32: 0.654596	tr-rmse: 0.548434	tr-rmse: 0.548434
2024-03-23 02:21:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.204641	tr-a-peak@32: 0.654596	tr-rmse: 0.548492	tr-rmse: 0.548492
2024-03-23 02:21:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.204641	tr-a-peak@32: 0.654596	tr-rmse: 0.548492	tr-rmse: 0.548492
2024-03-23 02:21:40 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20461	tr-a-peak@32:0.65460	tr-rmse:0.54851	tr-rmse:0.54851 
2024-03-23 02:21:41 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 02:21:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |       837.5262 |       7.4580 |                7.4580 |     63 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2889
Total latency (us): 236.832

2024-03-23 02:21:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 02:21:52 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:22:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:22:37 [DEBUG] XGB validation: p-rmse: 0.489835	a-peak@32: 0.639861
2024-03-23 02:22:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.084985	tr-a-peak@32: 1.000000	tr-rmse: 0.747101	tr-rmse: 0.747101
2024-03-23 02:22:38 [DEBUG] XGB iter  25: tr-p-rmse: 0.203352	tr-a-peak@32: 0.593088	tr-rmse: 0.544826	tr-rmse: 0.544826
2024-03-23 02:22:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.203217	tr-a-peak@32: 0.593088	tr-rmse: 0.544924	tr-rmse: 0.544924
2024-03-23 02:22:38 [DEBUG] XGB iter  75: tr-p-rmse: 0.203217	tr-a-peak@32: 0.593088	tr-rmse: 0.544924	tr-rmse: 0.544924
2024-03-23 02:22:38 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20315	tr-a-peak@32:0.59309	tr-rmse:0.54497	tr-rmse:0.54497 
2024-03-23 02:22:38 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 02:22:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      2805.3479 |      10.9054 |               21.8109 |    192 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 2953
Total latency (us): 235.508

2024-03-23 02:22:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:23:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:23:43 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:24:16 [DEBUG] XGB validation: p-rmse: 0.661004	a-peak@32: 0.821293
2024-03-23 02:24:16 [DEBUG] XGB iter   0: tr-p-rmse: 2.083062	tr-a-peak@32: 1.000000	tr-rmse: 0.753044	tr-rmse: 0.753044
2024-03-23 02:24:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.219084	tr-a-peak@32: 0.215727	tr-rmse: 0.548590	tr-rmse: 0.548590
2024-03-23 02:24:17 [DEBUG] XGB iter  50: tr-p-rmse: 0.219005	tr-a-peak@32: 0.215727	tr-rmse: 0.548647	tr-rmse: 0.548647
2024-03-23 02:24:17 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21885	tr-a-peak@32:0.21573	tr-rmse:0.54879	tr-rmse:0.54879 
2024-03-23 02:24:17 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:24:17 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    256 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1720.8014 |       7.2566 |                7.2566 |     64 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3017
Total latency (us): 233.852

2024-03-23 02:24:17 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 02:24:29 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:24:37 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:25:14 [DEBUG] XGB validation: p-rmse: 0.627979	a-peak@32: 0.873758
2024-03-23 02:25:14 [DEBUG] XGB iter   0: tr-p-rmse: 2.096589	tr-a-peak@32: 1.000000	tr-rmse: 0.748513	tr-rmse: 0.748513
2024-03-23 02:25:14 [DEBUG] XGB iter  25: tr-p-rmse: 0.223029	tr-a-peak@32: 0.000000	tr-rmse: 0.546733	tr-rmse: 0.546733
2024-03-23 02:25:14 [DEBUG] XGB iter  50: tr-p-rmse: 0.222960	tr-a-peak@32: 0.000000	tr-rmse: 0.546778	tr-rmse: 0.546778
2024-03-23 02:25:15 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.22278	tr-a-peak@32:0.00000	tr-rmse:0.54690	tr-rmse:0.54690 
2024-03-23 02:25:15 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 02:25:15 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    256 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5341.6738 |      32.4606 |               32.4606 |    319 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3081
Total latency (us): 233.088

2024-03-23 02:25:15 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:25:26 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 02:25:32 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 02:26:05 [DEBUG] XGB validation: p-rmse: 0.533759	a-peak@32: 0.590687
2024-03-23 02:26:05 [DEBUG] XGB iter   0: tr-p-rmse: 2.093084	tr-a-peak@32: 1.000000	tr-rmse: 0.747157	tr-rmse: 0.747157
2024-03-23 02:26:06 [DEBUG] XGB iter  25: tr-p-rmse: 0.207613	tr-a-peak@32: 0.499492	tr-rmse: 0.550600	tr-rmse: 0.550600
2024-03-23 02:26:06 [DEBUG] XGB iter  50: tr-p-rmse: 0.207193	tr-a-peak@32: 0.500000	tr-rmse: 0.550647	tr-rmse: 0.550647
2024-03-23 02:26:06 [DEBUG] XGB iter  75: tr-p-rmse: 0.207193	tr-a-peak@32: 0.500000	tr-rmse: 0.550647	tr-rmse: 0.550647
2024-03-23 02:26:06 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.20717	tr-a-peak@32:0.50000	tr-rmse:0.55067	tr-rmse:0.55067 
2024-03-23 02:26:06 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:26:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    256 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1598.1293 |      11.3434 |               22.6868 |    256 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3144
Total latency (us): 232.731

2024-03-23 02:26:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:27:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:27:16 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:27:47 [DEBUG] XGB validation: p-rmse: 0.818851	a-peak@32: 0.753842
2024-03-23 02:27:47 [DEBUG] XGB iter   0: tr-p-rmse: 2.114348	tr-a-peak@32: 1.000000	tr-rmse: 0.742208	tr-rmse: 0.742208
2024-03-23 02:27:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.211678	tr-a-peak@32: 0.312500	tr-rmse: 0.543057	tr-rmse: 0.543057
2024-03-23 02:27:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.211616	tr-a-peak@32: 0.312500	tr-rmse: 0.543093	tr-rmse: 0.543093
2024-03-23 02:27:48 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.21145	tr-a-peak@32:0.31250	tr-rmse:0.54319	tr-rmse:0.54319 
2024-03-23 02:27:48 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:27:48 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    256 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3208
Total latency (us): 230.61

2024-03-23 02:27:48 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:28:42 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:29:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:29:27 [DEBUG] XGB validation: p-rmse: 1.073097	a-peak@32: 0.992150
2024-03-23 02:29:27 [DEBUG] XGB iter   0: tr-p-rmse: 2.121735	tr-a-peak@32: 1.000000	tr-rmse: 0.743071	tr-rmse: 0.743071
2024-03-23 02:29:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.249587	tr-a-peak@32: 0.124008	tr-rmse: 0.543198	tr-rmse: 0.543198
2024-03-23 02:29:28 [DEBUG] XGB iter  50: tr-p-rmse: 0.249492	tr-a-peak@32: 0.124008	tr-rmse: 0.543242	tr-rmse: 0.543242
2024-03-23 02:29:28 [DEBUG] XGB iter  75: tr-p-rmse: 0.249492	tr-a-peak@32: 0.124008	tr-rmse: 0.543242	tr-rmse: 0.543242
2024-03-23 02:29:28 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.24946	tr-a-peak@32:0.12401	tr-rmse:0.54326	tr-rmse:0.54326 
2024-03-23 02:29:28 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:29:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3264.3200 |      10.8784 |               21.7568 |    256 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3272
Total latency (us): 230.61

2024-03-23 02:29:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:30:21 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:30:43 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:31:01 [DEBUG] XGB validation: p-rmse: 0.959772	a-peak@32: 0.000000
2024-03-23 02:31:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.133672	tr-a-peak@32: 0.995577	tr-rmse: 0.745705	tr-rmse: 0.745705
2024-03-23 02:31:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.259888	tr-a-peak@32: 0.218750	tr-rmse: 0.543978	tr-rmse: 0.543978
2024-03-23 02:31:02 [DEBUG] XGB iter  50: tr-p-rmse: 0.259671	tr-a-peak@32: 0.218750	tr-rmse: 0.544067	tr-rmse: 0.544067
2024-03-23 02:31:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.259671	tr-a-peak@32: 0.218750	tr-rmse: 0.544067	tr-rmse: 0.544067
2024-03-23 02:31:02 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.25959	tr-a-peak@32:0.21875	tr-rmse:0.54410	tr-rmse:0.54410 
2024-03-23 02:31:02 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:31:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4026.8204 |      11.2607 |               22.5214 |    256 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3336
Total latency (us): 229.79

2024-03-23 02:31:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:31:53 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:32:13 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:32:50 [DEBUG] XGB validation: p-rmse: 0.475458	a-peak@32: 0.792031
2024-03-23 02:32:50 [DEBUG] XGB iter   0: tr-p-rmse: 2.151969	tr-a-peak@32: 0.995577	tr-rmse: 0.761035	tr-rmse: 0.761035
2024-03-23 02:32:51 [DEBUG] XGB iter  25: tr-p-rmse: 0.278725	tr-a-peak@32: 0.000000	tr-rmse: 0.551423	tr-rmse: 0.551423
2024-03-23 02:32:51 [DEBUG] XGB iter  50: tr-p-rmse: 0.277952	tr-a-peak@32: 0.000000	tr-rmse: 0.551441	tr-rmse: 0.551441
2024-03-23 02:32:51 [DEBUG] XGB iter  75: tr-p-rmse: 0.277952	tr-a-peak@32: 0.000000	tr-rmse: 0.551441	tr-rmse: 0.551441
2024-03-23 02:32:51 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.27790	tr-a-peak@32:0.00000	tr-rmse:0.55146	tr-rmse:0.55146 
2024-03-23 02:32:51 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:32:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    382 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3400
Total latency (us): 229.171

2024-03-23 02:32:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:33:02 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:33:09 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:33:45 [DEBUG] XGB validation: p-rmse: 0.722814	a-peak@32: 0.551133
2024-03-23 02:33:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.171985	tr-a-peak@32: 0.997811	tr-rmse: 0.757130	tr-rmse: 0.757130
2024-03-23 02:33:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.275500	tr-a-peak@32: 0.000000	tr-rmse: 0.551248	tr-rmse: 0.551248
2024-03-23 02:33:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.275317	tr-a-peak@32: 0.000000	tr-rmse: 0.551326	tr-rmse: 0.551326
2024-03-23 02:33:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.275317	tr-a-peak@32: 0.000000	tr-rmse: 0.551326	tr-rmse: 0.551326
2024-03-23 02:33:46 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.27524	tr-a-peak@32:0.00000	tr-rmse:0.55136	tr-rmse:0.55136 
2024-03-23 02:33:46 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:33:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4010.0744 |      11.0119 |               11.0119 |    128 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3464
Total latency (us): 229.171

2024-03-23 02:33:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:33:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:34:05 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:34:20 [DEBUG] XGB validation: p-rmse: 1.404909	a-peak@32: 0.222408
2024-03-23 02:34:20 [DEBUG] XGB iter   0: tr-p-rmse: 2.160614	tr-a-peak@32: 0.997811	tr-rmse: 0.756809	tr-rmse: 0.756809
2024-03-23 02:34:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.294328	tr-a-peak@32: 0.000000	tr-rmse: 0.550816	tr-rmse: 0.550816
2024-03-23 02:34:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.294168	tr-a-peak@32: 0.000000	tr-rmse: 0.550887	tr-rmse: 0.550887
2024-03-23 02:34:21 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.29398	tr-a-peak@32:0.00000	tr-rmse:0.55105	tr-rmse:0.55105 
2024-03-23 02:34:21 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:34:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       760.0043 |       5.4862 |                5.4862 |     64 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3528
Total latency (us): 228.317

2024-03-23 02:34:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 02:34:31 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:34:40 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:35:11 [DEBUG] XGB validation: p-rmse: 0.844688	a-peak@32: 0.834598
2024-03-23 02:35:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.145889	tr-a-peak@32: 0.994252	tr-rmse: 0.753894	tr-rmse: 0.753894
2024-03-23 02:35:12 [DEBUG] XGB iter  25: tr-p-rmse: 0.264688	tr-a-peak@32: 0.000000	tr-rmse: 0.550352	tr-rmse: 0.550352
2024-03-23 02:35:12 [DEBUG] XGB iter  50: tr-p-rmse: 0.264464	tr-a-peak@32: 0.000000	tr-rmse: 0.550473	tr-rmse: 0.550473
2024-03-23 02:35:12 [DEBUG] XGB stopped. Best iteration: [16] tr-p-rmse:0.26396	tr-a-peak@32:0.20965	tr-rmse:0.55323	tr-rmse:0.55323 
2024-03-23 02:35:12 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 02:35:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    446 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3592
Total latency (us): 228.068

2024-03-23 02:35:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:35:23 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:35:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:36:19 [DEBUG] XGB validation: p-rmse: 0.113872	a-peak@32: 0.979876
2024-03-23 02:36:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.110825	tr-a-peak@32: 0.492926	tr-rmse: 0.750484	tr-rmse: 0.750484
2024-03-23 02:36:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.260735	tr-a-peak@32: 0.000000	tr-rmse: 0.554803	tr-rmse: 0.554803
2024-03-23 02:36:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.260560	tr-a-peak@32: 0.000000	tr-rmse: 0.554877	tr-rmse: 0.554877
2024-03-23 02:36:20 [DEBUG] XGB iter  75: tr-p-rmse: 0.260560	tr-a-peak@32: 0.000000	tr-rmse: 0.554877	tr-rmse: 0.554877
2024-03-23 02:36:20 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.26050	tr-a-peak@32:0.00000	tr-rmse:0.55490	tr-rmse:0.55490 
2024-03-23 02:36:20 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:36:20 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1159.4114 |       4.8510 |                9.7020 |    128 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3656
Total latency (us): 228.068

2024-03-23 02:36:20 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 02:36:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:36:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:37:08 [DEBUG] XGB validation: p-rmse: 0.509027	a-peak@32: 0.823536
2024-03-23 02:37:08 [DEBUG] XGB iter   0: tr-p-rmse: 2.097572	tr-a-peak@32: 0.475513	tr-rmse: 0.747420	tr-rmse: 0.747420
2024-03-23 02:37:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.252504	tr-a-peak@32: 0.218379	tr-rmse: 0.557990	tr-rmse: 0.557990
2024-03-23 02:37:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.252456	tr-a-peak@32: 0.218379	tr-rmse: 0.558007	tr-rmse: 0.558007
2024-03-23 02:37:09 [DEBUG] XGB stopped. Best iteration: [22] tr-p-rmse:0.25189	tr-a-peak@32:0.21843	tr-rmse:0.55825	tr-rmse:0.55825 
2024-03-23 02:37:09 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 02:37:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      1762.9530 |      10.2829 |               20.5658 |    320 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3720
Total latency (us): 226.934

2024-03-23 02:37:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:38:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:38:24 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:39:00 [DEBUG] XGB validation: p-rmse: 0.600348	a-peak@32: 0.952336
2024-03-23 02:39:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.109403	tr-a-peak@32: 0.669340	tr-rmse: 0.743465	tr-rmse: 0.743465
2024-03-23 02:39:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.238780	tr-a-peak@32: 0.187500	tr-rmse: 0.552058	tr-rmse: 0.552058
2024-03-23 02:39:01 [DEBUG] XGB iter  50: tr-p-rmse: 0.238733	tr-a-peak@32: 0.187500	tr-rmse: 0.552079	tr-rmse: 0.552079
2024-03-23 02:39:02 [DEBUG] XGB stopped. Best iteration: [24] tr-p-rmse:0.23867	tr-a-peak@32:0.18750	tr-rmse:0.55212	tr-rmse:0.55212 
2024-03-23 02:39:02 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:39:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3392.2339 |      10.4682 |               20.9364 |    320 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3784
Total latency (us): 224.169

2024-03-23 02:39:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:39:53 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:40:13 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:40:49 [DEBUG] XGB validation: p-rmse: 0.192658	a-peak@32: 0.981260
2024-03-23 02:40:49 [DEBUG] XGB iter   0: tr-p-rmse: 2.127507	tr-a-peak@32: 0.718466	tr-rmse: 0.762323	tr-rmse: 0.762323
2024-03-23 02:40:50 [DEBUG] XGB iter  25: tr-p-rmse: 0.237858	tr-a-peak@32: 0.718750	tr-rmse: 0.562619	tr-rmse: 0.562619
2024-03-23 02:40:50 [DEBUG] XGB iter  50: tr-p-rmse: 0.237658	tr-a-peak@32: 0.718750	tr-rmse: 0.562707	tr-rmse: 0.562707
2024-03-23 02:40:50 [DEBUG] XGB iter  75: tr-p-rmse: 0.237658	tr-a-peak@32: 0.718750	tr-rmse: 0.562707	tr-rmse: 0.562707
2024-03-23 02:40:50 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.23758	tr-a-peak@32:0.71875	tr-rmse:0.56274	tr-rmse:0.56274 
2024-03-23 02:40:50 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:40:50 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3848
Total latency (us): 222.869

2024-03-23 02:40:50 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #19: "fused_concatenate_2"
2024-03-23 02:40:52 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 02:40:52 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 02:40:52 [INFO] [task_scheduler.cc:237] [Updated] Task #19: "fused_concatenate_2"
2024-03-23 02:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3848
Total latency (us): 222.869

2024-03-23 02:40:52 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-03-23 02:40:55 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 02:40:55 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 02:40:55 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-03-23 02:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |     63 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3848
Total latency (us): 222.869

2024-03-23 02:40:55 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 02:41:05 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:41:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:41:45 [DEBUG] XGB validation: p-rmse: 0.553838	a-peak@32: 0.895387
2024-03-23 02:41:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.103143	tr-a-peak@32: 0.635091	tr-rmse: 0.758041	tr-rmse: 0.758041
2024-03-23 02:41:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.236298	tr-a-peak@32: 0.624669	tr-rmse: 0.562197	tr-rmse: 0.562197
2024-03-23 02:41:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.235433	tr-a-peak@32: 0.624669	tr-rmse: 0.562218	tr-rmse: 0.562218
2024-03-23 02:41:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.235433	tr-a-peak@32: 0.624669	tr-rmse: 0.562218	tr-rmse: 0.562218
2024-03-23 02:41:46 [DEBUG] XGB stopped. Best iteration: [29] tr-p-rmse:0.23543	tr-a-peak@32:0.62467	tr-rmse:0.56222	tr-rmse:0.56222 
2024-03-23 02:41:46 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 02:41:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3912
Total latency (us): 222.869

2024-03-23 02:41:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-03-23 02:41:48 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 02:41:48 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 02:41:48 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-03-23 02:41:48 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4140.6101 |      10.9513 |               21.9025 |    320 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3912
Total latency (us): 222.869

2024-03-23 02:41:48 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:42:40 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:43:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:43:37 [DEBUG] XGB validation: p-rmse: 0.328458	a-peak@32: 0.857208
2024-03-23 02:43:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.128954	tr-a-peak@32: 0.498576	tr-rmse: 0.775769	tr-rmse: 0.775769
2024-03-23 02:43:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.237291	tr-a-peak@32: 0.404927	tr-rmse: 0.572566	tr-rmse: 0.572566
2024-03-23 02:43:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.237120	tr-a-peak@32: 0.404927	tr-rmse: 0.572646	tr-rmse: 0.572646
2024-03-23 02:43:38 [DEBUG] XGB iter  75: tr-p-rmse: 0.237120	tr-a-peak@32: 0.404927	tr-rmse: 0.572646	tr-rmse: 0.572646
2024-03-23 02:43:38 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.23705	tr-a-peak@32:0.40493	tr-rmse:0.57268	tr-rmse:0.57268 
2024-03-23 02:43:38 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:43:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3035.9669 |      10.0770 |               20.1541 |    320 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 3976
Total latency (us): 222.492

2024-03-23 02:43:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:44:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:44:40 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:45:18 [DEBUG] XGB validation: p-rmse: 0.749767	a-peak@32: 0.409295
2024-03-23 02:45:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.146404	tr-a-peak@32: 0.691593	tr-rmse: 0.778293	tr-rmse: 0.778293
2024-03-23 02:45:19 [DEBUG] XGB iter  25: tr-p-rmse: 0.242409	tr-a-peak@32: 0.218419	tr-rmse: 0.572247	tr-rmse: 0.572247
2024-03-23 02:45:19 [DEBUG] XGB iter  50: tr-p-rmse: 0.241384	tr-a-peak@32: 0.218750	tr-rmse: 0.572278	tr-rmse: 0.572278
2024-03-23 02:45:20 [DEBUG] XGB iter  75: tr-p-rmse: 0.241384	tr-a-peak@32: 0.218750	tr-rmse: 0.572278	tr-rmse: 0.572278
2024-03-23 02:45:20 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.24138	tr-a-peak@32:0.21875	tr-rmse:0.57228	tr-rmse:0.57228 
2024-03-23 02:45:20 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:45:20 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    510 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4040
Total latency (us): 221.818

2024-03-23 02:45:20 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:45:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:45:36 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:46:11 [DEBUG] XGB validation: p-rmse: 0.543598	a-peak@32: 0.757435
2024-03-23 02:46:11 [DEBUG] XGB iter   0: tr-p-rmse: 2.128954	tr-a-peak@32: 0.806983	tr-rmse: 0.774772	tr-rmse: 0.774772
2024-03-23 02:46:11 [DEBUG] XGB iter  25: tr-p-rmse: 0.227402	tr-a-peak@32: 0.406250	tr-rmse: 0.573280	tr-rmse: 0.573280
2024-03-23 02:46:12 [DEBUG] XGB iter  50: tr-p-rmse: 0.227001	tr-a-peak@32: 0.406250	tr-rmse: 0.573394	tr-rmse: 0.573394
2024-03-23 02:46:12 [DEBUG] XGB iter  75: tr-p-rmse: 0.227001	tr-a-peak@32: 0.406250	tr-rmse: 0.573394	tr-rmse: 0.573394
2024-03-23 02:46:12 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.22698	tr-a-peak@32:0.40625	tr-rmse:0.57341	tr-rmse:0.57341 
2024-03-23 02:46:12 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:46:12 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1500.1939 |       7.9927 |                7.9927 |    128 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4104
Total latency (us): 221.818

2024-03-23 02:46:12 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 02:46:24 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:46:31 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:47:07 [DEBUG] XGB validation: p-rmse: 0.610626	a-peak@32: 0.755796
2024-03-23 02:47:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.115222	tr-a-peak@32: 0.659105	tr-rmse: 0.770735	tr-rmse: 0.770735
2024-03-23 02:47:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.234401	tr-a-peak@32: 0.406250	tr-rmse: 0.571258	tr-rmse: 0.571258
2024-03-23 02:47:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.232879	tr-a-peak@32: 0.406250	tr-rmse: 0.571287	tr-rmse: 0.571287
2024-03-23 02:47:08 [DEBUG] XGB iter  75: tr-p-rmse: 0.232879	tr-a-peak@32: 0.406250	tr-rmse: 0.571287	tr-rmse: 0.571287
2024-03-23 02:47:08 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.23282	tr-a-peak@32:0.40625	tr-rmse:0.57131	tr-rmse:0.57131 
2024-03-23 02:47:08 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 02:47:08 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    128 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4168
Total latency (us): 220.965

2024-03-23 02:47:08 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 02:47:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:47:28 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:48:02 [DEBUG] XGB validation: p-rmse: 0.704058	a-peak@32: 0.693520
2024-03-23 02:48:02 [DEBUG] XGB iter   0: tr-p-rmse: 2.111153	tr-a-peak@32: 0.438077	tr-rmse: 0.767390	tr-rmse: 0.767390
2024-03-23 02:48:02 [DEBUG] XGB iter  25: tr-p-rmse: 0.220592	tr-a-peak@32: 0.625000	tr-rmse: 0.571482	tr-rmse: 0.571482
2024-03-23 02:48:03 [DEBUG] XGB iter  50: tr-p-rmse: 0.220012	tr-a-peak@32: 0.625000	tr-rmse: 0.571580	tr-rmse: 0.571580
2024-03-23 02:48:03 [DEBUG] XGB iter  75: tr-p-rmse: 0.220012	tr-a-peak@32: 0.625000	tr-rmse: 0.571580	tr-rmse: 0.571580
2024-03-23 02:48:03 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.21989	tr-a-peak@32:0.62500	tr-rmse:0.57164	tr-rmse:0.57164 
2024-03-23 02:48:03 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 02:48:03 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    384 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4232
Total latency (us): 220.965

2024-03-23 02:48:03 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:49:00 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:49:40 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:50:15 [DEBUG] XGB validation: p-rmse: 0.231075	a-peak@32: 0.926207
2024-03-23 02:50:15 [DEBUG] XGB iter   0: tr-p-rmse: 2.114248	tr-a-peak@32: 0.808548	tr-rmse: 0.787717	tr-rmse: 0.787717
2024-03-23 02:50:16 [DEBUG] XGB iter  25: tr-p-rmse: 0.225251	tr-a-peak@32: 0.468750	tr-rmse: 0.584282	tr-rmse: 0.584282
2024-03-23 02:50:16 [DEBUG] XGB iter  50: tr-p-rmse: 0.224402	tr-a-peak@32: 0.468750	tr-rmse: 0.584416	tr-rmse: 0.584416
2024-03-23 02:50:17 [DEBUG] XGB iter  75: tr-p-rmse: 0.224402	tr-a-peak@32: 0.468750	tr-rmse: 0.584416	tr-rmse: 0.584416
2024-03-23 02:50:17 [DEBUG] XGB stopped. Best iteration: [26] tr-p-rmse:0.22426	tr-a-peak@32:0.46875	tr-rmse:0.58451	tr-rmse:0.58451 
2024-03-23 02:50:17 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 02:50:17 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1114.5278 |       7.4725 |                7.4725 |    127 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4296
Total latency (us): 220.965

2024-03-23 02:50:17 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 02:50:27 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:50:34 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:51:04 [DEBUG] XGB validation: p-rmse: 0.651578	a-peak@32: 0.964347
2024-03-23 02:51:04 [DEBUG] XGB iter   0: tr-p-rmse: 2.132786	tr-a-peak@32: 0.455242	tr-rmse: 0.786087	tr-rmse: 0.786087
2024-03-23 02:51:05 [DEBUG] XGB iter  25: tr-p-rmse: 0.233012	tr-a-peak@32: 0.000000	tr-rmse: 0.584140	tr-rmse: 0.584140
2024-03-23 02:51:05 [DEBUG] XGB iter  50: tr-p-rmse: 0.231763	tr-a-peak@32: 0.000000	tr-rmse: 0.584214	tr-rmse: 0.584214
2024-03-23 02:51:05 [DEBUG] XGB iter  75: tr-p-rmse: 0.231763	tr-a-peak@32: 0.000000	tr-rmse: 0.584214	tr-rmse: 0.584214
2024-03-23 02:51:05 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.23170	tr-a-peak@32:0.00000	tr-rmse:0.58424	tr-rmse:0.58424 
2024-03-23 02:51:05 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 02:51:05 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    384 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4360
Total latency (us): 220.249

2024-03-23 02:51:05 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:51:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:52:43 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:52:45 [DEBUG] XGB validation: p-rmse: 0.958872	a-peak@32: 1.000000
2024-03-23 02:52:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.134273	tr-a-peak@32: 0.458522	tr-rmse: 0.786087	tr-rmse: 0.786087
2024-03-23 02:52:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.271420	tr-a-peak@32: 0.000000	tr-rmse: 0.584140	tr-rmse: 0.584140
2024-03-23 02:52:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.270227	tr-a-peak@32: 0.000000	tr-rmse: 0.584214	tr-rmse: 0.584214
2024-03-23 02:52:47 [DEBUG] XGB iter  75: tr-p-rmse: 0.270227	tr-a-peak@32: 0.000000	tr-rmse: 0.584214	tr-rmse: 0.584214
2024-03-23 02:52:47 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.27016	tr-a-peak@32:0.00000	tr-rmse:0.58424	tr-rmse:0.58424 
2024-03-23 02:52:47 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 02:52:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5400.9727 |      32.1042 |               32.1042 |    574 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4424
Total latency (us): 220.249

2024-03-23 02:52:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:52:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:53:04 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:53:29 [DEBUG] XGB validation: p-rmse: 0.613830	a-peak@32: 0.187421
2024-03-23 02:53:29 [DEBUG] XGB iter   0: tr-p-rmse: 2.099982	tr-a-peak@32: 0.619907	tr-rmse: 0.784138	tr-rmse: 0.784138
2024-03-23 02:53:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.269816	tr-a-peak@32: 0.312063	tr-rmse: 0.586601	tr-rmse: 0.586601
2024-03-23 02:53:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.269392	tr-a-peak@32: 0.312500	tr-rmse: 0.586712	tr-rmse: 0.586712
2024-03-23 02:53:30 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26730	tr-a-peak@32:0.50000	tr-rmse:0.59132	tr-rmse:0.59132 
2024-03-23 02:53:30 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:53:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    384 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4488
Total latency (us): 220.217

2024-03-23 02:53:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:54:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:54:39 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:54:42 [DEBUG] XGB validation: p-rmse: 1.050486	a-peak@32: 1.000000
2024-03-23 02:54:42 [DEBUG] XGB iter   0: tr-p-rmse: 2.112790	tr-a-peak@32: 0.620997	tr-rmse: 0.784437	tr-rmse: 0.784437
2024-03-23 02:54:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.305642	tr-a-peak@32: 0.000000	tr-rmse: 0.586736	tr-rmse: 0.586736
2024-03-23 02:54:43 [DEBUG] XGB iter  50: tr-p-rmse: 0.304510	tr-a-peak@32: 0.000000	tr-rmse: 0.586831	tr-rmse: 0.586831
2024-03-23 02:54:43 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.30132	tr-a-peak@32:0.00000	tr-rmse:0.59500	tr-rmse:0.59500 
2024-03-23 02:54:43 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 02:54:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1796.0204 |       3.4290 |                6.8580 |    128 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4552
Total latency (us): 220.217

2024-03-23 02:54:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 02:54:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:55:02 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:55:21 [DEBUG] XGB validation: p-rmse: 1.073795	a-peak@32: 0.084865
2024-03-23 02:55:21 [DEBUG] XGB iter   0: tr-p-rmse: 2.090264	tr-a-peak@32: 0.450544	tr-rmse: 0.782363	tr-rmse: 0.782363
2024-03-23 02:55:22 [DEBUG] XGB iter  25: tr-p-rmse: 0.301997	tr-a-peak@32: 0.000000	tr-rmse: 0.586874	tr-rmse: 0.586874
2024-03-23 02:55:22 [DEBUG] XGB iter  50: tr-p-rmse: 0.301292	tr-a-peak@32: 0.000000	tr-rmse: 0.586937	tr-rmse: 0.586937
2024-03-23 02:55:22 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.29669	tr-a-peak@32:0.12500	tr-rmse:0.59473	tr-rmse:0.59473 
2024-03-23 02:55:22 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 02:55:22 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    192 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4616
Total latency (us): 220.033

2024-03-23 02:55:22 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:55:34 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:55:44 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:55:46 [DEBUG] XGB validation: p-rmse: 1.160954	a-peak@32: 1.000000
2024-03-23 02:55:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.082975	tr-a-peak@32: 0.016373	tr-rmse: 0.782363	tr-rmse: 0.782363
2024-03-23 02:55:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.321678	tr-a-peak@32: 0.000000	tr-rmse: 0.586874	tr-rmse: 0.586874
2024-03-23 02:55:47 [DEBUG] XGB iter  50: tr-p-rmse: 0.320951	tr-a-peak@32: 0.000000	tr-rmse: 0.586937	tr-rmse: 0.586937
2024-03-23 02:55:47 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.31597	tr-a-peak@32:0.00000	tr-rmse:0.59473	tr-rmse:0.59473 
2024-03-23 02:55:47 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 02:55:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     61 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4680
Total latency (us): 220.033

2024-03-23 02:55:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #5: "fused_nn_max_pool2d"
2024-03-23 02:55:51 [INFO] [task_scheduler.cc:193] Sending 9 sample(s) to builder
2024-03-23 02:55:52 [INFO] [task_scheduler.cc:195] Sending 9 sample(s) to runner
2024-03-23 02:55:52 [DEBUG] XGB validation: p-rmse: 0.517468	a-peak@32: 1.000000
2024-03-23 02:55:52 [DEBUG] XGB iter   0: tr-p-rmse: 2.082642	tr-a-peak@32: 0.016373	tr-rmse: 0.782363	tr-rmse: 0.782363
2024-03-23 02:55:53 [DEBUG] XGB iter  25: tr-p-rmse: 0.321764	tr-a-peak@32: 0.000000	tr-rmse: 0.586874	tr-rmse: 0.586874
2024-03-23 02:55:53 [DEBUG] XGB iter  50: tr-p-rmse: 0.321037	tr-a-peak@32: 0.000000	tr-rmse: 0.586937	tr-rmse: 0.586937
2024-03-23 02:55:53 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.31605	tr-a-peak@32:0.00000	tr-rmse:0.59473	tr-rmse:0.59473 
2024-03-23 02:55:53 [INFO] [task_scheduler.cc:237] [Updated] Task #5: "fused_nn_max_pool2d"
2024-03-23 02:55:53 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    384 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4689
Total latency (us): 220.033

2024-03-23 02:55:53 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:56:49 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:57:25 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:57:51 [DEBUG] XGB validation: p-rmse: 0.990137	a-peak@32: 0.375000
2024-03-23 02:57:51 [DEBUG] XGB iter   0: tr-p-rmse: 2.091027	tr-a-peak@32: 0.004920	tr-rmse: 0.787228	tr-rmse: 0.787228
2024-03-23 02:57:52 [DEBUG] XGB iter  25: tr-p-rmse: 0.329289	tr-a-peak@32: 0.000000	tr-rmse: 0.588322	tr-rmse: 0.588322
2024-03-23 02:57:52 [DEBUG] XGB iter  50: tr-p-rmse: 0.328687	tr-a-peak@32: 0.000000	tr-rmse: 0.588400	tr-rmse: 0.588400
2024-03-23 02:57:52 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.32432	tr-a-peak@32:0.00000	tr-rmse:0.59578	tr-rmse:0.59578 
2024-03-23 02:57:53 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 02:57:53 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      1923.2276 |       6.4928 |                6.4928 |    128 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4753
Total latency (us): 220.033

2024-03-23 02:57:53 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 02:58:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:58:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:58:47 [DEBUG] XGB validation: p-rmse: 0.666635	a-peak@32: 0.651607
2024-03-23 02:58:47 [DEBUG] XGB iter   0: tr-p-rmse: 2.095694	tr-a-peak@32: 0.194260	tr-rmse: 0.783711	tr-rmse: 0.783711
2024-03-23 02:58:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.311368	tr-a-peak@32: 0.000000	tr-rmse: 0.586127	tr-rmse: 0.586127
2024-03-23 02:58:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.311187	tr-a-peak@32: 0.000000	tr-rmse: 0.586186	tr-rmse: 0.586186
2024-03-23 02:58:48 [DEBUG] XGB stopped. Best iteration: [10] tr-p-rmse:0.30353	tr-a-peak@32:0.50000	tr-rmse:0.59791	tr-rmse:0.59791 
2024-03-23 02:58:48 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 02:58:48 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    638 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4817
Total latency (us): 218.53

2024-03-23 02:58:48 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:58:58 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 02:59:06 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 02:59:45 [DEBUG] XGB validation: p-rmse: 0.053298	a-peak@32: 0.996522
2024-03-23 02:59:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.085297	tr-a-peak@32: 0.009018	tr-rmse: 0.781310	tr-rmse: 0.781310
2024-03-23 02:59:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.322953	tr-a-peak@32: 0.000000	tr-rmse: 0.590878	tr-rmse: 0.590878
2024-03-23 02:59:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.321531	tr-a-peak@32: 0.000000	tr-rmse: 0.590871	tr-rmse: 0.590871
2024-03-23 02:59:46 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.31710	tr-a-peak@32:0.00000	tr-rmse:0.59763	tr-rmse:0.59763 
2024-03-23 02:59:46 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 02:59:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4213.1079 |      10.7628 |               21.5256 |    448 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4881
Total latency (us): 218.53

2024-03-23 02:59:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:00:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:01:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:01:37 [DEBUG] XGB validation: p-rmse: 0.472488	a-peak@32: 0.903143
2024-03-23 03:01:37 [DEBUG] XGB iter   0: tr-p-rmse: 2.096544	tr-a-peak@32: 0.106840	tr-rmse: 0.792643	tr-rmse: 0.792643
2024-03-23 03:01:37 [DEBUG] XGB iter  25: tr-p-rmse: 0.324824	tr-a-peak@32: 0.000000	tr-rmse: 0.596495	tr-rmse: 0.596495
2024-03-23 03:01:38 [DEBUG] XGB iter  50: tr-p-rmse: 0.324354	tr-a-peak@32: 0.000000	tr-rmse: 0.596557	tr-rmse: 0.596557
2024-03-23 03:01:38 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.31888	tr-a-peak@32:0.00000	tr-rmse:0.60449	tr-rmse:0.60449 
2024-03-23 03:01:38 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:01:38 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    127 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 4945
Total latency (us): 218.011

2024-03-23 03:01:38 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 03:01:50 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 03:01:57 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 03:02:32 [DEBUG] XGB validation: p-rmse: 0.511957	a-peak@32: 0.776116
2024-03-23 03:02:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.082740	tr-a-peak@32: 0.374665	tr-rmse: 0.788806	tr-rmse: 0.788806
2024-03-23 03:02:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.318856	tr-a-peak@32: 0.000000	tr-rmse: 0.595566	tr-rmse: 0.595566
2024-03-23 03:02:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.318749	tr-a-peak@32: 0.000000	tr-rmse: 0.595646	tr-rmse: 0.595646
2024-03-23 03:02:34 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.31558	tr-a-peak@32:0.00000	tr-rmse:0.60321	tr-rmse:0.60321 
2024-03-23 03:02:34 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 03:02:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3616.8134 |       9.8182 |               19.6364 |    448 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5008
Total latency (us): 218.011

2024-03-23 03:02:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:03:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:04:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:04:46 [DEBUG] XGB validation: p-rmse: 0.569874	a-peak@32: 0.960252
2024-03-23 03:04:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.120763	tr-a-peak@32: 0.000000	tr-rmse: 0.799478	tr-rmse: 0.799478
2024-03-23 03:04:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.306572	tr-a-peak@32: 0.000000	tr-rmse: 0.599647	tr-rmse: 0.599647
2024-03-23 03:04:47 [DEBUG] XGB iter  50: tr-p-rmse: 0.306078	tr-a-peak@32: 0.000000	tr-rmse: 0.599740	tr-rmse: 0.599740
2024-03-23 03:04:47 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.30110	tr-a-peak@32:0.00000	tr-rmse:0.60808	tr-rmse:0.60808 
2024-03-23 03:04:47 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:04:47 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2036.8073 |       8.9003 |               17.8007 |    448 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5072
Total latency (us): 217.787

2024-03-23 03:04:47 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:05:42 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:05:54 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:06:31 [DEBUG] XGB validation: p-rmse: 0.749912	a-peak@32: 0.999692
2024-03-23 03:06:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.130843	tr-a-peak@32: 0.212948	tr-rmse: 0.800501	tr-rmse: 0.800501
2024-03-23 03:06:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.314765	tr-a-peak@32: 0.000000	tr-rmse: 0.599848	tr-rmse: 0.599848
2024-03-23 03:06:32 [DEBUG] XGB iter  50: tr-p-rmse: 0.313785	tr-a-peak@32: 0.000000	tr-rmse: 0.599944	tr-rmse: 0.599944
2024-03-23 03:06:32 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.31303	tr-a-peak@32:0.00000	tr-rmse:0.60469	tr-rmse:0.60469 
2024-03-23 03:06:32 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:06:32 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1085.6199 |       2.9291 |                5.8582 |    128 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5136
Total latency (us): 217.165

2024-03-23 03:06:32 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 03:06:43 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:06:51 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:07:19 [DEBUG] XGB validation: p-rmse: 0.462824	a-peak@32: 0.789958
2024-03-23 03:07:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.130180	tr-a-peak@32: 0.000000	tr-rmse: 0.797826	tr-rmse: 0.797826
2024-03-23 03:07:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.293773	tr-a-peak@32: 0.000000	tr-rmse: 0.597206	tr-rmse: 0.597206
2024-03-23 03:07:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.293136	tr-a-peak@32: 0.000000	tr-rmse: 0.597279	tr-rmse: 0.597279
2024-03-23 03:07:21 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.28926	tr-a-peak@32:0.00000	tr-rmse:0.60551	tr-rmse:0.60551 
2024-03-23 03:07:21 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 03:07:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5406.3754 |      32.0721 |               32.0721 |    702 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5200
Total latency (us): 216.689

2024-03-23 03:07:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:07:31 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:07:39 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:08:16 [DEBUG] XGB validation: p-rmse: 0.488637	a-peak@32: 0.934869
2024-03-23 03:08:16 [DEBUG] XGB iter   0: tr-p-rmse: 2.102897	tr-a-peak@32: 0.000000	tr-rmse: 0.795314	tr-rmse: 0.795314
2024-03-23 03:08:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.309987	tr-a-peak@32: 0.000000	tr-rmse: 0.600206	tr-rmse: 0.600206
2024-03-23 03:08:17 [DEBUG] XGB iter  50: tr-p-rmse: 0.309124	tr-a-peak@32: 0.000000	tr-rmse: 0.600312	tr-rmse: 0.600312
2024-03-23 03:08:17 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.30525	tr-a-peak@32:0.00000	tr-rmse:0.60843	tr-rmse:0.60843 
2024-03-23 03:08:17 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:08:17 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1312.7602 |       4.2843 |                8.5687 |    192 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    766 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5264
Total latency (us): 216.48

2024-03-23 03:08:17 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 03:08:27 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:08:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:09:08 [DEBUG] XGB validation: p-rmse: 0.270159	a-peak@32: 0.951233
2024-03-23 03:09:08 [DEBUG] XGB iter   0: tr-p-rmse: 2.088883	tr-a-peak@32: 0.000000	tr-rmse: 0.792203	tr-rmse: 0.792203
2024-03-23 03:09:09 [DEBUG] XGB iter  25: tr-p-rmse: 0.300608	tr-a-peak@32: 0.000000	tr-rmse: 0.602320	tr-rmse: 0.602320
2024-03-23 03:09:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.300193	tr-a-peak@32: 0.000000	tr-rmse: 0.602379	tr-rmse: 0.602379
2024-03-23 03:09:09 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.29912	tr-a-peak@32:0.00000	tr-rmse:0.61003	tr-rmse:0.61003 
2024-03-23 03:09:09 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 03:09:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    448 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    766 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5328
Total latency (us): 216.184

2024-03-23 03:09:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:10:04 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:10:14 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:10:52 [DEBUG] XGB validation: p-rmse: 0.816092	a-peak@32: 0.721950
2024-03-23 03:10:52 [DEBUG] XGB iter   0: tr-p-rmse: 2.106743	tr-a-peak@32: 0.303700	tr-rmse: 0.794556	tr-rmse: 0.794556
2024-03-23 03:10:53 [DEBUG] XGB iter  25: tr-p-rmse: 0.297348	tr-a-peak@32: 0.000000	tr-rmse: 0.601556	tr-rmse: 0.601556
2024-03-23 03:10:53 [DEBUG] XGB iter  50: tr-p-rmse: 0.295799	tr-a-peak@32: 0.000000	tr-rmse: 0.601571	tr-rmse: 0.601571
2024-03-23 03:10:54 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.29542	tr-a-peak@32:0.03125	tr-rmse:0.60941	tr-rmse:0.60941 
2024-03-23 03:10:54 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:10:54 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    128 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    766 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5392
Total latency (us): 216.184

2024-03-23 03:10:54 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 03:11:05 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:11:13 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:11:46 [DEBUG] XGB validation: p-rmse: 1.070964	a-peak@32: 0.892884
2024-03-23 03:11:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.095952	tr-a-peak@32: 0.279217	tr-rmse: 0.791774	tr-rmse: 0.791774
2024-03-23 03:11:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.302116	tr-a-peak@32: 0.000000	tr-rmse: 0.600453	tr-rmse: 0.600453
2024-03-23 03:11:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.301008	tr-a-peak@32: 0.000000	tr-rmse: 0.600481	tr-rmse: 0.600481
2024-03-23 03:11:48 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.29787	tr-a-peak@32:0.00000	tr-rmse:0.60855	tr-rmse:0.60855 
2024-03-23 03:11:48 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 03:11:48 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    512 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    766 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5456
Total latency (us): 216.184

2024-03-23 03:11:48 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:12:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:12:57 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:13:30 [DEBUG] XGB validation: p-rmse: 0.591022	a-peak@32: 0.644206
2024-03-23 03:13:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.107338	tr-a-peak@32: 0.139609	tr-rmse: 0.802818	tr-rmse: 0.802818
2024-03-23 03:13:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.298878	tr-a-peak@32: 0.000000	tr-rmse: 0.607313	tr-rmse: 0.607313
2024-03-23 03:13:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.297352	tr-a-peak@32: 0.000000	tr-rmse: 0.607378	tr-rmse: 0.607378
2024-03-23 03:13:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.297352	tr-a-peak@32: 0.000000	tr-rmse: 0.607378	tr-rmse: 0.607378
2024-03-23 03:13:31 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.29734	tr-a-peak@32:0.00000	tr-rmse:0.60738	tr-rmse:0.60738 
2024-03-23 03:13:31 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:13:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    766 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5520
Total latency (us): 216.184

2024-03-23 03:13:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:13:42 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:13:50 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:14:28 [DEBUG] XGB validation: p-rmse: 0.402503	a-peak@32: 0.789935
2024-03-23 03:14:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.098940	tr-a-peak@32: 0.000000	tr-rmse: 0.800266	tr-rmse: 0.800266
2024-03-23 03:14:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.294575	tr-a-peak@32: 0.000000	tr-rmse: 0.608103	tr-rmse: 0.608103
2024-03-23 03:14:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.293831	tr-a-peak@32: 0.000000	tr-rmse: 0.608191	tr-rmse: 0.608191
2024-03-23 03:14:30 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29231	tr-a-peak@32:0.25125	tr-rmse:0.61290	tr-rmse:0.61290 
2024-03-23 03:14:30 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:14:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1648.5528 |       3.9928 |                7.9857 |    192 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5584
Total latency (us): 216.184

2024-03-23 03:14:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 03:14:40 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:14:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:15:19 [DEBUG] XGB validation: p-rmse: 0.922280	a-peak@32: 0.955945
2024-03-23 03:15:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.121009	tr-a-peak@32: 0.738748	tr-rmse: 0.798541	tr-rmse: 0.798541
2024-03-23 03:15:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.292085	tr-a-peak@32: 0.000000	tr-rmse: 0.605511	tr-rmse: 0.605511
2024-03-23 03:15:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.290780	tr-a-peak@32: 0.000000	tr-rmse: 0.605594	tr-rmse: 0.605594
2024-03-23 03:15:20 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29028	tr-a-peak@32:0.00000	tr-rmse:0.61064	tr-rmse:0.61064 
2024-03-23 03:15:20 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 03:15:20 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       796.2481 |       5.2365 |                5.2365 |    128 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5648
Total latency (us): 215.586

2024-03-23 03:15:20 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 03:15:31 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:15:38 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:16:12 [DEBUG] XGB validation: p-rmse: 0.566165	a-peak@32: 0.948989
2024-03-23 03:16:12 [DEBUG] XGB iter   0: tr-p-rmse: 2.102868	tr-a-peak@32: 0.488399	tr-rmse: 0.794615	tr-rmse: 0.794615
2024-03-23 03:16:13 [DEBUG] XGB iter  25: tr-p-rmse: 0.296084	tr-a-peak@32: 0.000000	tr-rmse: 0.604827	tr-rmse: 0.604827
2024-03-23 03:16:13 [DEBUG] XGB iter  50: tr-p-rmse: 0.294998	tr-a-peak@32: 0.000000	tr-rmse: 0.604901	tr-rmse: 0.604901
2024-03-23 03:16:13 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.29405	tr-a-peak@32:0.00000	tr-rmse:0.60969	tr-rmse:0.60969 
2024-03-23 03:16:13 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 03:16:13 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    256 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5712
Total latency (us): 214.794

2024-03-23 03:16:13 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 03:16:25 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:16:32 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:16:49 [DEBUG] XGB validation: p-rmse: 1.339410	a-peak@32: 1.000000
2024-03-23 03:16:50 [DEBUG] XGB iter   0: tr-p-rmse: 2.094916	tr-a-peak@32: 0.864301	tr-rmse: 0.794133	tr-rmse: 0.794133
2024-03-23 03:16:50 [DEBUG] XGB iter  25: tr-p-rmse: 0.285237	tr-a-peak@32: 0.000000	tr-rmse: 0.605288	tr-rmse: 0.605288
2024-03-23 03:16:51 [DEBUG] XGB iter  50: tr-p-rmse: 0.283956	tr-a-peak@32: 0.000000	tr-rmse: 0.605359	tr-rmse: 0.605359
2024-03-23 03:16:51 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.28298	tr-a-peak@32:0.00000	tr-rmse:0.61025	tr-rmse:0.61025 
2024-03-23 03:16:51 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 03:16:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3658.4685 |       9.7064 |               19.4128 |    512 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5776
Total latency (us): 214.794

2024-03-23 03:16:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:17:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:18:35 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:19:09 [DEBUG] XGB validation: p-rmse: 0.426996	a-peak@32: 0.967921
2024-03-23 03:19:10 [DEBUG] XGB iter   0: tr-p-rmse: 2.081158	tr-a-peak@32: 0.991895	tr-rmse: 0.804205	tr-rmse: 0.804205
2024-03-23 03:19:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.293467	tr-a-peak@32: 0.000000	tr-rmse: 0.611255	tr-rmse: 0.611255
2024-03-23 03:19:11 [DEBUG] XGB iter  50: tr-p-rmse: 0.292273	tr-a-peak@32: 0.000000	tr-rmse: 0.611335	tr-rmse: 0.611335
2024-03-23 03:19:11 [DEBUG] XGB iter  75: tr-p-rmse: 0.292273	tr-a-peak@32: 0.000000	tr-rmse: 0.611335	tr-rmse: 0.611335
2024-03-23 03:19:11 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.29225	tr-a-peak@32:0.00000	tr-rmse:0.61134	tr-rmse:0.61134 
2024-03-23 03:19:11 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:19:11 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    512 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5840
Total latency (us): 214.519

2024-03-23 03:19:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:20:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:20:19 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:20:55 [DEBUG] XGB validation: p-rmse: 0.640763	a-peak@32: 0.898996
2024-03-23 03:20:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.098829	tr-a-peak@32: 0.962085	tr-rmse: 0.809788	tr-rmse: 0.809788
2024-03-23 03:20:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.287504	tr-a-peak@32: 0.000000	tr-rmse: 0.614987	tr-rmse: 0.614987
2024-03-23 03:20:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.285425	tr-a-peak@32: 0.000000	tr-rmse: 0.615040	tr-rmse: 0.615040
2024-03-23 03:20:57 [DEBUG] XGB iter  75: tr-p-rmse: 0.285425	tr-a-peak@32: 0.000000	tr-rmse: 0.615040	tr-rmse: 0.615040
2024-03-23 03:20:57 [DEBUG] XGB stopped. Best iteration: [31] tr-p-rmse:0.28541	tr-a-peak@32:0.00000	tr-rmse:0.61504	tr-rmse:0.61504 
2024-03-23 03:20:57 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:20:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    830 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5904
Total latency (us): 214.519

2024-03-23 03:20:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:21:08 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:21:17 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:21:53 [DEBUG] XGB validation: p-rmse: 0.419230	a-peak@32: 0.901517
2024-03-23 03:21:53 [DEBUG] XGB iter   0: tr-p-rmse: 2.119262	tr-a-peak@32: 0.994483	tr-rmse: 0.808445	tr-rmse: 0.808445
2024-03-23 03:21:53 [DEBUG] XGB iter  25: tr-p-rmse: 0.274846	tr-a-peak@32: 0.343750	tr-rmse: 0.612300	tr-rmse: 0.612300
2024-03-23 03:21:54 [DEBUG] XGB iter  50: tr-p-rmse: 0.274048	tr-a-peak@32: 0.343750	tr-rmse: 0.612391	tr-rmse: 0.612391
2024-03-23 03:21:54 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.27161	tr-a-peak@32:0.59375	tr-rmse:0.61764	tr-rmse:0.61764 
2024-03-23 03:21:54 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:21:54 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    512 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 5968
Total latency (us): 214.519

2024-03-23 03:21:54 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:22:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:23:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:23:33 [DEBUG] XGB validation: p-rmse: 0.783849	a-peak@32: 0.974892
2024-03-23 03:23:33 [DEBUG] XGB iter   0: tr-p-rmse: 2.136466	tr-a-peak@32: 0.992249	tr-rmse: 0.811471	tr-rmse: 0.811471
2024-03-23 03:23:34 [DEBUG] XGB iter  25: tr-p-rmse: 0.274944	tr-a-peak@32: 0.326841	tr-rmse: 0.612943	tr-rmse: 0.612943
2024-03-23 03:23:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.273545	tr-a-peak@32: 0.181159	tr-rmse: 0.613021	tr-rmse: 0.613021
2024-03-23 03:23:34 [DEBUG] XGB iter  75: tr-p-rmse: 0.273545	tr-a-peak@32: 0.181159	tr-rmse: 0.613021	tr-rmse: 0.613021
2024-03-23 03:23:34 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27353	tr-a-peak@32:0.18116	tr-rmse:0.61303	tr-rmse:0.61303 
2024-03-23 03:23:34 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:23:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     61 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6032
Total latency (us): 214.519

2024-03-23 03:23:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #10: "fused_nn_max_pool2d_1"
2024-03-23 03:23:38 [INFO] [task_scheduler.cc:193] Sending 9 sample(s) to builder
2024-03-23 03:23:39 [INFO] [task_scheduler.cc:195] Sending 9 sample(s) to runner
2024-03-23 03:23:44 [DEBUG] XGB validation: p-rmse: 0.061004	a-peak@32: 0.984249
2024-03-23 03:23:44 [DEBUG] XGB iter   0: tr-p-rmse: 2.136095	tr-a-peak@32: 0.992249	tr-rmse: 0.811406	tr-rmse: 0.811406
2024-03-23 03:23:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.269138	tr-a-peak@32: 0.458352	tr-rmse: 0.612698	tr-rmse: 0.612698
2024-03-23 03:23:45 [DEBUG] XGB iter  50: tr-p-rmse: 0.267241	tr-a-peak@32: 0.461323	tr-rmse: 0.612821	tr-rmse: 0.612821
2024-03-23 03:23:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.267241	tr-a-peak@32: 0.461323	tr-rmse: 0.612821	tr-rmse: 0.612821
2024-03-23 03:23:46 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.26717	tr-a-peak@32:0.46132	tr-rmse:0.61285	tr-rmse:0.61285 
2024-03-23 03:23:46 [INFO] [task_scheduler.cc:237] [Updated] Task #10: "fused_nn_max_pool2d_1"
2024-03-23 03:23:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1679.4088 |       7.1398 |                7.1398 |    192 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6041
Total latency (us): 214.519

2024-03-23 03:23:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 03:23:57 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:24:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:24:43 [DEBUG] XGB validation: p-rmse: 0.564845	a-peak@32: 0.827053
2024-03-23 03:24:43 [DEBUG] XGB iter   0: tr-p-rmse: 2.142663	tr-a-peak@32: 0.995577	tr-rmse: 0.808971	tr-rmse: 0.808971
2024-03-23 03:24:44 [DEBUG] XGB iter  25: tr-p-rmse: 0.269829	tr-a-peak@32: 0.405463	tr-rmse: 0.610817	tr-rmse: 0.610817
2024-03-23 03:24:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.268902	tr-a-peak@32: 0.405463	tr-rmse: 0.610896	tr-rmse: 0.610896
2024-03-23 03:24:44 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26771	tr-a-peak@32:0.59375	tr-rmse:0.61619	tr-rmse:0.61619 
2024-03-23 03:24:44 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 03:24:44 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    576 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6105
Total latency (us): 213.704

2024-03-23 03:24:44 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:25:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:26:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:27:00 [DEBUG] XGB validation: p-rmse: 0.895216	a-peak@32: 0.653150
2024-03-23 03:27:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.155270	tr-a-peak@32: 0.995577	tr-rmse: 0.811947	tr-rmse: 0.811947
2024-03-23 03:27:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.264507	tr-a-peak@32: 0.312500	tr-rmse: 0.611356	tr-rmse: 0.611356
2024-03-23 03:27:02 [DEBUG] XGB iter  50: tr-p-rmse: 0.263747	tr-a-peak@32: 0.343750	tr-rmse: 0.611454	tr-rmse: 0.611454
2024-03-23 03:27:02 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26192	tr-a-peak@32:0.46875	tr-rmse:0.61676	tr-rmse:0.61676 
2024-03-23 03:27:02 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:27:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        73.9216 |       2.2997 |                2.2997 |     62 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6169
Total latency (us): 213.704

2024-03-23 03:27:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #25: "fused_nn_global_avg_pool2d"
2024-03-23 03:27:05 [INFO] [task_scheduler.cc:193] Sending 62 sample(s) to builder
2024-03-23 03:27:09 [INFO] [task_scheduler.cc:195] Sending 62 sample(s) to runner
2024-03-23 03:27:40 [DEBUG] XGB validation: p-rmse: 0.096158	a-peak@32: 0.995138
2024-03-23 03:27:40 [DEBUG] XGB iter   0: tr-p-rmse: 2.154124	tr-a-peak@32: 1.000000	tr-rmse: 0.810254	tr-rmse: 0.810254
2024-03-23 03:27:41 [DEBUG] XGB iter  25: tr-p-rmse: 0.265996	tr-a-peak@32: 0.437500	tr-rmse: 0.610908	tr-rmse: 0.610908
2024-03-23 03:27:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.264769	tr-a-peak@32: 0.437500	tr-rmse: 0.610980	tr-rmse: 0.610980
2024-03-23 03:27:42 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26374	tr-a-peak@32:0.56250	tr-rmse:0.61636	tr-rmse:0.61636 
2024-03-23 03:27:42 [INFO] [task_scheduler.cc:237] [Updated] Task #25: "fused_nn_global_avg_pool2d"
2024-03-23 03:27:42 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6231
Total latency (us): 213.69

2024-03-23 03:27:42 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #19: "fused_concatenate_2"
2024-03-23 03:27:44 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 03:27:44 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 03:27:44 [INFO] [task_scheduler.cc:237] [Updated] Task #19: "fused_concatenate_2"
2024-03-23 03:27:44 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    894 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6231
Total latency (us): 213.69

2024-03-23 03:27:44 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:27:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:28:00 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:28:39 [DEBUG] XGB validation: p-rmse: 0.228841	a-peak@32: 0.848920
2024-03-23 03:28:40 [DEBUG] XGB iter   0: tr-p-rmse: 2.130442	tr-a-peak@32: 0.925141	tr-rmse: 0.807829	tr-rmse: 0.807829
2024-03-23 03:28:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.275391	tr-a-peak@32: 0.446863	tr-rmse: 0.611881	tr-rmse: 0.611881
2024-03-23 03:28:41 [DEBUG] XGB iter  50: tr-p-rmse: 0.274539	tr-a-peak@32: 0.388513	tr-rmse: 0.611971	tr-rmse: 0.611971
2024-03-23 03:28:41 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.27309	tr-a-peak@32:0.90779	tr-rmse:0.61698	tr-rmse:0.61698 
2024-03-23 03:28:41 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:28:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7517 |       2.2835 |                2.2835 |     64 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6295
Total latency (us): 213.69

2024-03-23 03:28:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #27: "fused_nn_softmax"
2024-03-23 03:28:45 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 03:28:51 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 03:29:25 [DEBUG] XGB validation: p-rmse: 0.202897	a-peak@32: 0.992437
2024-03-23 03:29:25 [DEBUG] XGB iter   0: tr-p-rmse: 2.113369	tr-a-peak@32: 1.000000	tr-rmse: 0.806184	tr-rmse: 0.806184
2024-03-23 03:29:26 [DEBUG] XGB iter  25: tr-p-rmse: 0.274304	tr-a-peak@32: 0.125000	tr-rmse: 0.611945	tr-rmse: 0.611945
2024-03-23 03:29:26 [DEBUG] XGB iter  50: tr-p-rmse: 0.273894	tr-a-peak@32: 0.125000	tr-rmse: 0.612034	tr-rmse: 0.612034
2024-03-23 03:29:26 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.27118	tr-a-peak@32:0.90625	tr-rmse:0.61988	tr-rmse:0.61988 
2024-03-23 03:29:26 [INFO] [task_scheduler.cc:237] [Updated] Task #27: "fused_nn_softmax"
2024-03-23 03:29:26 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6358
Total latency (us): 213.684

2024-03-23 03:29:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #26: "fused_nn_batch_flatten"
2024-03-23 03:29:28 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 03:29:28 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 03:29:28 [INFO] [task_scheduler.cc:237] [Updated] Task #26: "fused_nn_batch_flatten"
2024-03-23 03:29:28 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6358
Total latency (us): 213.684

2024-03-23 03:29:28 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-03-23 03:29:30 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 03:29:30 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 03:29:30 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-03-23 03:29:30 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1392.1430 |       4.5197 |                4.5197 |    127 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6358
Total latency (us): 213.684

2024-03-23 03:29:30 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 03:29:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:29:53 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:30:21 [DEBUG] XGB validation: p-rmse: 0.716651	a-peak@32: 0.925326
2024-03-23 03:30:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.103394	tr-a-peak@32: 1.000000	tr-rmse: 0.804519	tr-rmse: 0.804519
2024-03-23 03:30:22 [DEBUG] XGB iter  25: tr-p-rmse: 0.274748	tr-a-peak@32: 0.187500	tr-rmse: 0.611854	tr-rmse: 0.611854
2024-03-23 03:30:23 [DEBUG] XGB iter  50: tr-p-rmse: 0.273711	tr-a-peak@32: 0.187500	tr-rmse: 0.611941	tr-rmse: 0.611941
2024-03-23 03:30:23 [DEBUG] XGB iter  75: tr-p-rmse: 0.273711	tr-a-peak@32: 0.187500	tr-rmse: 0.611941	tr-rmse: 0.611941
2024-03-23 03:30:23 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27370	tr-a-peak@32:0.18750	tr-rmse:0.61194	tr-rmse:0.61194 
2024-03-23 03:30:23 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 03:30:23 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     62 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6422
Total latency (us): 213.471

2024-03-23 03:30:23 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #15: "fused_nn_max_pool2d_2"
2024-03-23 03:30:26 [INFO] [task_scheduler.cc:193] Sending 8 sample(s) to builder
2024-03-23 03:30:27 [INFO] [task_scheduler.cc:195] Sending 8 sample(s) to runner
2024-03-23 03:30:28 [DEBUG] XGB validation: p-rmse: 0.746347	a-peak@32: 1.000000
2024-03-23 03:30:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.103180	tr-a-peak@32: 1.000000	tr-rmse: 0.804519	tr-rmse: 0.804519
2024-03-23 03:30:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.274939	tr-a-peak@32: 0.187500	tr-rmse: 0.611854	tr-rmse: 0.611854
2024-03-23 03:30:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.273903	tr-a-peak@32: 0.187500	tr-rmse: 0.611941	tr-rmse: 0.611941
2024-03-23 03:30:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.273903	tr-a-peak@32: 0.187500	tr-rmse: 0.611941	tr-rmse: 0.611941
2024-03-23 03:30:29 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27389	tr-a-peak@32:0.18750	tr-rmse:0.61194	tr-rmse:0.61194 
2024-03-23 03:30:29 [INFO] [task_scheduler.cc:237] [Updated] Task #15: "fused_nn_max_pool2d_2"
2024-03-23 03:30:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1232.5181 |       6.7572 |                6.7572 |    191 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6430
Total latency (us): 213.471

2024-03-23 03:30:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 03:30:41 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:30:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:31:30 [DEBUG] XGB validation: p-rmse: 0.501885	a-peak@32: 0.822799
2024-03-23 03:31:30 [DEBUG] XGB iter   0: tr-p-rmse: 2.091371	tr-a-peak@32: 0.968750	tr-rmse: 0.802654	tr-rmse: 0.802654
2024-03-23 03:31:31 [DEBUG] XGB iter  25: tr-p-rmse: 0.272442	tr-a-peak@32: 0.125000	tr-rmse: 0.611631	tr-rmse: 0.611631
2024-03-23 03:31:31 [DEBUG] XGB iter  50: tr-p-rmse: 0.271074	tr-a-peak@32: 0.187500	tr-rmse: 0.611731	tr-rmse: 0.611731
2024-03-23 03:31:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.271074	tr-a-peak@32: 0.187500	tr-rmse: 0.611731	tr-rmse: 0.611731
2024-03-23 03:31:31 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27106	tr-a-peak@32:0.18750	tr-rmse:0.61174	tr-rmse:0.61174 
2024-03-23 03:31:31 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 03:31:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6494
Total latency (us): 212.652

2024-03-23 03:31:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-03-23 03:31:34 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 03:31:34 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 03:31:34 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-03-23 03:31:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    192 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6494
Total latency (us): 212.652

2024-03-23 03:31:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 03:31:44 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:31:55 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:32:28 [DEBUG] XGB validation: p-rmse: 0.921510	a-peak@32: 0.958465
2024-03-23 03:32:28 [DEBUG] XGB iter   0: tr-p-rmse: 2.078874	tr-a-peak@32: 0.968750	tr-rmse: 0.799941	tr-rmse: 0.799941
2024-03-23 03:32:29 [DEBUG] XGB iter  25: tr-p-rmse: 0.275596	tr-a-peak@32: 0.268072	tr-rmse: 0.610328	tr-rmse: 0.610328
2024-03-23 03:32:29 [DEBUG] XGB iter  50: tr-p-rmse: 0.273531	tr-a-peak@32: 0.148929	tr-rmse: 0.610350	tr-rmse: 0.610350
2024-03-23 03:32:29 [DEBUG] XGB iter  75: tr-p-rmse: 0.273531	tr-a-peak@32: 0.148929	tr-rmse: 0.610350	tr-rmse: 0.610350
2024-03-23 03:32:29 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.27353	tr-a-peak@32:0.14893	tr-rmse:0.61035	tr-rmse:0.61035 
2024-03-23 03:32:29 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 03:32:29 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1359.8492 |       4.1360 |                8.2720 |    256 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6558
Total latency (us): 212.652

2024-03-23 03:32:29 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 03:32:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:32:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:33:20 [DEBUG] XGB validation: p-rmse: 0.439328	a-peak@32: 0.799348
2024-03-23 03:33:20 [DEBUG] XGB iter   0: tr-p-rmse: 2.070686	tr-a-peak@32: 1.000000	tr-rmse: 0.796772	tr-rmse: 0.796772
2024-03-23 03:33:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.274672	tr-a-peak@32: 0.000000	tr-rmse: 0.608305	tr-rmse: 0.608305
2024-03-23 03:33:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.273468	tr-a-peak@32: 0.000000	tr-rmse: 0.608382	tr-rmse: 0.608382
2024-03-23 03:33:21 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.27332	tr-a-peak@32:0.30518	tr-rmse:0.61318	tr-rmse:0.61318 
2024-03-23 03:33:21 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 03:33:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    576 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6622
Total latency (us): 211.698

2024-03-23 03:33:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:34:18 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:34:36 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:35:07 [DEBUG] XGB validation: p-rmse: 0.625793	a-peak@32: 0.971132
2024-03-23 03:35:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.079550	tr-a-peak@32: 1.000000	tr-rmse: 0.803747	tr-rmse: 0.803747
2024-03-23 03:35:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.280370	tr-a-peak@32: 0.000000	tr-rmse: 0.612115	tr-rmse: 0.612115
2024-03-23 03:35:08 [DEBUG] XGB iter  50: tr-p-rmse: 0.278906	tr-a-peak@32: 0.000000	tr-rmse: 0.612209	tr-rmse: 0.612209
2024-03-23 03:35:08 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.27813	tr-a-peak@32:0.00000	tr-rmse:0.62064	tr-rmse:0.62064 
2024-03-23 03:35:09 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:35:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3141.1197 |       9.7397 |               19.4794 |    576 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6686
Total latency (us): 211.698

2024-03-23 03:35:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:36:02 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:36:19 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:36:56 [DEBUG] XGB validation: p-rmse: 0.832633	a-peak@32: 0.999259
2024-03-23 03:36:56 [DEBUG] XGB iter   0: tr-p-rmse: 2.101932	tr-a-peak@32: 1.000000	tr-rmse: 0.804274	tr-rmse: 0.804274
2024-03-23 03:36:57 [DEBUG] XGB iter  25: tr-p-rmse: 0.268636	tr-a-peak@32: 0.000000	tr-rmse: 0.609830	tr-rmse: 0.609830
2024-03-23 03:36:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.267946	tr-a-peak@32: 0.000000	tr-rmse: 0.609919	tr-rmse: 0.609919
2024-03-23 03:36:57 [DEBUG] XGB stopped. Best iteration: [12] tr-p-rmse:0.26527	tr-a-peak@32:0.59375	tr-rmse:0.61800	tr-rmse:0.61800 
2024-03-23 03:36:57 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:36:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    640 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6750
Total latency (us): 211.437

2024-03-23 03:36:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:37:48 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 03:38:24 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 03:38:58 [DEBUG] XGB validation: p-rmse: 1.197980	a-peak@32: 0.626258
2024-03-23 03:38:58 [DEBUG] XGB iter   0: tr-p-rmse: 2.111348	tr-a-peak@32: 1.000000	tr-rmse: 0.804869	tr-rmse: 0.804869
2024-03-23 03:38:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.273441	tr-a-peak@32: 0.000000	tr-rmse: 0.611126	tr-rmse: 0.611126
2024-03-23 03:39:00 [DEBUG] XGB iter  50: tr-p-rmse: 0.272156	tr-a-peak@32: 0.000000	tr-rmse: 0.611202	tr-rmse: 0.611202
2024-03-23 03:39:00 [DEBUG] XGB iter  75: tr-p-rmse: 0.272156	tr-a-peak@32: 0.000000	tr-rmse: 0.611202	tr-rmse: 0.611202
2024-03-23 03:39:00 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.27215	tr-a-peak@32:0.00000	tr-rmse:0.61121	tr-rmse:0.61121 
2024-03-23 03:39:00 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:39:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |    958 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6813
Total latency (us): 211.437

2024-03-23 03:39:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:39:11 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:39:23 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:40:00 [DEBUG] XGB validation: p-rmse: 0.350345	a-peak@32: 0.814864
2024-03-23 03:40:00 [DEBUG] XGB iter   0: tr-p-rmse: 2.109735	tr-a-peak@32: 1.000000	tr-rmse: 0.803479	tr-rmse: 0.803479
2024-03-23 03:40:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.264190	tr-a-peak@32: 0.000000	tr-rmse: 0.610158	tr-rmse: 0.610158
2024-03-23 03:40:02 [DEBUG] XGB iter  50: tr-p-rmse: 0.263123	tr-a-peak@32: 0.000000	tr-rmse: 0.610228	tr-rmse: 0.610228
2024-03-23 03:40:02 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26201	tr-a-peak@32:0.02809	tr-rmse:0.61507	tr-rmse:0.61507 
2024-03-23 03:40:02 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:40:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      4347.0011 |      10.1584 |               10.1584 |    320 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |   1022 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6877
Total latency (us): 211.437

2024-03-23 03:40:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 03:40:14 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:40:24 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:40:47 [DEBUG] XGB validation: p-rmse: 0.979902	a-peak@32: 0.975664
2024-03-23 03:40:47 [DEBUG] XGB iter   0: tr-p-rmse: 2.099003	tr-a-peak@32: 1.000000	tr-rmse: 0.802843	tr-rmse: 0.802843
2024-03-23 03:40:48 [DEBUG] XGB iter  25: tr-p-rmse: 0.268859	tr-a-peak@32: 0.312500	tr-rmse: 0.611143	tr-rmse: 0.611143
2024-03-23 03:40:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.267471	tr-a-peak@32: 0.215134	tr-rmse: 0.611189	tr-rmse: 0.611189
2024-03-23 03:40:49 [DEBUG] XGB iter  75: tr-p-rmse: 0.267471	tr-a-peak@32: 0.215134	tr-rmse: 0.611189	tr-rmse: 0.611189
2024-03-23 03:40:49 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26747	tr-a-peak@32:0.21513	tr-rmse:0.61119	tr-rmse:0.61119 
2024-03-23 03:40:49 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 03:40:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1018.2646 |       6.1342 |                6.1342 |    190 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |   1022 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 6941
Total latency (us): 209.647

2024-03-23 03:40:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 03:41:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:41:09 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:41:45 [DEBUG] XGB validation: p-rmse: 0.632711	a-peak@32: 0.997840
2024-03-23 03:41:45 [DEBUG] XGB iter   0: tr-p-rmse: 2.096984	tr-a-peak@32: 1.000000	tr-rmse: 0.800558	tr-rmse: 0.800558
2024-03-23 03:41:46 [DEBUG] XGB iter  25: tr-p-rmse: 0.259321	tr-a-peak@32: 0.269536	tr-rmse: 0.609173	tr-rmse: 0.609173
2024-03-23 03:41:46 [DEBUG] XGB iter  50: tr-p-rmse: 0.258253	tr-a-peak@32: 0.268072	tr-rmse: 0.609282	tr-rmse: 0.609282
2024-03-23 03:41:46 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.25754	tr-a-peak@32:0.63010	tr-rmse:0.61435	tr-rmse:0.61435 
2024-03-23 03:41:46 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 03:41:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1782.0581 |       3.6937 |                7.3874 |    256 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |   1022 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7005
Total latency (us): 209.392

2024-03-23 03:41:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 03:41:56 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:42:09 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:42:35 [DEBUG] XGB validation: p-rmse: 0.663673	a-peak@32: 0.821383
2024-03-23 03:42:35 [DEBUG] XGB iter   0: tr-p-rmse: 2.098189	tr-a-peak@32: 1.000000	tr-rmse: 0.799289	tr-rmse: 0.799289
2024-03-23 03:42:36 [DEBUG] XGB iter  25: tr-p-rmse: 0.268711	tr-a-peak@32: 0.000000	tr-rmse: 0.609504	tr-rmse: 0.609504
2024-03-23 03:42:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.267616	tr-a-peak@32: 0.000000	tr-rmse: 0.609575	tr-rmse: 0.609575
2024-03-23 03:42:37 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26726	tr-a-peak@32:0.00000	tr-rmse:0.61465	tr-rmse:0.61465 
2024-03-23 03:42:37 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 03:42:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5441.7237 |      31.8638 |               31.8638 |   1022 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7069
Total latency (us): 209.29

2024-03-23 03:42:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:42:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:42:54 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:43:31 [DEBUG] XGB validation: p-rmse: 0.359926	a-peak@32: 0.822378
2024-03-23 03:43:31 [DEBUG] XGB iter   0: tr-p-rmse: 2.093507	tr-a-peak@32: 1.000000	tr-rmse: 0.797701	tr-rmse: 0.797701
2024-03-23 03:43:32 [DEBUG] XGB iter  25: tr-p-rmse: 0.270171	tr-a-peak@32: 0.000000	tr-rmse: 0.610270	tr-rmse: 0.610270
2024-03-23 03:43:33 [DEBUG] XGB iter  50: tr-p-rmse: 0.268822	tr-a-peak@32: 0.000000	tr-rmse: 0.610354	tr-rmse: 0.610354
2024-03-23 03:43:33 [DEBUG] XGB iter  75: tr-p-rmse: 0.268822	tr-a-peak@32: 0.000000	tr-rmse: 0.610354	tr-rmse: 0.610354
2024-03-23 03:43:33 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.26882	tr-a-peak@32:0.00000	tr-rmse:0.61036	tr-rmse:0.61036 
2024-03-23 03:43:33 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:43:33 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2110.5633 |       8.5893 |               17.1786 |    576 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1086 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7133
Total latency (us): 209.283

2024-03-23 03:43:33 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:44:29 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:44:50 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:45:25 [DEBUG] XGB validation: p-rmse: 0.564994	a-peak@32: 0.862840
2024-03-23 03:45:26 [DEBUG] XGB iter   0: tr-p-rmse: 2.105152	tr-a-peak@32: 1.000000	tr-rmse: 0.803192	tr-rmse: 0.803192
2024-03-23 03:45:27 [DEBUG] XGB iter  25: tr-p-rmse: 0.260855	tr-a-peak@32: 0.370607	tr-rmse: 0.612283	tr-rmse: 0.612283
2024-03-23 03:45:27 [DEBUG] XGB iter  50: tr-p-rmse: 0.259399	tr-a-peak@32: 0.125000	tr-rmse: 0.612356	tr-rmse: 0.612356
2024-03-23 03:45:27 [DEBUG] XGB iter  75: tr-p-rmse: 0.259399	tr-a-peak@32: 0.125000	tr-rmse: 0.612356	tr-rmse: 0.612356
2024-03-23 03:45:27 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25940	tr-a-peak@32:0.12500	tr-rmse:0.61236	tr-rmse:0.61236 
2024-03-23 03:45:27 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:45:27 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    640 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1086 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7197
Total latency (us): 209.149

2024-03-23 03:45:27 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:46:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:46:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:47:17 [DEBUG] XGB validation: p-rmse: 0.574748	a-peak@32: 0.860357
2024-03-23 03:47:18 [DEBUG] XGB iter   0: tr-p-rmse: 2.101330	tr-a-peak@32: 1.000000	tr-rmse: 0.809323	tr-rmse: 0.809323
2024-03-23 03:47:18 [DEBUG] XGB iter  25: tr-p-rmse: 0.264108	tr-a-peak@32: 0.093750	tr-rmse: 0.616735	tr-rmse: 0.616735
2024-03-23 03:47:19 [DEBUG] XGB iter  50: tr-p-rmse: 0.262470	tr-a-peak@32: 0.093750	tr-rmse: 0.616795	tr-rmse: 0.616795
2024-03-23 03:47:19 [DEBUG] XGB iter  75: tr-p-rmse: 0.262470	tr-a-peak@32: 0.093750	tr-rmse: 0.616795	tr-rmse: 0.616795
2024-03-23 03:47:19 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26247	tr-a-peak@32:0.09375	tr-rmse:0.61680	tr-rmse:0.61680 
2024-03-23 03:47:19 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:47:19 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3183.7625 |       9.6092 |               19.2185 |    640 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1086 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7261
Total latency (us): 209.149

2024-03-23 03:47:19 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:48:11 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:48:26 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:48:58 [DEBUG] XGB validation: p-rmse: 0.734434	a-peak@32: 0.877029
2024-03-23 03:48:58 [DEBUG] XGB iter   0: tr-p-rmse: 2.111684	tr-a-peak@32: 1.000000	tr-rmse: 0.814535	tr-rmse: 0.814535
2024-03-23 03:48:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.266824	tr-a-peak@32: 0.000000	tr-rmse: 0.618783	tr-rmse: 0.618783
2024-03-23 03:48:59 [DEBUG] XGB iter  50: tr-p-rmse: 0.265504	tr-a-peak@32: 0.000000	tr-rmse: 0.618862	tr-rmse: 0.618862
2024-03-23 03:48:59 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26526	tr-a-peak@32:0.10626	tr-rmse:0.62369	tr-rmse:0.62369 
2024-03-23 03:49:00 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:49:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    703 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1086 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7325
Total latency (us): 209.079

2024-03-23 03:49:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:49:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:50:04 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:50:40 [DEBUG] XGB validation: p-rmse: 0.441224	a-peak@32: 0.908581
2024-03-23 03:50:41 [DEBUG] XGB iter   0: tr-p-rmse: 2.120229	tr-a-peak@32: 1.000000	tr-rmse: 0.820393	tr-rmse: 0.820393
2024-03-23 03:50:42 [DEBUG] XGB iter  25: tr-p-rmse: 0.271748	tr-a-peak@32: 0.000000	tr-rmse: 0.622184	tr-rmse: 0.622184
2024-03-23 03:50:42 [DEBUG] XGB iter  50: tr-p-rmse: 0.270276	tr-a-peak@32: 0.000000	tr-rmse: 0.622254	tr-rmse: 0.622254
2024-03-23 03:50:42 [DEBUG] XGB iter  75: tr-p-rmse: 0.270276	tr-a-peak@32: 0.000000	tr-rmse: 0.622254	tr-rmse: 0.622254
2024-03-23 03:50:43 [DEBUG] XGB stopped. Best iteration: [28] tr-p-rmse:0.27024	tr-a-peak@32:0.00000	tr-rmse:0.62228	tr-rmse:0.62228 
2024-03-23 03:50:43 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 03:50:43 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1086 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7389
Total latency (us): 209.079

2024-03-23 03:50:43 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:50:52 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:51:01 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:51:38 [DEBUG] XGB validation: p-rmse: 0.137903	a-peak@32: 0.965777
2024-03-23 03:51:38 [DEBUG] XGB iter   0: tr-p-rmse: 2.112448	tr-a-peak@32: 1.000000	tr-rmse: 0.818485	tr-rmse: 0.818485
2024-03-23 03:51:39 [DEBUG] XGB iter  25: tr-p-rmse: 0.260516	tr-a-peak@32: 0.342416	tr-rmse: 0.622775	tr-rmse: 0.622775
2024-03-23 03:51:39 [DEBUG] XGB iter  50: tr-p-rmse: 0.258836	tr-a-peak@32: 0.342194	tr-rmse: 0.622817	tr-rmse: 0.622817
2024-03-23 03:51:40 [DEBUG] XGB iter  75: tr-p-rmse: 0.258836	tr-a-peak@32: 0.342194	tr-rmse: 0.622817	tr-rmse: 0.622817
2024-03-23 03:51:40 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25882	tr-a-peak@32:0.34219	tr-rmse:0.62282	tr-rmse:0.62282 
2024-03-23 03:51:40 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:51:40 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1845.7065 |       3.3367 |                6.6734 |    256 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1150 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7453
Total latency (us): 209.079

2024-03-23 03:51:40 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 03:51:51 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:51:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:52:22 [DEBUG] XGB validation: p-rmse: 0.901085	a-peak@32: 0.869456
2024-03-23 03:52:23 [DEBUG] XGB iter   0: tr-p-rmse: 2.104297	tr-a-peak@32: 1.000000	tr-rmse: 0.816945	tr-rmse: 0.816945
2024-03-23 03:52:24 [DEBUG] XGB iter  25: tr-p-rmse: 0.263015	tr-a-peak@32: 0.281066	tr-rmse: 0.621569	tr-rmse: 0.621569
2024-03-23 03:52:24 [DEBUG] XGB iter  50: tr-p-rmse: 0.261276	tr-a-peak@32: 0.249631	tr-rmse: 0.621629	tr-rmse: 0.621629
2024-03-23 03:52:24 [DEBUG] XGB iter  75: tr-p-rmse: 0.261276	tr-a-peak@32: 0.249631	tr-rmse: 0.621629	tr-rmse: 0.621629
2024-03-23 03:52:25 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26127	tr-a-peak@32:0.24963	tr-rmse:0.62163	tr-rmse:0.62163 
2024-03-23 03:52:25 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 03:52:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1107.5462 |       5.4342 |                5.4342 |    192 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1150 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7517
Total latency (us): 208.977

2024-03-23 03:52:25 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 03:52:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:52:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:53:19 [DEBUG] XGB validation: p-rmse: 0.377607	a-peak@32: 0.628495
2024-03-23 03:53:20 [DEBUG] XGB iter   0: tr-p-rmse: 2.120435	tr-a-peak@32: 1.000000	tr-rmse: 0.814988	tr-rmse: 0.814988
2024-03-23 03:53:21 [DEBUG] XGB iter  25: tr-p-rmse: 0.259254	tr-a-peak@32: 0.402245	tr-rmse: 0.619805	tr-rmse: 0.619805
2024-03-23 03:53:21 [DEBUG] XGB iter  50: tr-p-rmse: 0.257975	tr-a-peak@32: 0.404923	tr-rmse: 0.619917	tr-rmse: 0.619917
2024-03-23 03:53:21 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.25773	tr-a-peak@32:0.45939	tr-rmse:0.62507	tr-rmse:0.62507 
2024-03-23 03:53:21 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 03:53:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    192 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1150 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7581
Total latency (us): 208.091

2024-03-23 03:53:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 03:53:33 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:53:39 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:54:09 [DEBUG] XGB validation: p-rmse: 0.339467	a-peak@32: 0.885624
2024-03-23 03:54:09 [DEBUG] XGB iter   0: tr-p-rmse: 2.106115	tr-a-peak@32: 0.968750	tr-rmse: 0.812921	tr-rmse: 0.812921
2024-03-23 03:54:10 [DEBUG] XGB iter  25: tr-p-rmse: 0.250832	tr-a-peak@32: 0.404784	tr-rmse: 0.619526	tr-rmse: 0.619526
2024-03-23 03:54:10 [DEBUG] XGB iter  50: tr-p-rmse: 0.249442	tr-a-peak@32: 0.530881	tr-rmse: 0.619603	tr-rmse: 0.619603
2024-03-23 03:54:11 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.24779	tr-a-peak@32:0.59375	tr-rmse:0.62467	tr-rmse:0.62467 
2024-03-23 03:54:11 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 03:54:11 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    256 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1150 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7645
Total latency (us): 208.091

2024-03-23 03:54:11 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:54:21 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:54:29 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:55:07 [DEBUG] XGB validation: p-rmse: 0.053239	a-peak@32: 1.000000
2024-03-23 03:55:07 [DEBUG] XGB iter   0: tr-p-rmse: 2.096580	tr-a-peak@32: 1.000000	tr-rmse: 0.811027	tr-rmse: 0.811027
2024-03-23 03:55:08 [DEBUG] XGB iter  25: tr-p-rmse: 0.262395	tr-a-peak@32: 0.000000	tr-rmse: 0.620874	tr-rmse: 0.620874
2024-03-23 03:55:09 [DEBUG] XGB iter  50: tr-p-rmse: 0.261161	tr-a-peak@32: 0.000000	tr-rmse: 0.620965	tr-rmse: 0.620965
2024-03-23 03:55:09 [DEBUG] XGB stopped. Best iteration: [14] tr-p-rmse:0.26091	tr-a-peak@32:0.23482	tr-rmse:0.62593	tr-rmse:0.62593 
2024-03-23 03:55:09 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 03:55:09 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3195.3648 |       9.5743 |               19.1487 |    704 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    256 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7709
Total latency (us): 208.091

2024-03-23 03:55:09 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:56:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:56:38 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:57:13 [DEBUG] XGB validation: p-rmse: 0.428410	a-peak@32: 0.968400
2024-03-23 03:57:13 [DEBUG] XGB iter   0: tr-p-rmse: 2.109984	tr-a-peak@32: 0.968750	tr-rmse: 0.817455	tr-rmse: 0.817455
2024-03-23 03:57:14 [DEBUG] XGB iter  25: tr-p-rmse: 0.256762	tr-a-peak@32: 0.432448	tr-rmse: 0.624453	tr-rmse: 0.624453
2024-03-23 03:57:15 [DEBUG] XGB iter  50: tr-p-rmse: 0.255623	tr-a-peak@32: 0.370213	tr-rmse: 0.624517	tr-rmse: 0.624517
2024-03-23 03:57:15 [DEBUG] XGB iter  75: tr-p-rmse: 0.255623	tr-a-peak@32: 0.370213	tr-rmse: 0.624517	tr-rmse: 0.624517
2024-03-23 03:57:15 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25561	tr-a-peak@32:0.37021	tr-rmse:0.62452	tr-rmse:0.62452 
2024-03-23 03:57:15 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 03:57:15 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    640 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    256 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7773
Total latency (us): 208.026

2024-03-23 03:57:15 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:58:11 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 03:58:21 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 03:58:58 [DEBUG] XGB validation: p-rmse: 0.740766	a-peak@32: 0.938536
2024-03-23 03:58:58 [DEBUG] XGB iter   0: tr-p-rmse: 2.136722	tr-a-peak@32: 0.962378	tr-rmse: 0.819686	tr-rmse: 0.819686
2024-03-23 03:58:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.254635	tr-a-peak@32: 0.283136	tr-rmse: 0.623214	tr-rmse: 0.623214
2024-03-23 03:58:59 [DEBUG] XGB iter  50: tr-p-rmse: 0.252683	tr-a-peak@32: 0.218750	tr-rmse: 0.623267	tr-rmse: 0.623267
2024-03-23 03:59:00 [DEBUG] XGB iter  75: tr-p-rmse: 0.252683	tr-a-peak@32: 0.218750	tr-rmse: 0.623267	tr-rmse: 0.623267
2024-03-23 03:59:00 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.25267	tr-a-peak@32:0.21875	tr-rmse:0.62327	tr-rmse:0.62327 
2024-03-23 03:59:00 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 03:59:00 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    704 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    256 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7837
Total latency (us): 208.026

2024-03-23 03:59:00 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 03:59:54 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:00:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:00:48 [DEBUG] XGB validation: p-rmse: 0.567701	a-peak@32: 0.997008
2024-03-23 04:00:48 [DEBUG] XGB iter   0: tr-p-rmse: 2.132485	tr-a-peak@32: 1.000000	tr-rmse: 0.824804	tr-rmse: 0.824804
2024-03-23 04:00:49 [DEBUG] XGB iter  25: tr-p-rmse: 0.253351	tr-a-peak@32: 0.996006	tr-rmse: 0.626431	tr-rmse: 0.626431
2024-03-23 04:00:49 [DEBUG] XGB iter  50: tr-p-rmse: 0.251283	tr-a-peak@32: 0.996374	tr-rmse: 0.626498	tr-rmse: 0.626498
2024-03-23 04:00:50 [DEBUG] XGB iter  75: tr-p-rmse: 0.251283	tr-a-peak@32: 0.996374	tr-rmse: 0.626498	tr-rmse: 0.626498
2024-03-23 04:00:50 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.25128	tr-a-peak@32:0.99637	tr-rmse:0.62650	tr-rmse:0.62650 
2024-03-23 04:00:50 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:00:50 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    256 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7901
Total latency (us): 208.026

2024-03-23 04:00:50 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 04:01:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:01:08 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:01:33 [DEBUG] XGB validation: p-rmse: 0.782105	a-peak@32: 0.793593
2024-03-23 04:01:34 [DEBUG] XGB iter   0: tr-p-rmse: 2.122817	tr-a-peak@32: 1.000000	tr-rmse: 0.823459	tr-rmse: 0.823459
2024-03-23 04:01:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.253414	tr-a-peak@32: 0.522564	tr-rmse: 0.625546	tr-rmse: 0.625546
2024-03-23 04:01:35 [DEBUG] XGB iter  50: tr-p-rmse: 0.252318	tr-a-peak@32: 0.490343	tr-rmse: 0.625639	tr-rmse: 0.625639
2024-03-23 04:01:35 [DEBUG] XGB iter  75: tr-p-rmse: 0.252318	tr-a-peak@32: 0.490343	tr-rmse: 0.625639	tr-rmse: 0.625639
2024-03-23 04:01:35 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25231	tr-a-peak@32:0.49034	tr-rmse:0.62564	tr-rmse:0.62564 
2024-03-23 04:01:36 [INFO] [task_scheduler.cc:237] [Updated] Task #18: "fused_nn_conv2d_add_nn_relu_9"
2024-03-23 04:01:36 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    767 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 7965
Total latency (us): 208.026

2024-03-23 04:01:36 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:02:26 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:02:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:03:24 [DEBUG] XGB validation: p-rmse: 0.244237	a-peak@32: 0.914538
2024-03-23 04:03:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.132812	tr-a-peak@32: 0.968750	tr-rmse: 0.831625	tr-rmse: 0.831625
2024-03-23 04:03:25 [DEBUG] XGB iter  25: tr-p-rmse: 0.252077	tr-a-peak@32: 0.702499	tr-rmse: 0.630353	tr-rmse: 0.630353
2024-03-23 04:03:25 [DEBUG] XGB iter  50: tr-p-rmse: 0.250610	tr-a-peak@32: 0.681970	tr-rmse: 0.630437	tr-rmse: 0.630437
2024-03-23 04:03:26 [DEBUG] XGB iter  75: tr-p-rmse: 0.250610	tr-a-peak@32: 0.681970	tr-rmse: 0.630437	tr-rmse: 0.630437
2024-03-23 04:03:26 [DEBUG] XGB stopped. Best iteration: [31] tr-p-rmse:0.25061	tr-a-peak@32:0.68197	tr-rmse:0.63044	tr-rmse:0.63044 
2024-03-23 04:03:26 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:03:26 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    256 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8029
Total latency (us): 208.026

2024-03-23 04:03:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 04:03:38 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:03:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:04:19 [DEBUG] XGB validation: p-rmse: 0.887753	a-peak@32: 0.637186
2024-03-23 04:04:19 [DEBUG] XGB iter   0: tr-p-rmse: 2.125240	tr-a-peak@32: 0.981189	tr-rmse: 0.829776	tr-rmse: 0.829776
2024-03-23 04:04:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.248977	tr-a-peak@32: 0.712255	tr-rmse: 0.629714	tr-rmse: 0.629714
2024-03-23 04:04:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.247620	tr-a-peak@32: 0.591585	tr-rmse: 0.629800	tr-rmse: 0.629800
2024-03-23 04:04:21 [DEBUG] XGB iter  75: tr-p-rmse: 0.247620	tr-a-peak@32: 0.591585	tr-rmse: 0.629800	tr-rmse: 0.629800
2024-03-23 04:04:21 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.24761	tr-a-peak@32:0.59159	tr-rmse:0.62980	tr-rmse:0.62980 
2024-03-23 04:04:21 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 04:04:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8093
Total latency (us): 208.026

2024-03-23 04:04:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #5: "fused_nn_max_pool2d"
2024-03-23 04:04:24 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 04:04:24 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 04:04:24 [INFO] [task_scheduler.cc:237] [Updated] Task #5: "fused_nn_max_pool2d"
2024-03-23 04:04:24 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1214 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8093
Total latency (us): 208.026

2024-03-23 04:04:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:04:35 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:05:11 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:05:49 [DEBUG] XGB validation: p-rmse: 0.258772	a-peak@32: 0.882727
2024-03-23 04:05:49 [DEBUG] XGB iter   0: tr-p-rmse: 2.126063	tr-a-peak@32: 0.968750	tr-rmse: 0.828166	tr-rmse: 0.828166
2024-03-23 04:05:50 [DEBUG] XGB iter  25: tr-p-rmse: 0.250095	tr-a-peak@32: 0.491973	tr-rmse: 0.629840	tr-rmse: 0.629840
2024-03-23 04:05:51 [DEBUG] XGB iter  50: tr-p-rmse: 0.248459	tr-a-peak@32: 0.497495	tr-rmse: 0.629916	tr-rmse: 0.629916
2024-03-23 04:05:51 [DEBUG] XGB iter  75: tr-p-rmse: 0.248459	tr-a-peak@32: 0.497495	tr-rmse: 0.629916	tr-rmse: 0.629916
2024-03-23 04:05:51 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.24846	tr-a-peak@32:0.49750	tr-rmse:0.62992	tr-rmse:0.62992 
2024-03-23 04:05:51 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:05:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    192 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8157
Total latency (us): 208.026

2024-03-23 04:05:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 04:06:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:06:15 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:06:51 [DEBUG] XGB validation: p-rmse: 0.834858	a-peak@32: 0.893606
2024-03-23 04:06:51 [DEBUG] XGB iter   0: tr-p-rmse: 2.118262	tr-a-peak@32: 1.000000	tr-rmse: 0.826375	tr-rmse: 0.826375
2024-03-23 04:06:52 [DEBUG] XGB iter  25: tr-p-rmse: 0.254334	tr-a-peak@32: 0.269041	tr-rmse: 0.629806	tr-rmse: 0.629806
2024-03-23 04:06:52 [DEBUG] XGB iter  50: tr-p-rmse: 0.252086	tr-a-peak@32: 0.123280	tr-rmse: 0.629809	tr-rmse: 0.629809
2024-03-23 04:06:53 [DEBUG] XGB iter  75: tr-p-rmse: 0.252086	tr-a-peak@32: 0.123280	tr-rmse: 0.629809	tr-rmse: 0.629809
2024-03-23 04:06:53 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25208	tr-a-peak@32:0.12328	tr-rmse:0.62981	tr-rmse:0.62981 
2024-03-23 04:06:53 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 04:06:53 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1537.2632 |       3.6587 |                7.3173 |    320 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8221
Total latency (us): 208.026

2024-03-23 04:06:53 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 04:07:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:07:12 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:07:44 [DEBUG] XGB validation: p-rmse: 0.238592	a-peak@32: 0.975859
2024-03-23 04:07:44 [DEBUG] XGB iter   0: tr-p-rmse: 2.117032	tr-a-peak@32: 0.968750	tr-rmse: 0.824589	tr-rmse: 0.824589
2024-03-23 04:07:45 [DEBUG] XGB iter  25: tr-p-rmse: 0.258357	tr-a-peak@32: 0.370699	tr-rmse: 0.629787	tr-rmse: 0.629787
2024-03-23 04:07:45 [DEBUG] XGB iter  50: tr-p-rmse: 0.256712	tr-a-peak@32: 0.339019	tr-rmse: 0.629823	tr-rmse: 0.629823
2024-03-23 04:07:46 [DEBUG] XGB iter  75: tr-p-rmse: 0.256712	tr-a-peak@32: 0.339019	tr-rmse: 0.629823	tr-rmse: 0.629823
2024-03-23 04:07:46 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25671	tr-a-peak@32:0.33902	tr-rmse:0.62982	tr-rmse:0.62982 
2024-03-23 04:07:46 [INFO] [task_scheduler.cc:237] [Updated] Task #22: "fused_nn_conv2d_add_nn_relu_12"
2024-03-23 04:07:46 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    768 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8285
Total latency (us): 208.01

2024-03-23 04:07:46 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:08:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:08:56 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:09:32 [DEBUG] XGB validation: p-rmse: 0.534145	a-peak@32: 0.847989
2024-03-23 04:09:32 [DEBUG] XGB iter   0: tr-p-rmse: 2.116484	tr-a-peak@32: 0.937500	tr-rmse: 0.829658	tr-rmse: 0.829658
2024-03-23 04:09:33 [DEBUG] XGB iter  25: tr-p-rmse: 0.247578	tr-a-peak@32: 0.681672	tr-rmse: 0.632614	tr-rmse: 0.632614
2024-03-23 04:09:34 [DEBUG] XGB iter  50: tr-p-rmse: 0.245962	tr-a-peak@32: 0.623057	tr-rmse: 0.632691	tr-rmse: 0.632691
2024-03-23 04:09:34 [DEBUG] XGB iter  75: tr-p-rmse: 0.245962	tr-a-peak@32: 0.623057	tr-rmse: 0.632691	tr-rmse: 0.632691
2024-03-23 04:09:34 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.24596	tr-a-peak@32:0.62306	tr-rmse:0.63269	tr-rmse:0.63269 
2024-03-23 04:09:34 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:09:34 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4317.3257 |      10.5030 |               21.0060 |    831 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8349
Total latency (us): 208.01

2024-03-23 04:09:34 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:10:23 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:10:47 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:11:23 [DEBUG] XGB validation: p-rmse: 0.140753	a-peak@32: 0.961580
2024-03-23 04:11:24 [DEBUG] XGB iter   0: tr-p-rmse: 2.129498	tr-a-peak@32: 0.986353	tr-rmse: 0.837075	tr-rmse: 0.837075
2024-03-23 04:11:25 [DEBUG] XGB iter  25: tr-p-rmse: 0.253998	tr-a-peak@32: 0.119693	tr-rmse: 0.635973	tr-rmse: 0.635973
2024-03-23 04:11:25 [DEBUG] XGB iter  50: tr-p-rmse: 0.251701	tr-a-peak@32: 0.119693	tr-rmse: 0.636035	tr-rmse: 0.636035
2024-03-23 04:11:26 [DEBUG] XGB iter  75: tr-p-rmse: 0.251701	tr-a-peak@32: 0.119693	tr-rmse: 0.636035	tr-rmse: 0.636035
2024-03-23 04:11:26 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25170	tr-a-peak@32:0.11969	tr-rmse:0.63604	tr-rmse:0.63604 
2024-03-23 04:11:26 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:11:26 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    255 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8413
Total latency (us): 207.925

2024-03-23 04:11:26 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 04:11:37 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:11:48 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:12:22 [DEBUG] XGB validation: p-rmse: 0.485107	a-peak@32: 0.954973
2024-03-23 04:12:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.125089	tr-a-peak@32: 0.923853	tr-rmse: 0.835893	tr-rmse: 0.835893
2024-03-23 04:12:23 [DEBUG] XGB iter  25: tr-p-rmse: 0.250137	tr-a-peak@32: 0.000000	tr-rmse: 0.636069	tr-rmse: 0.636069
2024-03-23 04:12:24 [DEBUG] XGB iter  50: tr-p-rmse: 0.247896	tr-a-peak@32: 0.000000	tr-rmse: 0.636117	tr-rmse: 0.636117
2024-03-23 04:12:24 [DEBUG] XGB iter  75: tr-p-rmse: 0.247896	tr-a-peak@32: 0.000000	tr-rmse: 0.636117	tr-rmse: 0.636117
2024-03-23 04:12:25 [DEBUG] XGB stopped. Best iteration: [37] tr-p-rmse:0.24789	tr-a-peak@32:0.00000	tr-rmse:0.63612	tr-rmse:0.63612 
2024-03-23 04:12:25 [INFO] [task_scheduler.cc:237] [Updated] Task #20: "fused_nn_conv2d_add_nn_relu_10"
2024-03-23 04:12:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1062.4261 |       5.8792 |                5.8792 |    254 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8477
Total latency (us): 207.925

2024-03-23 04:12:25 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 04:12:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:12:52 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:13:22 [DEBUG] XGB validation: p-rmse: 0.509740	a-peak@32: 0.647892
2024-03-23 04:13:23 [DEBUG] XGB iter   0: tr-p-rmse: 2.117124	tr-a-peak@32: 0.968750	tr-rmse: 0.834369	tr-rmse: 0.834369
2024-03-23 04:13:24 [DEBUG] XGB iter  25: tr-p-rmse: 0.247898	tr-a-peak@32: 0.187500	tr-rmse: 0.636167	tr-rmse: 0.636167
2024-03-23 04:13:24 [DEBUG] XGB iter  50: tr-p-rmse: 0.245663	tr-a-peak@32: 0.187500	tr-rmse: 0.636195	tr-rmse: 0.636195
2024-03-23 04:13:25 [DEBUG] XGB iter  75: tr-p-rmse: 0.245663	tr-a-peak@32: 0.187500	tr-rmse: 0.636195	tr-rmse: 0.636195
2024-03-23 04:13:25 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.24564	tr-a-peak@32:0.18750	tr-rmse:0.63621	tr-rmse:0.63621 
2024-03-23 04:13:25 [INFO] [task_scheduler.cc:237] [Updated] Task #17: "fused_nn_conv2d_add_nn_relu_8"
2024-03-23 04:13:25 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    768 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8541
Total latency (us): 207.539

2024-03-23 04:13:25 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:14:22 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:14:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:15:17 [DEBUG] XGB validation: p-rmse: 0.414224	a-peak@32: 0.884866
2024-03-23 04:15:17 [DEBUG] XGB iter   0: tr-p-rmse: 2.127447	tr-a-peak@32: 0.937536	tr-rmse: 0.839508	tr-rmse: 0.839508
2024-03-23 04:15:18 [DEBUG] XGB iter  25: tr-p-rmse: 0.247168	tr-a-peak@32: 0.152908	tr-rmse: 0.639208	tr-rmse: 0.639208
2024-03-23 04:15:18 [DEBUG] XGB iter  50: tr-p-rmse: 0.244623	tr-a-peak@32: 0.246559	tr-rmse: 0.639263	tr-rmse: 0.639263
2024-03-23 04:15:19 [DEBUG] XGB iter  75: tr-p-rmse: 0.244623	tr-a-peak@32: 0.246559	tr-rmse: 0.639263	tr-rmse: 0.639263
2024-03-23 04:15:19 [DEBUG] XGB stopped. Best iteration: [37] tr-p-rmse:0.24461	tr-a-peak@32:0.24656	tr-rmse:0.63927	tr-rmse:0.63927 
2024-03-23 04:15:19 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:15:19 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1278 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8605
Total latency (us): 207.539

2024-03-23 04:15:19 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:15:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:15:40 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:16:16 [DEBUG] XGB validation: p-rmse: 0.273987	a-peak@32: 0.861800
2024-03-23 04:16:16 [DEBUG] XGB iter   0: tr-p-rmse: 2.114163	tr-a-peak@32: 0.926005	tr-rmse: 0.837919	tr-rmse: 0.837919
2024-03-23 04:16:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.251300	tr-a-peak@32: 0.184920	tr-rmse: 0.638616	tr-rmse: 0.638616
2024-03-23 04:16:17 [DEBUG] XGB iter  50: tr-p-rmse: 0.249288	tr-a-peak@32: 0.154100	tr-rmse: 0.638675	tr-rmse: 0.638675
2024-03-23 04:16:18 [DEBUG] XGB iter  75: tr-p-rmse: 0.249288	tr-a-peak@32: 0.154100	tr-rmse: 0.638675	tr-rmse: 0.638675
2024-03-23 04:16:18 [DEBUG] XGB stopped. Best iteration: [33] tr-p-rmse:0.24929	tr-a-peak@32:0.15410	tr-rmse:0.63868	tr-rmse:0.63868 
2024-03-23 04:16:18 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:16:18 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2127.1240 |       8.5224 |               17.0449 |    704 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1342 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8669
Total latency (us): 207.539

2024-03-23 04:16:18 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 04:17:11 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:17:23 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:18:00 [DEBUG] XGB validation: p-rmse: 0.731501	a-peak@32: 0.910932
2024-03-23 04:18:00 [DEBUG] XGB iter   0: tr-p-rmse: 2.116199	tr-a-peak@32: 0.937536	tr-rmse: 0.839795	tr-rmse: 0.839795
2024-03-23 04:18:01 [DEBUG] XGB iter  25: tr-p-rmse: 0.254152	tr-a-peak@32: 0.000000	tr-rmse: 0.639856	tr-rmse: 0.639856
2024-03-23 04:18:02 [DEBUG] XGB iter  50: tr-p-rmse: 0.250793	tr-a-peak@32: 0.000000	tr-rmse: 0.639851	tr-rmse: 0.639851
2024-03-23 04:18:02 [DEBUG] XGB iter  75: tr-p-rmse: 0.250793	tr-a-peak@32: 0.000000	tr-rmse: 0.639851	tr-rmse: 0.639851
2024-03-23 04:18:02 [DEBUG] XGB stopped. Best iteration: [37] tr-p-rmse:0.25079	tr-a-peak@32:0.00000	tr-rmse:0.63985	tr-rmse:0.63985 
2024-03-23 04:18:02 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 04:18:02 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    384 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1342 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8733
Total latency (us): 207.068

2024-03-23 04:18:02 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 04:18:15 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:18:39 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:18:58 [DEBUG] XGB validation: p-rmse: 1.755260	a-peak@32: 0.475240
2024-03-23 04:18:58 [DEBUG] XGB iter   0: tr-p-rmse: 2.111523	tr-a-peak@32: 0.906286	tr-rmse: 0.839555	tr-rmse: 0.839555
2024-03-23 04:18:59 [DEBUG] XGB iter  25: tr-p-rmse: 0.247228	tr-a-peak@32: 0.154100	tr-rmse: 0.638337	tr-rmse: 0.638337
2024-03-23 04:19:00 [DEBUG] XGB iter  50: tr-p-rmse: 0.245434	tr-a-peak@32: 0.092460	tr-rmse: 0.638401	tr-rmse: 0.638401
2024-03-23 04:19:00 [DEBUG] XGB iter  75: tr-p-rmse: 0.245434	tr-a-peak@32: 0.092460	tr-rmse: 0.638401	tr-rmse: 0.638401
2024-03-23 04:19:01 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.24543	tr-a-peak@32:0.09246	tr-rmse:0.63840	tr-rmse:0.63840 
2024-03-23 04:19:01 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 04:19:01 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1342 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8797
Total latency (us): 207.068

2024-03-23 04:19:01 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #19: "fused_concatenate_2"
2024-03-23 04:19:03 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 04:19:03 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 04:19:03 [INFO] [task_scheduler.cc:237] [Updated] Task #19: "fused_concatenate_2"
2024-03-23 04:19:03 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1342 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8797
Total latency (us): 207.068

2024-03-23 04:19:03 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:19:14 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:19:24 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:20:01 [DEBUG] XGB validation: p-rmse: 0.290753	a-peak@32: 0.906801
2024-03-23 04:20:01 [DEBUG] XGB iter   0: tr-p-rmse: 2.107932	tr-a-peak@32: 0.937500	tr-rmse: 0.837858	tr-rmse: 0.837858
2024-03-23 04:20:02 [DEBUG] XGB iter  25: tr-p-rmse: 0.256553	tr-a-peak@32: 0.000000	tr-rmse: 0.639666	tr-rmse: 0.639666
2024-03-23 04:20:03 [DEBUG] XGB iter  50: tr-p-rmse: 0.254314	tr-a-peak@32: 0.000000	tr-rmse: 0.639720	tr-rmse: 0.639720
2024-03-23 04:20:04 [DEBUG] XGB iter  75: tr-p-rmse: 0.254314	tr-a-peak@32: 0.000000	tr-rmse: 0.639720	tr-rmse: 0.639720
2024-03-23 04:20:04 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.25430	tr-a-peak@32:0.00000	tr-rmse:0.63972	tr-rmse:0.63972 
2024-03-23 04:20:04 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:20:04 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8861
Total latency (us): 207.068

2024-03-23 04:20:04 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #14: "fused_concatenate_1"
2024-03-23 04:20:06 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 04:20:06 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 04:20:06 [INFO] [task_scheduler.cc:237] [Updated] Task #14: "fused_concatenate_1"
2024-03-23 04:20:06 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1806.9257 |       3.6429 |                7.2857 |    320 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8861
Total latency (us): 207.068

2024-03-23 04:20:06 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 04:20:16 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:20:22 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:20:54 [DEBUG] XGB validation: p-rmse: 0.653335	a-peak@32: 0.906643
2024-03-23 04:20:54 [DEBUG] XGB iter   0: tr-p-rmse: 2.104558	tr-a-peak@32: 0.878613	tr-rmse: 0.836134	tr-rmse: 0.836134
2024-03-23 04:20:55 [DEBUG] XGB iter  25: tr-p-rmse: 0.250486	tr-a-peak@32: 0.205681	tr-rmse: 0.638991	tr-rmse: 0.638991
2024-03-23 04:20:56 [DEBUG] XGB iter  50: tr-p-rmse: 0.247502	tr-a-peak@32: 0.203713	tr-rmse: 0.638990	tr-rmse: 0.638990
2024-03-23 04:20:56 [DEBUG] XGB iter  75: tr-p-rmse: 0.247502	tr-a-peak@32: 0.203713	tr-rmse: 0.638990	tr-rmse: 0.638990
2024-03-23 04:20:56 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.24750	tr-a-peak@32:0.20371	tr-rmse:0.63899	tr-rmse:0.63899 
2024-03-23 04:20:56 [INFO] [task_scheduler.cc:237] [Updated] Task #8: "fused_nn_conv2d_add_nn_relu_3"
2024-03-23 04:20:56 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1323.3063 |       4.5482 |                4.5482 |    256 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8925
Total latency (us): 207.02

2024-03-23 04:20:56 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 04:21:08 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:21:15 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:21:47 [DEBUG] XGB validation: p-rmse: 0.730775	a-peak@32: 0.626635
2024-03-23 04:21:47 [DEBUG] XGB iter   0: tr-p-rmse: 2.109717	tr-a-peak@32: 0.968750	tr-rmse: 0.834996	tr-rmse: 0.834996
2024-03-23 04:21:49 [DEBUG] XGB iter  25: tr-p-rmse: 0.247020	tr-a-peak@32: 0.673533	tr-rmse: 0.637962	tr-rmse: 0.637962
2024-03-23 04:21:49 [DEBUG] XGB iter  50: tr-p-rmse: 0.244743	tr-a-peak@32: 0.521093	tr-rmse: 0.638027	tr-rmse: 0.638027
2024-03-23 04:21:50 [DEBUG] XGB iter  75: tr-p-rmse: 0.244743	tr-a-peak@32: 0.521093	tr-rmse: 0.638027	tr-rmse: 0.638027
2024-03-23 04:21:50 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.24474	tr-a-peak@32:0.52109	tr-rmse:0.63803	tr-rmse:0.63803 
2024-03-23 04:21:50 [INFO] [task_scheduler.cc:237] [Updated] Task #11: "fused_nn_conv2d_add_nn_relu_4"
2024-03-23 04:21:50 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4334.9712 |      10.4603 |               20.9205 |    895 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 8989
Total latency (us): 206.805

2024-03-23 04:21:50 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:22:39 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:23:10 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:23:46 [DEBUG] XGB validation: p-rmse: 0.297498	a-peak@32: 0.954043
2024-03-23 04:23:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.122054	tr-a-peak@32: 0.968750	tr-rmse: 0.841015	tr-rmse: 0.841015
2024-03-23 04:23:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.241937	tr-a-peak@32: 0.398827	tr-rmse: 0.641000	tr-rmse: 0.641000
2024-03-23 04:23:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.239321	tr-a-peak@32: 0.369899	tr-rmse: 0.641070	tr-rmse: 0.641070
2024-03-23 04:23:49 [DEBUG] XGB iter  75: tr-p-rmse: 0.239321	tr-a-peak@32: 0.369899	tr-rmse: 0.641070	tr-rmse: 0.641070
2024-03-23 04:23:49 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.23932	tr-a-peak@32:0.36990	tr-rmse:0.64107	tr-rmse:0.64107 
2024-03-23 04:23:49 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:23:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9053
Total latency (us): 206.781

2024-03-23 04:23:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #23: "fused_concatenate_3"
2024-03-23 04:23:51 [INFO] [task_scheduler.cc:193] Sending 0 sample(s) to builder
2024-03-23 04:23:51 [INFO] [task_scheduler.cc:195] Sending 0 sample(s) to runner
2024-03-23 04:23:51 [INFO] [task_scheduler.cc:237] [Updated] Task #23: "fused_concatenate_3"
2024-03-23 04:23:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |       938.0634 |       4.4449 |                4.4449 |    192 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9053
Total latency (us): 206.781

2024-03-23 04:23:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 04:24:01 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:24:10 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:24:42 [DEBUG] XGB validation: p-rmse: 0.109181	a-peak@32: 0.989319
2024-03-23 04:24:42 [DEBUG] XGB iter   0: tr-p-rmse: 2.106062	tr-a-peak@32: 0.937500	tr-rmse: 0.838838	tr-rmse: 0.838838
2024-03-23 04:24:43 [DEBUG] XGB iter  25: tr-p-rmse: 0.250683	tr-a-peak@32: 0.030859	tr-rmse: 0.641006	tr-rmse: 0.641006
2024-03-23 04:24:44 [DEBUG] XGB iter  50: tr-p-rmse: 0.247653	tr-a-peak@32: 0.000000	tr-rmse: 0.641090	tr-rmse: 0.641090
2024-03-23 04:24:44 [DEBUG] XGB iter  75: tr-p-rmse: 0.247653	tr-a-peak@32: 0.000000	tr-rmse: 0.641090	tr-rmse: 0.641090
2024-03-23 04:24:44 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.24765	tr-a-peak@32:0.00000	tr-rmse:0.64109	tr-rmse:0.64109 
2024-03-23 04:24:44 [INFO] [task_scheduler.cc:237] [Updated] Task #16: "fused_nn_conv2d_add_nn_relu_7"
2024-03-23 04:24:44 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    832 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9117
Total latency (us): 206.338

2024-03-23 04:24:44 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:25:39 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 04:25:52 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 04:26:28 [DEBUG] XGB validation: p-rmse: 0.689944	a-peak@32: 0.970768
2024-03-23 04:26:29 [DEBUG] XGB iter   0: tr-p-rmse: 2.123222	tr-a-peak@32: 0.875036	tr-rmse: 0.841772	tr-rmse: 0.841772
2024-03-23 04:26:30 [DEBUG] XGB iter  25: tr-p-rmse: 0.239974	tr-a-peak@32: 0.243096	tr-rmse: 0.641984	tr-rmse: 0.641984
2024-03-23 04:26:30 [DEBUG] XGB iter  50: tr-p-rmse: 0.237423	tr-a-peak@32: 0.243096	tr-rmse: 0.642009	tr-rmse: 0.642009
2024-03-23 04:26:31 [DEBUG] XGB iter  75: tr-p-rmse: 0.237423	tr-a-peak@32: 0.243096	tr-rmse: 0.642009	tr-rmse: 0.642009
2024-03-23 04:26:31 [DEBUG] XGB stopped. Best iteration: [39] tr-p-rmse:0.23742	tr-a-peak@32:0.24310	tr-rmse:0.64201	tr-rmse:0.64201 
2024-03-23 04:26:31 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:26:31 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3710.9642 |       9.5691 |               19.1382 |    832 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9180
Total latency (us): 206.338

2024-03-23 04:26:31 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:27:29 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 04:28:03 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 04:28:39 [DEBUG] XGB validation: p-rmse: 0.451944	a-peak@32: 0.871874
2024-03-23 04:28:39 [DEBUG] XGB iter   0: tr-p-rmse: 2.111285	tr-a-peak@32: 0.937500	tr-rmse: 0.845219	tr-rmse: 0.845219
2024-03-23 04:28:40 [DEBUG] XGB iter  25: tr-p-rmse: 0.243597	tr-a-peak@32: 0.217884	tr-rmse: 0.643695	tr-rmse: 0.643695
2024-03-23 04:28:40 [DEBUG] XGB iter  50: tr-p-rmse: 0.240780	tr-a-peak@32: 0.217884	tr-rmse: 0.643741	tr-rmse: 0.643741
2024-03-23 04:28:41 [DEBUG] XGB iter  75: tr-p-rmse: 0.240780	tr-a-peak@32: 0.217884	tr-rmse: 0.643741	tr-rmse: 0.643741
2024-03-23 04:28:41 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.24078	tr-a-peak@32:0.21788	tr-rmse:0.64374	tr-rmse:0.64374 
2024-03-23 04:28:41 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:28:41 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1406 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9243
Total latency (us): 206.288

2024-03-23 04:28:41 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:28:52 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:29:01 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:29:34 [DEBUG] XGB validation: p-rmse: 0.423429	a-peak@32: 0.654055
2024-03-23 04:29:34 [DEBUG] XGB iter   0: tr-p-rmse: 2.119666	tr-a-peak@32: 0.942830	tr-rmse: 0.844182	tr-rmse: 0.844182
2024-03-23 04:29:35 [DEBUG] XGB iter  25: tr-p-rmse: 0.241401	tr-a-peak@32: 0.307616	tr-rmse: 0.644364	tr-rmse: 0.644364
2024-03-23 04:29:36 [DEBUG] XGB iter  50: tr-p-rmse: 0.239253	tr-a-peak@32: 0.277001	tr-rmse: 0.644458	tr-rmse: 0.644458
2024-03-23 04:29:36 [DEBUG] XGB iter  75: tr-p-rmse: 0.239253	tr-a-peak@32: 0.277001	tr-rmse: 0.644458	tr-rmse: 0.644458
2024-03-23 04:29:37 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.23923	tr-a-peak@32:0.27700	tr-rmse:0.64447	tr-rmse:0.64447 
2024-03-23 04:29:37 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:29:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    256 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9307
Total latency (us): 206.288

2024-03-23 04:29:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 04:29:48 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:29:55 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:30:18 [DEBUG] XGB validation: p-rmse: 1.011211	a-peak@32: 0.546214
2024-03-23 04:30:18 [DEBUG] XGB iter   0: tr-p-rmse: 2.101677	tr-a-peak@32: 0.801611	tr-rmse: 0.842663	tr-rmse: 0.842663
2024-03-23 04:30:20 [DEBUG] XGB iter  25: tr-p-rmse: 0.259431	tr-a-peak@32: 0.000000	tr-rmse: 0.643574	tr-rmse: 0.643574
2024-03-23 04:30:20 [DEBUG] XGB iter  50: tr-p-rmse: 0.256608	tr-a-peak@32: 0.000000	tr-rmse: 0.643615	tr-rmse: 0.643615
2024-03-23 04:30:21 [DEBUG] XGB iter  75: tr-p-rmse: 0.256608	tr-a-peak@32: 0.000000	tr-rmse: 0.643615	tr-rmse: 0.643615
2024-03-23 04:30:21 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.25659	tr-a-peak@32:0.00000	tr-rmse:0.64362	tr-rmse:0.64362 
2024-03-23 04:30:21 [INFO] [task_scheduler.cc:237] [Updated] Task #7: "fused_nn_conv2d_add_nn_relu_2"
2024-03-23 04:30:21 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1460.9721 |       4.3067 |                4.3067 |    191 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9371
Total latency (us): 206.288

2024-03-23 04:30:21 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 04:30:32 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:30:41 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:31:13 [DEBUG] XGB validation: p-rmse: 0.950952	a-peak@32: 0.802674
2024-03-23 04:31:13 [DEBUG] XGB iter   0: tr-p-rmse: 2.104097	tr-a-peak@32: 0.968750	tr-rmse: 0.841443	tr-rmse: 0.841443
2024-03-23 04:31:14 [DEBUG] XGB iter  25: tr-p-rmse: 0.248592	tr-a-peak@32: 0.401170	tr-rmse: 0.643160	tr-rmse: 0.643160
2024-03-23 04:31:15 [DEBUG] XGB iter  50: tr-p-rmse: 0.245414	tr-a-peak@32: 0.214508	tr-rmse: 0.643180	tr-rmse: 0.643180
2024-03-23 04:31:16 [DEBUG] XGB iter  75: tr-p-rmse: 0.245414	tr-a-peak@32: 0.214508	tr-rmse: 0.643180	tr-rmse: 0.643180
2024-03-23 04:31:16 [DEBUG] XGB stopped. Best iteration: [40] tr-p-rmse:0.24541	tr-a-peak@32:0.21451	tr-rmse:0.64318	tr-rmse:0.64318 
2024-03-23 04:31:16 [INFO] [task_scheduler.cc:237] [Updated] Task #6: "fused_nn_conv2d_add_nn_relu_1"
2024-03-23 04:31:16 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    768 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9435
Total latency (us): 206.222

2024-03-23 04:31:16 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 04:32:06 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:32:18 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:32:48 [DEBUG] XGB validation: p-rmse: 0.526836	a-peak@32: 0.973427
2024-03-23 04:32:49 [DEBUG] XGB iter   0: tr-p-rmse: 2.115869	tr-a-peak@32: 0.937500	tr-rmse: 0.845320	tr-rmse: 0.845320
2024-03-23 04:32:50 [DEBUG] XGB iter  25: tr-p-rmse: 0.244649	tr-a-peak@32: 0.338671	tr-rmse: 0.644809	tr-rmse: 0.644809
2024-03-23 04:32:50 [DEBUG] XGB iter  50: tr-p-rmse: 0.242267	tr-a-peak@32: 0.277441	tr-rmse: 0.644869	tr-rmse: 0.644869
2024-03-23 04:32:51 [DEBUG] XGB iter  75: tr-p-rmse: 0.242267	tr-a-peak@32: 0.277441	tr-rmse: 0.644869	tr-rmse: 0.644869
2024-03-23 04:32:51 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.24226	tr-a-peak@32:0.27744	tr-rmse:0.64488	tr-rmse:0.64488 
2024-03-23 04:32:51 [INFO] [task_scheduler.cc:237] [Updated] Task #1: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1"
2024-03-23 04:32:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    320 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9499
Total latency (us): 206.222

2024-03-23 04:32:51 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 04:33:03 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:33:14 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:33:15 [DEBUG] XGB validation: p-rmse: 0.981695	a-peak@32: 1.000000
2024-03-23 04:33:15 [DEBUG] XGB iter   0: tr-p-rmse: 2.111953	tr-a-peak@32: 0.937500	tr-rmse: 0.845320	tr-rmse: 0.845320
2024-03-23 04:33:17 [DEBUG] XGB iter  25: tr-p-rmse: 0.253054	tr-a-peak@32: 0.122461	tr-rmse: 0.644809	tr-rmse: 0.644809
2024-03-23 04:33:17 [DEBUG] XGB iter  50: tr-p-rmse: 0.250757	tr-a-peak@32: 0.030615	tr-rmse: 0.644869	tr-rmse: 0.644869
2024-03-23 04:33:18 [DEBUG] XGB iter  75: tr-p-rmse: 0.250757	tr-a-peak@32: 0.030615	tr-rmse: 0.644869	tr-rmse: 0.644869
2024-03-23 04:33:18 [DEBUG] XGB stopped. Best iteration: [30] tr-p-rmse:0.25075	tr-a-peak@32:0.06123	tr-rmse:0.64488	tr-rmse:0.64488 
2024-03-23 04:33:18 [INFO] [task_scheduler.cc:237] [Updated] Task #12: "fused_nn_conv2d_add_nn_relu_5"
2024-03-23 04:33:18 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |    959 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9563
Total latency (us): 206.222

2024-03-23 04:33:18 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:34:05 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:34:20 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:34:45 [DEBUG] XGB validation: p-rmse: 0.669869	a-peak@32: 0.298393
2024-03-23 04:34:46 [DEBUG] XGB iter   0: tr-p-rmse: 2.119422	tr-a-peak@32: 0.916078	tr-rmse: 0.849291	tr-rmse: 0.849291
2024-03-23 04:34:47 [DEBUG] XGB iter  25: tr-p-rmse: 0.251555	tr-a-peak@32: 0.517968	tr-rmse: 0.647422	tr-rmse: 0.647422
2024-03-23 04:34:48 [DEBUG] XGB iter  50: tr-p-rmse: 0.249441	tr-a-peak@32: 0.370311	tr-rmse: 0.647495	tr-rmse: 0.647495
2024-03-23 04:34:48 [DEBUG] XGB iter  75: tr-p-rmse: 0.249441	tr-a-peak@32: 0.370311	tr-rmse: 0.647495	tr-rmse: 0.647495
2024-03-23 04:34:48 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.24943	tr-a-peak@32:0.37031	tr-rmse:0.64751	tr-rmse:0.64751 
2024-03-23 04:34:49 [INFO] [task_scheduler.cc:237] [Updated] Task #3: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-03-23 04:34:49 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1470 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9627
Total latency (us): 206.222

2024-03-23 04:34:49 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:34:59 [INFO] [task_scheduler.cc:193] Sending 63 sample(s) to builder
2024-03-23 04:35:05 [INFO] [task_scheduler.cc:195] Sending 63 sample(s) to runner
2024-03-23 04:35:35 [DEBUG] XGB validation: p-rmse: 0.619176	a-peak@32: 0.443831
2024-03-23 04:35:35 [DEBUG] XGB iter   0: tr-p-rmse: 2.102092	tr-a-peak@32: 0.968750	tr-rmse: 0.847974	tr-rmse: 0.847974
2024-03-23 04:35:36 [DEBUG] XGB iter  25: tr-p-rmse: 0.261812	tr-a-peak@32: 0.000000	tr-rmse: 0.647250	tr-rmse: 0.647250
2024-03-23 04:35:37 [DEBUG] XGB iter  50: tr-p-rmse: 0.259076	tr-a-peak@32: 0.000000	tr-rmse: 0.647286	tr-rmse: 0.647286
2024-03-23 04:35:37 [DEBUG] XGB iter  75: tr-p-rmse: 0.259076	tr-a-peak@32: 0.000000	tr-rmse: 0.647286	tr-rmse: 0.647286
2024-03-23 04:35:37 [DEBUG] XGB stopped. Best iteration: [40] tr-p-rmse:0.25908	tr-a-peak@32:0.00000	tr-rmse:0.64729	tr-rmse:0.64729 
2024-03-23 04:35:37 [INFO] [task_scheduler.cc:237] [Updated] Task #24: "fused_nn_conv2d_add_nn_relu_13"
2024-03-23 04:35:37 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    895 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9690
Total latency (us): 206.222

2024-03-23 04:35:37 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:36:30 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:36:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:37:22 [DEBUG] XGB validation: p-rmse: 0.322184	a-peak@32: 0.980486
2024-03-23 04:37:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.120372	tr-a-peak@32: 0.853253	tr-rmse: 0.853575	tr-rmse: 0.853575
2024-03-23 04:37:23 [DEBUG] XGB iter  25: tr-p-rmse: 0.248443	tr-a-peak@32: 0.702260	tr-rmse: 0.649818	tr-rmse: 0.649818
2024-03-23 04:37:23 [DEBUG] XGB iter  50: tr-p-rmse: 0.245806	tr-a-peak@32: 0.681638	tr-rmse: 0.649861	tr-rmse: 0.649861
2024-03-23 04:37:24 [DEBUG] XGB iter  75: tr-p-rmse: 0.245806	tr-a-peak@32: 0.681638	tr-rmse: 0.649861	tr-rmse: 0.649861
2024-03-23 04:37:24 [DEBUG] XGB stopped. Best iteration: [35] tr-p-rmse:0.24580	tr-a-peak@32:0.68164	tr-rmse:0.64986	tr-rmse:0.64986 
2024-03-23 04:37:24 [INFO] [task_scheduler.cc:237] [Updated] Task #0: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu"
2024-03-23 04:37:24 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3720.6888 |       9.5441 |               19.0881 |    895 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9754
Total latency (us): 206.222

2024-03-23 04:37:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:38:20 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:38:46 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:39:21 [DEBUG] XGB validation: p-rmse: 0.258088	a-peak@32: 0.941535
2024-03-23 04:39:22 [DEBUG] XGB iter   0: tr-p-rmse: 2.135988	tr-a-peak@32: 0.742921	tr-rmse: 0.856465	tr-rmse: 0.856465
2024-03-23 04:39:23 [DEBUG] XGB iter  25: tr-p-rmse: 0.254147	tr-a-peak@32: 0.711716	tr-rmse: 0.650952	tr-rmse: 0.650952
2024-03-23 04:39:24 [DEBUG] XGB iter  50: tr-p-rmse: 0.250967	tr-a-peak@32: 0.555466	tr-rmse: 0.650978	tr-rmse: 0.650978
2024-03-23 04:39:24 [DEBUG] XGB iter  75: tr-p-rmse: 0.250967	tr-a-peak@32: 0.555466	tr-rmse: 0.650978	tr-rmse: 0.650978
2024-03-23 04:39:24 [DEBUG] XGB stopped. Best iteration: [36] tr-p-rmse:0.25095	tr-a-peak@32:0.55547	tr-rmse:0.65099	tr-rmse:0.65099 
2024-03-23 04:39:24 [INFO] [task_scheduler.cc:237] [Updated] Task #2: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2"
2024-03-23 04:39:24 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    448 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9818
Total latency (us): 205.984

2024-03-23 04:39:24 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 04:39:36 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:39:51 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:39:55 [DEBUG] XGB validation: p-rmse: 1.205424	a-peak@32: 1.000000
2024-03-23 04:39:55 [DEBUG] XGB iter   0: tr-p-rmse: 2.131902	tr-a-peak@32: 0.738687	tr-rmse: 0.856434	tr-rmse: 0.856434
2024-03-23 04:39:56 [DEBUG] XGB iter  25: tr-p-rmse: 0.264899	tr-a-peak@32: 0.401170	tr-rmse: 0.650873	tr-rmse: 0.650873
2024-03-23 04:39:57 [DEBUG] XGB iter  50: tr-p-rmse: 0.261725	tr-a-peak@32: 0.000000	tr-rmse: 0.650873	tr-rmse: 0.650873
2024-03-23 04:39:57 [DEBUG] XGB iter  75: tr-p-rmse: 0.261725	tr-a-peak@32: 0.000000	tr-rmse: 0.650873	tr-rmse: 0.650873
2024-03-23 04:39:57 [DEBUG] XGB stopped. Best iteration: [34] tr-p-rmse:0.26172	tr-a-peak@32:0.00000	tr-rmse:0.65088	tr-rmse:0.65088 
2024-03-23 04:39:57 [INFO] [task_scheduler.cc:237] [Updated] Task #4: "fused_nn_conv2d_add_nn_relu"
2024-03-23 04:39:57 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |      
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:39:57 [INFO] [task_scheduler.cc:180] TaskScheduler picks Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 04:40:08 [INFO] [task_scheduler.cc:193] Sending 64 sample(s) to builder
2024-03-23 04:40:23 [INFO] [task_scheduler.cc:195] Sending 64 sample(s) to runner
2024-03-23 04:40:51 [INFO] [task_scheduler.cc:260] Task #0 has finished. Remaining task(s): 27
2024-03-23 04:40:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |      
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:51 [INFO] [task_scheduler.cc:260] Task #1 has finished. Remaining task(s): 26
2024-03-23 04:40:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |      
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:51 [INFO] [task_scheduler.cc:260] Task #2 has finished. Remaining task(s): 25
2024-03-23 04:40:51 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |      
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #3 has finished. Remaining task(s): 24
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |      
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #4 has finished. Remaining task(s): 23
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |      
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #5 has finished. Remaining task(s): 22
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |      
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #6 has finished. Remaining task(s): 21
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |      
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #7 has finished. Remaining task(s): 20
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |      
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #8 has finished. Remaining task(s): 19
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |      
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #9 has finished. Remaining task(s): 18
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |      
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #10 has finished. Remaining task(s): 17
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |      
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #11 has finished. Remaining task(s): 16
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |      
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [INFO] [task_scheduler.cc:260] Task #12 has finished. Remaining task(s): 15
2024-03-23 04:40:52 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1874.3908 |       3.2856 |                6.5713 |    320 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9882
Total latency (us): 205.984

2024-03-23 04:40:52 [DEBUG] XGB validation: p-rmse: 0.645637	a-peak@32: 0.774563
2024-03-23 04:40:52 [DEBUG] XGB iter   0: tr-p-rmse: 2.118656	tr-a-peak@32: 0.987705	tr-rmse: 0.854805	tr-rmse: 0.854805
2024-03-23 04:40:54 [DEBUG] XGB iter  25: tr-p-rmse: 0.258236	tr-a-peak@32: 0.000000	tr-rmse: 0.650492	tr-rmse: 0.650492
2024-03-23 04:40:54 [DEBUG] XGB iter  50: tr-p-rmse: 0.256415	tr-a-peak@32: 0.000000	tr-rmse: 0.650589	tr-rmse: 0.650589
2024-03-23 04:40:55 [DEBUG] XGB iter  75: tr-p-rmse: 0.256415	tr-a-peak@32: 0.000000	tr-rmse: 0.650589	tr-rmse: 0.650589
2024-03-23 04:40:55 [DEBUG] XGB stopped. Best iteration: [32] tr-p-rmse:0.25641	tr-a-peak@32:0.00000	tr-rmse:0.65059	tr-rmse:0.65059 
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:237] [Updated] Task #13: "fused_nn_conv2d_add_nn_relu_6"
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |      
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #13 has finished. Remaining task(s): 14
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |      
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #14 has finished. Remaining task(s): 13
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |      
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #15 has finished. Remaining task(s): 12
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |      
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #16 has finished. Remaining task(s): 11
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |      
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #17 has finished. Remaining task(s): 10
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |      
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #18 has finished. Remaining task(s): 9
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |      
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #19 has finished. Remaining task(s): 8
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |      
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #20 has finished. Remaining task(s): 7
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |      
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #21 has finished. Remaining task(s): 6
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |      
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #22 has finished. Remaining task(s): 5
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |      
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #23 has finished. Remaining task(s): 4
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |      
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #24 has finished. Remaining task(s): 3
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |      
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #25 has finished. Remaining task(s): 2
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |      
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #26 has finished. Remaining task(s): 1
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |    Y 
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |      
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

2024-03-23 04:40:55 [INFO] [task_scheduler.cc:260] Task #27 has finished. Remaining task(s): 0
2024-03-23 04:40:55 [INFO] [task_scheduler.cc:320] 
 ID |                                                                    Name |      FLOP | Weight | Speed (GFLOPS) | Latency (us) | Weighted Latency (us) | Trials | Done 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  0 |   fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu |  30593536 |      2 |      3206.2920 |       9.5417 |               19.0834 |    959 |    Y 
  1 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_1 |  18128256 |      2 |      2187.5315 |       8.2871 |               16.5742 |    832 |    Y 
  2 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_2 |  35510528 |      2 |      3767.7110 |       9.4250 |               18.8499 |    959 |    Y 
  3 | fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3 |  45344896 |      2 |      4340.1456 |      10.4478 |               20.8956 |   1023 |    Y 
  4 |                                             fused_nn_conv2d_add_nn_relu |  44158464 |      1 |      5276.7483 |       8.3685 |                8.3685 |    512 |    Y 
  5 |                                                     fused_nn_max_pool2d |   1742400 |      1 |       516.0760 |       3.3762 |                3.3762 |     70 |    Y 
  6 |                                           fused_nn_conv2d_add_nn_relu_1 |   6292000 |      1 |      1483.7983 |       4.2405 |                4.2405 |    255 |    Y 
  7 |                                           fused_nn_conv2d_add_nn_relu_2 |  12487200 |      1 |      2502.2610 |       4.9904 |                4.9904 |    320 |    Y 
  8 |                                           fused_nn_conv2d_add_nn_relu_3 |   6582400 |      2 |      1819.0113 |       3.6187 |                7.2373 |    384 |    Y 
  9 |                                                       fused_concatenate |         1 |      2 |            N/A |          N/A |                   N/A |      1 |    Y 
 10 |                                                   fused_nn_max_pool2d_1 |    839808 |      1 |       346.0911 |       2.4266 |                2.4266 |     70 |    Y 
 11 |                                           fused_nn_conv2d_add_nn_relu_4 |   6018624 |      1 |      1388.8226 |       4.3336 |                4.3336 |    320 |    Y 
 12 |                                           fused_nn_conv2d_add_nn_relu_5 |  11990592 |      1 |      1895.7450 |       6.3250 |                6.3250 |    384 |    Y 
 13 |                                           fused_nn_conv2d_add_nn_relu_6 |   6158592 |      2 |      1895.3825 |       3.2493 |                6.4985 |    384 |    Y 
 14 |                                                     fused_concatenate_1 |         1 |      2 |         0.0004 |       2.2741 |                4.5482 |      6 |    Y 
 15 |                                                   fused_nn_max_pool2d_2 |    389376 |      1 |       172.4035 |       2.2585 |                2.2585 |     70 |    Y 
 16 |                                           fused_nn_conv2d_add_nn_relu_7 |   4169568 |      1 |      1041.7433 |       4.0025 |                4.0025 |    256 |    Y 
 17 |                                           fused_nn_conv2d_add_nn_relu_8 |   6246240 |      1 |      1136.9948 |       5.4936 |                5.4936 |    318 |    Y 
 18 |                                           fused_nn_conv2d_add_nn_relu_9 |   3179904 |      2 |      1181.6710 |       2.6910 |                5.3820 |    320 |    Y 
 19 |                                                     fused_concatenate_2 |         1 |      2 |         0.0004 |       2.2983 |                4.5966 |      6 |    Y 
 20 |                                          fused_nn_conv2d_add_nn_relu_10 |   8328320 |      1 |      1402.3936 |       5.9386 |                5.9386 |    319 |    Y 
 21 |                                          fused_nn_conv2d_add_nn_relu_11 |  11097216 |      1 |            N/A |          N/A |                   N/A |     64 |    Y 
 22 |                                          fused_nn_conv2d_add_nn_relu_12 |   5624320 |      2 |      1540.5754 |       3.6508 |                7.3016 |    384 |    Y 
 23 |                                                     fused_concatenate_3 |         1 |      2 |         0.0004 |       2.2452 |                4.4905 |      6 |    Y 
 24 |                                          fused_nn_conv2d_add_nn_relu_13 | 173394000 |      1 |      5442.9801 |      31.8564 |               31.8564 |   1533 |    Y 
 25 |                                              fused_nn_global_avg_pool2d |    170000 |      1 |        74.3826 |       2.2855 |                2.2855 |    124 |    Y 
 26 |                                                  fused_nn_batch_flatten |         1 |      1 |         0.0004 |       2.2799 |                2.2799 |      5 |    Y 
 27 |                                                        fused_nn_softmax |      4000 |      1 |         1.7566 |       2.2771 |                2.2771 |    127 |    Y 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Total trials: 9946
Total latency (us): 205.911

[04:41:02] /home/canesche/tvm-0.16.dev0/src/relay/backend/te_compiler_cache.cc:679: Warning: Cannot find workload: tvmgen_default_fused_concatenate
[04:41:07] /home/canesche/tvm-0.16.dev0/src/relay/backend/te_compiler_cache.cc:679: Warning: Cannot find workload: tvmgen_default_fused_nn_conv2d_add_nn_relu_12
Tuning Time (min): 192.90
 ID |                                        Name | Time (min) | Percentage 
----------------------------------------------------------------------------
    |                                       Total |   192.8964 |   100.0000 
  1 |                                SendToRunner |    80.7995 |    41.8875 
  2 |                               SendToBuilder |    39.6726 |    20.5668 
  3 |                   EvoSearch/Evolve/Mutation |    35.6465 |    18.4796 
  4 |     EvoSearch/Evolve/PredictNormalizedScore |    18.0717 |     9.3686 
  5 |              EvoSearch/SampleInitPopulation |     9.0532 |     4.6933 
  6 |             MeasureCallback/UpdateCostModel |     4.4274 |     2.2952 
  7 |                       EvoSearch/Evolve/Misc |     2.2767 |     1.1803 
  8 |              EvoSearch/PickBestFromDatabase |     1.5883 |     0.8234 
  9 |                       PostTuningCompilation |     0.3466 |     0.1797 
 10 |               MeasureCallback/AddToDatabase |     0.1264 |     0.0655 
 11 |                              TaskExtraction |     0.1068 |     0.0554 
 12 |                 EvoSearch/PickWithEpsGreedy |     0.0547 |     0.0283 
 13 |         MeasureCallback/RemoveBuildArtifact |     0.0212 |     0.0110 
 14 |                           JoinRunnerFutures |     0.0094 |     0.0049 
 15 |                              InitializeTask |     0.0009 |     0.0005 
 16 | EvoSearch/Evolve/Misc/CopyMeasuredWorkloads |     0.0002 |     0.0001 
----------------------------------------------------------------------------
