2024-04-29 17:02:31 [INFO] [task_scheduler.cc:160] Initializing Task #10: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7"
2024-04-29 17:02:31 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(30), T.int64(30)))
        input_tile = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)))
        B = T.alloc_buffer((T.int64(4), T.int64(4)))
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        A = T.alloc_buffer((T.int64(4), T.int64(2)))
        inverse = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)))
        conv2d_winograd = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(30), T.int64(30)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3])
                data_pad[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(29) and T.int64(1) <= v_i3 and v_i3 < T.int64(29), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for ci, p, eps, nu in T.grid(T.int64(512), T.int64(196), T.int64(4), T.int64(4)):
            with T.block("input_tile"):
                v_ci, v_p, v_eps, v_nu = T.axis.remap("SSSS", [ci, p, eps, nu])
                T.reads(data_pad[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps, v_p % T.int64(14) * T.int64(2) + v_nu])
                T.writes(input_tile[v_ci, v_p, v_eps, v_nu])
                T.block_attr({"schedule_rule": "None"})
                input_tile[v_ci, v_p, v_eps, v_nu] = data_pad[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps, v_p % T.int64(14) * T.int64(2) + v_nu]
        for i, j in T.grid(T.int64(4), T.int64(4)):
            with T.block("B"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(B[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                B[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
        for eps, nu, ci, p, r_a, r_b in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(196), T.int64(4), T.int64(4)):
            with T.block("data_pack"):
                v_eps, v_nu, v_ci, v_p, v_r_a, v_r_b = T.axis.remap("SSSSRR", [eps, nu, ci, p, r_a, r_b])
                T.reads(input_tile[v_ci, v_p, v_r_a, v_r_b], B[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_eps, v_nu):T.min(v_eps, v_nu) + (T.max(v_eps, v_nu) + T.int64(1) - T.min(v_eps, v_nu))])
                T.writes(data_pack[v_eps, v_nu, v_ci, v_p])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                with T.init():
                    data_pack[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                data_pack[v_eps, v_nu, v_ci, v_p] = data_pack[v_eps, v_nu, v_ci, v_p] + input_tile[v_ci, v_p, v_r_a, v_r_b] * B[v_r_a, v_eps] * B[v_r_b, v_nu]
        for eps, nu, co, p, ci in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(196), T.int64(512)):
            with T.block("bgemm"):
                v_eps, v_nu, v_co, v_p, v_ci = T.axis.remap("SSSSR", [eps, nu, co, p, ci])
                T.reads(data_pack[v_eps, v_nu, v_ci, v_p], p1[v_eps, v_nu, v_ci, v_co])
                T.writes(bgemm[v_eps, v_nu, v_co, v_p])
                with T.init():
                    bgemm[v_eps, v_nu, v_co, v_p] = T.float32(0)
                bgemm[v_eps, v_nu, v_co, v_p] = bgemm[v_eps, v_nu, v_co, v_p] + data_pack[v_eps, v_nu, v_ci, v_p] * p1[v_eps, v_nu, v_ci, v_co]
        for i, j in T.grid(T.int64(4), T.int64(2)):
            with T.block("A"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(A[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                A[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
        for co, p, vh, vw, r_a, r_b in T.grid(T.int64(512), T.int64(196), T.int64(2), T.int64(2), T.int64(4), T.int64(4)):
            with T.block("inverse"):
                v_co, v_p, v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSSSRR", [co, p, vh, vw, r_a, r_b])
                T.reads(bgemm[v_r_a, v_r_b, v_co, v_p], A[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_vh, v_vw):T.min(v_vh, v_vw) + (T.max(v_vh, v_vw) + T.int64(1) - T.min(v_vh, v_vw))])
                T.writes(inverse[v_co, v_p, v_vh, v_vw])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                with T.init():
                    inverse[v_co, v_p, v_vh, v_vw] = T.float32(0)
                inverse[v_co, v_p, v_vh, v_vw] = inverse[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * A[v_r_a, v_vh] * A[v_r_b, v_vw]
        for n, co, h, w in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("conv2d_winograd"):
                v_n, v_co, v_h, v_w = T.axis.remap("SSSS", [n, co, h, w])
                T.reads(inverse[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                conv2d_winograd[v_n, v_co, v_h, v_w] = inverse[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3], T.float32(0))
2024-04-29 17:02:31 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 17:02:31 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax0)
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax2)
                            v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(7), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(3584), thread="threadIdx.x"):
                        for ci_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(7168)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1792))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(1792) // T.int64(448))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(448) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + ax0_ax1_ax2_ax3_fused % T.int64(28))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                            v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                            v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 4, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 2, 14, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 2, 8])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
2024-04-29 17:02:31 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax0)
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax2)
                            v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(7), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(3584), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(32), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(7168)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1792))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(1792) // T.int64(448))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(448) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + ax0_ax1_ax2_ax3_fused % T.int64(28))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                            v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(196))
                            v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 4, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 2, 14, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 2, 8])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
2024-04-29 17:02:31 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax0)
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax2)
                            v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(7), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(3584), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(32), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(7168)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(1792))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(1792) // T.int64(448))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(448) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + ax0_ax1_ax2_ax3_fused % T.int64(28))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + co_3 + co_4)
                                    v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(896) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(896) // T.int64(448) * T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(14) * T.int64(4) + ax2)
                                v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(3136), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                            v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(196))
                            v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 4, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 2, 14, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 2, 8])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
2024-04-29 17:31:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 17:31:28 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 17:31:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 498 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:31:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:31:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1509 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:31:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2012 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2510 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:02 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2024-04-29 17:32:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 138 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:31 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:45 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:59 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:32:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9991  0.9989  0.9957  0.9954  0.9953  0.9946  0.9942  0.9928  0.9922  0.9920  0.9908  0.9907  0.9890  0.9882  0.9878  0.9852
[17 : 32]:	0.9852  0.9838  0.9838  0.9835  0.9831  0.9820  0.9805  0.9790  0.9785  0.9784  0.9783  0.9765  0.9760  0.9748  0.9737  0.9715
[33 : 48]:	0.9715  0.9715  0.9712  0.9710  0.9707  0.9706  0.9702  0.9699  0.9698  0.9688  0.9682  0.9671  0.9665  0.9664  0.9663  0.9660
[49 : 64]:	0.9653  0.9652  0.9647  0.9644  0.9628  0.9625  0.9624  0.9616  0.9597  0.9596  0.9595  0.9583  0.9582  0.9576  0.9571  0.9571
2024-04-29 17:33:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 17:33:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1: GFLOPs: 1681.7284. Time: 1035.4275 us. Best GFLOPs: 1681.7284
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #2: GFLOPs: 2297.3325. Time: 757.9695 us. Best GFLOPs: 2297.3325
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #3: GFLOPs: 119.2996. Time: 14596.0954 us. Best GFLOPs: 2297.3325
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #4: GFLOPs: 194.9514. Time: 8932.0106 us. Best GFLOPs: 2297.3325
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #5: GFLOPs: 63.7845. Time: 27299.8408 us. Best GFLOPs: 2297.3325
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #6: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(196))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(21)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 32, 1, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 49, 1, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 98, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 98], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #7: GFLOPs: 183.9386. Time: 9466.7871 us. Best GFLOPs: 2297.3325
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #8: GFLOPs: 6289.4208. Time: 276.8630 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #9: GFLOPs: 119.4792. Time: 14574.1533 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #10: GFLOPs: 395.2564. Time: 4405.5152 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #11: GFLOPs: 1872.1438. Time: 930.1144 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #12: GFLOPs: 1236.8243. Time: 1407.8862 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #13: GFLOPs: 3111.7870. Time: 559.5845 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #14: GFLOPs: 128.0470. Time: 13598.9761 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #15: GFLOPs: 299.0584. Time: 5822.6348 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #16: GFLOPs: 24.2790. Time: 71720.6163 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #17: GFLOPs: 3492.7108. Time: 498.5549 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #18: GFLOPs: 216.8043. Time: 8031.7048 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #19: GFLOPs: 198.9233. Time: 8753.6640 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #20: GFLOPs: 247.1172. Time: 7046.4853 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #21: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(196))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(11)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 32, 1, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 49, 1, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 196, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 196], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #22: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(3136), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(512), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(256) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(256) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) // T.int64(784))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(784) // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(6)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(128))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(1024))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(256) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(256) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(256) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(256) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 64, 2, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 4, 49, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 98], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 98, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #23: GFLOPs: 13.4512. Time: 129454.0810 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #24: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(128), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(2) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(196))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(21)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(2) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(2) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 32, 1, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 2, 49, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 98, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 98], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #25: GFLOPs: 517.2506. Time: 3366.4683 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #26: GFLOPs: 96.9284. Time: 17964.8857 us. Best GFLOPs: 6289.4208
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #27: GFLOPs: 6741.0383. Time: 258.3145 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #28: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(3136), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(14), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(2), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(13)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1568))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1568) // T.int64(392))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(392) // T.int64(196))
                                    v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(3136))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(1024))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(8), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 32, 4, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 7, 4, 7, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #29: GFLOPs: 3360.9487. Time: 518.1001 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #30: GFLOPs: 443.5483. Time: 3925.8584 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #31: GFLOPs: 2306.8038. Time: 754.8574 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #32: GFLOPs: 1830.2541. Time: 951.4023 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #33: GFLOPs: 3678.0363. Time: 473.4341 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #34: GFLOPs: 2837.7579. Time: 613.6210 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #35: GFLOPs: 33.1966. Time: 52454.4013 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #36: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(3136), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(112), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(896), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(448) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(224) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(224) // T.int64(7) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(896), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(784))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(784) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(896) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(3136))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(896), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(3584) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(896) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(8192))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(448) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(224) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(224) // T.int64(7) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(448) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(448) // T.int64(224) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(224) // T.int64(7) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 16, 32, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 7, 7, 4, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 896, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 896, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #37: GFLOPs: 3766.2660. Time: 462.3433 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #38: GFLOPs: 2265.5641. Time: 768.5980 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #39: GFLOPs: 174.1620. Time: 9998.2080 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #40: GFLOPs: 66.1639. Time: 26318.0808 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #41: GFLOPs: 818.2920. Time: 2127.9786 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #42: GFLOPs: 65.9990. Time: 26383.8710 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #43: GFLOPs: 111.0585. Time: 15679.1959 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #44: GFLOPs: 2232.6896. Time: 779.9149 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #45: GFLOPs: 23.9052. Time: 72842.2393 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #46: GFLOPs: 6153.3177. Time: 282.9868 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #47: GFLOPs: 509.9703. Time: 3414.5279 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #48: GFLOPs: 3368.9947. Time: 516.8628 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #49: GFLOPs: 3161.2555. Time: 550.8280 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #50: GFLOPs: 1219.4245. Time: 1427.9752 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #51: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) // T.int64(196))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196) // T.int64(98))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(98))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(11)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 32, 1, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 49, 1, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 196], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 196], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b150)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b152)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b154)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #52: GFLOPs: 3261.9591. Time: 533.8227 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #53: GFLOPs: 2232.3488. Time: 780.0340 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #54: GFLOPs: 163.3208. Time: 10661.8881 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #55: GFLOPs: 3087.6497. Time: 563.9590 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #56: GFLOPs: 16.5619. Time: 105139.2007 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #57: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(3136), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(2), T.int64(4), T.int64(49), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(49) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(13)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1568))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1568) // T.int64(392))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(392) // T.int64(196))
                                    v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(3136))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(1024))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(49), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(49) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(8), T.int64(49)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(4) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 32, 4, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 4, 49, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #58: GFLOPs: 97.0769. Time: 17937.4083 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #59: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(196))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(11)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(196), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(196) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(98) // T.int64(49) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_2_nu_2_co_2_p_2_fused % T.int64(49) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 32, 1, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 49, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 196, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 196], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #60: GFLOPs: 167.9967. Time: 10365.1329 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #61: GFLOPs: 3733.9637. Time: 466.3430 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #62: GFLOPs: 390.8718. Time: 4454.9341 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #63: GFLOPs: 3553.7257. Time: 489.9950 us. Best GFLOPs: 6741.0383
2024-04-29 17:45:12 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #64: GFLOPs: 2306.9451. Time: 754.8112 us. Best GFLOPs: 6741.0383
2024-04-29 17:47:54 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 17:47:55 [INFO] [evolutionary_search.cc:715] Picked top 55 candidate(s) from database
2024-04-29 17:48:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 450 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 899 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1349 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1796 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2244 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2693 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3145 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:48:40 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2024-04-29 17:48:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:49:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:49:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:49:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 17:49:54 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0863  1.0825  1.0779  1.0711  1.0600  1.0592  1.0544  1.0534  1.0520  1.0519  1.0515  1.0512  1.0492  1.0467  1.0462  1.0462
[17 : 32]:	1.0454  1.0452  1.0436  1.0430  1.0376  1.0369  1.0346  1.0343  1.0342  1.0333  1.0319  1.0318  1.0318  1.0297  1.0259  1.0259
[33 : 48]:	1.0194  1.0165  1.0115  1.0111  1.0054  1.0043  1.0036  1.0035  1.0029  1.0020  1.0000  0.9997  0.9977  0.9975  0.9970  0.9970
[49 : 64]:	0.9953  0.9938  0.9938  0.9937  0.9919  0.9872  0.9845  0.9797  0.9788  0.9787  0.9783  0.9780  0.9702  0.9701  0.9696  0.9676
2024-04-29 17:49:55 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 17:49:55 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #65: GFLOPs: 6498.8260. Time: 267.9419 us. Best GFLOPs: 6741.0383
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #66: GFLOPs: 6618.7359. Time: 263.0877 us. Best GFLOPs: 6741.0383
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #67: GFLOPs: 6186.6334. Time: 281.4629 us. Best GFLOPs: 6741.0383
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #68: GFLOPs: 8200.5720. Time: 212.3398 us. Best GFLOPs: 8200.5720
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #69: GFLOPs: 6688.5905. Time: 260.3400 us. Best GFLOPs: 8200.5720
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #70: GFLOPs: 8193.4326. Time: 212.5248 us. Best GFLOPs: 8200.5720
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #71: GFLOPs: 8405.3283. Time: 207.1671 us. Best GFLOPs: 8405.3283
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #72: GFLOPs: 8822.6870. Time: 197.3671 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #73: GFLOPs: 8477.9646. Time: 205.3922 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #74: GFLOPs: 8450.7474. Time: 206.0537 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #75: GFLOPs: 8157.6487. Time: 213.4571 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #76: GFLOPs: 5596.3358. Time: 311.1514 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #77: GFLOPs: 8648.7113. Time: 201.3373 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #78: GFLOPs: 5930.6187. Time: 293.6132 us. Best GFLOPs: 8822.6870
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #79: GFLOPs: 8847.9078. Time: 196.8045 us. Best GFLOPs: 8847.9078
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #80: GFLOPs: 8910.5133. Time: 195.4217 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #81: GFLOPs: 8156.5197. Time: 213.4866 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #82: GFLOPs: 8510.7834. Time: 204.6002 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #83: GFLOPs: 5833.3779. Time: 298.5076 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #84: GFLOPs: 8158.8512. Time: 213.4256 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #85: GFLOPs: 5995.2385. Time: 290.4485 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #86: GFLOPs: 5934.4302. Time: 293.4246 us. Best GFLOPs: 8910.5133
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #87: GFLOPs: 8989.4199. Time: 193.7064 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #88: GFLOPs: 5995.8267. Time: 290.4200 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #89: GFLOPs: 6376.2043. Time: 273.0947 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #90: GFLOPs: 5983.5526. Time: 291.0157 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #91: GFLOPs: 6294.6818. Time: 276.6316 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #92: GFLOPs: 6078.1823. Time: 286.4850 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #93: GFLOPs: 5401.3290. Time: 322.3851 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #94: GFLOPs: 5849.1000. Time: 297.7053 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #95: GFLOPs: 5657.5675. Time: 307.7839 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #96: GFLOPs: 5769.2254. Time: 301.8270 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #97: GFLOPs: 6377.9871. Time: 273.0184 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #98: GFLOPs: 6619.7462. Time: 263.0475 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #99: GFLOPs: 5633.3583. Time: 309.1065 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #100: GFLOPs: 2939.0172. Time: 592.4797 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #101: GFLOPs: 2144.5997. Time: 811.9501 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #102: GFLOPs: 5868.9255. Time: 296.6996 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #103: GFLOPs: 5414.9538. Time: 321.5739 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #104: GFLOPs: 7789.1022. Time: 223.5569 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #105: GFLOPs: 4318.6585. Time: 403.2057 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #106: GFLOPs: 6469.6613. Time: 269.1498 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #107: GFLOPs: 6302.6573. Time: 276.2815 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #108: GFLOPs: 5441.6927. Time: 319.9938 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #109: GFLOPs: 6127.5612. Time: 284.1763 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #110: GFLOPs: 6099.0592. Time: 285.5043 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #111: GFLOPs: 6129.8218. Time: 284.0715 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #112: GFLOPs: 6347.3930. Time: 274.3343 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #113: GFLOPs: 5811.5144. Time: 299.6307 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #114: GFLOPs: 6442.6563. Time: 270.2779 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #115: GFLOPs: 5728.2994. Time: 303.9834 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #116: GFLOPs: 6263.2756. Time: 278.0187 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #117: GFLOPs: 6273.7445. Time: 277.5548 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #118: GFLOPs: 7791.7668. Time: 223.4805 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #119: GFLOPs: 5505.9940. Time: 316.2568 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #120: GFLOPs: 4943.2054. Time: 352.2629 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #121: GFLOPs: 4956.2360. Time: 351.3368 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #122: GFLOPs: 6623.8131. Time: 262.8860 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #123: GFLOPs: 3332.5466. Time: 522.5157 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #124: GFLOPs: 6243.1337. Time: 278.9157 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #125: GFLOPs: 6362.3719. Time: 273.6885 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #126: GFLOPs: 6287.7424. Time: 276.9369 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #127: GFLOPs: 5448.0045. Time: 319.6231 us. Best GFLOPs: 8989.4199
2024-04-29 17:50:55 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #128: GFLOPs: 1242.9264. Time: 1400.9743 us. Best GFLOPs: 8989.4199
2024-04-29 18:22:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 18:22:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 18:22:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:22:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 810 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:22:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1218 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1626 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2028 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2429 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2832 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3239 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3639 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:23:31 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2024-04-29 18:23:45 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:24:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 80 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:24:18 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:24:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 66 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:24:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0476  0.9944  0.9941  0.9885  0.9827  0.9826  0.9774  0.9774  0.9671  0.9671  0.9601  0.9558  0.9558  0.9544  0.9536  0.9497
[17 : 32]:	0.9452  0.9423  0.9417  0.9355  0.9355  0.9351  0.9349  0.9331  0.9331  0.9330  0.9306  0.9302  0.9301  0.9296  0.9285  0.9243
[33 : 48]:	0.9233  0.9228  0.9212  0.9205  0.9197  0.9189  0.9187  0.9185  0.9182  0.9182  0.9170  0.9139  0.9126  0.9125  0.9109  0.9097
[49 : 64]:	0.9082  0.9082  0.9082  0.9072  0.9050  0.9047  0.9036  0.9036  0.9022  0.8990  0.8988  0.8978  0.8936  0.8936  0.8936  0.8927
2024-04-29 18:24:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 18:24:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #129: GFLOPs: 5666.3462. Time: 307.3070 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #130: GFLOPs: 5697.8843. Time: 305.6060 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #131: GFLOPs: 8840.9555. Time: 196.9592 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #132: GFLOPs: 5572.1394. Time: 312.5026 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #133: GFLOPs: 8846.9477. Time: 196.8258 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #134: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(392), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(196) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(196) // T.int64(49) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(49) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(13)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(392))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(392) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(784))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(196) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(196) // T.int64(49) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(49) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(196) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(196) // T.int64(49) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(49) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 4, 4, 2, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 49, 4, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #135: GFLOPs: 8851.1568. Time: 196.7322 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #136: GFLOPs: 8924.8243. Time: 195.1084 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #137: GFLOPs: 8810.0976. Time: 197.6491 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #138: GFLOPs: 8804.7267. Time: 197.7697 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #139: GFLOPs: 8592.3458. Time: 202.6580 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #140: GFLOPs: 8855.5653. Time: 196.6343 us. Best GFLOPs: 8989.4199
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #141: GFLOPs: 9016.6858. Time: 193.1206 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #142: GFLOPs: 8824.7725. Time: 197.3204 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #143: GFLOPs: 8644.5433. Time: 201.4343 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #144: GFLOPs: 8665.7456. Time: 200.9415 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #145: GFLOPs: 8638.3884. Time: 201.5779 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #146: GFLOPs: 8648.8134. Time: 201.3349 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #147: GFLOPs: 8937.0061. Time: 194.8424 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #148: GFLOPs: 8159.6903. Time: 213.4037 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #149: GFLOPs: 8628.9073. Time: 201.7994 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #150: GFLOPs: 8432.8212. Time: 206.4917 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #151: GFLOPs: 8528.0157. Time: 204.1868 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #152: GFLOPs: 8507.0430. Time: 204.6901 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #153: GFLOPs: 8329.5635. Time: 209.0515 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #154: GFLOPs: 8529.4795. Time: 204.1517 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #155: GFLOPs: 8394.7662. Time: 207.4278 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #156: GFLOPs: 8756.9327. Time: 198.8491 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #157: GFLOPs: 8837.1334. Time: 197.0444 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #158: GFLOPs: 6199.6516. Time: 280.8719 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #159: GFLOPs: 8190.5705. Time: 212.5991 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #160: GFLOPs: 8562.0242. Time: 203.3757 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #161: GFLOPs: 8378.6152. Time: 207.8276 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #162: GFLOPs: 8481.4390. Time: 205.3081 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #163: GFLOPs: 8372.6793. Time: 207.9750 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #164: GFLOPs: 8627.2315. Time: 201.8386 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #165: GFLOPs: 8753.1380. Time: 198.9353 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #166: GFLOPs: 4531.3659. Time: 384.2788 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #167: GFLOPs: 8189.1626. Time: 212.6356 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #168: GFLOPs: 8132.2899. Time: 214.1227 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #169: GFLOPs: 8522.4902. Time: 204.3191 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #170: GFLOPs: 8530.1252. Time: 204.1363 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #171: GFLOPs: 8176.4898. Time: 212.9652 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #172: GFLOPs: 8042.3598. Time: 216.5170 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #173: GFLOPs: 8045.4647. Time: 216.4335 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #174: GFLOPs: 8236.7319. Time: 211.4076 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #175: GFLOPs: 8536.7563. Time: 203.9777 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #176: GFLOPs: 7997.3663. Time: 217.7352 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #177: GFLOPs: 8197.9721. Time: 212.4072 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #178: GFLOPs: 8197.7041. Time: 212.4141 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #179: GFLOPs: 8205.6155. Time: 212.2093 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #180: GFLOPs: 8300.6491. Time: 209.7797 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #181: GFLOPs: 8648.4022. Time: 201.3445 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #182: GFLOPs: 8517.0672. Time: 204.4492 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #183: GFLOPs: 8129.8102. Time: 214.1880 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #184: GFLOPs: 8130.3539. Time: 214.1737 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #185: GFLOPs: 3754.1648. Time: 463.8336 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #186: GFLOPs: 8919.5625. Time: 195.2235 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #187: GFLOPs: 8503.2882. Time: 204.7805 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #188: GFLOPs: 7815.1935. Time: 222.8106 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #189: GFLOPs: 8146.7601. Time: 213.7424 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #190: GFLOPs: 1454.0831. Time: 1197.5298 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #191: GFLOPs: 3564.2791. Time: 488.5442 us. Best GFLOPs: 9016.6858
2024-04-29 18:25:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #192: GFLOPs: 4117.8424. Time: 422.8690 us. Best GFLOPs: 9016.6858
2024-04-29 18:48:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 18:48:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 18:48:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 811 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2013 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2416 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2819 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:48:59 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2024-04-29 18:49:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 74 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:49:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:49:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 64 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:50:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 52 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 18:50:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0037  0.9965  0.9958  0.9927  0.9918  0.9913  0.9906  0.9906  0.9906  0.9905  0.9903  0.9893  0.9829  0.9829  0.9823  0.9819
[17 : 32]:	0.9811  0.9807  0.9791  0.9786  0.9782  0.9764  0.9758  0.9758  0.9758  0.9735  0.9735  0.9733  0.9724  0.9703  0.9700  0.9691
[33 : 48]:	0.9685  0.9660  0.9587  0.9575  0.9575  0.9573  0.9573  0.9550  0.9549  0.9546  0.9539  0.9539  0.9531  0.9517  0.9516  0.9508
[49 : 64]:	0.9505  0.9500  0.9498  0.9497  0.9496  0.9492  0.9492  0.9489  0.9479  0.9470  0.9468  0.9468  0.9465  0.9465  0.9461  0.9461
2024-04-29 18:50:07 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 18:50:07 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #193: GFLOPs: 1698.2606. Time: 1025.3479 us. Best GFLOPs: 9016.6858
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #194: GFLOPs: 9039.4634. Time: 192.6340 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #195: GFLOPs: 495.9010. Time: 3511.4020 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #196: GFLOPs: 8939.9208. Time: 194.7789 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #197: GFLOPs: 9038.9768. Time: 192.6444 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #198: GFLOPs: 8945.4119. Time: 194.6593 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #199: GFLOPs: 8903.2926. Time: 195.5802 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #200: GFLOPs: 8898.8770. Time: 195.6773 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #201: GFLOPs: 8849.0407. Time: 196.7793 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #202: GFLOPs: 9025.4696. Time: 192.9327 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #203: GFLOPs: 559.5000. Time: 3112.2571 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #204: GFLOPs: 8823.7082. Time: 197.3442 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #205: GFLOPs: 7139.4430. Time: 243.8997 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #206: GFLOPs: 7136.4433. Time: 244.0022 us. Best GFLOPs: 9039.4634
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #207: GFLOPs: 9470.1613. Time: 183.8731 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #208: GFLOPs: 8978.4509. Time: 193.9430 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #209: GFLOPs: 9019.1658. Time: 193.0675 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #210: GFLOPs: 8866.1367. Time: 196.3998 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #211: GFLOPs: 8843.9644. Time: 196.8922 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #212: GFLOPs: 8924.6995. Time: 195.1111 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #213: GFLOPs: 8963.8753. Time: 194.2584 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #214: GFLOPs: 8951.9876. Time: 194.5163 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #215: GFLOPs: 8805.0087. Time: 197.7633 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #216: GFLOPs: 8802.4078. Time: 197.8218 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #217: GFLOPs: 8835.9075. Time: 197.0718 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #218: GFLOPs: 8880.2523. Time: 196.0877 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #219: GFLOPs: 8980.8949. Time: 193.8902 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #220: GFLOPs: 8989.0357. Time: 193.7146 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #221: GFLOPs: 8998.2570. Time: 193.5161 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #222: GFLOPs: 8923.1917. Time: 195.1441 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #223: GFLOPs: 8988.0747. Time: 193.7354 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #224: GFLOPs: 8843.6997. Time: 196.8981 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #225: GFLOPs: 8872.5171. Time: 196.2586 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #226: GFLOPs: 8915.9277. Time: 195.3031 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #227: GFLOPs: 8872.0412. Time: 196.2691 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #228: GFLOPs: 8923.6608. Time: 195.1338 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #229: GFLOPs: 8779.7790. Time: 198.3316 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #230: GFLOPs: 8854.1696. Time: 196.6653 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #231: GFLOPs: 8884.1921. Time: 196.0007 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #232: GFLOPs: 8748.6980. Time: 199.0362 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #233: GFLOPs: 8622.0161. Time: 201.9606 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #234: GFLOPs: 8751.0247. Time: 198.9833 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #235: GFLOPs: 8873.1542. Time: 196.2445 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #236: GFLOPs: 8777.5137. Time: 198.3828 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #237: GFLOPs: 8659.9488. Time: 201.0760 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #238: GFLOPs: 8186.4820. Time: 212.7053 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #239: GFLOPs: 8657.9698. Time: 201.1220 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #240: GFLOPs: 8690.5005. Time: 200.3691 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #241: GFLOPs: 8700.7732. Time: 200.1325 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #242: GFLOPs: 8792.5877. Time: 198.0427 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #243: GFLOPs: 8709.8653. Time: 199.9236 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #244: GFLOPs: 8196.0274. Time: 212.4575 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #245: GFLOPs: 8539.0525. Time: 203.9228 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #246: GFLOPs: 8601.9453. Time: 202.4319 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #247: GFLOPs: 8631.8785. Time: 201.7299 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #248: GFLOPs: 8820.5326. Time: 197.4153 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #249: GFLOPs: 8715.3228. Time: 199.7984 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #250: GFLOPs: 8676.7406. Time: 200.6869 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #251: GFLOPs: 8660.0676. Time: 201.0732 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #252: GFLOPs: 8420.0473. Time: 206.8050 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #253: GFLOPs: 8711.3432. Time: 199.8897 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #254: GFLOPs: 4172.1741. Time: 417.3622 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #255: GFLOPs: 1757.7895. Time: 990.6237 us. Best GFLOPs: 9470.1613
2024-04-29 18:51:11 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #256: GFLOPs: 6497.7889. Time: 267.9847 us. Best GFLOPs: 9470.1613
2024-04-29 19:01:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 19:01:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 19:01:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2009 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2412 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2818 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:01:48 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2024-04-29 19:02:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 60 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:02:19 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 62 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:02:35 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 58 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:02:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 56 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:02:57 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0303  0.9840  0.9840  0.9829  0.9808  0.9679  0.9647  0.9647  0.9629  0.9618  0.9610  0.9610  0.9610  0.9610  0.9600  0.9589
[17 : 32]:	0.9569  0.9542  0.9537  0.9526  0.9518  0.9505  0.9499  0.9499  0.9475  0.9467  0.9462  0.9453  0.9450  0.9450  0.9445  0.9437
[33 : 48]:	0.9437  0.9429  0.9429  0.9429  0.9429  0.9424  0.9412  0.9408  0.9408  0.9404  0.9401  0.9400  0.9396  0.9395  0.9391  0.9391
[49 : 64]:	0.9387  0.9387  0.9381  0.9381  0.9375  0.9371  0.9371  0.9367  0.9366  0.9366  0.9366  0.9366  0.9359  0.9359  0.9356  0.9355
2024-04-29 19:02:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 19:02:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #257: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(784), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(98) * T.int64(2) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(784), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(784) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1568))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(784) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1568) // T.int64(196))
                                    v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(784) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(784), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(3136) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(3136) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(3136) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(784) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(98) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(98) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(98) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 8, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 98, 1, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 784], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 784, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #258: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(896), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(224))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(224) // T.int64(28))
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 8, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 1, 14, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 112, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 112, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #259: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(896), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(224))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(224) // T.int64(28))
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 8, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 1, 14, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 112, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 112, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #260: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(896), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) // T.int64(224))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(28))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 8, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 1, 14, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 112], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 112, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #261: Error in running:
LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(896), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) // T.int64(224))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(224) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(28))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(14) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 8, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 1, 14, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 112], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 112, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #262: GFLOPs: 8995.9202. Time: 193.5664 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #263: GFLOPs: 9032.0579. Time: 192.7919 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #264: GFLOPs: 9037.1373. Time: 192.6836 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #265: GFLOPs: 9030.2936. Time: 192.8296 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #266: GFLOPs: 8910.0101. Time: 195.4328 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #267: GFLOPs: 8874.2791. Time: 196.2196 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #268: GFLOPs: 8926.9903. Time: 195.0610 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #269: GFLOPs: 7234.0819. Time: 240.7089 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #270: GFLOPs: 9016.4502. Time: 193.1257 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #271: GFLOPs: 9014.4969. Time: 193.1675 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #272: GFLOPs: 8986.8707. Time: 193.7613 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #273: GFLOPs: 8926.8275. Time: 195.0646 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #274: GFLOPs: 8380.6902. Time: 207.7762 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #275: GFLOPs: 8953.9555. Time: 194.4736 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #276: GFLOPs: 8872.4867. Time: 196.2593 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #277: GFLOPs: 7328.4952. Time: 237.6078 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #278: GFLOPs: 9072.1531. Time: 191.9399 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #279: GFLOPs: 9105.7566. Time: 191.2315 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #280: GFLOPs: 9120.8232. Time: 190.9157 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #281: GFLOPs: 9034.3430. Time: 192.7432 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #282: GFLOPs: 9089.7694. Time: 191.5679 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #283: GFLOPs: 9030.5878. Time: 192.8233 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #284: GFLOPs: 9110.5152. Time: 191.1317 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #285: GFLOPs: 8960.1711. Time: 194.3387 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #286: GFLOPs: 8994.5391. Time: 193.5961 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #287: GFLOPs: 8972.8553. Time: 194.0640 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #288: GFLOPs: 8965.0433. Time: 194.2331 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #289: GFLOPs: 9080.7411. Time: 191.7583 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #290: GFLOPs: 9076.0717. Time: 191.8570 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #291: GFLOPs: 9077.3223. Time: 191.8306 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #292: GFLOPs: 9019.1981. Time: 193.0668 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #293: GFLOPs: 8925.6656. Time: 195.0900 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #294: GFLOPs: 8944.2445. Time: 194.6847 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #295: GFLOPs: 8987.5432. Time: 193.7468 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #296: GFLOPs: 8898.8221. Time: 195.6785 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #297: GFLOPs: 8898.1442. Time: 195.6934 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #298: GFLOPs: 8960.3057. Time: 194.3358 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #299: GFLOPs: 9017.6197. Time: 193.1006 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #300: GFLOPs: 8983.0395. Time: 193.8440 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #301: GFLOPs: 9012.0382. Time: 193.2202 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #302: GFLOPs: 8898.2036. Time: 195.6921 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #303: GFLOPs: 8886.4187. Time: 195.9516 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #304: GFLOPs: 8943.5482. Time: 194.6999 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #305: GFLOPs: 8834.4202. Time: 197.1049 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #306: GFLOPs: 9094.7948. Time: 191.4620 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #307: GFLOPs: 8901.4899. Time: 195.6198 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #308: GFLOPs: 8903.7226. Time: 195.5708 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #309: GFLOPs: 8336.6391. Time: 208.8741 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #310: GFLOPs: 9009.5134. Time: 193.2744 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #311: GFLOPs: 8915.1933. Time: 195.3191 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #312: GFLOPs: 9007.4903. Time: 193.3178 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #313: GFLOPs: 8786.9682. Time: 198.1694 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #314: GFLOPs: 8896.3685. Time: 195.7324 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #315: GFLOPs: 8784.2466. Time: 198.2308 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #316: GFLOPs: 8938.3250. Time: 194.8137 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #317: GFLOPs: 8989.7264. Time: 193.6998 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #318: GFLOPs: 118.9764. Time: 14635.7389 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #319: GFLOPs: 5652.0881. Time: 308.0822 us. Best GFLOPs: 9470.1613
2024-04-29 19:04:01 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #320: GFLOPs: 206.2687. Time: 8441.9415 us. Best GFLOPs: 9470.1613
2024-04-29 19:40:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 19:40:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 19:40:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1206 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1608 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2412 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2816 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:40:52 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2024-04-29 19:41:06 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 58 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:41:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 63 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:41:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 60 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:41:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 57 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:42:03 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9666  0.9645  0.9644  0.9628  0.9613  0.9599  0.9572  0.9554  0.9528  0.9526  0.9526  0.9522  0.9521  0.9520  0.9518  0.9499
[17 : 32]:	0.9499  0.9499  0.9499  0.9499  0.9499  0.9499  0.9499  0.9499  0.9492  0.9490  0.9488  0.9488  0.9487  0.9482  0.9482  0.9482
[33 : 48]:	0.9482  0.9482  0.9482  0.9478  0.9474  0.9474  0.9474  0.9473  0.9473  0.9471  0.9470  0.9470  0.9470  0.9459  0.9459  0.9456
[49 : 64]:	0.9456  0.9452  0.9446  0.9444  0.9444  0.9441  0.9440  0.9423  0.9422  0.9418  0.9415  0.9415  0.9408  0.9407  0.9400  0.9400
2024-04-29 19:42:03 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 19:42:03 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #321: Error in running:
LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(896), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(7) * T.int64(8) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(224))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(224) // T.int64(28))
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(7) * T.int64(8) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(112) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(7) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 4, 4, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 1, 7, 2, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 56, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 56, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #322: GFLOPs: 9136.8611. Time: 190.5805 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #323: GFLOPs: 9009.1417. Time: 193.2823 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #324: GFLOPs: 9180.0595. Time: 189.6837 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #325: GFLOPs: 9127.0573. Time: 190.7852 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #326: GFLOPs: 8921.9232. Time: 195.1718 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #327: GFLOPs: 9020.5593. Time: 193.0377 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #328: GFLOPs: 9018.6256. Time: 193.0791 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #329: GFLOPs: 9005.6675. Time: 193.3569 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #330: GFLOPs: 9009.3769. Time: 193.2773 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #331: GFLOPs: 9010.0911. Time: 193.2620 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #332: GFLOPs: 9009.6545. Time: 193.2713 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #333: GFLOPs: 8928.7425. Time: 195.0227 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #334: GFLOPs: 8953.4819. Time: 194.4839 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #335: GFLOPs: 8927.4886. Time: 195.0501 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #336: GFLOPs: 8846.2830. Time: 196.8406 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #337: GFLOPs: 8940.7388. Time: 194.7611 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #338: GFLOPs: 8894.3307. Time: 195.7773 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #339: GFLOPs: 8980.8388. Time: 193.8915 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #340: GFLOPs: 8985.8954. Time: 193.7823 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #341: GFLOPs: 8864.7539. Time: 196.4305 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #342: GFLOPs: 8917.6305. Time: 195.2658 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #343: GFLOPs: 8885.6225. Time: 195.9692 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #344: GFLOPs: 8985.8131. Time: 193.7841 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #345: GFLOPs: 8924.6665. Time: 195.1118 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #346: GFLOPs: 8935.0276. Time: 194.8856 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #347: GFLOPs: 8855.0697. Time: 196.6453 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #348: GFLOPs: 8950.1504. Time: 194.5563 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #349: GFLOPs: 8858.1121. Time: 196.5778 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #350: GFLOPs: 8836.0320. Time: 197.0690 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #351: GFLOPs: 8855.1394. Time: 196.6438 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #352: GFLOPs: 8941.8794. Time: 194.7362 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #353: GFLOPs: 8830.4087. Time: 197.1945 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #354: GFLOPs: 8834.8741. Time: 197.0948 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #355: GFLOPs: 8754.2038. Time: 198.9111 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #356: GFLOPs: 8921.3361. Time: 195.1847 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #357: GFLOPs: 8908.1421. Time: 195.4737 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #358: GFLOPs: 8868.4233. Time: 196.3492 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #359: GFLOPs: 8975.7388. Time: 194.0016 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #360: GFLOPs: 8947.8343. Time: 194.6066 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #361: GFLOPs: 8945.3819. Time: 194.6600 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #362: GFLOPs: 8934.5819. Time: 194.8953 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #363: GFLOPs: 8834.9667. Time: 197.0928 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #364: GFLOPs: 8850.1290. Time: 196.7551 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #365: GFLOPs: 8829.5796. Time: 197.2130 us. Best GFLOPs: 9470.1613
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #366: GFLOPs: 9508.9064. Time: 183.1239 us. Best GFLOPs: 9508.9064
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #367: GFLOPs: 9529.4628. Time: 182.7289 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #368: GFLOPs: 8806.6582. Time: 197.7263 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #369: GFLOPs: 8923.9714. Time: 195.1270 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #370: GFLOPs: 8898.1766. Time: 195.6927 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #371: GFLOPs: 8883.3816. Time: 196.0186 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #372: GFLOPs: 8811.5340. Time: 197.6169 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #373: GFLOPs: 8829.7032. Time: 197.2102 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #374: GFLOPs: 8924.3817. Time: 195.1180 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #375: GFLOPs: 8990.9678. Time: 193.6730 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #376: GFLOPs: 8936.3821. Time: 194.8560 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #377: GFLOPs: 8869.9737. Time: 196.3149 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #378: GFLOPs: 8821.8472. Time: 197.3859 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #379: GFLOPs: 8887.7218. Time: 195.9229 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #380: GFLOPs: 9043.3314. Time: 192.5516 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #381: GFLOPs: 8916.8513. Time: 195.2828 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #382: GFLOPs: 4942.6754. Time: 352.3007 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #383: GFLOPs: 219.6281. Time: 7928.4380 us. Best GFLOPs: 9529.4628
2024-04-29 19:43:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #384: GFLOPs: 25.8278. Time: 67419.8200 us. Best GFLOPs: 9529.4628
2024-04-29 19:57:07 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 19:57:10 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 19:57:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1610 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2014 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2417 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2821 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3223 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:57:56 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2024-04-29 19:58:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:58:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:58:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 87 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:59:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 43 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 19:59:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0846  0.9637  0.9612  0.9593  0.9587  0.9577  0.9558  0.9558  0.9544  0.9521  0.9509  0.9506  0.9492  0.9477  0.9452  0.9442
[17 : 32]:	0.9438  0.9438  0.9434  0.9427  0.9423  0.9423  0.9422  0.9421  0.9420  0.9417  0.9416  0.9413  0.9405  0.9395  0.9391  0.9385
[33 : 48]:	0.9385  0.9381  0.9381  0.9379  0.9379  0.9379  0.9379  0.9376  0.9375  0.9353  0.9353  0.9353  0.9350  0.9347  0.9347  0.9345
[49 : 64]:	0.9345  0.9344  0.9339  0.9338  0.9334  0.9330  0.9329  0.9326  0.9325  0.9323  0.9322  0.9319  0.9317  0.9317  0.9313  0.9312
2024-04-29 19:59:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 19:59:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #385: GFLOPs: 6107.7344. Time: 285.0988 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #386: GFLOPs: 9323.2694. Time: 186.7701 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #387: GFLOPs: 9000.4848. Time: 193.4682 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #388: GFLOPs: 9455.9407. Time: 184.1496 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #389: GFLOPs: 9501.8897. Time: 183.2591 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #390: GFLOPs: 8596.9514. Time: 202.5495 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #391: GFLOPs: 9004.5497. Time: 193.3809 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #392: GFLOPs: 9111.0738. Time: 191.1199 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #393: GFLOPs: 9007.3359. Time: 193.3211 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #394: GFLOPs: 9034.2777. Time: 192.7446 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #395: GFLOPs: 8901.8423. Time: 195.6121 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #396: GFLOPs: 8881.2637. Time: 196.0653 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #397: GFLOPs: 9177.8480. Time: 189.7294 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #398: GFLOPs: 6110.9576. Time: 284.9485 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #399: GFLOPs: 9027.0073. Time: 192.8998 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #400: GFLOPs: 8875.3925. Time: 196.1950 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #401: GFLOPs: 8964.5952. Time: 194.2428 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #402: GFLOPs: 8912.9444. Time: 195.3684 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #403: GFLOPs: 8946.3634. Time: 194.6386 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #404: GFLOPs: 9272.5502. Time: 187.7917 us. Best GFLOPs: 9529.4628
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #405: GFLOPs: 9609.8024. Time: 181.2012 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #406: GFLOPs: 9608.4260. Time: 181.2272 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #407: GFLOPs: 8944.9378. Time: 194.6696 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #408: GFLOPs: 8789.0151. Time: 198.1232 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #409: GFLOPs: 8985.4894. Time: 193.7911 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #410: GFLOPs: 8900.7483. Time: 195.6361 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #411: GFLOPs: 8855.7401. Time: 196.6304 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #412: GFLOPs: 8952.3821. Time: 194.5078 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #413: GFLOPs: 8821.3193. Time: 197.3977 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #414: GFLOPs: 8808.5022. Time: 197.6849 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #415: GFLOPs: 9181.1423. Time: 189.6614 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #416: GFLOPs: 8932.9060. Time: 194.9319 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #417: GFLOPs: 8956.7621. Time: 194.4127 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #418: GFLOPs: 8866.0876. Time: 196.4009 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #419: GFLOPs: 8966.0181. Time: 194.2120 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #420: GFLOPs: 8999.9277. Time: 193.4802 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #421: GFLOPs: 8920.3182. Time: 195.2069 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #422: GFLOPs: 8815.5711. Time: 197.5264 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #423: GFLOPs: 9448.3683. Time: 184.2972 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #424: GFLOPs: 8903.8013. Time: 195.5690 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #425: GFLOPs: 8885.0723. Time: 195.9813 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #426: GFLOPs: 8813.2233. Time: 197.5790 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #427: GFLOPs: 8807.9133. Time: 197.6981 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #428: GFLOPs: 8832.9866. Time: 197.1369 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #429: GFLOPs: 8921.6687. Time: 195.1774 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #430: GFLOPs: 8973.6783. Time: 194.0462 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #431: GFLOPs: 8979.0012. Time: 193.9311 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #432: GFLOPs: 8914.8955. Time: 195.3257 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #433: GFLOPs: 8801.9554. Time: 197.8319 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #434: GFLOPs: 8935.8950. Time: 194.8666 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #435: GFLOPs: 9007.1846. Time: 193.3243 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #436: GFLOPs: 9027.1747. Time: 192.8962 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #437: GFLOPs: 8929.7752. Time: 195.0002 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #438: GFLOPs: 8912.6354. Time: 195.3752 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #439: GFLOPs: 9299.5373. Time: 187.2467 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #440: GFLOPs: 8876.3943. Time: 196.1729 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #441: GFLOPs: 8945.1288. Time: 194.6655 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #442: GFLOPs: 8832.9834. Time: 197.1370 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #443: GFLOPs: 8912.9807. Time: 195.3676 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #444: GFLOPs: 9009.5279. Time: 193.2740 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #445: GFLOPs: 9002.0377. Time: 193.4349 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #446: GFLOPs: 279.7476. Time: 6224.5685 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #447: GFLOPs: 2567.4935. Time: 678.2132 us. Best GFLOPs: 9609.8024
2024-04-29 20:00:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #448: GFLOPs: 138.8373. Time: 12542.0799 us. Best GFLOPs: 9609.8024
2024-04-29 20:21:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:21:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 20:21:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:21:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 807 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:21:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1211 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:21:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1615 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:21:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2016 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:22:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2417 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:22:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2821 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:22:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3222 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:22:17 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2024-04-29 20:22:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 70 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:22:49 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 70 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:23:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 60 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:23:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 63 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:23:29 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9736  0.9736  0.9710  0.9706  0.9696  0.9686  0.9628  0.9627  0.9621  0.9599  0.9598  0.9597  0.9593  0.9584  0.9557  0.9554
[17 : 32]:	0.9546  0.9545  0.9524  0.9521  0.9485  0.9473  0.9470  0.9469  0.9462  0.9455  0.9440  0.9438  0.9438  0.9436  0.9429  0.9425
[33 : 48]:	0.9421  0.9421  0.9420  0.9417  0.9417  0.9415  0.9411  0.9411  0.9410  0.9396  0.9372  0.9370  0.9367  0.9367  0.9366  0.9366
[49 : 64]:	0.9361  0.9361  0.9358  0.9358  0.9353  0.9353  0.9351  0.9347  0.9344  0.9342  0.9341  0.9339  0.9339  0.9339  0.9337  0.9337
2024-04-29 20:23:29 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:23:29 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #449: GFLOPs: 9397.5222. Time: 185.2944 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #450: GFLOPs: 9502.5015. Time: 183.2473 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #451: GFLOPs: 9449.8298. Time: 184.2687 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #452: GFLOPs: 9228.7069. Time: 188.6838 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #453: GFLOPs: 9399.5956. Time: 185.2535 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #454: GFLOPs: 9399.4543. Time: 185.2563 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #455: GFLOPs: 9099.1660. Time: 191.3701 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #456: GFLOPs: 9439.6034. Time: 184.4683 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #457: GFLOPs: 9390.7892. Time: 185.4272 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #458: GFLOPs: 9606.9542. Time: 181.2549 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #459: GFLOPs: 9419.3099. Time: 184.8658 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #460: GFLOPs: 9379.2943. Time: 185.6545 us. Best GFLOPs: 9609.8024
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #461: GFLOPs: 9726.3677. Time: 179.0296 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #462: GFLOPs: 9425.8865. Time: 184.7368 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #463: GFLOPs: 9402.8384. Time: 185.1896 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #464: GFLOPs: 9582.6226. Time: 181.7152 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #465: GFLOPs: 9443.5630. Time: 184.3910 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #466: GFLOPs: 9551.2353. Time: 182.3123 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #467: GFLOPs: 9371.1798. Time: 185.8152 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #468: GFLOPs: 9193.3553. Time: 189.4094 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #469: GFLOPs: 9512.2766. Time: 183.0590 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #470: GFLOPs: 9516.2579. Time: 182.9824 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #471: GFLOPs: 9516.7002. Time: 182.9739 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #472: GFLOPs: 9435.1591. Time: 184.5552 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #473: GFLOPs: 9110.3165. Time: 191.1358 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #474: GFLOPs: 9532.2937. Time: 182.6746 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #475: GFLOPs: 8931.7028. Time: 194.9581 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #476: GFLOPs: 9175.1891. Time: 189.7844 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #477: GFLOPs: 9281.0673. Time: 187.6194 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #478: GFLOPs: 8876.0267. Time: 196.1810 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #479: GFLOPs: 9113.4519. Time: 191.0701 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #480: GFLOPs: 9077.3238. Time: 191.8305 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #481: GFLOPs: 9200.8488. Time: 189.2551 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #482: GFLOPs: 9027.6021. Time: 192.8871 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #483: GFLOPs: 9257.3738. Time: 188.0996 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #484: GFLOPs: 8961.1423. Time: 194.3176 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #485: GFLOPs: 8971.9361. Time: 194.0839 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #486: GFLOPs: 9445.8287. Time: 184.3468 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #487: GFLOPs: 8889.9175. Time: 195.8745 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #488: GFLOPs: 8890.7916. Time: 195.8552 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #489: GFLOPs: 8820.9595. Time: 197.4057 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #490: GFLOPs: 9082.2171. Time: 191.7272 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #491: GFLOPs: 9021.6782. Time: 193.0137 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #492: GFLOPs: 8836.5587. Time: 197.0572 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #493: GFLOPs: 9003.8892. Time: 193.3951 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #494: GFLOPs: 8952.4086. Time: 194.5072 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #495: GFLOPs: 8872.1532. Time: 196.2667 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #496: GFLOPs: 9328.2834. Time: 186.6697 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #497: GFLOPs: 9027.5590. Time: 192.8880 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #498: GFLOPs: 9030.4387. Time: 192.8265 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #499: GFLOPs: 9032.4081. Time: 192.7845 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #500: GFLOPs: 9108.8707. Time: 191.1662 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #501: GFLOPs: 9345.0757. Time: 186.3343 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #502: GFLOPs: 9048.6231. Time: 192.4390 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #503: GFLOPs: 9026.4418. Time: 192.9119 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #504: GFLOPs: 9062.5315. Time: 192.1437 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #505: GFLOPs: 8980.0244. Time: 193.9090 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #506: GFLOPs: 8846.7152. Time: 196.8310 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #507: GFLOPs: 9078.5491. Time: 191.8046 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #508: GFLOPs: 9063.5163. Time: 192.1228 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #509: GFLOPs: 9022.5917. Time: 192.9942 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #510: GFLOPs: 85.2362. Time: 20429.2098 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #511: GFLOPs: 4982.9489. Time: 349.4533 us. Best GFLOPs: 9726.3677
2024-04-29 20:24:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #512: GFLOPs: 31.4321. Time: 55399.0833 us. Best GFLOPs: 9726.3677
2024-04-29 20:41:30 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:41:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 20:41:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:41:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:41:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:41:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1614 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2020 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2424 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2824 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3226 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:21 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2024-04-29 20:42:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 62 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:42:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 69 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:43:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 66 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:43:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 20:43:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9687  0.9664  0.9664  0.9664  0.9613  0.9604  0.9586  0.9578  0.9578  0.9574  0.9574  0.9567  0.9557  0.9534  0.9533  0.9532
[17 : 32]:	0.9527  0.9518  0.9516  0.9515  0.9513  0.9503  0.9497  0.9492  0.9488  0.9488  0.9488  0.9488  0.9475  0.9467  0.9462  0.9453
[33 : 48]:	0.9452  0.9444  0.9439  0.9422  0.9422  0.9419  0.9418  0.9417  0.9415  0.9409  0.9385  0.9383  0.9382  0.9381  0.9373  0.9371
[49 : 64]:	0.9370  0.9369  0.9367  0.9366  0.9358  0.9356  0.9354  0.9353  0.9352  0.9348  0.9347  0.9347  0.9343  0.9342  0.9341  0.9339
2024-04-29 20:43:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 20:43:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #513: GFLOPs: 59.2043. Time: 29411.8403 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #514: GFLOPs: 30.2266. Time: 57608.5357 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #515: GFLOPs: 30.3814. Time: 57314.9870 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #516: GFLOPs: 30.2235. Time: 57614.3340 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #517: GFLOPs: 9272.0969. Time: 187.8009 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #518: GFLOPs: 9351.3515. Time: 186.2092 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #519: GFLOPs: 9361.0961. Time: 186.0154 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #520: GFLOPs: 9338.2808. Time: 186.4699 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #521: GFLOPs: 9626.3391. Time: 180.8899 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #522: GFLOPs: 9157.5271. Time: 190.1505 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #523: GFLOPs: 9278.4754. Time: 187.6718 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #524: GFLOPs: 9313.5113. Time: 186.9658 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #525: GFLOPs: 9580.3512. Time: 181.7583 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #526: GFLOPs: 9318.4717. Time: 186.8663 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #527: GFLOPs: 9421.6269. Time: 184.8203 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #528: GFLOPs: 9527.6377. Time: 182.7639 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #529: GFLOPs: 9504.3493. Time: 183.2117 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #530: GFLOPs: 9579.1943. Time: 181.7802 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #531: GFLOPs: 9486.0081. Time: 183.5659 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #532: GFLOPs: 9331.6475. Time: 186.6024 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #533: GFLOPs: 9527.4025. Time: 182.7684 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #534: GFLOPs: 9502.8348. Time: 183.2409 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #535: GFLOPs: 9555.5247. Time: 182.2305 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #536: GFLOPs: 9492.8207. Time: 183.4342 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #537: GFLOPs: 9407.5333. Time: 185.0972 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #538: GFLOPs: 9545.5580. Time: 182.4208 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #539: GFLOPs: 9541.5795. Time: 182.4968 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #540: GFLOPs: 9375.6493. Time: 185.7266 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #541: GFLOPs: 9547.6110. Time: 182.3815 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #542: GFLOPs: 9541.5080. Time: 182.4982 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #543: GFLOPs: 9280.1892. Time: 187.6371 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #544: GFLOPs: 9435.9287. Time: 184.5402 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #545: GFLOPs: 9557.5853. Time: 182.1912 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #546: GFLOPs: 25.7025. Time: 67748.5247 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #547: GFLOPs: 9500.2492. Time: 183.2908 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #548: GFLOPs: 9529.4222. Time: 182.7296 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #549: GFLOPs: 9169.6331. Time: 189.8994 us. Best GFLOPs: 9726.3677
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #550: GFLOPs: 9899.7068. Time: 175.8949 us. Best GFLOPs: 9899.7068
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #551: GFLOPs: 9378.1844. Time: 185.6764 us. Best GFLOPs: 9899.7068
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #552: GFLOPs: 9354.0364. Time: 186.1558 us. Best GFLOPs: 9899.7068
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #553: GFLOPs: 9169.2358. Time: 189.9076 us. Best GFLOPs: 9899.7068
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #554: GFLOPs: 9907.7728. Time: 175.7517 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #555: GFLOPs: 9152.0882. Time: 190.2635 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #556: GFLOPs: 8940.0087. Time: 194.7770 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #557: GFLOPs: 9117.5490. Time: 190.9842 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #558: GFLOPs: 9141.6558. Time: 190.4806 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #559: GFLOPs: 9118.1107. Time: 190.9724 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #560: GFLOPs: 9263.4027. Time: 187.9771 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #561: GFLOPs: 9357.8453. Time: 186.0800 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #562: GFLOPs: 8955.7312. Time: 194.4350 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #563: GFLOPs: 9032.2830. Time: 192.7871 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #564: GFLOPs: 9294.2913. Time: 187.3524 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #565: GFLOPs: 9888.6313. Time: 176.0919 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #566: GFLOPs: 9159.3096. Time: 190.1134 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #567: GFLOPs: 9279.9555. Time: 187.6418 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #568: GFLOPs: 8899.6300. Time: 195.6607 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #569: GFLOPs: 9091.8824. Time: 191.5234 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #570: GFLOPs: 9047.6281. Time: 192.4602 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #571: GFLOPs: 8943.9660. Time: 194.6908 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #572: GFLOPs: 8883.2957. Time: 196.0205 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #573: GFLOPs: 9756.4198. Time: 178.4782 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #574: GFLOPs: 232.5919. Time: 7486.5374 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #575: GFLOPs: 2338.7017. Time: 744.5618 us. Best GFLOPs: 9907.7728
2024-04-29 20:44:44 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #576: GFLOPs: 4104.1179. Time: 424.2831 us. Best GFLOPs: 9907.7728
2024-04-29 21:06:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:06:21 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:06:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:06:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 807 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:06:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1205 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:06:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1606 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:06:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2012 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:06:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2415 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:07:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2817 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:07:02 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2024-04-29 21:07:16 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:07:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:07:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 78 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:08:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 85 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:08:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9652  0.9628  0.9620  0.9574  0.9541  0.9528  0.9523  0.9513  0.9513  0.9502  0.9496  0.9490  0.9490  0.9488  0.9480  0.9480
[17 : 32]:	0.9479  0.9477  0.9477  0.9477  0.9471  0.9468  0.9465  0.9465  0.9463  0.9463  0.9462  0.9462  0.9461  0.9460  0.9460  0.9460
[33 : 48]:	0.9457  0.9454  0.9454  0.9452  0.9452  0.9452  0.9452  0.9448  0.9445  0.9445  0.9436  0.9435  0.9432  0.9431  0.9430  0.9430
[49 : 64]:	0.9430  0.9427  0.9426  0.9426  0.9426  0.9426  0.9421  0.9416  0.9413  0.9407  0.9404  0.9402  0.9401  0.9401  0.9401  0.9401
2024-04-29 21:08:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:08:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #577: GFLOPs: 9830.4514. Time: 177.1341 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #578: GFLOPs: 9734.4177. Time: 178.8816 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #579: GFLOPs: 9441.2419. Time: 184.4363 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #580: GFLOPs: 9588.4246. Time: 181.6052 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #581: GFLOPs: 9325.4599. Time: 186.7262 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #582: GFLOPs: 9781.5443. Time: 178.0197 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #583: GFLOPs: 9347.7691. Time: 186.2806 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #584: GFLOPs: 9579.1441. Time: 181.7812 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #585: GFLOPs: 9580.4399. Time: 181.7566 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #586: GFLOPs: 9771.9560. Time: 178.1944 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #587: GFLOPs: 9827.4246. Time: 177.1886 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #588: GFLOPs: 9326.3032. Time: 186.7093 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #589: GFLOPs: 9438.2651. Time: 184.4945 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #590: GFLOPs: 9382.3994. Time: 185.5930 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #591: GFLOPs: 9714.7028. Time: 179.2446 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #592: GFLOPs: 9350.6466. Time: 186.2233 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #593: GFLOPs: 9402.0156. Time: 185.2058 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #594: GFLOPs: 9292.5058. Time: 187.3884 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #595: GFLOPs: 9281.2061. Time: 187.6166 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #596: GFLOPs: 9396.6276. Time: 185.3120 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #597: GFLOPs: 9585.2055. Time: 181.6662 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #598: GFLOPs: 9392.0480. Time: 185.4024 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #599: GFLOPs: 9430.5708. Time: 184.6450 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #600: GFLOPs: 9579.5296. Time: 181.7738 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #601: GFLOPs: 9747.8647. Time: 178.6348 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #602: GFLOPs: 9398.1175. Time: 185.2826 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #603: GFLOPs: 9352.9146. Time: 186.1781 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #604: GFLOPs: 9432.2284. Time: 184.6126 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #605: GFLOPs: 9286.6895. Time: 187.5058 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #606: GFLOPs: 9265.5808. Time: 187.9329 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #607: GFLOPs: 9262.1927. Time: 188.0017 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #608: GFLOPs: 9606.4038. Time: 181.2653 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #609: GFLOPs: 9355.0057. Time: 186.1365 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #610: GFLOPs: 9498.0664. Time: 183.3329 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #611: GFLOPs: 9641.0189. Time: 180.6145 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #612: GFLOPs: 9399.9051. Time: 185.2474 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #613: GFLOPs: 9295.0906. Time: 187.3363 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #614: GFLOPs: 9307.0906. Time: 187.0948 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #615: GFLOPs: 9314.1154. Time: 186.9537 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #616: GFLOPs: 9520.9619. Time: 182.8920 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #617: GFLOPs: 9320.5030. Time: 186.8255 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #618: GFLOPs: 9276.9419. Time: 187.7028 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #619: GFLOPs: 9283.0967. Time: 187.5783 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #620: GFLOPs: 9435.9218. Time: 184.5403 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #621: GFLOPs: 9422.9760. Time: 184.7938 us. Best GFLOPs: 9907.7728
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #622: GFLOPs: 10124.8161. Time: 171.9842 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #623: GFLOPs: 9786.1499. Time: 177.9360 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #624: GFLOPs: 9429.3147. Time: 184.6696 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #625: GFLOPs: 9465.5335. Time: 183.9630 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #626: GFLOPs: 9264.0748. Time: 187.9635 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #627: GFLOPs: 9263.4902. Time: 187.9754 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #628: GFLOPs: 9305.9351. Time: 187.1180 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #629: GFLOPs: 9307.9303. Time: 187.0779 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #630: GFLOPs: 9396.3887. Time: 185.3167 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #631: GFLOPs: 9106.3448. Time: 191.2192 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #632: GFLOPs: 9443.2337. Time: 184.3974 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #633: GFLOPs: 9238.5205. Time: 188.4834 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #634: GFLOPs: 9445.8610. Time: 184.3461 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #635: GFLOPs: 9446.5710. Time: 184.3323 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #636: GFLOPs: 9249.1716. Time: 188.2664 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #637: GFLOPs: 9305.8066. Time: 187.1206 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #638: GFLOPs: 1185.8650. Time: 1468.3863 us. Best GFLOPs: 10124.8161
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #639: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(28) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(128), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(28)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(784))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(784) // T.int64(196))
                                    v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(10)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1 < T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(28) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(4) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(32), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_2_nu_2_co_2_p_2_fused % T.int64(28) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 2, 32, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 28, 1, 7])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 1, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b150)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b152)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b154)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2024-04-29 21:09:43 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #640: GFLOPs: 79.8475. Time: 21807.9238 us. Best GFLOPs: 10124.8161
2024-04-29 21:22:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:22:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:23:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 811 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1213 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1615 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2016 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2420 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2823 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3230 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:23:42 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2024-04-29 21:23:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:24:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:24:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 62 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:24:47 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:24:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9552  0.9531  0.9530  0.9504  0.9496  0.9491  0.9488  0.9487  0.9484  0.9478  0.9470  0.9469  0.9467  0.9465  0.9465  0.9459
[17 : 32]:	0.9458  0.9454  0.9444  0.9435  0.9431  0.9431  0.9425  0.9423  0.9421  0.9418  0.9418  0.9415  0.9411  0.9397  0.9396  0.9381
[33 : 48]:	0.9370  0.9366  0.9365  0.9348  0.9343  0.9335  0.9327  0.9321  0.9319  0.9304  0.9303  0.9303  0.9301  0.9297  0.9297  0.9297
[49 : 64]:	0.9295  0.9295  0.9294  0.9294  0.9290  0.9288  0.9280  0.9280  0.9280  0.9280  0.9279  0.9278  0.9277  0.9277  0.9274  0.9274
2024-04-29 21:24:52 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:24:52 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #641: GFLOPs: 9753.8082. Time: 178.5260 us. Best GFLOPs: 10124.8161
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #642: GFLOPs: 10139.6744. Time: 171.7321 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #643: GFLOPs: 9809.2062. Time: 177.5177 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #644: GFLOPs: 9734.2630. Time: 178.8844 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #645: GFLOPs: 9833.1297. Time: 177.0858 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #646: GFLOPs: 9588.9028. Time: 181.5962 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #647: GFLOPs: 9871.4129. Time: 176.3991 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #648: GFLOPs: 9580.5293. Time: 181.7549 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #649: GFLOPs: 9603.0930. Time: 181.3278 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #650: GFLOPs: 9718.5370. Time: 179.1739 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #651: GFLOPs: 10034.2430. Time: 173.5365 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #652: GFLOPs: 9702.4816. Time: 179.4704 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #653: GFLOPs: 9718.0098. Time: 179.1836 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #654: GFLOPs: 9764.4377. Time: 178.3316 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #655: GFLOPs: 9774.5311. Time: 178.1475 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #656: GFLOPs: 9835.2245. Time: 177.0481 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #657: GFLOPs: 9745.8813. Time: 178.6712 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #658: GFLOPs: 9755.6223. Time: 178.4928 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #659: GFLOPs: 9580.4399. Time: 181.7566 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #660: GFLOPs: 10033.7198. Time: 173.5456 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #661: GFLOPs: 9732.4869. Time: 178.9171 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #662: GFLOPs: 9692.9048. Time: 179.6477 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #663: GFLOPs: 10111.3291. Time: 172.2136 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #664: GFLOPs: 9959.6954. Time: 174.8355 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #665: GFLOPs: 9849.9427. Time: 176.7836 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #666: GFLOPs: 9594.1057. Time: 181.4977 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #667: GFLOPs: 9591.3952. Time: 181.5490 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #668: GFLOPs: 9717.2999. Time: 179.1967 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #669: GFLOPs: 9716.0401. Time: 179.2199 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #670: GFLOPs: 9773.6102. Time: 178.1642 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #671: GFLOPs: 9671.6225. Time: 180.0430 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #672: GFLOPs: 9586.3195. Time: 181.6451 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #673: GFLOPs: 9771.6003. Time: 178.2009 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #674: GFLOPs: 9734.7538. Time: 178.8754 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #675: GFLOPs: 9586.7621. Time: 181.6367 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #676: GFLOPs: 9697.3234. Time: 179.5658 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #677: GFLOPs: 9170.3182. Time: 189.8852 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #678: GFLOPs: 9036.9825. Time: 192.6869 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #679: GFLOPs: 9456.8498. Time: 184.1319 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #680: GFLOPs: 9451.5682. Time: 184.2348 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #681: GFLOPs: 9399.6698. Time: 185.2520 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #682: GFLOPs: 9194.1139. Time: 189.3938 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #683: GFLOPs: 9552.3411. Time: 182.2912 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #684: GFLOPs: 9323.7289. Time: 186.7609 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #685: GFLOPs: 9469.3183. Time: 183.8895 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #686: GFLOPs: 9397.6063. Time: 185.2927 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #687: GFLOPs: 9323.0383. Time: 186.7747 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #688: GFLOPs: 9715.3202. Time: 179.2332 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #689: GFLOPs: 9338.5995. Time: 186.4635 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #690: GFLOPs: 9366.7531. Time: 185.9030 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #691: GFLOPs: 9240.1405. Time: 188.4504 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #692: GFLOPs: 9237.0450. Time: 188.5135 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #693: GFLOPs: 9839.3919. Time: 176.9731 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #694: GFLOPs: 9438.5658. Time: 184.4886 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #695: GFLOPs: 9394.3113. Time: 185.3577 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #696: GFLOPs: 9377.7950. Time: 185.6842 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #697: GFLOPs: 9414.8593. Time: 184.9532 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #698: GFLOPs: 9684.6199. Time: 179.8014 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #699: GFLOPs: 9367.4394. Time: 185.8894 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #700: GFLOPs: 9730.8829. Time: 178.9465 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #701: GFLOPs: 9371.9350. Time: 185.8003 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #702: GFLOPs: 55.3200. Time: 31476.9915 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #703: GFLOPs: 191.3034. Time: 9102.3358 us. Best GFLOPs: 10139.6744
2024-04-29 21:26:06 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #704: GFLOPs: 1976.7160. Time: 880.9095 us. Best GFLOPs: 10139.6744
2024-04-29 21:44:35 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 21:44:37 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 21:44:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:44:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:44:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1211 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1612 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2013 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2417 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2820 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:18 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2024-04-29 21:45:33 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 69 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:45:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 87 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:46:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 53 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:46:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 71 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 21:46:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9941  0.9941  0.9897  0.9878  0.9824  0.9787  0.9773  0.9763  0.9763  0.9693  0.9670  0.9643  0.9615  0.9608  0.9601  0.9599
[17 : 32]:	0.9597  0.9597  0.9595  0.9595  0.9595  0.9594  0.9594  0.9593  0.9584  0.9584  0.9581  0.9581  0.9579  0.9573  0.9572  0.9570
[33 : 48]:	0.9570  0.9553  0.9552  0.9551  0.9551  0.9549  0.9549  0.9544  0.9541  0.9541  0.9536  0.9535  0.9534  0.9534  0.9526  0.9522
[49 : 64]:	0.9522  0.9521  0.9521  0.9519  0.9518  0.9513  0.9512  0.9510  0.9502  0.9502  0.9492  0.9492  0.9492  0.9491  0.9490  0.9488
2024-04-29 21:46:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 21:46:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #705: GFLOPs: 10118.3156. Time: 172.0946 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #706: GFLOPs: 9948.9184. Time: 175.0248 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #707: GFLOPs: 10004.5805. Time: 174.0511 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #708: GFLOPs: 10088.7218. Time: 172.5995 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #709: GFLOPs: 10021.4391. Time: 173.7583 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #710: GFLOPs: 9927.0330. Time: 175.4107 us. Best GFLOPs: 10139.6744
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #711: GFLOPs: 10153.8099. Time: 171.4931 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #712: GFLOPs: 10089.5747. Time: 172.5849 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #713: GFLOPs: 10123.2257. Time: 172.0112 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #714: GFLOPs: 10133.5203. Time: 171.8364 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #715: GFLOPs: 9995.0415. Time: 174.2172 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #716: GFLOPs: 9973.0706. Time: 174.6010 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #717: GFLOPs: 9785.9228. Time: 177.9401 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #718: GFLOPs: 9972.4731. Time: 174.6114 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #719: GFLOPs: 9689.5262. Time: 179.7103 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #720: GFLOPs: 9766.1786. Time: 178.2998 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #721: GFLOPs: 9662.8163. Time: 180.2071 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #722: GFLOPs: 9709.6248. Time: 179.3383 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #723: GFLOPs: 9764.1339. Time: 178.3372 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #724: GFLOPs: 9788.8024. Time: 177.8877 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #725: GFLOPs: 9830.8426. Time: 177.1270 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #726: GFLOPs: 9789.4053. Time: 177.8768 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #727: GFLOPs: 9686.6805. Time: 179.7631 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #728: GFLOPs: 9830.1026. Time: 177.1404 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #729: GFLOPs: 9872.2556. Time: 176.3840 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #730: GFLOPs: 9848.1568. Time: 176.8156 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #731: GFLOPs: 9831.1900. Time: 177.1208 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #732: GFLOPs: 9692.3263. Time: 179.6584 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #733: GFLOPs: 9691.0391. Time: 179.6823 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #734: GFLOPs: 9794.3788. Time: 177.7865 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #735: GFLOPs: 9743.4015. Time: 178.7166 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #736: GFLOPs: 9804.6673. Time: 177.5999 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #737: GFLOPs: 9828.5331. Time: 177.1686 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #738: GFLOPs: 9799.6096. Time: 177.6916 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #739: GFLOPs: 9580.0348. Time: 181.7643 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #740: GFLOPs: 9829.6415. Time: 177.1487 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #741: GFLOPs: 9790.0182. Time: 177.8656 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #742: GFLOPs: 9733.2585. Time: 178.9029 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #743: GFLOPs: 9735.6643. Time: 178.8587 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #744: GFLOPs: 9774.6286. Time: 178.1457 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #745: GFLOPs: 9750.6427. Time: 178.5839 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #746: GFLOPs: 9754.9194. Time: 178.5056 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #747: GFLOPs: 9830.4729. Time: 177.1337 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #748: GFLOPs: 9688.3464. Time: 179.7322 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #749: GFLOPs: 9720.7742. Time: 179.1326 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #750: GFLOPs: 9756.9822. Time: 178.4679 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #751: GFLOPs: 9580.3038. Time: 181.7592 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #752: GFLOPs: 9707.9960. Time: 179.3684 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #753: GFLOPs: 9744.5067. Time: 178.6964 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #754: GFLOPs: 9686.5904. Time: 179.7648 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #755: GFLOPs: 9710.3089. Time: 179.3257 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #756: GFLOPs: 9674.7386. Time: 179.9850 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #757: GFLOPs: 9755.4107. Time: 178.4966 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #758: GFLOPs: 9761.9467. Time: 178.3771 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #759: GFLOPs: 9735.8768. Time: 178.8548 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #760: GFLOPs: 9877.9169. Time: 176.2829 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #761: GFLOPs: 9719.8795. Time: 179.1491 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #762: GFLOPs: 9801.4515. Time: 177.6582 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #763: GFLOPs: 9640.7798. Time: 180.6190 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #764: GFLOPs: 9868.3997. Time: 176.4529 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #765: GFLOPs: 9564.0768. Time: 182.0675 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #766: GFLOPs: 311.8174. Time: 5584.3841 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #767: GFLOPs: 1059.9537. Time: 1642.8150 us. Best GFLOPs: 10153.8099
2024-04-29 21:47:41 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #768: GFLOPs: 436.9079. Time: 3985.5262 us. Best GFLOPs: 10153.8099
2024-04-29 22:09:45 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 22:09:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 22:09:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:09:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 809 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1216 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1621 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2027 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2429 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2833 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3239 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3641 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 4041 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:10:46 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2024-04-29 22:10:59 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 49 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:11:17 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:11:33 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:11:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 55 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:11:55 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.5070  0.9936  0.9863  0.9863  0.9863  0.9863  0.9857  0.9849  0.9844  0.9844  0.9844  0.9838  0.9838  0.9838  0.9838  0.9837
[17 : 32]:	0.9834  0.9831  0.9825  0.9825  0.9825  0.9818  0.9818  0.9814  0.9802  0.9772  0.9764  0.9764  0.9757  0.9757  0.9754  0.9754
[33 : 48]:	0.9753  0.9750  0.9745  0.9745  0.9739  0.9737  0.9734  0.9721  0.9718  0.9692  0.9673  0.9664  0.9664  0.9664  0.9664  0.9664
[49 : 64]:	0.9660  0.9658  0.9658  0.9651  0.9646  0.9646  0.9645  0.9635  0.9635  0.9635  0.9634  0.9628  0.9627  0.9627  0.9627  0.9626
2024-04-29 22:11:56 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 22:11:56 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #769: GFLOPs: 3120.8219. Time: 557.9645 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #770: GFLOPs: 10113.1093. Time: 172.1832 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #771: GFLOPs: 10010.6832. Time: 173.9450 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #772: GFLOPs: 10134.7935. Time: 171.8148 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #773: GFLOPs: 9949.3707. Time: 175.0169 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #774: GFLOPs: 10146.6824. Time: 171.6135 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #775: GFLOPs: 9973.9069. Time: 174.5863 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #776: GFLOPs: 9760.9514. Time: 178.3953 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #777: GFLOPs: 10048.7377. Time: 173.2862 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #778: GFLOPs: 9974.7354. Time: 174.5718 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #779: GFLOPs: 9969.9349. Time: 174.6559 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #780: GFLOPs: 10053.3557. Time: 173.2066 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #781: GFLOPs: 9985.5272. Time: 174.3832 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #782: GFLOPs: 10131.4726. Time: 171.8712 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #783: GFLOPs: 9958.7734. Time: 174.8516 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #784: GFLOPs: 9948.4084. Time: 175.0338 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #785: GFLOPs: 10136.0965. Time: 171.7928 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #786: GFLOPs: 9866.5049. Time: 176.4868 us. Best GFLOPs: 10153.8099
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #787: GFLOPs: 10161.5159. Time: 171.3630 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #788: GFLOPs: 9989.3791. Time: 174.3159 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #789: GFLOPs: 9984.0003. Time: 174.4098 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #790: GFLOPs: 10004.1357. Time: 174.0588 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #791: GFLOPs: 9914.0833. Time: 175.6398 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #792: GFLOPs: 9833.1915. Time: 177.0847 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #793: GFLOPs: 9939.3383. Time: 175.1935 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #794: GFLOPs: 10008.4136. Time: 173.9844 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #795: GFLOPs: 10005.2063. Time: 174.0402 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #796: GFLOPs: 10011.6053. Time: 173.9289 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #797: GFLOPs: 9923.9110. Time: 175.4659 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #798: GFLOPs: 9972.0642. Time: 174.6186 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #799: GFLOPs: 9980.6956. Time: 174.4676 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #800: GFLOPs: 9936.9639. Time: 175.2354 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #801: GFLOPs: 9834.7491. Time: 177.0567 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #802: GFLOPs: 9911.0783. Time: 175.6931 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #803: GFLOPs: 9997.2387. Time: 174.1789 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #804: GFLOPs: 10015.7703. Time: 173.8566 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #805: GFLOPs: 9202.4166. Time: 189.2229 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #806: GFLOPs: 9897.8068. Time: 175.9287 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #807: GFLOPs: 9933.7835. Time: 175.2915 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #808: GFLOPs: 9868.4913. Time: 176.4513 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #809: GFLOPs: 9654.0984. Time: 180.3698 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #810: GFLOPs: 9966.5730. Time: 174.7148 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #811: GFLOPs: 9511.8559. Time: 183.0671 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #812: GFLOPs: 9595.6858. Time: 181.4678 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #813: GFLOPs: 9637.9291. Time: 180.6724 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #814: GFLOPs: 9746.2321. Time: 178.6647 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #815: GFLOPs: 9587.0220. Time: 181.6318 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #816: GFLOPs: 9732.2789. Time: 178.9209 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #817: GFLOPs: 10019.0742. Time: 173.7993 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #818: GFLOPs: 9797.7669. Time: 177.7250 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #819: GFLOPs: 9787.5795. Time: 177.9100 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #820: GFLOPs: 9732.7620. Time: 178.9120 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #821: GFLOPs: 9773.0572. Time: 178.1743 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #822: GFLOPs: 9765.3414. Time: 178.3151 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #823: GFLOPs: 9571.9592. Time: 181.9176 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #824: GFLOPs: 9733.7140. Time: 178.8945 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #825: GFLOPs: 9565.1890. Time: 182.0464 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #826: GFLOPs: 9733.5328. Time: 178.8978 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #827: GFLOPs: 9823.4025. Time: 177.2612 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #828: GFLOPs: 9691.5874. Time: 179.6721 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #829: GFLOPs: 9541.0538. Time: 182.5069 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #830: GFLOPs: 7355.8872. Time: 236.7230 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #831: GFLOPs: 569.4607. Time: 3057.8192 us. Best GFLOPs: 10161.5159
2024-04-29 22:12:58 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #832: GFLOPs: 241.0439. Time: 7224.0274 us. Best GFLOPs: 10161.5159
2024-04-29 22:37:14 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 22:37:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 22:37:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1209 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2012 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2412 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2815 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:37:57 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2024-04-29 22:38:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 58 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:38:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 57 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:38:46 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:39:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 61 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:39:09 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9989  0.9989  0.9926  0.9915  0.9911  0.9898  0.9890  0.9888  0.9888  0.9882  0.9875  0.9874  0.9870  0.9870  0.9869  0.9867
[17 : 32]:	0.9866  0.9864  0.9862  0.9859  0.9854  0.9851  0.9851  0.9848  0.9846  0.9846  0.9846  0.9839  0.9839  0.9838  0.9838  0.9838
[33 : 48]:	0.9837  0.9833  0.9833  0.9831  0.9829  0.9829  0.9827  0.9826  0.9825  0.9822  0.9818  0.9817  0.9817  0.9814  0.9813  0.9812
[49 : 64]:	0.9811  0.9811  0.9803  0.9798  0.9794  0.9794  0.9787  0.9784  0.9784  0.9773  0.9765  0.9761  0.9757  0.9749  0.9744  0.9738
2024-04-29 22:39:09 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 22:39:09 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #833: GFLOPs: 98.8067. Time: 17623.3812 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #834: GFLOPs: 104.8164. Time: 16612.9367 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #835: GFLOPs: 9844.9437. Time: 176.8733 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #836: GFLOPs: 10110.4778. Time: 172.2281 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #837: GFLOPs: 10068.6230. Time: 172.9440 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #838: GFLOPs: 10156.4516. Time: 171.4485 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #839: GFLOPs: 9960.8508. Time: 174.8152 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #840: GFLOPs: 9963.1983. Time: 174.7740 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #841: GFLOPs: 10070.9520. Time: 172.9040 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #842: GFLOPs: 100.9416. Time: 17250.6458 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #843: GFLOPs: 10068.4403. Time: 172.9471 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #844: GFLOPs: 9898.6054. Time: 175.9145 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #845: GFLOPs: 9830.2852. Time: 177.1371 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #846: GFLOPs: 9934.2660. Time: 175.2830 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #847: GFLOPs: 10048.2426. Time: 173.2948 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #848: GFLOPs: 10029.2616. Time: 173.6227 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #849: GFLOPs: 9993.3545. Time: 174.2466 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #850: GFLOPs: 10136.8017. Time: 171.7808 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #851: GFLOPs: 9875.3817. Time: 176.3282 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #852: GFLOPs: 9949.6697. Time: 175.0116 us. Best GFLOPs: 10161.5159
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #853: GFLOPs: 10198.3219. Time: 170.7446 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #854: GFLOPs: 9928.4933. Time: 175.3849 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #855: GFLOPs: 9928.7037. Time: 175.3812 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #856: GFLOPs: 9916.3846. Time: 175.5991 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #857: GFLOPs: 10113.7991. Time: 172.1715 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #858: GFLOPs: 10067.6652. Time: 172.9604 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #859: GFLOPs: 10182.5175. Time: 171.0096 us. Best GFLOPs: 10198.3219
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #860: GFLOPs: 10198.9845. Time: 170.7335 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #861: GFLOPs: 9985.0936. Time: 174.3907 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #862: GFLOPs: 9985.5545. Time: 174.3827 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #863: GFLOPs: 10185.4435. Time: 170.9604 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #864: GFLOPs: 10037.5684. Time: 173.4791 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #865: GFLOPs: 10046.6149. Time: 173.3228 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #866: GFLOPs: 9930.0618. Time: 175.3572 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #867: GFLOPs: 9831.0126. Time: 177.1240 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #868: GFLOPs: 10140.8459. Time: 171.7123 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #869: GFLOPs: 10004.5858. Time: 174.0510 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #870: GFLOPs: 9991.4976. Time: 174.2790 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #871: GFLOPs: 10188.4570. Time: 170.9099 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #872: GFLOPs: 10042.8538. Time: 173.3878 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #873: GFLOPs: 9933.2603. Time: 175.3007 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #874: GFLOPs: 10108.5251. Time: 172.2613 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #875: GFLOPs: 10106.3071. Time: 172.2991 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #876: GFLOPs: 9945.4333. Time: 175.0862 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #877: GFLOPs: 10181.4885. Time: 171.0268 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #878: GFLOPs: 10183.3645. Time: 170.9953 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #879: GFLOPs: 9916.6775. Time: 175.5939 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #880: GFLOPs: 10016.3666. Time: 173.8463 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #881: GFLOPs: 10103.3233. Time: 172.3500 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #882: GFLOPs: 10026.8589. Time: 173.6643 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #883: GFLOPs: 9900.0445. Time: 175.8889 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #884: GFLOPs: 10000.9047. Time: 174.1150 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #885: GFLOPs: 9879.8311. Time: 176.2488 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #886: GFLOPs: 9990.7938. Time: 174.2912 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #887: GFLOPs: 9883.5993. Time: 176.1816 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #888: GFLOPs: 9868.6746. Time: 176.4480 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #889: GFLOPs: 9999.5170. Time: 174.1392 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #890: GFLOPs: 9850.9583. Time: 176.7653 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #891: GFLOPs: 10171.5799. Time: 171.1935 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #892: GFLOPs: 9889.8144. Time: 176.0708 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #893: GFLOPs: 9972.3203. Time: 174.6141 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #894: GFLOPs: 247.8688. Time: 7025.1180 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #895: GFLOPs: 2759.9130. Time: 630.9285 us. Best GFLOPs: 10198.9845
2024-04-29 22:40:13 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #896: GFLOPs: 739.2714. Time: 2355.4380 us. Best GFLOPs: 10198.9845
2024-04-29 22:55:39 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 22:55:42 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 22:55:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:55:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:55:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2011 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2413 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2819 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:21 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2024-04-29 22:56:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 37 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:56:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 50 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:57:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 56 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:57:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 62 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 22:57:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9976  0.9941  0.9941  0.9941  0.9937  0.9936  0.9936  0.9925  0.9925  0.9924  0.9923  0.9923  0.9923  0.9922  0.9922  0.9907
[17 : 32]:	0.9907  0.9907  0.9907  0.9907  0.9906  0.9906  0.9900  0.9896  0.9896  0.9895  0.9895  0.9894  0.9894  0.9892  0.9883  0.9881
[33 : 48]:	0.9879  0.9879  0.9876  0.9876  0.9876  0.9876  0.9875  0.9869  0.9867  0.9867  0.9866  0.9866  0.9865  0.9865  0.9862  0.9862
[49 : 64]:	0.9861  0.9858  0.9854  0.9854  0.9853  0.9853  0.9852  0.9852  0.9850  0.9850  0.9840  0.9839  0.9836  0.9836  0.9836  0.9835
2024-04-29 22:57:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 22:57:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #897: GFLOPs: 10129.0229. Time: 171.9127 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #898: GFLOPs: 9950.6292. Time: 174.9948 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #899: GFLOPs: 10009.1154. Time: 173.9722 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #900: GFLOPs: 10193.4768. Time: 170.8257 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #901: GFLOPs: 10008.8328. Time: 173.9771 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #902: GFLOPs: 10124.7178. Time: 171.9858 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #903: GFLOPs: 10110.2622. Time: 172.2317 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #904: GFLOPs: 9995.2979. Time: 174.2127 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #905: GFLOPs: 10002.9175. Time: 174.0800 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #906: GFLOPs: 9999.2187. Time: 174.1444 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #907: GFLOPs: 10194.4571. Time: 170.8093 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #908: GFLOPs: 10182.0447. Time: 171.0175 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #909: GFLOPs: 10179.3106. Time: 171.0634 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #910: GFLOPs: 10104.4423. Time: 172.3309 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #911: GFLOPs: 10195.5385. Time: 170.7912 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #912: GFLOPs: 9934.6317. Time: 175.2765 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #913: GFLOPs: 9988.2987. Time: 174.3348 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #914: GFLOPs: 9937.5735. Time: 175.2247 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #915: GFLOPs: 9833.9899. Time: 177.0703 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #916: GFLOPs: 9834.8402. Time: 177.0550 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #917: GFLOPs: 9958.9808. Time: 174.8480 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #918: GFLOPs: 9985.6201. Time: 174.3815 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #919: GFLOPs: 9989.1186. Time: 174.3205 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #920: GFLOPs: 10066.0156. Time: 172.9888 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #921: GFLOPs: 10013.1811. Time: 173.9016 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #922: GFLOPs: 10013.0410. Time: 173.9040 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #923: GFLOPs: 10138.1427. Time: 171.7581 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #924: GFLOPs: 9951.6143. Time: 174.9774 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #925: GFLOPs: 9949.5499. Time: 175.0137 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #926: GFLOPs: 9939.6312. Time: 175.1884 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #927: GFLOPs: 9909.3540. Time: 175.7237 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #928: GFLOPs: 10115.1159. Time: 172.1491 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #929: GFLOPs: 9984.2639. Time: 174.4052 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #930: GFLOPs: 10181.8402. Time: 171.0209 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #931: GFLOPs: 9968.3030. Time: 174.6845 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #932: GFLOPs: 9976.2854. Time: 174.5447 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #933: GFLOPs: 10190.4874. Time: 170.8758 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #934: GFLOPs: 9948.7103. Time: 175.0285 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #935: GFLOPs: 9908.6757. Time: 175.7357 us. Best GFLOPs: 10198.9845
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #936: GFLOPs: 10206.6250. Time: 170.6057 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #937: GFLOPs: 9954.9891. Time: 174.9181 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #938: GFLOPs: 9942.5043. Time: 175.1378 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #939: GFLOPs: 9917.4778. Time: 175.5797 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #940: GFLOPs: 10010.6850. Time: 173.9449 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #941: GFLOPs: 9976.1019. Time: 174.5479 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #942: GFLOPs: 10006.3098. Time: 174.0210 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #943: GFLOPs: 9875.5848. Time: 176.3245 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #944: GFLOPs: 10138.5093. Time: 171.7519 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #945: GFLOPs: 10050.0083. Time: 173.2643 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #946: GFLOPs: 9741.7712. Time: 178.7465 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #947: GFLOPs: 10049.0790. Time: 173.2803 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #948: GFLOPs: 10013.1899. Time: 173.9014 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #949: GFLOPs: 9973.5372. Time: 174.5928 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #950: GFLOPs: 9952.0245. Time: 174.9702 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #951: GFLOPs: 10155.2037. Time: 171.4695 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #952: GFLOPs: 10156.5326. Time: 171.4471 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #953: GFLOPs: 9985.2874. Time: 174.3874 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #954: GFLOPs: 10002.0756. Time: 174.0947 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #955: GFLOPs: 9965.7152. Time: 174.7298 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #956: GFLOPs: 10126.0311. Time: 171.9635 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #957: GFLOPs: 10118.1360. Time: 172.0977 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #958: GFLOPs: 126.7927. Time: 13733.5042 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #959: GFLOPs: 233.6305. Time: 7453.2569 us. Best GFLOPs: 10206.6250
2024-04-29 22:58:34 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #960: GFLOPs: 338.1346. Time: 5149.7470 us. Best GFLOPs: 10206.6250
2024-04-29 23:11:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:11:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:11:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 807 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1611 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2013 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2413 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2814 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:11:50 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2024-04-29 23:12:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 52 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:12:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 58 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:12:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 71 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:12:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:13:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9980  0.9954  0.9936  0.9931  0.9913  0.9904  0.9897  0.9897  0.9895  0.9892  0.9891  0.9881  0.9879  0.9871  0.9871  0.9871
[17 : 32]:	0.9859  0.9858  0.9854  0.9852  0.9851  0.9847  0.9846  0.9845  0.9843  0.9842  0.9839  0.9837  0.9837  0.9835  0.9831  0.9828
[33 : 48]:	0.9827  0.9827  0.9827  0.9827  0.9820  0.9816  0.9815  0.9812  0.9812  0.9812  0.9807  0.9807  0.9807  0.9807  0.9804  0.9801
[49 : 64]:	0.9801  0.9801  0.9800  0.9800  0.9800  0.9797  0.9796  0.9796  0.9795  0.9792  0.9791  0.9790  0.9788  0.9787  0.9780  0.9776
2024-04-29 23:13:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:13:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #961: GFLOPs: 10197.0317. Time: 170.7662 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #962: GFLOPs: 10119.0824. Time: 172.0816 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #963: GFLOPs: 10195.1026. Time: 170.7985 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #964: GFLOPs: 10205.4092. Time: 170.6260 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #965: GFLOPs: 9800.5386. Time: 177.6747 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #966: GFLOPs: 10099.7479. Time: 172.4110 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #967: GFLOPs: 10200.7478. Time: 170.7039 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #968: GFLOPs: 10134.6412. Time: 171.8174 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #969: GFLOPs: 10138.4928. Time: 171.7521 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #970: GFLOPs: 10004.2314. Time: 174.0571 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #971: GFLOPs: 9988.0226. Time: 174.3396 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #972: GFLOPs: 9987.4720. Time: 174.3492 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #973: GFLOPs: 10073.3631. Time: 172.8626 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #974: GFLOPs: 10178.7665. Time: 171.0726 us. Best GFLOPs: 10206.6250
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #975: GFLOPs: 10235.5910. Time: 170.1228 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #976: GFLOPs: 10178.1487. Time: 171.0830 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #977: GFLOPs: 10144.4442. Time: 171.6514 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #978: GFLOPs: 10207.6631. Time: 170.5883 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #979: GFLOPs: 9983.8952. Time: 174.4117 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #980: GFLOPs: 10167.7198. Time: 171.2584 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #981: GFLOPs: 10198.9404. Time: 170.7342 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #982: GFLOPs: 10071.6306. Time: 172.8924 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #983: GFLOPs: 10143.5972. Time: 171.6657 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #984: GFLOPs: 9951.4158. Time: 174.9809 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #985: GFLOPs: 10104.4147. Time: 172.3314 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #986: GFLOPs: 10035.2014. Time: 173.5200 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #987: GFLOPs: 10110.2464. Time: 172.2320 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #988: GFLOPs: 10039.5477. Time: 173.4449 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #989: GFLOPs: 9982.2208. Time: 174.4409 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #990: GFLOPs: 10140.3333. Time: 171.7210 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #991: GFLOPs: 10182.8933. Time: 171.0033 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #992: GFLOPs: 10068.8835. Time: 172.9395 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #993: GFLOPs: 10182.9857. Time: 171.0017 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #994: GFLOPs: 10179.7843. Time: 171.0555 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #995: GFLOPs: 10155.2651. Time: 171.4685 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #996: GFLOPs: 10155.9751. Time: 171.4565 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #997: GFLOPs: 9876.6661. Time: 176.3052 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #998: GFLOPs: 9996.0714. Time: 174.1992 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #999: GFLOPs: 9984.1757. Time: 174.4068 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1000: GFLOPs: 9984.8459. Time: 174.3951 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1001: GFLOPs: 10166.3198. Time: 171.2820 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1002: GFLOPs: 10113.5871. Time: 172.1751 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1003: GFLOPs: 10202.0398. Time: 170.6823 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1004: GFLOPs: 9885.6964. Time: 176.1442 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1005: GFLOPs: 9859.4375. Time: 176.6133 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1006: GFLOPs: 9886.0592. Time: 176.1377 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1007: GFLOPs: 10176.0484. Time: 171.1183 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1008: GFLOPs: 9877.5713. Time: 176.2891 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1009: GFLOPs: 9863.8678. Time: 176.5340 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1010: GFLOPs: 10110.9725. Time: 172.2196 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1011: GFLOPs: 10231.7009. Time: 170.1875 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1012: GFLOPs: 10069.2528. Time: 172.9332 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1013: GFLOPs: 10083.8291. Time: 172.6832 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1014: GFLOPs: 10180.2551. Time: 171.0476 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1015: GFLOPs: 9859.0804. Time: 176.6197 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1016: GFLOPs: 10080.2719. Time: 172.7441 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1017: GFLOPs: 10111.7333. Time: 172.2067 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1018: GFLOPs: 9985.9086. Time: 174.3765 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1019: GFLOPs: 10156.1572. Time: 171.4534 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1020: GFLOPs: 9984.9023. Time: 174.3941 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1021: GFLOPs: 9981.9605. Time: 174.4455 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1022: GFLOPs: 32.2618. Time: 53974.3550 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1023: GFLOPs: 650.9207. Time: 2675.1462 us. Best GFLOPs: 10235.5910
2024-04-29 23:14:04 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1024: GFLOPs: 359.1333. Time: 4848.6400 us. Best GFLOPs: 10235.5910
2024-04-29 23:39:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 23:39:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 23:39:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:39:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:39:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:39:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1596 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:39:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1995 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:39:38 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2024-04-29 23:39:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:40:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 43 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:40:26 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 58 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:40:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-29 23:40:49 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9934  0.9919  0.9917  0.9908  0.9904  0.9902  0.9897  0.9896  0.9890  0.9889  0.9884  0.9881  0.9881  0.9879  0.9874  0.9871
[17 : 32]:	0.9861  0.9857  0.9856  0.9856  0.9853  0.9845  0.9845  0.9841  0.9838  0.9838  0.9838  0.9837  0.9836  0.9835  0.9835  0.9833
[33 : 48]:	0.9831  0.9828  0.9826  0.9826  0.9823  0.9821  0.9820  0.9820  0.9820  0.9819  0.9818  0.9818  0.9817  0.9816  0.9815  0.9815
[49 : 64]:	0.9813  0.9812  0.9809  0.9809  0.9808  0.9808  0.9800  0.9800  0.9799  0.9796  0.9796  0.9792  0.9791  0.9791  0.9791  0.9788
2024-04-29 23:40:49 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 23:40:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1025: GFLOPs: 10136.5748. Time: 171.7846 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1026: GFLOPs: 10120.5033. Time: 172.0574 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1027: GFLOPs: 10121.9063. Time: 172.0336 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1028: GFLOPs: 9863.6656. Time: 176.5376 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1029: GFLOPs: 10137.5966. Time: 171.7673 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1030: GFLOPs: 9930.7183. Time: 175.3456 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1031: GFLOPs: 10048.1812. Time: 173.2958 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1032: GFLOPs: 10214.7488. Time: 170.4700 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1033: GFLOPs: 10114.9447. Time: 172.1520 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1034: GFLOPs: 9972.9395. Time: 174.6033 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1035: GFLOPs: 10070.3547. Time: 172.9143 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1036: GFLOPs: 10113.7827. Time: 172.1718 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1037: GFLOPs: 10156.8398. Time: 171.4419 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1038: GFLOPs: 9952.4844. Time: 174.9621 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1039: GFLOPs: 9991.9373. Time: 174.2713 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1040: GFLOPs: 10021.5190. Time: 173.7569 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1041: GFLOPs: 10054.0065. Time: 173.1954 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1042: GFLOPs: 10021.7164. Time: 173.7535 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1043: GFLOPs: 10072.0707. Time: 172.8848 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1044: GFLOPs: 9988.3215. Time: 174.3344 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1045: GFLOPs: 9874.5669. Time: 176.3427 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1046: GFLOPs: 9867.9317. Time: 176.4613 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1047: GFLOPs: 10198.1585. Time: 170.7473 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1048: GFLOPs: 10139.2038. Time: 171.7401 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1049: GFLOPs: 10034.0999. Time: 173.5390 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1050: GFLOPs: 10098.5719. Time: 172.4311 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1051: GFLOPs: 9972.3990. Time: 174.6127 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1052: GFLOPs: 9971.4462. Time: 174.6294 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1053: GFLOPs: 10158.1474. Time: 171.4198 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1054: GFLOPs: 10009.7853. Time: 173.9606 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1055: GFLOPs: 9989.3926. Time: 174.3157 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1056: GFLOPs: 9917.4245. Time: 175.5807 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1057: GFLOPs: 10117.8112. Time: 172.1032 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1058: GFLOPs: 10194.3282. Time: 170.8114 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1059: GFLOPs: 9920.1878. Time: 175.5317 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1060: GFLOPs: 9825.6090. Time: 177.2214 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1061: GFLOPs: 10013.2419. Time: 173.9005 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1062: GFLOPs: 10133.4979. Time: 171.8368 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1063: GFLOPs: 9949.1991. Time: 175.0199 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1064: GFLOPs: 10047.5900. Time: 173.3060 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1065: GFLOPs: 9986.2786. Time: 174.3701 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1066: GFLOPs: 10195.3097. Time: 170.7950 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1067: GFLOPs: 10104.0411. Time: 172.3378 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1068: GFLOPs: 10105.0686. Time: 172.3202 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1069: GFLOPs: 9904.4411. Time: 175.8108 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1070: GFLOPs: 10101.3958. Time: 172.3829 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1071: GFLOPs: 10010.5128. Time: 173.9479 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1072: GFLOPs: 10095.7383. Time: 172.4795 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1073: GFLOPs: 10089.2767. Time: 172.5900 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1074: GFLOPs: 10130.1205. Time: 171.8941 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1075: GFLOPs: 9985.8045. Time: 174.3783 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1076: GFLOPs: 10210.9040. Time: 170.5342 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1077: GFLOPs: 9861.4468. Time: 176.5773 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1078: GFLOPs: 10074.2151. Time: 172.8480 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1079: GFLOPs: 10194.4620. Time: 170.8092 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1080: GFLOPs: 9932.3943. Time: 175.3160 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1081: GFLOPs: 10151.1246. Time: 171.5384 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1082: GFLOPs: 10182.0447. Time: 171.0175 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1083: GFLOPs: 10193.9913. Time: 170.8171 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1084: GFLOPs: 9832.0361. Time: 177.1055 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1085: GFLOPs: 10046.4092. Time: 173.3264 us. Best GFLOPs: 10235.5910
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1086: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(120) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(14), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(14) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(256), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(49)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(784))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(784) // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196) // T.int64(98))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(98))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(14) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(2), T.int64(14)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(7) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(14) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 7, 1, 14, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b150)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b152)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b154)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1087: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(60) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + p_3_init * T.int64(49) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(25)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(392))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(392) // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(196) // T.int64(98))
                                    v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(98))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1 < T.int64(784))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(1024))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(512))
                                        v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + p_3 * T.int64(49) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(98) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 8, 16, 1, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 49])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 23:42:20 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1088: GFLOPs: 85.6242. Time: 20336.6394 us. Best GFLOPs: 10235.5910
2024-04-30 00:02:50 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:02:53 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:02:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 809 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1213 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1612 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2017 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2421 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2827 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3227 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:03:40 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2024-04-30 00:03:55 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 59 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:04:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 38 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:04:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:04:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:04:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9936  0.9930  0.9924  0.9919  0.9910  0.9908  0.9907  0.9907  0.9906  0.9906  0.9906  0.9905  0.9904  0.9893  0.9885  0.9879
[17 : 32]:	0.9878  0.9873  0.9873  0.9872  0.9868  0.9868  0.9864  0.9862  0.9854  0.9853  0.9848  0.9847  0.9846  0.9846  0.9845  0.9843
[33 : 48]:	0.9843  0.9840  0.9837  0.9835  0.9834  0.9834  0.9834  0.9832  0.9830  0.9825  0.9823  0.9820  0.9820  0.9818  0.9817  0.9812
[49 : 64]:	0.9811  0.9811  0.9807  0.9806  0.9805  0.9801  0.9796  0.9795  0.9794  0.9794  0.9790  0.9790  0.9781  0.9780  0.9780  0.9779
2024-04-30 00:04:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:04:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1089: GFLOPs: 10119.0956. Time: 172.0814 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1090: GFLOPs: 10089.1398. Time: 172.5923 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1091: GFLOPs: 9932.2126. Time: 175.3192 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1092: GFLOPs: 10156.9331. Time: 171.4403 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1093: GFLOPs: 10091.3196. Time: 172.5550 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1094: GFLOPs: 10047.0372. Time: 173.3156 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1095: GFLOPs: 10066.2944. Time: 172.9840 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1096: GFLOPs: 10047.2440. Time: 173.3120 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1097: GFLOPs: 9883.5706. Time: 176.1821 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1098: GFLOPs: 10195.5385. Time: 170.7912 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1099: GFLOPs: 10093.2220. Time: 172.5225 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1100: GFLOPs: 10124.3394. Time: 171.9922 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1101: GFLOPs: 10126.0122. Time: 171.9638 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1102: GFLOPs: 10020.0746. Time: 173.7819 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1103: GFLOPs: 10126.0057. Time: 171.9639 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1104: GFLOPs: 10090.5695. Time: 172.5679 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1105: GFLOPs: 9971.9716. Time: 174.6202 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1106: GFLOPs: 9847.1243. Time: 176.8342 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1107: GFLOPs: 9997.9318. Time: 174.1668 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1108: GFLOPs: 10084.6224. Time: 172.6696 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1109: GFLOPs: 9874.3094. Time: 176.3473 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1110: GFLOPs: 10043.8200. Time: 173.3711 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1111: GFLOPs: 10135.0537. Time: 171.8104 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1112: GFLOPs: 10050.1939. Time: 173.2611 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1113: GFLOPs: 10017.8330. Time: 173.8208 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1114: GFLOPs: 9875.7517. Time: 176.3216 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1115: GFLOPs: 9972.5815. Time: 174.6095 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1116: GFLOPs: 9848.6758. Time: 176.8063 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1117: GFLOPs: 10117.2952. Time: 172.1120 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1118: GFLOPs: 9989.2224. Time: 174.3187 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1119: GFLOPs: 10113.4005. Time: 172.1783 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1120: GFLOPs: 10011.6966. Time: 173.9274 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1121: GFLOPs: 10181.3952. Time: 171.0284 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1122: GFLOPs: 10095.4584. Time: 172.4843 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1123: GFLOPs: 9967.6638. Time: 174.6957 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1124: GFLOPs: 10082.2090. Time: 172.7110 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1125: GFLOPs: 10138.6802. Time: 171.7490 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1126: GFLOPs: 10155.9398. Time: 171.4571 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1127: GFLOPs: 10113.0547. Time: 172.1842 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1128: GFLOPs: 10182.6111. Time: 171.0080 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1129: GFLOPs: 10153.9097. Time: 171.4914 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1130: GFLOPs: 9886.2395. Time: 176.1345 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1131: GFLOPs: 9884.1765. Time: 176.1713 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1132: GFLOPs: 9917.5821. Time: 175.5779 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1133: GFLOPs: 10063.6811. Time: 173.0289 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1134: GFLOPs: 10131.8326. Time: 171.8650 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1135: GFLOPs: 9989.5501. Time: 174.3129 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1136: GFLOPs: 10122.3740. Time: 172.0256 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1137: GFLOPs: 9916.8533. Time: 175.5908 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1138: GFLOPs: 9688.7189. Time: 179.7253 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1139: GFLOPs: 10014.8093. Time: 173.8733 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1140: GFLOPs: 10133.8298. Time: 171.8312 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1141: GFLOPs: 10067.5050. Time: 172.9632 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1142: GFLOPs: 9998.7099. Time: 174.1533 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1143: GFLOPs: 10080.8456. Time: 172.7343 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1144: GFLOPs: 10022.1502. Time: 173.7459 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1145: GFLOPs: 10199.1120. Time: 170.7313 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1146: GFLOPs: 10185.5514. Time: 170.9586 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1147: GFLOPs: 10061.9205. Time: 173.0592 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1148: GFLOPs: 10106.3515. Time: 172.2984 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1149: GFLOPs: 10132.9579. Time: 171.8460 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1150: GFLOPs: 6460.9141. Time: 269.5142 us. Best GFLOPs: 10235.5910
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1151: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(112), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(56) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(56) // T.int64(7) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(8) + co_3_init * T.int64(8) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(7)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(392))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(392) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(37)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(56) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(56) // T.int64(7) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(8) + co_3 * T.int64(8) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(56) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(56) // T.int64(7) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(7) * T.int64(28) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 8, 8, 1, 8])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 7, 7, 1, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 56, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-30 00:06:23 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1152: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(7), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(14) * T.int64(32) + co_3_init * T.int64(32) + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(28))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(147)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(2048) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1 < T.int64(8192))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(14) * T.int64(32) + co_3 * T.int64(32) + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(2), T.int64(32), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(28) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(28) // T.int64(14) * T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_0_nu_0_co_0_p_0_fused * T.int64(28) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(14) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 1, 4, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 8, 2, 1, 32])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[7, 2, 14, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 56, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-30 00:17:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:18:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:18:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 807 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1613 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2018 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2422 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2827 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3228 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:18:48 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2024-04-30 00:19:03 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 47 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:19:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 70 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:19:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:19:55 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 84 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:20:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1421  1.1421  1.1391  1.0297  0.9925  0.9921  0.9921  0.9901  0.9887  0.9883  0.9883  0.9880  0.9875  0.9874  0.9871  0.9868
[17 : 32]:	0.9863  0.9861  0.9860  0.9857  0.9853  0.9849  0.9848  0.9848  0.9848  0.9844  0.9838  0.9838  0.9838  0.9837  0.9837  0.9837
[33 : 48]:	0.9837  0.9833  0.9831  0.9831  0.9830  0.9823  0.9822  0.9820  0.9818  0.9814  0.9811  0.9809  0.9803  0.9802  0.9799  0.9797
[49 : 64]:	0.9796  0.9793  0.9793  0.9792  0.9792  0.9789  0.9788  0.9787  0.9785  0.9785  0.9783  0.9782  0.9781  0.9780  0.9780  0.9777
2024-04-30 00:20:01 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:20:01 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1153: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(49), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(7)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(784))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(784) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(3136))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(49), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 4, 1, 49, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1154: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(7)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(784))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(784) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(3136))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 4, 1, 7, 7])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:121] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1155: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(196), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(196)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax0)
                        v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps and v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps < T.int64(29) and T.int64(1) <= v_p % T.int64(14) * T.int64(2) + v_nu and v_p % T.int64(14) * T.int64(2) + v_nu < T.int64(29), p0[v_p // T.int64(196), v_ci, v_p % T.int64(196) // T.int64(14) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(14) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                            v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196))
                                    v_p = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(196))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(196) + ax2)
                        v3 = T.axis.spatial(T.int64(196), (ci_p_fused_0 * T.int64(44) + ci_p_fused_1) % T.int64(196) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(7)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(784))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(784) // T.int64(196))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(196), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(3136))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(49)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(196), eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(1568), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196) + ax0)
                                        v_p = T.axis.spatial(T.int64(196), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(196))
                        v_h = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(196) // T.int64(14) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(28), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(14) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(196) + v_h // T.int64(2) * T.int64(14) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 32, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 4, 1, 7, 7])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1156: GFLOPs: 29.5131. Time: 59001.1747 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1157: GFLOPs: 10194.5765. Time: 170.8073 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1158: GFLOPs: 10196.9777. Time: 170.7671 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1159: GFLOPs: 10197.6407. Time: 170.7560 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1160: GFLOPs: 10079.2785. Time: 172.7612 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1161: GFLOPs: 10198.0180. Time: 170.7496 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1162: GFLOPs: 10196.6415. Time: 170.7727 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1163: GFLOPs: 10157.7403. Time: 171.4267 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1164: GFLOPs: 9857.2602. Time: 176.6523 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1165: GFLOPs: 10180.8209. Time: 171.0381 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1166: GFLOPs: 10057.2016. Time: 173.1404 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1167: GFLOPs: 10044.5442. Time: 173.3586 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1168: GFLOPs: 10128.5227. Time: 171.9212 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1169: GFLOPs: 10136.5153. Time: 171.7857 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1170: GFLOPs: 9975.1960. Time: 174.5638 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1171: GFLOPs: 10009.6575. Time: 173.9628 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1172: GFLOPs: 10008.7581. Time: 173.9784 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1173: GFLOPs: 9775.4079. Time: 178.1315 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1174: GFLOPs: 10173.1807. Time: 171.1665 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1175: GFLOPs: 10074.6813. Time: 172.8400 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1176: GFLOPs: 10061.2731. Time: 173.0703 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1177: GFLOPs: 10053.8724. Time: 173.1977 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1178: GFLOPs: 10134.0460. Time: 171.8275 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1179: GFLOPs: 10016.5716. Time: 173.8427 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1180: GFLOPs: 10019.3396. Time: 173.7947 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1181: GFLOPs: 10013.9623. Time: 173.8880 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1182: GFLOPs: 10104.7883. Time: 172.3250 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1183: GFLOPs: 10104.0411. Time: 172.3378 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1184: GFLOPs: 10104.8015. Time: 172.3248 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1185: GFLOPs: 10137.3663. Time: 171.7712 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1186: GFLOPs: 10199.4353. Time: 170.7259 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1187: GFLOPs: 10075.7657. Time: 172.8214 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1188: GFLOPs: 10138.7380. Time: 171.7480 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1189: GFLOPs: 10020.1444. Time: 173.7807 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1190: GFLOPs: 10049.3247. Time: 173.2761 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1191: GFLOPs: 10181.4747. Time: 171.0271 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1192: GFLOPs: 9855.6586. Time: 176.6810 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1193: GFLOPs: 10014.0724. Time: 173.8861 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1194: GFLOPs: 10100.7747. Time: 172.3935 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1195: GFLOPs: 10180.6320. Time: 171.0412 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1196: GFLOPs: 10078.2440. Time: 172.7789 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1197: GFLOPs: 10120.5101. Time: 172.0573 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1198: GFLOPs: 9814.4795. Time: 177.4223 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1199: GFLOPs: 9959.7386. Time: 174.8347 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1200: GFLOPs: 9948.4972. Time: 175.0323 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1201: GFLOPs: 10129.1266. Time: 171.9110 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1202: GFLOPs: 9879.4824. Time: 176.2550 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1203: GFLOPs: 10137.0383. Time: 171.7768 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1204: GFLOPs: 9917.5963. Time: 175.5776 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1205: GFLOPs: 10135.3341. Time: 171.8057 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1206: GFLOPs: 9960.9988. Time: 174.8126 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1207: GFLOPs: 9973.9981. Time: 174.5847 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1208: GFLOPs: 10079.7202. Time: 172.7536 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1209: GFLOPs: 9891.5417. Time: 176.0401 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1210: GFLOPs: 9997.3665. Time: 174.1767 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1211: GFLOPs: 10008.8691. Time: 173.9765 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1212: GFLOPs: 10181.2919. Time: 171.0302 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1213: GFLOPs: 10176.4141. Time: 171.1121 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1214: GFLOPs: 204.1922. Time: 8527.7868 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1215: GFLOPs: 450.8162. Time: 3862.5673 us. Best GFLOPs: 10235.5910
2024-04-30 00:21:26 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1216: GFLOPs: 5762.5910. Time: 302.1745 us. Best GFLOPs: 10235.5910
2024-04-30 00:45:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 00:45:24 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 00:45:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1197 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1596 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2398 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:45:58 [INFO] [evolutionary_search.cc:723] Sampled 62 candidate(s)
2024-04-30 00:46:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 56 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:46:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 61 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:46:45 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 68 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:47:01 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 00:47:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1448  0.9914  0.9914  0.9875  0.9875  0.9870  0.9869  0.9854  0.9852  0.9849  0.9849  0.9844  0.9835  0.9827  0.9826  0.9824
[17 : 32]:	0.9824  0.9817  0.9816  0.9811  0.9811  0.9809  0.9808  0.9806  0.9802  0.9800  0.9799  0.9797  0.9794  0.9791  0.9789  0.9787
[33 : 48]:	0.9787  0.9786  0.9783  0.9783  0.9783  0.9782  0.9782  0.9782  0.9782  0.9781  0.9777  0.9775  0.9771  0.9771  0.9766  0.9761
[49 : 64]:	0.9761  0.9761  0.9760  0.9758  0.9758  0.9757  0.9757  0.9750  0.9747  0.9745  0.9744  0.9741  0.9740  0.9740  0.9740  0.9739
2024-04-30 00:47:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 00:47:06 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1217: GFLOPs: 68.0927. Time: 25572.6087 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1218: GFLOPs: 10220.2288. Time: 170.3786 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1219: GFLOPs: 10219.9421. Time: 170.3833 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1220: GFLOPs: 10022.5386. Time: 173.7392 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1221: GFLOPs: 10055.1340. Time: 173.1760 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1222: GFLOPs: 10019.0427. Time: 173.7998 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1223: GFLOPs: 10225.5579. Time: 170.2898 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1224: GFLOPs: 10136.1464. Time: 171.7919 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1225: GFLOPs: 10124.9195. Time: 171.9824 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1226: GFLOPs: 10137.8799. Time: 171.7625 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1227: GFLOPs: 9974.4561. Time: 174.5767 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1228: GFLOPs: 10218.5544. Time: 170.4065 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1229: GFLOPs: 9936.7478. Time: 175.2392 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1230: GFLOPs: 9999.3053. Time: 174.1429 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1231: GFLOPs: 10176.0158. Time: 171.1188 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1232: GFLOPs: 10215.8242. Time: 170.4520 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1233: GFLOPs: 10172.7378. Time: 171.1740 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1234: GFLOPs: 9786.9149. Time: 177.9220 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1235: GFLOPs: 9933.2286. Time: 175.3013 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1236: GFLOPs: 9978.4682. Time: 174.5065 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1237: GFLOPs: 10130.1205. Time: 171.8941 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1238: GFLOPs: 10229.9288. Time: 170.2170 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1239: GFLOPs: 10095.5107. Time: 172.4834 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1240: GFLOPs: 10176.4141. Time: 171.1121 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1241: GFLOPs: 10011.8266. Time: 173.9251 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1242: GFLOPs: 10130.0648. Time: 171.8950 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1243: GFLOPs: 9792.8026. Time: 177.8151 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1244: GFLOPs: 10172.5833. Time: 171.1766 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1245: GFLOPs: 9891.2421. Time: 176.0454 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1246: GFLOPs: 9879.3789. Time: 176.2568 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1247: GFLOPs: 10179.6192. Time: 171.0583 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1248: GFLOPs: 10125.8196. Time: 171.9671 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1249: GFLOPs: 9893.4783. Time: 176.0056 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1250: GFLOPs: 9934.6771. Time: 175.2757 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1251: GFLOPs: 10127.8432. Time: 171.9327 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1252: GFLOPs: 10060.5399. Time: 173.0829 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1253: GFLOPs: 10026.7475. Time: 173.6663 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1254: GFLOPs: 10033.0606. Time: 173.5570 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1255: GFLOPs: 10023.4580. Time: 173.7233 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1256: GFLOPs: 10017.1219. Time: 173.8332 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1257: GFLOPs: 10220.0459. Time: 170.3816 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1258: GFLOPs: 9893.3883. Time: 176.0072 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1259: GFLOPs: 9972.1126. Time: 174.6178 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1260: GFLOPs: 10027.5712. Time: 173.6520 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1261: GFLOPs: 10147.6993. Time: 171.5963 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1262: GFLOPs: 10136.1464. Time: 171.7919 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1263: GFLOPs: 10192.5642. Time: 170.8410 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1264: GFLOPs: 9948.3371. Time: 175.0351 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1265: GFLOPs: 9923.4018. Time: 175.4749 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1266: GFLOPs: 9852.1099. Time: 176.7447 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1267: GFLOPs: 10018.2235. Time: 173.8140 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1268: GFLOPs: 10026.3450. Time: 173.6732 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1269: GFLOPs: 10026.2710. Time: 173.6745 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1270: GFLOPs: 9969.4463. Time: 174.6645 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1271: GFLOPs: 9936.6424. Time: 175.2411 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1272: GFLOPs: 10033.2992. Time: 173.5529 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1273: GFLOPs: 10014.1164. Time: 173.8853 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1274: GFLOPs: 10016.6418. Time: 173.8415 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1275: GFLOPs: 9806.9446. Time: 177.5587 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1276: GFLOPs: 9999.8026. Time: 174.1342 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1277: GFLOPs: 10025.0659. Time: 173.6954 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1278: GFLOPs: 2613.3117. Time: 666.3223 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1279: GFLOPs: 6323.6949. Time: 275.3624 us. Best GFLOPs: 10235.5910
2024-04-30 00:48:10 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1280: GFLOPs: 2240.9004. Time: 777.0573 us. Best GFLOPs: 10235.5910
2024-04-30 01:07:04 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 01:07:06 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 01:07:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 808 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1214 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1620 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2022 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2424 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2830 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:07:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3233 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:08:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3631 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:08:01 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2024-04-30 01:08:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 47 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:08:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 66 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:08:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:09:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:09:15 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9965  0.9962  0.9949  0.9919  0.9912  0.9912  0.9902  0.9899  0.9894  0.9891  0.9889  0.9888  0.9886  0.9884  0.9877  0.9873
[17 : 32]:	0.9868  0.9867  0.9865  0.9865  0.9863  0.9860  0.9846  0.9844  0.9844  0.9841  0.9830  0.9828  0.9823  0.9821  0.9820  0.9819
[33 : 48]:	0.9819  0.9816  0.9815  0.9812  0.9812  0.9810  0.9809  0.9802  0.9800  0.9800  0.9799  0.9799  0.9799  0.9797  0.9795  0.9795
[49 : 64]:	0.9794  0.9791  0.9788  0.9787  0.9786  0.9785  0.9785  0.9783  0.9783  0.9782  0.9782  0.9779  0.9775  0.9773  0.9769  0.9767
2024-04-30 01:09:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 01:09:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1281: GFLOPs: 10102.8028. Time: 172.3589 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1282: GFLOPs: 10084.7634. Time: 172.6672 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1283: GFLOPs: 10216.0121. Time: 170.4489 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1284: GFLOPs: 10234.8737. Time: 170.1348 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1285: GFLOPs: 10109.3413. Time: 172.2474 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1286: GFLOPs: 10142.4070. Time: 171.6859 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1287: GFLOPs: 10094.6623. Time: 172.4979 us. Best GFLOPs: 10235.5910
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1288: GFLOPs: 10236.8585. Time: 170.1018 us. Best GFLOPs: 10236.8585
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1289: GFLOPs: 10305.8448. Time: 168.9631 us. Best GFLOPs: 10305.8448
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1290: GFLOPs: 10020.8253. Time: 173.7689 us. Best GFLOPs: 10305.8448
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1291: GFLOPs: 10018.9401. Time: 173.8016 us. Best GFLOPs: 10305.8448
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1292: GFLOPs: 10340.1217. Time: 168.4030 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1293: GFLOPs: 10253.2552. Time: 169.8298 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1294: GFLOPs: 10090.9353. Time: 172.5616 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1295: GFLOPs: 10097.5823. Time: 172.4480 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1296: GFLOPs: 10307.5838. Time: 168.9346 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1297: GFLOPs: 10295.4772. Time: 169.1333 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1298: GFLOPs: 10096.1100. Time: 172.4732 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1299: GFLOPs: 9939.2983. Time: 175.1942 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1300: GFLOPs: 9936.8417. Time: 175.2376 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1301: GFLOPs: 9948.1092. Time: 175.0391 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1302: GFLOPs: 10198.4755. Time: 170.7420 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1303: GFLOPs: 10223.5187. Time: 170.3237 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1304: GFLOPs: 10131.5519. Time: 171.8698 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1305: GFLOPs: 10141.8731. Time: 171.6949 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1306: GFLOPs: 10246.6027. Time: 169.9400 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1307: GFLOPs: 10061.7297. Time: 173.0625 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1308: GFLOPs: 10191.1657. Time: 170.8644 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1309: GFLOPs: 10034.6946. Time: 173.5287 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1310: GFLOPs: 10128.6254. Time: 171.9195 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1311: GFLOPs: 9999.0273. Time: 174.1477 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1312: GFLOPs: 10236.2199. Time: 170.1124 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1313: GFLOPs: 10009.4086. Time: 173.9671 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1314: GFLOPs: 10024.9968. Time: 173.6966 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1315: GFLOPs: 10162.2954. Time: 171.3499 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1316: GFLOPs: 10033.0384. Time: 173.5574 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1317: GFLOPs: 10051.0166. Time: 173.2469 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1318: GFLOPs: 9902.0862. Time: 175.8526 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1319: GFLOPs: 10303.4261. Time: 169.0028 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1320: GFLOPs: 9956.8259. Time: 174.8858 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1321: GFLOPs: 10203.5104. Time: 170.6577 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1322: GFLOPs: 10201.9667. Time: 170.6836 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1323: GFLOPs: 10108.4224. Time: 172.2631 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1324: GFLOPs: 9933.5114. Time: 175.2963 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1325: GFLOPs: 9985.1557. Time: 174.3897 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1326: GFLOPs: 10004.1149. Time: 174.0592 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1327: GFLOPs: 10091.1169. Time: 172.5585 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1328: GFLOPs: 10195.3138. Time: 170.7949 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1329: GFLOPs: 10301.7840. Time: 169.0297 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1330: GFLOPs: 10111.3842. Time: 172.2126 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1331: GFLOPs: 10147.1511. Time: 171.6056 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1332: GFLOPs: 10031.5250. Time: 173.5836 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1333: GFLOPs: 10147.1353. Time: 171.6059 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1334: GFLOPs: 10012.0141. Time: 173.9218 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1335: GFLOPs: 10268.0278. Time: 169.5854 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1336: GFLOPs: 10256.7256. Time: 169.7723 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1337: GFLOPs: 10257.8417. Time: 169.7538 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1338: GFLOPs: 10143.5972. Time: 171.6657 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1339: GFLOPs: 10127.1645. Time: 171.9443 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1340: GFLOPs: 9824.7475. Time: 177.2369 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1341: GFLOPs: 9895.4910. Time: 175.9698 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1342: GFLOPs: 249.0086. Time: 6992.9641 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1343: GFLOPs: 6476.7600. Time: 268.8548 us. Best GFLOPs: 10340.1217
2024-04-30 01:10:36 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1344: GFLOPs: 264.2496. Time: 6589.6320 us. Best GFLOPs: 10340.1217
2024-04-30 01:20:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-30 01:20:27 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-30 01:20:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 409 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:20:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 810 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:20:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1213 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:20:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 1615 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:20:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2016 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:21:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2421 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:21:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 2821 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:21:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 3223 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:21:13 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2024-04-30 01:21:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 46 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:21:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 53 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:22:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:22:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0xac5e518)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xb511448)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xb52b6e8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x722db58)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xac5f288)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xb551ad8)]: 69 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xb532c98)]: 0 failure(s)
2024-04-30 01:22:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9864  0.9864  0.9839  0.9838  0.9835  0.9824  0.9824  0.9822  0.9819  0.9819  0.9813  0.9805  0.9804  0.9802  0.9799  0.9799
[17 : 32]:	0.9794  0.9794  0.9785  0.9783  0.9777  0.9776  0.9775  0.9773  0.9770  0.9770  0.9770  0.9768  0.9766  0.9765  0.9764  0.9762
[33 : 48]:	0.9762  0.9761  0.9760  0.9758  0.9754  0.9750  0.9750  0.9748  0.9748  0.9747  0.9744  0.9743  0.9743  0.9739  0.9737  0.9737
[49 : 64]:	0.9737  0.9734  0.9732  0.9732  0.9732  0.9732  0.9730  0.9728  0.9728  0.9720  0.9718  0.9713  0.9713  0.9712  0.9711  0.9710
2024-04-30 01:22:25 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-30 01:22:25 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1345: GFLOPs: 10235.7028. Time: 170.1210 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1346: GFLOPs: 10217.6268. Time: 170.4220 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1347: GFLOPs: 10131.9420. Time: 171.8632 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1348: GFLOPs: 10166.9912. Time: 171.2707 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1349: GFLOPs: 10231.1314. Time: 170.1970 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1350: GFLOPs: 10299.5922. Time: 169.0657 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1351: GFLOPs: 10251.7547. Time: 169.8546 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1352: GFLOPs: 10334.6720. Time: 168.4918 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1353: GFLOPs: 10308.8152. Time: 168.9145 us. Best GFLOPs: 10340.1217
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1354: GFLOPs: 10359.4126. Time: 168.0894 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1355: GFLOPs: 10270.2222. Time: 169.5492 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1356: GFLOPs: 10191.0577. Time: 170.8663 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1357: GFLOPs: 10298.5970. Time: 169.0821 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1358: GFLOPs: 10165.8707. Time: 171.2896 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1359: GFLOPs: 10256.4811. Time: 169.7763 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1360: GFLOPs: 10096.9186. Time: 172.4593 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1361: GFLOPs: 10222.3517. Time: 170.3432 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1362: GFLOPs: 10097.5237. Time: 172.4490 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1363: GFLOPs: 10064.5528. Time: 173.0139 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1364: GFLOPs: 10061.6357. Time: 173.0641 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1365: GFLOPs: 10133.9891. Time: 171.8285 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1366: GFLOPs: 10017.9074. Time: 173.8195 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1367: GFLOPs: 10246.8054. Time: 169.9367 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1368: GFLOPs: 10031.6664. Time: 173.5811 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1369: GFLOPs: 10243.1947. Time: 169.9966 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1370: GFLOPs: 10295.3643. Time: 169.1351 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1371: GFLOPs: 10221.7840. Time: 170.3526 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1372: GFLOPs: 10233.8652. Time: 170.1515 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1373: GFLOPs: 10183.2688. Time: 170.9969 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1374: GFLOPs: 10304.9745. Time: 168.9774 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1375: GFLOPs: 10330.9269. Time: 168.5529 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1376: GFLOPs: 10115.5621. Time: 172.1415 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1377: GFLOPs: 10182.5155. Time: 171.0096 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1378: GFLOPs: 10264.1169. Time: 169.6500 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1379: GFLOPs: 10257.7050. Time: 169.7561 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1380: GFLOPs: 9954.6836. Time: 174.9235 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1381: GFLOPs: 10059.8353. Time: 173.0951 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1382: GFLOPs: 10076.4694. Time: 172.8093 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1383: GFLOPs: 10152.8737. Time: 171.5089 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1384: GFLOPs: 10292.4425. Time: 169.1832 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1385: GFLOPs: 10208.0161. Time: 170.5824 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1386: GFLOPs: 10145.0270. Time: 171.6415 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1387: GFLOPs: 9983.7166. Time: 174.4148 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1388: GFLOPs: 10311.0126. Time: 168.8785 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1389: GFLOPs: 10252.7885. Time: 169.8375 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1390: GFLOPs: 10270.9320. Time: 169.5375 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1391: GFLOPs: 10043.0190. Time: 173.3849 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1392: GFLOPs: 10175.0185. Time: 171.1356 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1393: GFLOPs: 10070.0261. Time: 172.9199 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1394: GFLOPs: 10040.8942. Time: 173.4216 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1395: GFLOPs: 10122.7535. Time: 172.0192 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1396: GFLOPs: 9915.1963. Time: 175.6201 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1397: GFLOPs: 9969.8354. Time: 174.6576 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1398: GFLOPs: 10108.3127. Time: 172.2649 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1399: GFLOPs: 10052.1771. Time: 173.2269 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1400: GFLOPs: 10141.9984. Time: 171.6928 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1401: GFLOPs: 10149.7056. Time: 171.5624 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1402: GFLOPs: 10243.6699. Time: 169.9887 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1403: GFLOPs: 9989.5419. Time: 174.3131 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1404: GFLOPs: 10122.4634. Time: 172.0241 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1405: GFLOPs: 10018.1407. Time: 173.8155 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1406: GFLOPs: 2924.9461. Time: 595.3299 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1407: GFLOPs: 3650.9635. Time: 476.9448 us. Best GFLOPs: 10359.4126
2024-04-30 01:23:29 [INFO] [task_scheduler.cc:131] [Task #10: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_7] Trial #1408: GFLOPs: 323.4338. Time: 5383.8147 us. Best GFLOPs: 10359.4126
