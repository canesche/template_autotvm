2024-04-29 11:32:38 [INFO] [task_scheduler.cc:160] Initializing Task #14: "fused_nn_conv2d_add_add_nn_relu_1"
2024-04-29 11:32:38 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        pad_temp = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)))
        conv2d_nchw = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(128), T.int64(28), T.int64(28)):
            with T.block("pad_temp"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2, v_i3])
                T.writes(pad_temp[v_i0, v_i1, v_i2, v_i3])
                pad_temp[v_i0, v_i1, v_i2, v_i3] = p0[v_i0, v_i1, v_i2, v_i3]
        for nn, ff, yy, xx, rc, ry, rx in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28), T.int64(128), T.int64(1), T.int64(1)):
            with T.block("conv2d_nchw"):
                v_nn, v_ff, v_yy, v_xx, v_rc, v_ry, v_rx = T.axis.remap("SSSSRRR", [nn, ff, yy, xx, rc, ry, rx])
                T.reads(pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1[v_ff, v_rc, v_ry, v_rx])
                T.writes(conv2d_nchw[v_nn, v_ff, v_yy, v_xx])
                with T.init():
                    conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                conv2d_nchw[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw[v_nn, v_ff, v_yy, v_xx] + pad_temp[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1[v_ff, v_rc, v_ry, v_rx]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_nchw[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3], p3[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_add[v_ax0, v_ax1, v_ax2, v_ax3] + p3[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(28), T.int64(28)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3], T.float32(0))
2024-04-29 11:32:38 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 11:32:38 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(49), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(2), thread="threadIdx.x"):
                        for rc_0, ry_0, rx_0 in T.grid(T.int64(4), T.int64(1), T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(6272)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(128), rc_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(196) // T.int64(14))
                                    v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(14))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(128), rc_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ff_3 * T.int64(4) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + yy_3 + yy_4)
                                    v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(128), rc_0 * T.int64(32) + rc_1 + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_0 + ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_0 + rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax1)
                                v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + ax2)
                                v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_relu[v0, v1, v2, v3])
                                T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[16, 1, 1, 8, 4])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 7, 2, 1, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 7, 1, 2, 1])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[4, 32, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v101 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v101)
2024-04-29 11:32:38 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(49), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(2), thread="threadIdx.x"):
                        for rc_0_ry_0_rx_0_fused in T.serial(T.int64(4), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(6272)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(196) // T.int64(14))
                                    v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(14))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ff_3 * T.int64(4) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + yy_3 + yy_4)
                                    v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + rc_1 + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax1)
                                v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + ax2)
                                v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_relu[v0, v1, v2, v3])
                                T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[16, 1, 1, 8, 4])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 7, 2, 1, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 7, 1, 2, 1])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[4, 32, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
2024-04-29 11:32:38 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 0})
            conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
            pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
            for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x"):
                for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(49), thread="vthread.x"):
                    for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(2), thread="threadIdx.x"):
                        for rc_0_ry_0_rx_0_fused in T.serial(T.int64(4), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(6272)):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(196))
                                    v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(196) // T.int64(14))
                                    v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + ax0_ax1_ax2_ax3_fused % T.int64(14))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax0_ax1_ax2_ax3_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + ax0_ax1_ax2_ax3_fused % T.int64(32))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1)):
                                with T.block("conv2d_nchw"):
                                    v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                    v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ff_3 * T.int64(4) + ff_4)
                                    v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + yy_3 + yy_4)
                                    v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + xx_3 + xx_4)
                                    v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(32) + rc_1 + rc_2)
                                    v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                    v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                    T.reads(pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                    T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                                    conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(32), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(4) * T.int64(32) + ax1)
                                v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(4) // T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused // T.int64(7) * T.int64(2) + nn_2_ff_2_yy_2_xx_2_fused + ax2)
                                v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(2) + ax3)
                                T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                                T.writes(T_relu[v0, v1, v2, v3])
                                T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[16, 1, 1, 8, 4])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[2, 7, 2, 1, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 7, 1, 2, 1])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[4, 32, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
2024-04-29 11:57:53 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 11:57:53 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 11:57:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 474 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:57:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 942 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:57:58 [INFO] [evolutionary_search.cc:723] Sampled 82 candidate(s)
2024-04-29 11:58:02 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:58:06 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:58:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:58:14 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 80 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 11:58:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0000  0.9994  0.9991  0.9971  0.9970  0.9969  0.9965  0.9957  0.9943  0.9933  0.9916  0.9907  0.9906  0.9895  0.9893  0.9887
[17 : 32]:	0.9882  0.9846  0.9841  0.9837  0.9834  0.9827  0.9827  0.9825  0.9824  0.9807  0.9807  0.9777  0.9774  0.9772  0.9765  0.9764
[33 : 48]:	0.9753  0.9742  0.9740  0.9740  0.9735  0.9730  0.9729  0.9728  0.9727  0.9713  0.9708  0.9690  0.9684  0.9680  0.9674  0.9660
[49 : 64]:	0.9654  0.9648  0.9643  0.9643  0.9639  0.9634  0.9618  0.9601  0.9600  0.9592  0.9591  0.9591  0.9581  0.9580  0.9580  0.9579
2024-04-29 11:58:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 11:58:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #1: GFLOPs: 762.7884. Time: 136.2956 us. Best GFLOPs: 762.7884
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #2: GFLOPs: 126.8087. Time: 819.8547 us. Best GFLOPs: 762.7884
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #3: GFLOPs: 90.2195. Time: 1152.3531 us. Best GFLOPs: 762.7884
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #4: GFLOPs: 1894.1592. Time: 54.8870 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #5: GFLOPs: 13.8002. Time: 7533.5682 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #6: GFLOPs: 26.1608. Time: 3974.0653 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #7: GFLOPs: 1810.0690. Time: 57.4369 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #8: GFLOPs: 51.3385. Time: 2025.0828 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #9: GFLOPs: 117.7735. Time: 882.7509 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:121] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #10: Error in building:
LocalBuilder: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 165, in <lambda>
    lambda x: _worker_func(*x),
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 231, in _worker_func
    rt_mod: Module = f_build(mod, target, _deserialize_params(params))
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
  File "Objects/call.c", line 200, in PyVectorcall_Call
  File "Python/ceval.c", line 4963, in call_function
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 261, in default_build
    return tvm_build(mod, target=target)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  408: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}>(tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::allocator<char>, tvm::runtime::TVMArgs const&)
  407: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  406: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  405: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  404: tvm::transform::Pass::operator()(tvm::IRModule) const
  403: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  402: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  401: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  400: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  399: _ZN3tvm7runtime13PackedFun
  398: tvm::runtime::TypedPackedFunc<tvm::tir::PrimFunc (tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::tir::transform::LowerTVMBuiltin()::{lambda(tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::tir::transform::LowerTVMBuiltin()::{lambda(tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  397: tvm::tir::BuiltinLower::VisitBodyAndRealizeAlloca(tvm::tir::Stmt)
  396: tvm::tir::BuiltinLower::GetMaxStack(tvm::tir::Stmt)
  395: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  394: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  393: _ZZN3tvm3tir11StmtFunctorI
  392: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  391: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  390: _ZZN3tvm3tir11StmtFunctorI
  389: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  388: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  387: _ZZN3tvm3tir11StmtFunctorI
  386: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  385: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  384: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  383: _ZZN3tvm3tir11StmtFunctorI
  382: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  381: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  380: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  379: _ZZN3tvm3tir11StmtFunctorI
  378: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  377: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  376: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  375: _ZZN3tvm3tir11StmtFunctorI
  374: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  373: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  372: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  371: _ZZN3tvm3tir11StmtFunctorI
  370: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  369: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  368: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  367: _ZZN3tvm3tir11StmtFunctorI
  366: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  365: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  364: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  363: _ZZN3tvm3tir11StmtFunctorI
  362: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  361: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  360: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  359: _ZZN3tvm3tir11StmtFunctorI
  358: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  357: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  356: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  355: _ZZN3tvm3tir11StmtFunctorI
  354: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  353: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  352: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  351: _ZZN3tvm3tir11StmtFunctorI
  350: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  349: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  348: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  347: _ZZN3tvm3tir11StmtFunctorI
  346: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  345: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  344: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  343: _ZZN3tvm3tir11StmtFunctorI
  342: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  341: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  340: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  339: _ZZN3tvm3tir11StmtFunctorI
  338: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  337: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  336: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  335: _ZZN3tvm3tir11StmtFunctorI
  334: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  333: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  332: _ZZN3tvm3tir11StmtFunctorI
  331: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  330: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  329: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  328: _ZZN3tvm3tir11StmtFunctorI
  327: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  326: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  325: _ZZN3tvm3tir11StmtFunctorI
  324: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  323: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  322: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  321: _ZZN3tvm3tir11StmtFunctorI
  320: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  319: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  318: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  317: _ZZN3tvm3tir11StmtFunctorI
  316: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  315: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  314: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  313: _ZZN3tvm3tir11StmtFunctorI
  312: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  311: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  310: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  309: _ZZN3tvm3tir11StmtFunctorI
  308: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  307: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  306: _ZZN3tvm3tir11StmtFunctorI
  305: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  304: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  303: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  302: _ZZN3tvm3tir11StmtFunctorI
  301: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  300: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  299: _ZZN3tvm3tir11StmtFunctorI
  298: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  297: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  296: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  295: _ZZN3tvm3tir11StmtFunctorI
  294: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  293: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  292: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  291: _ZZN3tvm3tir11StmtFunctorI
  290: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  289: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  288: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  287: _ZZN3tvm3tir11StmtFunctorI
  286: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  285: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  284: _ZZN3tvm3tir11StmtFunctorI
  283: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  282: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  281: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  280: _ZZN3tvm3tir11StmtFunctorI
  279: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  278: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  277: _ZZN3tvm3tir11StmtFunctorI
  276: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  275: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  274: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  273: _ZZN3tvm3tir11StmtFunctorI
  272: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  271: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  270: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  269: _ZZN3tvm3tir11StmtFunctorI
  268: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  267: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  266: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  265: _ZZN3tvm3tir11StmtFunctorI
  264: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  263: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  262: _ZZN3tvm3tir11StmtFunctorI
  261: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  260: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  259: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  258: _ZZN3tvm3tir11StmtFunctorI
  257: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  256: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  255: _ZZN3tvm3tir11StmtFunctorI
  254: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  253: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  252: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  251: _ZZN3tvm3tir11StmtFunctorI
  250: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  249: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  248: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  247: _ZZN3tvm3tir11StmtFunctorI
  246: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  245: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  244: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  243: _ZZN3tvm3tir11StmtFunctorI
  242: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  241: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  240: _ZZN3tvm3tir11StmtFunctorI
  239: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  238: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  237: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  236: _ZZN3tvm3tir11StmtFunctorI
  235: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  234: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  233: _ZZN3tvm3tir11StmtFunctorI
  232: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  231: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  230: _ZZN3tvm3tir11StmtFunctorI
  229: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  228: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  227: _ZZN3tvm3tir11StmtFunctorI
  226: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  225: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  224: _ZZN3tvm3tir11StmtFunctorI
  223: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  222: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  221: _ZZN3tvm3tir11StmtFunctorI
  220: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  219: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  218: _ZZN3tvm3tir11StmtFunctorI
  217: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  216: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  215: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  214: _ZZN3tvm3tir11StmtFunctorI
  213: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  212: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  211: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  210: _ZZN3tvm3tir11StmtFunctorI
  209: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  208: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  207: _ZZN3tvm3tir11StmtFunctorI
  206: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  205: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  204: _ZZN3tvm3tir11StmtFunctorI
  203: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  202: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  201: _ZZN3tvm3tir11StmtFunctorI
  200: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  199: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  198: _ZZN3tvm3tir11StmtFunctorI
  197: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  196: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  195: _ZZN3tvm3tir11StmtFunctorI
  194: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  193: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  192: _ZZN3tvm3tir11StmtFunctorI
  191: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  190: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  189: _ZZN3tvm3tir11StmtFunctorIFNS
  188: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  187: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  186: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  185: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  184: _ZZN3tvm3tir11StmtFunctorI
  183: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  182: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  181: _ZZN3tvm3tir11StmtFunctorI
  180: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  179: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  178: _ZZN3tvm3tir11StmtFunctorI
  177: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  176: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  175: _ZZN3tvm3tir11StmtFunctorI
  174: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  173: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  172: _ZZN3tvm3tir11StmtFunctorI
  171: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  170: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  169: _ZZN3tvm3tir11StmtFunctorI
  168: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  167: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  166: _ZZN3tvm3tir11StmtFunctorI
  165: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  164: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  163: _ZZN3tvm3tir11StmtFunctorI
  162: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  161: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  160: _ZZN3tvm3tir11StmtFunctorI
  159: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  158: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  157: _ZZN3tvm3tir11StmtFunctorIFNS
  156: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  155: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  154: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  153: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  152: _ZZN3tvm3tir11StmtFunctorI
  151: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  150: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  149: _ZZN3tvm3tir11StmtFunctorI
  148: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  147: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  146: _ZZN3tvm3tir11StmtFunctorI
  145: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  144: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  143: _ZZN3tvm3tir11StmtFunctorI
  142: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  141: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  140: _ZZN3tvm3tir11StmtFunctorI
  139: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  138: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  137: _ZZN3tvm3tir11StmtFunctorI
  136: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  135: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  134: _ZZN3tvm3tir11StmtFunctorI
  133: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  132: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  131: _ZZN3tvm3tir11StmtFunctorI
  130: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  129: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  128: _ZZN3tvm3tir11StmtFunctorI
  127: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  126: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  125: _ZZN3tvm3tir11StmtFunctorI
  124: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  123: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  122: _ZZN3tvm3tir11StmtFunctorIFNS
  121: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  120: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  119: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  118: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  117: _ZZN3tvm3tir11StmtFunctorI
  116: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  115: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  114: _ZZN3tvm3tir11StmtFunctorI
  113: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  112: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  111: _ZZN3tvm3tir11StmtFunctorI
  110: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  109: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  108: _ZZN3tvm3tir11StmtFunctorI
  107: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  106: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  105: _ZZN3tvm3tir11StmtFunctorI
  104: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  103: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  102: _ZZN3tvm3tir11StmtFunctorI
  101: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  100: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  99: _ZZN3tvm3tir11StmtFunctorI
  98: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  97: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  96: _ZZN3tvm3tir11StmtFunctorI
  95: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  94: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  93: _ZZN3tvm3tir11StmtFunctorI
  92: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  91: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  90: _ZZN3tvm3tir11StmtFunctorI
  89: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  88: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  87: _ZZN3tvm3tir11StmtFunctorIFNS
  86: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  85: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  84: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  83: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  82: _ZZN3tvm3tir11StmtFunctorI
  81: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  80: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  79: _ZZN3tvm3tir11StmtFunctorI
  78: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  77: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  76: _ZZN3tvm3tir11StmtFunctorI
  75: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  74: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  73: _ZZN3tvm3tir11StmtFunctorI
  72: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  71: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  70: _ZZN3tvm3tir11StmtFunctorI
  69: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  68: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  67: _ZZN3tvm3tir11StmtFunctorI
  66: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  65: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  64: _ZZN3tvm3tir11StmtFunctorI
  63: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  62: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  61: _ZZN3tvm3tir11StmtFunctorI
  60: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  59: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  58: _ZZN3tvm3tir11StmtFunctorI
  57: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  56: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  55: _ZZN3tvm3tir11StmtFunctorI
  54: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  53: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  52: _ZZN3tvm3tir11StmtFunctorIFNS
  51: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  50: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  49: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  48: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  47: _ZZN3tvm3tir11StmtFunctorI
  46: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  45: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  44: _ZZN3tvm3tir11StmtFunctorI
  43: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  42: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  41: _ZZN3tvm3tir11StmtFunctorI
  40: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  39: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  38: _ZZN3tvm3tir11StmtFunctorI
  37: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  36: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  35: _ZZN3tvm3tir11StmtFunctorI
  34: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  33: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  32: _ZZN3tvm3tir11StmtFunctorI
  31: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  30: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  29: _ZZN3tvm3tir11StmtFunctorI
  28: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  27: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  26: _ZZN3tvm3tir11StmtFunctorI
  25: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  24: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  23: _ZZN3tvm3tir11StmtFunctorIFNS
  22: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  21: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  20: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  19: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  18: _ZZN3tvm3tir11StmtFunctorI
  17: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  16: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  14: _ZZN3tvm3tir11StmtFunctorI
  13: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  12: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  11: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  10: _ZZN3tvm3tir11StmtFunctorI
  9: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  8: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  7: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  6: _ZZN3tvm3tir11StmtFunctorIFNS
  5: tvm::tir::StmtExprMutator::VisitExpr(tvm::PrimExpr const&)
  4: _ZZN3tvm3tir11ExprFunctorI
  3: tvm::tir::BuiltinLower::VisitExpr_(tvm::tir::CallNode const*)
  2: tvm::tir::BuiltinLower::MakeCallPacked(tvm::tir::CallNode const*, bool)
  1: tvm::tir::APIType(tvm::runtime::DataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/tir/transforms/ir_utils.h", line 157
InternalError: Check failed: t.lanes() == 1 (4 vs. 1) : Cannot pass vector type through packed API.

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(98) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(8) + ff_3_init + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(98) // T.int64(14) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(2) + nn_1_ff_1_yy_1_xx_1_fused + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0_ry_0_rx_0_fused in T.serial(T.int64(64), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(98) // T.int64(14) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8) // T.int64(2))
                                        v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(16))
                                        T.reads(p0[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(98) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2))
                                        v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(98) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(8) + ff_3 + ff_4)
                                v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(98) // T.int64(14) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(2) + nn_1_ff_1_yy_1_xx_1_fused + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                T.reads(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(1)):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(98) * T.int64(128) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(2) * T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(98) // T.int64(14) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(14) * T.int64(2) + nn_1_ff_1_yy_1_xx_1_fused + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                            T.writes(T_relu[v0, v1, v2, v3])
                            T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[4, 1, 16, 8, 1])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[7, 1, 2, 2, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[14, 2, 1, 1, 1])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
sch.enter_postproc()
sch.unannotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch")
l103, l104, l105, l106, l107 = sch.get_loops(block=b75)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115 = sch.get_loops(block=b88)
l116, l117, l118 = sch.split(loop=l115, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l118)
sch.bind(loop=l117, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b120)
l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b121)
l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b123)
b163 = sch.get_block(name="conv2d_nchw", func_name="main")
l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b163)
b182 = sch.decompose_reduction(block=b163, loop=l167)
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #11: GFLOPs: 111.7979. Time: 929.9343 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #12: GFLOPs: 421.9329. Time: 246.4010 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #13: GFLOPs: 1047.7821. Time: 99.2236 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #14: GFLOPs: 134.0654. Time: 775.4776 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #15: GFLOPs: 122.4994. Time: 848.6955 us. Best GFLOPs: 1894.1592
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #16: GFLOPs: 2515.1744. Time: 41.3350 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #17: GFLOPs: 73.6319. Time: 1411.9517 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #18: GFLOPs: 1.8503. Time: 56186.8793 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #19: GFLOPs: 122.5481. Time: 848.3580 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #20: GFLOPs: 1080.3832. Time: 96.2294 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #21: GFLOPs: 64.4536. Time: 1613.0147 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #22: GFLOPs: 882.0356. Time: 117.8690 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #23: GFLOPs: 109.8306. Time: 946.5914 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #24: GFLOPs: 136.2203. Time: 763.2100 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #25: GFLOPs: 128.4810. Time: 809.1830 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #26: GFLOPs: 108.4335. Time: 958.7870 us. Best GFLOPs: 2515.1744
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #27: GFLOPs: 2690.3933. Time: 38.6429 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #28: GFLOPs: 1494.4690. Time: 69.5663 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #29: GFLOPs: 32.2103. Time: 3227.6811 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #30: GFLOPs: 11.3864. Time: 9130.6353 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #31: GFLOPs: 231.9903. Time: 448.1422 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #32: GFLOPs: 89.2408. Time: 1164.9905 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #33: GFLOPs: 1590.8603. Time: 65.3512 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #34: GFLOPs: 240.6305. Time: 432.0511 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #35: GFLOPs: 590.7660. Time: 175.9828 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #36: GFLOPs: 2097.9482. Time: 49.5554 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #37: GFLOPs: 1537.1084. Time: 67.6365 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #38: GFLOPs: 2158.6108. Time: 48.1628 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #39: GFLOPs: 2562.4163. Time: 40.5729 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #40: GFLOPs: 74.7652. Time: 1390.5493 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #41: GFLOPs: 65.4008. Time: 1589.6543 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #42: GFLOPs: 77.7270. Time: 1337.5625 us. Best GFLOPs: 2690.3933
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #43: GFLOPs: 2909.3629. Time: 35.7345 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #44: GFLOPs: 2254.7231. Time: 46.1097 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #45: GFLOPs: 1890.6554. Time: 54.9887 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #46: GFLOPs: 1092.6734. Time: 95.1471 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #47: GFLOPs: 2549.3525. Time: 40.7808 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #48: GFLOPs: 2477.7381. Time: 41.9595 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #49: GFLOPs: 871.4822. Time: 119.2964 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #50: GFLOPs: 1265.1201. Time: 82.1777 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #51: GFLOPs: 1843.5617. Time: 56.3934 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #52: GFLOPs: 305.1286. Time: 340.7241 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #53: GFLOPs: 32.0346. Time: 3245.3864 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #54: GFLOPs: 504.8532. Time: 205.9305 us. Best GFLOPs: 2909.3629
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #55: GFLOPs: 3298.7876. Time: 31.5160 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #56: GFLOPs: 2242.9932. Time: 46.3509 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:121] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #57: Error in building:
LocalBuilder: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 165, in <lambda>
    lambda x: _worker_func(*x),
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 231, in _worker_func
    rt_mod: Module = f_build(mod, target, _deserialize_params(params))
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
  File "Objects/call.c", line 200, in PyVectorcall_Call
  File "Python/ceval.c", line 4963, in call_function
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/builder/local_builder.py", line 261, in default_build
    return tvm_build(mod, target=target)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/driver/build_module.py", line 281, in build
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  404: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)>::AssignTypedLambda<tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}>(tvm::__mk_TVM22::{lambda(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target)#1}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, std::allocator<char>, tvm::runtime::TVMArgs const&)
  403: tvm::TIRToRuntime(tvm::runtime::Map<tvm::Target, tvm::IRModule, void, void> const&, tvm::Target const&)
  402: tvm::SplitMixedModule(tvm::IRModule, tvm::Target const&, tvm::Target const&)
  401: tvm::ApplyPasses(tvm::IRModule, tvm::transform::Sequential)
  400: tvm::transform::Pass::operator()(tvm::IRModule) const
  399: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  398: tvm::transform::SequentialNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  397: tvm::transform::Pass::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  396: tvm::tir::transform::PrimFuncPassNode::operator()(tvm::IRModule, tvm::transform::PassContext const&) const
  395: _ZN3tvm7runtime13PackedFun
  394: tvm::runtime::TypedPackedFunc<tvm::tir::PrimFunc (tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)>::AssignTypedLambda<tvm::tir::transform::LowerTVMBuiltin()::{lambda(tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)#1}>(tvm::tir::transform::LowerTVMBuiltin()::{lambda(tvm::tir::PrimFunc, tvm::IRModule, tvm::transform::PassContext)#1})::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const, tvm::runtime::TVMRetValue) const
  393: tvm::tir::BuiltinLower::VisitBodyAndRealizeAlloca(tvm::tir::Stmt)
  392: tvm::tir::BuiltinLower::GetMaxStack(tvm::tir::Stmt)
  391: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  390: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  389: _ZZN3tvm3tir11StmtFunctorI
  388: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  387: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  386: _ZZN3tvm3tir11StmtFunctorI
  385: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  384: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  383: _ZZN3tvm3tir11StmtFunctorI
  382: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  381: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  380: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  379: _ZZN3tvm3tir11StmtFunctorI
  378: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  377: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  376: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  375: _ZZN3tvm3tir11StmtFunctorI
  374: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  373: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  372: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  371: _ZZN3tvm3tir11StmtFunctorI
  370: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  369: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  368: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  367: _ZZN3tvm3tir11StmtFunctorI
  366: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  365: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  364: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  363: _ZZN3tvm3tir11StmtFunctorI
  362: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  361: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  360: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  359: _ZZN3tvm3tir11StmtFunctorI
  358: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  357: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  356: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  355: _ZZN3tvm3tir11StmtFunctorI
  354: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  353: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  352: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  351: _ZZN3tvm3tir11StmtFunctorI
  350: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  349: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  348: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  347: _ZZN3tvm3tir11StmtFunctorI
  346: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  345: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  344: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  343: _ZZN3tvm3tir11StmtFunctorI
  342: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  341: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  340: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  339: _ZZN3tvm3tir11StmtFunctorI
  338: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  337: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  336: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  335: _ZZN3tvm3tir11StmtFunctorI
  334: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  333: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  332: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  331: _ZZN3tvm3tir11StmtFunctorI
  330: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  329: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  328: _ZZN3tvm3tir11StmtFunctorI
  327: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  326: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  325: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  324: _ZZN3tvm3tir11StmtFunctorI
  323: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  322: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  321: _ZZN3tvm3tir11StmtFunctorI
  320: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  319: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  318: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  317: _ZZN3tvm3tir11StmtFunctorI
  316: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  315: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  314: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  313: _ZZN3tvm3tir11StmtFunctorI
  312: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  311: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  310: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  309: _ZZN3tvm3tir11StmtFunctorI
  308: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  307: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  306: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  305: _ZZN3tvm3tir11StmtFunctorI
  304: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  303: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  302: _ZZN3tvm3tir11StmtFunctorI
  301: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  300: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  299: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  298: _ZZN3tvm3tir11StmtFunctorI
  297: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  296: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  295: _ZZN3tvm3tir11StmtFunctorI
  294: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  293: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  292: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  291: _ZZN3tvm3tir11StmtFunctorI
  290: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  289: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  288: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  287: _ZZN3tvm3tir11StmtFunctorI
  286: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  285: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  284: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  283: _ZZN3tvm3tir11StmtFunctorI
  282: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  281: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  280: _ZZN3tvm3tir11StmtFunctorI
  279: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  278: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  277: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  276: _ZZN3tvm3tir11StmtFunctorI
  275: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  274: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  273: _ZZN3tvm3tir11StmtFunctorI
  272: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  271: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  270: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  269: _ZZN3tvm3tir11StmtFunctorI
  268: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  267: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  266: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  265: _ZZN3tvm3tir11StmtFunctorI
  264: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  263: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  262: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  261: _ZZN3tvm3tir11StmtFunctorI
  260: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  259: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  258: _ZZN3tvm3tir11StmtFunctorI
  257: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  256: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  255: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  254: _ZZN3tvm3tir11StmtFunctorI
  253: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  252: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  251: _ZZN3tvm3tir11StmtFunctorI
  250: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  249: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  248: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  247: _ZZN3tvm3tir11StmtFunctorI
  246: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  245: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  244: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  243: _ZZN3tvm3tir11StmtFunctorI
  242: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  241: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  240: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  239: _ZZN3tvm3tir11StmtFunctorI
  238: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  237: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  236: _ZZN3tvm3tir11StmtFunctorI
  235: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  234: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  233: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  232: _ZZN3tvm3tir11StmtFunctorI
  231: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  230: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  229: _ZZN3tvm3tir11StmtFunctorI
  228: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  227: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  226: _ZZN3tvm3tir11StmtFunctorI
  225: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  224: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  223: _ZZN3tvm3tir11StmtFunctorI
  222: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  221: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  220: _ZZN3tvm3tir11StmtFunctorI
  219: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  218: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  217: _ZZN3tvm3tir11StmtFunctorI
  216: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  215: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  214: _ZZN3tvm3tir11StmtFunctorI
  213: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  212: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  211: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  210: _ZZN3tvm3tir11StmtFunctorI
  209: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  208: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  207: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  206: _ZZN3tvm3tir11StmtFunctorI
  205: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  204: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  203: _ZZN3tvm3tir11StmtFunctorI
  202: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  201: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  200: _ZZN3tvm3tir11StmtFunctorI
  199: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  198: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  197: _ZZN3tvm3tir11StmtFunctorI
  196: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  195: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  194: _ZZN3tvm3tir11StmtFunctorI
  193: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  192: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  191: _ZZN3tvm3tir11StmtFunctorI
  190: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  189: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  188: _ZZN3tvm3tir11StmtFunctorI
  187: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  186: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  185: _ZZN3tvm3tir11StmtFunctorIFNS
  184: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  183: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  182: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  181: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  180: _ZZN3tvm3tir11StmtFunctorI
  179: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  178: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  177: _ZZN3tvm3tir11StmtFunctorI
  176: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  175: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  174: _ZZN3tvm3tir11StmtFunctorI
  173: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  172: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  171: _ZZN3tvm3tir11StmtFunctorI
  170: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  169: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  168: _ZZN3tvm3tir11StmtFunctorI
  167: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  166: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  165: _ZZN3tvm3tir11StmtFunctorI
  164: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  163: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  162: _ZZN3tvm3tir11StmtFunctorI
  161: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  160: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  159: _ZZN3tvm3tir11StmtFunctorI
  158: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  157: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  156: _ZZN3tvm3tir11StmtFunctorI
  155: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  154: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  153: _ZZN3tvm3tir11StmtFunctorIFNS
  152: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  151: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  150: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  149: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  148: _ZZN3tvm3tir11StmtFunctorI
  147: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  146: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  145: _ZZN3tvm3tir11StmtFunctorI
  144: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  143: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  142: _ZZN3tvm3tir11StmtFunctorI
  141: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  140: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  139: _ZZN3tvm3tir11StmtFunctorI
  138: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  137: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  136: _ZZN3tvm3tir11StmtFunctorI
  135: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  134: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  133: _ZZN3tvm3tir11StmtFunctorI
  132: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  131: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  130: _ZZN3tvm3tir11StmtFunctorI
  129: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  128: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  127: _ZZN3tvm3tir11StmtFunctorI
  126: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  125: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  124: _ZZN3tvm3tir11StmtFunctorI
  123: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  122: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  121: _ZZN3tvm3tir11StmtFunctorI
  120: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  119: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  118: _ZZN3tvm3tir11StmtFunctorIFNS
  117: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  116: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  115: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  114: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  113: _ZZN3tvm3tir11StmtFunctorI
  112: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  111: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  110: _ZZN3tvm3tir11StmtFunctorI
  109: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  108: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  107: _ZZN3tvm3tir11StmtFunctorI
  106: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  105: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  104: _ZZN3tvm3tir11StmtFunctorI
  103: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  102: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  101: _ZZN3tvm3tir11StmtFunctorI
  100: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  99: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  98: _ZZN3tvm3tir11StmtFunctorI
  97: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  96: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  95: _ZZN3tvm3tir11StmtFunctorI
  94: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  93: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  92: _ZZN3tvm3tir11StmtFunctorI
  91: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  90: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  89: _ZZN3tvm3tir11StmtFunctorI
  88: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  87: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  86: _ZZN3tvm3tir11StmtFunctorI
  85: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  84: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  83: _ZZN3tvm3tir11StmtFunctorIFNS
  82: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  81: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  80: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  79: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  78: _ZZN3tvm3tir11StmtFunctorI
  77: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  76: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  75: _ZZN3tvm3tir11StmtFunctorI
  74: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  73: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  72: _ZZN3tvm3tir11StmtFunctorI
  71: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  70: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  69: _ZZN3tvm3tir11StmtFunctorI
  68: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  67: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  66: _ZZN3tvm3tir11StmtFunctorI
  65: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  64: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  63: _ZZN3tvm3tir11StmtFunctorI
  62: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  61: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  60: _ZZN3tvm3tir11StmtFunctorI
  59: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  58: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  57: _ZZN3tvm3tir11StmtFunctorI
  56: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  55: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  54: _ZZN3tvm3tir11StmtFunctorI
  53: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  52: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  51: _ZZN3tvm3tir11StmtFunctorI
  50: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  49: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  48: _ZZN3tvm3tir11StmtFunctorIFNS
  47: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  46: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  45: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  44: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  43: _ZZN3tvm3tir11StmtFunctorI
  42: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  41: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  40: _ZZN3tvm3tir11StmtFunctorI
  39: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  38: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  37: _ZZN3tvm3tir11StmtFunctorI
  36: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  35: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  34: _ZZN3tvm3tir11StmtFunctorI
  33: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  32: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  31: _ZZN3tvm3tir11StmtFunctorI
  30: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  29: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  28: _ZZN3tvm3tir11StmtFunctorI
  27: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  26: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  25: _ZZN3tvm3tir11StmtFunctorI
  24: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  23: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  22: _ZZN3tvm3tir11StmtFunctorI
  21: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  20: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  19: _ZZN3tvm3tir11StmtFunctorIFNS
  18: tvm::runtime::Array<tvm::tir::Stmt, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type> tvm::tir::StmtMutator::Internal::MutateArray<tvm::tir::Stmt, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>(tvm::tir::StmtMutator*, std::enable_if<std::is_base_of<tvm::runtime::ObjectRef, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}>::value, void>::type const&, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  17: tvm::runtime::ObjectPtr<tvm::runtime::Object> tvm::runtime::Array<tvm::tir::Stmt, void>::MapHelper<tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1}, tvm::tir::Stmt>(tvm::runtime::Object, tvm::tir::StmtMutator::Internal::Mutate(tvm::tir::StmtMutator*, tvm::runtime::Array<tvm::tir::Stmt, void> const&)::{lambda(tvm::tir::Stmt const&)#1})
  16: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  15: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  14: _ZZN3tvm3tir11StmtFunctorI
  13: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::AttrStmtNode const*)
  12: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  11: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  10: _ZZN3tvm3tir11StmtFunctorI
  9: tvm::tir::BuiltinLower::VisitStmt_(tvm::tir::LetStmtNode const*)
  8: tvm::tir::BuiltinLower::VisitStmt(tvm::tir::Stmt const&)
  7: tvm::tir::StmtFunctor<tvm::tir::Stmt (tvm::tir::Stmt const&)>::VisitStmt(tvm::tir::Stmt const&)
  6: _ZZN3tvm3tir11StmtFunctorIFNS
  5: tvm::tir::StmtExprMutator::VisitExpr(tvm::PrimExpr const&)
  4: _ZZN3tvm3tir11ExprFunctorI
  3: tvm::tir::BuiltinLower::VisitExpr_(tvm::tir::CallNode const*)
  2: tvm::tir::BuiltinLower::MakeCallPacked(tvm::tir::CallNode const*, bool)
  1: tvm::tir::APIType(tvm::runtime::DataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/tir/transforms/ir_utils.h", line 157
InternalError: Check failed: t.lanes() == 1 (4 vs. 1) : Cannot pass vector type through packed API.

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(7)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(256) + nn_2_ff_2_yy_2_xx_2_fused * T.int64(2) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) // T.int64(2) * T.int64(7) + yy_3_init * T.int64(7) + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(7) + xx_3_init * T.int64(7) + xx_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0_ry_0_rx_0_fused in T.serial(T.int64(64), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) // T.int64(2) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98) // T.int64(14))
                                        v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(14))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(196))
                                        T.reads(p0[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2))
                                        v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(7)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(256) + nn_2_ff_2_yy_2_xx_2_fused * T.int64(2) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) // T.int64(2) * T.int64(7) + yy_3 * T.int64(7) + yy_4)
                                v_xx = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(7) + xx_3 * T.int64(7) + xx_4)
                                v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + rc_1 * T.int64(2) + rc_2)
                                v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                T.reads(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(7)):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(512), nn_0_ff_0_yy_0_xx_0_fused // T.int64(8) * T.int64(256) + nn_2_ff_2_yy_2_xx_2_fused * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(8) // T.int64(2) * T.int64(7) + ax2)
                            v3 = T.axis.spatial(T.int64(28), nn_0_ff_0_yy_0_xx_0_fused % T.int64(2) * T.int64(14) + nn_1_ff_1_yy_1_xx_1_fused * T.int64(7) + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                            T.writes(T_relu[v0, v1, v2, v3])
                            T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[2, 1, 128, 1, 2])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 7])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 7])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[64, 1, 2])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
sch.enter_postproc()
sch.unannotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch")
l103, l104, l105, l106, l107 = sch.get_loops(block=b75)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115 = sch.get_loops(block=b88)
l116, l117, l118 = sch.split(loop=l115, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l118)
sch.bind(loop=l117, thread_axis="threadIdx.x")
b119 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b119, ann_key="meta_schedule.unroll_explicit")
b120, b121, b122, b123 = sch.get_child_blocks(b119)
l124, l125, l126, l127, l128, l129, l130 = sch.get_loops(block=b120)
l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b121)
l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153, l154, l155 = sch.get_loops(block=b122)
sch.annotate(block_or_loop=l138, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l138, ann_key="pragma_unroll_explicit", ann_val=1)
l156, l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b123)
b163 = sch.get_block(name="conv2d_nchw", func_name="main")
l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b163)
b182 = sch.decompose_reduction(block=b163, loop=l167)
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #58: GFLOPs: 87.3590. Time: 1190.0852 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #59: GFLOPs: 1876.8917. Time: 55.3919 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:121] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #60: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(112), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(224), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(14) * T.int64(4) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(14) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(14) // T.int64(2) * T.int64(2) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + xx_3_init * T.int64(2) + xx_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0_ry_0_rx_0_fused in T.serial(T.int64(128), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(224), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("pad_temp_shared"):
                                        v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                        v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused)
                                        v2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_fused_0 * T.int64(896) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(28))
                                        v3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_fused_0 * T.int64(896) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(784))
                                        T.reads(p0[v0, v1, v2, v3])
                                        T.writes(pad_temp_shared[v0, v1, v2, v3])
                                        pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(3)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(224), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1)
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused)
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(224) + ax0_ax1_ax2_ax3_fused_1 < T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(14) * T.int64(4) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(14) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(14) // T.int64(2) * T.int64(2) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + xx_3 * T.int64(2) + xx_4)
                                v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                T.reads(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(14) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(14) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(14) // T.int64(7) * T.int64(14) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(7) * T.int64(4) + nn_2_ff_2_yy_2_xx_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                            T.writes(T_relu[v0, v1, v2, v3])
                            T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 8, 16, 2, 2])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 2, 7, 2, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 7, 2, 1, 2])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[128, 1, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
sch.enter_postproc()
sch.unannotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch")
l103, l104, l105, l106, l107 = sch.get_loops(block=b75)
l108, l109, l110 = sch.split(loop=l107, factors=[None, 224, 4], preserve_unit_iters=True)
sch.vectorize(loop=l110)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch")
l111, l112, l113, l114, l115 = sch.get_loops(block=b88)
l116, l117 = sch.split(loop=l115, factors=[None, 224], preserve_unit_iters=True)
sch.bind(loop=l117, thread_axis="threadIdx.x")
b118 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b118, ann_key="meta_schedule.unroll_explicit")
b119, b120, b121, b122 = sch.get_child_blocks(b118)
l123, l124, l125, l126, l127, l128, l129 = sch.get_loops(block=b119)
l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b120)
l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151, l152, l153 = sch.get_loops(block=b121)
sch.annotate(block_or_loop=l136, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l136, ann_key="pragma_unroll_explicit", ann_val=1)
l154, l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b122)
b161 = sch.get_block(name="conv2d_nchw", func_name="main")
l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b161)
b180 = sch.decompose_reduction(block=b161, loop=l165)
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #61: GFLOPs: 1997.9747. Time: 52.0350 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #62: GFLOPs: 1006.9610. Time: 103.2460 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #63: GFLOPs: 265.0699. Time: 392.2161 us. Best GFLOPs: 3298.7876
2024-04-29 12:20:45 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #64: GFLOPs: 586.5755. Time: 177.2401 us. Best GFLOPs: 3298.7876
2024-04-29 13:04:18 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 13:04:18 [INFO] [evolutionary_search.cc:715] Picked top 61 candidate(s) from database
2024-04-29 13:04:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 420 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 842 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:23 [INFO] [evolutionary_search.cc:723] Sampled 60 candidate(s)
2024-04-29 13:04:27 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 78 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:43 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 67 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 13:04:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.5187  1.4945  1.3260  1.3071  1.3025  1.2994  1.2960  1.2665  1.2510  1.2413  1.2383  1.2355  1.2134  1.2134  1.2101  1.1940
[17 : 32]:	1.1785  1.1785  1.1734  1.1689  1.1638  1.1577  1.1500  1.1493  1.1465  1.1360  1.1317  1.1258  1.1195  1.1191  1.0964  1.0940
[33 : 48]:	1.0877  1.0859  1.0838  1.0806  1.0732  1.0715  1.0711  1.0676  1.0629  1.0568  1.0556  1.0536  1.0536  1.0516  1.0505  1.0494
[49 : 64]:	1.0420  1.0401  1.0369  1.0348  1.0327  1.0292  1.0252  1.0227  1.0181  1.0174  1.0146  1.0146  1.0143  1.0141  1.0087  0.9991
2024-04-29 13:04:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 13:04:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #65: GFLOPs: 2327.0082. Time: 44.6774 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #66: GFLOPs: 2501.1121. Time: 41.5674 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #67: GFLOPs: 2552.5887. Time: 40.7291 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #68: GFLOPs: 2478.5256. Time: 41.9462 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #69: GFLOPs: 1856.3841. Time: 56.0039 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #70: GFLOPs: 2517.9707. Time: 41.2891 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #71: GFLOPs: 2632.5329. Time: 39.4923 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #72: GFLOPs: 2646.3496. Time: 39.2861 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #73: GFLOPs: 2791.0601. Time: 37.2492 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #74: GFLOPs: 1864.9551. Time: 55.7465 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #75: GFLOPs: 2502.4165. Time: 41.5457 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #76: GFLOPs: 2502.8505. Time: 41.5385 us. Best GFLOPs: 3298.7876
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #77: GFLOPs: 5740.0306. Time: 18.1122 us. Best GFLOPs: 5740.0306
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #78: GFLOPs: 5740.0868. Time: 18.1120 us. Best GFLOPs: 5740.0868
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #79: GFLOPs: 2216.6763. Time: 46.9012 us. Best GFLOPs: 5740.0868
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #80: GFLOPs: 5842.6407. Time: 17.7941 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #81: GFLOPs: 2574.4386. Time: 40.3834 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #82: GFLOPs: 3281.9255. Time: 31.6779 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #83: GFLOPs: 2324.4494. Time: 44.7266 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #84: GFLOPs: 2932.9981. Time: 35.4466 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #85: GFLOPs: 3017.5338. Time: 34.4535 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #86: GFLOPs: 2093.1574. Time: 49.6688 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #87: GFLOPs: 3004.2643. Time: 34.6057 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #88: GFLOPs: 2842.9819. Time: 36.5689 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #89: GFLOPs: 2465.6539. Time: 42.1652 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #90: GFLOPs: 3763.8458. Time: 27.6219 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #91: GFLOPs: 2014.2955. Time: 51.6134 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #92: GFLOPs: 2499.4431. Time: 41.5951 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #93: GFLOPs: 2198.9972. Time: 47.2782 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #94: GFLOPs: 2568.4563. Time: 40.4775 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #95: GFLOPs: 2585.9228. Time: 40.2041 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #96: GFLOPs: 2318.4974. Time: 44.8414 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #97: GFLOPs: 2628.2360. Time: 39.5568 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #98: GFLOPs: 2337.4734. Time: 44.4774 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #99: GFLOPs: 2372.1772. Time: 43.8267 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #100: GFLOPs: 1237.9309. Time: 83.9826 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #101: GFLOPs: 1158.8286. Time: 89.7153 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #102: GFLOPs: 1733.1321. Time: 59.9866 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #103: GFLOPs: 2399.8437. Time: 43.3214 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #104: GFLOPs: 1844.1159. Time: 56.3764 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #105: GFLOPs: 2501.9802. Time: 41.5530 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #106: GFLOPs: 2414.5158. Time: 43.0582 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #107: GFLOPs: 2921.0706. Time: 35.5913 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #108: GFLOPs: 1648.8419. Time: 63.0531 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #109: GFLOPs: 1386.1324. Time: 75.0034 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #110: GFLOPs: 575.2324. Time: 180.7351 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #111: GFLOPs: 3584.7030. Time: 29.0023 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #112: GFLOPs: 1386.2454. Time: 74.9973 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #113: GFLOPs: 3904.2232. Time: 26.6288 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #114: GFLOPs: 2422.5450. Time: 42.9155 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #115: GFLOPs: 2569.2747. Time: 40.4646 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #116: GFLOPs: 1800.0434. Time: 57.7568 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #117: GFLOPs: 2295.4675. Time: 45.2913 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #118: GFLOPs: 3864.2257. Time: 26.9044 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #119: GFLOPs: 1679.3406. Time: 61.9080 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #120: GFLOPs: 3564.4149. Time: 29.1674 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #121: GFLOPs: 2578.1116. Time: 40.3259 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #122: GFLOPs: 4314.5447. Time: 24.0963 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #123: GFLOPs: 2613.6132. Time: 39.7781 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #124: GFLOPs: 4310.1636. Time: 24.1208 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #125: GFLOPs: 1878.0775. Time: 55.3570 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #126: GFLOPs: 3127.0390. Time: 33.2470 us. Best GFLOPs: 5842.6407
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:121] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #127: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), "float32"), p1: T.Buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), p3: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_nchw_local = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(28), T.int64(28)), scope="local")
        pad_temp_shared = T.alloc_buffer((T.int64(1), T.int64(128), T.int64(28), T.int64(28)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(512), T.int64(128), T.int64(1), T.int64(1)), scope="shared")
        for nn_0_ff_0_yy_0_xx_0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for nn_1_ff_1_yy_1_xx_1_fused in T.thread_binding(T.int64(224), thread="vthread.x"):
                for nn_2_ff_2_yy_2_xx_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for nn_3_init, ff_3_init, yy_3_init, xx_3_init, nn_4_init, ff_4_init, yy_4_init, xx_4_init in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_nchw_init"):
                            v_nn = T.axis.spatial(T.int64(1), nn_3_init + nn_4_init)
                            v_ff = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3_init * T.int64(2) + ff_4_init)
                            v_yy = T.axis.spatial(T.int64(28), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(7) + yy_3_init + yy_4_init)
                            v_xx = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) + xx_3_init + xx_4_init)
                            T.reads()
                            T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = T.float32(0)
                    for rc_0_ry_0_rx_0_fused in T.serial(T.int64(64), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(25)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("pad_temp_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(784))
                                    v2 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(784) // T.int64(28))
                                    v3 = T.axis.spatial(T.int64(28), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(28))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(1568))
                                    T.reads(p0[v0, v1, v2, v3])
                                    T.writes(pad_temp_shared[v0, v1, v2, v3])
                                    pad_temp_shared[v0, v1, v2, v3] = p0[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(2))
                                    v1 = T.axis.spatial(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(2))
                                    v2 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v3 = T.axis.spatial(T.int64(1), T.int64(0))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for rc_1, ry_1, rx_1, nn_3, ff_3, yy_3, xx_3, rc_2, ry_2, rx_2, nn_4, ff_4, yy_4, xx_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                            with T.block("conv2d_nchw_update"):
                                v_nn = T.axis.spatial(T.int64(1), nn_3 + nn_4)
                                v_ff = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ff_3 * T.int64(2) + ff_4)
                                v_yy = T.axis.spatial(T.int64(28), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(7) + yy_3 + yy_4)
                                v_xx = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) + xx_3 + xx_4)
                                v_rc = T.axis.reduce(T.int64(128), rc_0_ry_0_rx_0_fused * T.int64(2) + rc_1 + rc_2)
                                v_ry = T.axis.reduce(T.int64(1), ry_1 + ry_2)
                                v_rx = T.axis.reduce(T.int64(1), rx_1 + rx_2)
                                T.reads(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx], pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx], p1_shared[v_ff, v_rc, v_ry, v_rx])
                                T.writes(conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] = conv2d_nchw_local[v_nn, v_ff, v_yy, v_xx] + pad_temp_shared[v_nn, v_rc, v_yy + v_ry, v_xx + v_rx] * p1_shared[v_ff, v_rc, v_ry, v_rx]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(7), T.int64(1)):
                        with T.block("conv2d_nchw_local"):
                            v0 = T.axis.spatial(T.int64(1), ax0)
                            v1 = T.axis.spatial(T.int64(512), nn_1_ff_1_yy_1_xx_1_fused // T.int64(28) * T.int64(64) + nn_2_ff_2_yy_2_xx_2_fused // T.int64(4) * T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(28), nn_2_ff_2_yy_2_xx_2_fused % T.int64(4) * T.int64(7) + ax2)
                            v3 = T.axis.spatial(T.int64(28), nn_1_ff_1_yy_1_xx_1_fused % T.int64(28) + ax3)
                            T.reads(conv2d_nchw_local[v0, v1, v2, v3], p2[v0, v1, T.int64(0), T.int64(0)], p3[v0, v1, v2, v3])
                            T.writes(T_relu[v0, v1, v2, v3])
                            T_relu[v0, v1, v2, v3] = T.max(conv2d_nchw_local[v0, v1, v2, v3] + p2[v0, v1, T.int64(0), T.int64(0)] + p3[v0, v1, v2, v3], T.float32(0))
b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="conv2d_nchw", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="T_relu", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16, v17 = sch.sample_perfect_tile(loop=l6, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l18, l19, l20, l21, l22 = sch.split(loop=l6, factors=[v13, v14, v15, v16, v17], preserve_unit_iters=True)
v23, v24, v25, v26, v27 = sch.sample_perfect_tile(loop=l7, n=5, max_innermost_factor=64, decision=[1, 8, 16, 2, 2])
l28, l29, l30, l31, l32 = sch.split(loop=l7, factors=[v23, v24, v25, v26, v27], preserve_unit_iters=True)
v33, v34, v35, v36, v37 = sch.sample_perfect_tile(loop=l8, n=5, max_innermost_factor=64, decision=[1, 1, 4, 7, 1])
l38, l39, l40, l41, l42 = sch.split(loop=l8, factors=[v33, v34, v35, v36, v37], preserve_unit_iters=True)
v43, v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l9, n=5, max_innermost_factor=64, decision=[1, 28, 1, 1, 1])
l48, l49, l50, l51, l52 = sch.split(loop=l9, factors=[v43, v44, v45, v46, v47], preserve_unit_iters=True)
v53, v54, v55 = sch.sample_perfect_tile(loop=l10, n=3, max_innermost_factor=64, decision=[64, 2, 1])
l56, l57, l58 = sch.split(loop=l10, factors=[v53, v54, v55], preserve_unit_iters=True)
v59, v60, v61 = sch.sample_perfect_tile(loop=l11, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l62, l63, l64 = sch.split(loop=l11, factors=[v59, v60, v61], preserve_unit_iters=True)
v65, v66, v67 = sch.sample_perfect_tile(loop=l12, n=3, max_innermost_factor=64, decision=[1, 1, 1])
l68, l69, l70 = sch.split(loop=l12, factors=[v65, v66, v67], preserve_unit_iters=True)
sch.reorder(l18, l28, l38, l48, l19, l29, l39, l49, l20, l30, l40, l50, l56, l62, l68, l57, l63, l69, l21, l31, l41, l51, l58, l64, l70, l22, l32, l42, l52)
l71 = sch.fuse(l18, l28, l38, l48, preserve_unit_iters=True)
sch.bind(loop=l71, thread_axis="blockIdx.x")
l72 = sch.fuse(l19, l29, l39, l49, preserve_unit_iters=True)
sch.bind(loop=l72, thread_axis="vthread.x")
l73 = sch.fuse(l20, l30, l40, l50, preserve_unit_iters=True)
sch.bind(loop=l73, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b74 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b74, loop=l73, preserve_unit_loops=True, index=-1)
b75 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b75, loop=l68, preserve_unit_loops=True, index=-1)
l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b75)
l86 = sch.fuse(l82, l83, l84, l85, preserve_unit_iters=True)
v87 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch", ann_val=v87)
b88 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b88, loop=l68, preserve_unit_loops=True, index=-1)
l89, l90, l91, l92, l93, l94, l95, l96, l97, l98 = sch.get_loops(block=b88)
l99 = sch.fuse(l95, l96, l97, l98, preserve_unit_iters=True)
v100 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch", ann_val=v100)
l101 = sch.fuse(l56, l62, l68, preserve_unit_iters=True)
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l101, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
sch.compute_inline(block=b0)
v102 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v102)
sch.enter_postproc()
sch.unannotate(block_or_loop=b75, ann_key="meta_schedule.cooperative_fetch")
l103, l104, l105, l106, l107 = sch.get_loops(block=b75)
l108, l109 = sch.split(loop=l107, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l109, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b88, ann_key="meta_schedule.cooperative_fetch")
l110, l111, l112, l113, l114 = sch.get_loops(block=b88)
l115, l116 = sch.split(loop=l114, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l116, thread_axis="threadIdx.x")
b117 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b117, ann_key="meta_schedule.unroll_explicit")
b118, b119, b120, b121 = sch.get_child_blocks(b117)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b118)
l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b119)
l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149, l150, l151 = sch.get_loops(block=b120)
sch.annotate(block_or_loop=l134, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l134, ann_key="pragma_unroll_explicit", ann_val=1)
l152, l153, l154, l155, l156, l157, l158 = sch.get_loops(block=b121)
b159 = sch.get_block(name="conv2d_nchw", func_name="main")
l160, l161, l162, l163, l164, l165, l166, l167, l168, l169, l170, l171, l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b159)
b178 = sch.decompose_reduction(block=b159, loop=l163)
2024-04-29 13:06:21 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #128: GFLOPs: 26.3052. Time: 3952.2461 us. Best GFLOPs: 5842.6407
2024-04-29 15:02:12 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 15:02:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 15:02:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 383 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 764 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:17 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2024-04-29 15:02:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:37 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 81 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 15:02:39 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.7974  1.5925  1.5861  1.5844  1.5585  1.5258  1.5204  1.5085  1.5064  1.5037  1.4864  1.4843  1.4789  1.3906  1.3624  1.3597
[17 : 32]:	1.3595  1.3568  1.3549  1.3523  1.3462  1.2923  1.2788  1.2636  1.2267  1.2259  1.2245  1.2042  1.1935  1.1927  1.1910  1.1851
[33 : 48]:	1.1826  1.1786  1.1743  1.1735  1.1718  1.1694  1.1597  1.1595  1.1560  1.1534  1.1503  1.1487  1.1452  1.1440  1.1403  1.1402
[49 : 64]:	1.1400  1.1337  1.1327  1.1299  1.1247  1.1229  1.1212  1.1196  1.1102  1.0956  1.0935  1.0772  1.0669  1.0658  1.0636  1.0635
2024-04-29 15:02:39 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 15:02:39 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #129: GFLOPs: 2047.9249. Time: 50.7659 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #130: GFLOPs: 1236.6033. Time: 84.0728 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #131: GFLOPs: 5283.9301. Time: 19.6756 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #132: GFLOPs: 5287.2753. Time: 19.6632 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #133: GFLOPs: 5260.4397. Time: 19.7635 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #134: GFLOPs: 4563.8321. Time: 22.7801 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #135: GFLOPs: 1956.0579. Time: 53.1501 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #136: GFLOPs: 4559.9935. Time: 22.7993 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #137: GFLOPs: 4611.4712. Time: 22.5448 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #138: GFLOPs: 4526.8037. Time: 22.9665 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #139: GFLOPs: 4514.1684. Time: 23.0307 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #140: GFLOPs: 4597.1663. Time: 22.6149 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #141: GFLOPs: 1264.6782. Time: 82.2064 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #142: GFLOPs: 5772.5250. Time: 18.0103 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #143: GFLOPs: 5588.5676. Time: 18.6031 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #144: GFLOPs: 5609.5671. Time: 18.5335 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #145: GFLOPs: 5669.9949. Time: 18.3359 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #146: GFLOPs: 4211.0655. Time: 24.6884 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #147: GFLOPs: 3818.1090. Time: 27.2294 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #148: GFLOPs: 4079.4027. Time: 25.4853 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #149: GFLOPs: 3197.4136. Time: 32.5152 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #150: GFLOPs: 3494.6281. Time: 29.7499 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #151: GFLOPs: 1913.4988. Time: 54.3322 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #152: GFLOPs: 3043.2719. Time: 34.1621 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #153: GFLOPs: 1345.5100. Time: 77.2679 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #154: GFLOPs: 1332.9730. Time: 77.9946 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #155: GFLOPs: 2427.7465. Time: 42.8235 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #156: GFLOPs: 1127.6569. Time: 92.1953 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #157: GFLOPs: 1172.9858. Time: 88.6325 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #158: GFLOPs: 1275.7452. Time: 81.4933 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #159: GFLOPs: 1274.1859. Time: 81.5930 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #160: GFLOPs: 1131.2039. Time: 91.9062 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #161: GFLOPs: 1289.5463. Time: 80.6211 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #162: GFLOPs: 944.7504. Time: 110.0446 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #163: GFLOPs: 1169.1371. Time: 88.9243 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #164: GFLOPs: 1277.5842. Time: 81.3760 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #165: GFLOPs: 1278.9994. Time: 81.2859 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #166: GFLOPs: 1168.3847. Time: 88.9815 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #167: GFLOPs: 1154.7727. Time: 90.0304 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #168: GFLOPs: 1141.7904. Time: 91.0541 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #169: GFLOPs: 1212.1442. Time: 85.7692 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #170: GFLOPs: 961.1633. Time: 108.1655 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #171: GFLOPs: 1154.9211. Time: 90.0189 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #172: GFLOPs: 1173.6472. Time: 88.5826 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #173: GFLOPs: 1195.1571. Time: 86.9883 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #174: GFLOPs: 3430.3138. Time: 30.3076 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #175: GFLOPs: 1171.5422. Time: 88.7417 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #176: GFLOPs: 2947.0722. Time: 35.2773 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #177: GFLOPs: 603.8402. Time: 172.1725 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #178: GFLOPs: 2945.7213. Time: 35.2935 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #179: GFLOPs: 3546.7238. Time: 29.3129 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #180: GFLOPs: 3607.0365. Time: 28.8227 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #181: GFLOPs: 1155.9387. Time: 89.9396 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #182: GFLOPs: 2718.2784. Time: 38.2465 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #183: GFLOPs: 1185.3904. Time: 87.7050 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #184: GFLOPs: 1191.2949. Time: 87.2703 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #185: GFLOPs: 1367.6519. Time: 76.0169 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #186: GFLOPs: 1185.2733. Time: 87.7137 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #187: GFLOPs: 5698.6970. Time: 18.2436 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #188: GFLOPs: 2622.7440. Time: 39.6397 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #189: GFLOPs: 3744.8537. Time: 27.7620 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #190: GFLOPs: 2166.1483. Time: 47.9952 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #191: GFLOPs: 792.3293. Time: 131.2140 us. Best GFLOPs: 5842.6407
2024-04-29 15:03:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #192: GFLOPs: 515.5810. Time: 201.6457 us. Best GFLOPs: 5842.6407
2024-04-29 16:21:00 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 16:21:01 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 16:21:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 376 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 752 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:05 [INFO] [evolutionary_search.cc:723] Sampled 68 candidate(s)
2024-04-29 16:21:09 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 79 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:14 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:19 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:21:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.5391  1.5192  1.5134  1.5074  1.5074  1.4896  1.4794  1.4749  1.4719  1.4551  1.4267  1.4113  1.3965  1.3936  1.3888  1.3863
[17 : 32]:	1.3643  1.3635  1.3539  1.3499  1.3420  1.3405  1.3342  1.3316  1.3263  1.3230  1.3221  1.3156  1.3132  1.3110  1.3110  1.3041
[33 : 48]:	1.2996  1.2860  1.2859  1.2826  1.2777  1.2714  1.2681  1.2637  1.2607  1.2606  1.2592  1.2454  1.2452  1.2419  1.2404  1.2385
[49 : 64]:	1.2380  1.2377  1.2272  1.1958  1.1890  1.1850  1.1682  1.1562  1.1555  1.1551  1.1545  1.1533  1.1128  1.1037  1.1033  1.0932
2024-04-29 16:21:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 16:21:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #193: GFLOPs: 2251.4009. Time: 46.1778 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #194: GFLOPs: 2964.1471. Time: 35.0741 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #195: GFLOPs: 5747.6502. Time: 18.0882 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #196: GFLOPs: 2172.3439. Time: 47.8583 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #197: GFLOPs: 2241.0391. Time: 46.3913 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #198: GFLOPs: 2219.1263. Time: 46.8494 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #199: GFLOPs: 5730.2509. Time: 18.1431 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #200: GFLOPs: 2180.5632. Time: 47.6779 us. Best GFLOPs: 5842.6407
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #201: GFLOPs: 6274.9098. Time: 16.5683 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #202: GFLOPs: 5618.8675. Time: 18.5028 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #203: GFLOPs: 4729.9170. Time: 21.9802 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #204: GFLOPs: 4877.6405. Time: 21.3145 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #205: GFLOPs: 4785.7700. Time: 21.7237 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #206: GFLOPs: 4788.9289. Time: 21.7094 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #207: GFLOPs: 4408.8003. Time: 23.5812 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #208: GFLOPs: 4806.8753. Time: 21.6283 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #209: GFLOPs: 5582.2066. Time: 18.6243 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #210: GFLOPs: 4771.9402. Time: 21.7867 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #211: GFLOPs: 5658.2486. Time: 18.3740 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #212: GFLOPs: 5698.3322. Time: 18.2448 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #213: GFLOPs: 5640.9429. Time: 18.4304 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #214: GFLOPs: 5680.9006. Time: 18.3007 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #215: GFLOPs: 5813.0191. Time: 17.8848 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #216: GFLOPs: 5845.1787. Time: 17.7864 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #217: GFLOPs: 4666.8451. Time: 22.2773 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #218: GFLOPs: 4748.9728. Time: 21.8920 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #219: GFLOPs: 5689.5472. Time: 18.2729 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #220: GFLOPs: 3045.2115. Time: 34.1404 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #221: GFLOPs: 4667.4072. Time: 22.2746 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #222: GFLOPs: 5852.9040. Time: 17.7629 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #223: GFLOPs: 5749.9209. Time: 18.0811 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #224: GFLOPs: 2899.7430. Time: 35.8531 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #225: GFLOPs: 2161.8608. Time: 48.0904 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #226: GFLOPs: 5352.6786. Time: 19.4229 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #227: GFLOPs: 4584.2622. Time: 22.6786 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #228: GFLOPs: 3072.0555. Time: 33.8421 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #229: GFLOPs: 1932.3194. Time: 53.8030 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #230: GFLOPs: 5630.4013. Time: 18.4649 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #231: GFLOPs: 5662.2706. Time: 18.3610 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #232: GFLOPs: 5813.1041. Time: 17.8845 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #233: GFLOPs: 1916.6295. Time: 54.2435 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #234: GFLOPs: 5442.3641. Time: 19.1029 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #235: GFLOPs: 2000.3821. Time: 51.9724 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #236: GFLOPs: 3308.0962. Time: 31.4273 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #237: GFLOPs: 5547.3922. Time: 18.7412 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #238: GFLOPs: 2280.4025. Time: 45.5905 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #239: GFLOPs: 1927.1336. Time: 53.9478 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #240: GFLOPs: 1918.4928. Time: 54.1908 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #241: GFLOPs: 3042.6499. Time: 34.1691 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #242: GFLOPs: 5770.6894. Time: 18.0160 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #243: GFLOPs: 2003.0721. Time: 51.9026 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #244: GFLOPs: 2433.6969. Time: 42.7188 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #245: GFLOPs: 2637.1512. Time: 39.4231 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #246: GFLOPs: 5615.5345. Time: 18.5138 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #247: GFLOPs: 5587.0987. Time: 18.6080 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #248: GFLOPs: 5573.3248. Time: 18.6540 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #249: GFLOPs: 5526.5323. Time: 18.8119 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #250: GFLOPs: 5522.9158. Time: 18.8242 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #251: GFLOPs: 3578.0143. Time: 29.0565 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #252: GFLOPs: 5412.7801. Time: 19.2073 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #253: GFLOPs: 5551.4742. Time: 18.7274 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #254: GFLOPs: 2720.3308. Time: 38.2177 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #255: GFLOPs: 69.0442. Time: 1505.7691 us. Best GFLOPs: 6274.9098
2024-04-29 16:22:50 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #256: GFLOPs: 2718.9171. Time: 38.2375 us. Best GFLOPs: 6274.9098
2024-04-29 16:46:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 16:46:23 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 16:46:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 381 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 763 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:28 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2024-04-29 16:46:32 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:49 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x16233118)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b6252f8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x1b625928)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x495c678)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x155ccf28)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xf46bad8)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b625d28)]: 0 failure(s)
2024-04-29 16:46:51 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.6158  1.6061  1.5832  1.5464  1.5396  1.5383  1.5383  1.5382  1.5351  1.5326  1.5313  1.5262  1.5238  1.5207  1.5190  1.5124
[17 : 32]:	1.5078  1.4948  1.4920  1.4766  1.4711  1.4706  1.4678  1.4618  1.4560  1.4415  1.4399  1.4367  1.4345  1.4304  1.4250  1.4246
[33 : 48]:	1.4245  1.4195  1.4147  1.4130  1.4110  1.4094  1.4074  1.4065  1.4024  1.4019  1.4016  1.3980  1.3977  1.3948  1.3939  1.3936
[49 : 64]:	1.3901  1.3890  1.3863  1.3826  1.3820  1.3807  1.3770  1.3733  1.3690  1.3675  1.3642  1.3549  1.3479  1.3373  1.3336  1.3327
2024-04-29 16:46:51 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 16:46:51 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #257: GFLOPs: 559.8655. Time: 185.6958 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #258: GFLOPs: 5632.6266. Time: 18.4576 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #259: GFLOPs: 3624.6302. Time: 28.6828 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #260: GFLOPs: 2460.0383. Time: 42.2614 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #261: GFLOPs: 797.0871. Time: 130.4307 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #262: GFLOPs: 2459.8627. Time: 42.2644 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #263: GFLOPs: 2527.3363. Time: 41.1361 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #264: GFLOPs: 5535.7485. Time: 18.7806 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #265: GFLOPs: 630.6651. Time: 164.8493 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #266: GFLOPs: 2477.8268. Time: 41.9580 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #267: GFLOPs: 849.8489. Time: 122.3331 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #268: GFLOPs: 3629.1984. Time: 28.6467 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #269: GFLOPs: 447.0373. Time: 232.5638 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #270: GFLOPs: 4296.8666. Time: 24.1955 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #271: GFLOPs: 2476.9057. Time: 41.9736 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #272: GFLOPs: 2465.9140. Time: 42.1607 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #273: GFLOPs: 4307.2197. Time: 24.1373 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #274: GFLOPs: 4339.6953. Time: 23.9567 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #275: GFLOPs: 755.8190. Time: 137.5523 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #276: GFLOPs: 4594.3712. Time: 22.6287 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #277: GFLOPs: 4704.3648. Time: 22.0996 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #278: GFLOPs: 4784.9827. Time: 21.7273 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #279: GFLOPs: 1179.2627. Time: 88.1607 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #280: GFLOPs: 4556.0108. Time: 22.8192 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #281: GFLOPs: 1187.9612. Time: 87.5152 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #282: GFLOPs: 4466.7573. Time: 23.2752 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #283: GFLOPs: 3792.4808. Time: 27.4134 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #284: GFLOPs: 4257.0481. Time: 24.4218 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #285: GFLOPs: 2537.6193. Time: 40.9694 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #286: GFLOPs: 2563.9291. Time: 40.5490 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #287: GFLOPs: 505.2910. Time: 205.7521 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #288: GFLOPs: 2530.0097. Time: 41.0926 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #289: GFLOPs: 4194.5841. Time: 24.7855 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #290: GFLOPs: 2526.9962. Time: 41.1416 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #291: GFLOPs: 2555.4228. Time: 40.6839 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #292: GFLOPs: 4442.0944. Time: 23.4044 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #293: GFLOPs: 2529.8797. Time: 41.0947 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #294: GFLOPs: 4431.8863. Time: 23.4583 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #295: GFLOPs: 5466.8138. Time: 19.0174 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #296: GFLOPs: 3918.1424. Time: 26.5342 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #297: GFLOPs: 2569.7766. Time: 40.4567 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #298: GFLOPs: 2813.6106. Time: 36.9506 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #299: GFLOPs: 5443.5370. Time: 19.0987 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #300: GFLOPs: 5387.9897. Time: 19.2956 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #301: GFLOPs: 5417.7732. Time: 19.1896 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #302: GFLOPs: 2725.7688. Time: 38.1414 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #303: GFLOPs: 4262.1369. Time: 24.3926 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #304: GFLOPs: 5385.2119. Time: 19.3056 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #305: GFLOPs: 4538.1679. Time: 22.9090 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #306: GFLOPs: 1782.9469. Time: 58.3106 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #307: GFLOPs: 2081.7665. Time: 49.9406 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #308: GFLOPs: 872.1416. Time: 119.2062 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #309: GFLOPs: 4290.3744. Time: 24.2321 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #310: GFLOPs: 2739.3661. Time: 37.9521 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #311: GFLOPs: 5286.2313. Time: 19.6671 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #312: GFLOPs: 5287.3478. Time: 19.6629 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #313: GFLOPs: 5290.5545. Time: 19.6510 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #314: GFLOPs: 4638.2587. Time: 22.4146 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #315: GFLOPs: 4525.3918. Time: 22.9736 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #316: GFLOPs: 3051.7806. Time: 34.0669 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #317: GFLOPs: 787.4161. Time: 132.0327 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #318: GFLOPs: 66.1319. Time: 1572.0800 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #319: GFLOPs: 1014.3945. Time: 102.4894 us. Best GFLOPs: 6274.9098
2024-04-29 16:48:07 [INFO] [task_scheduler.cc:131] [Task #14: fused_nn_conv2d_add_add_nn_relu_1] Trial #320: GFLOPs: 5.8111. Time: 17890.6453 us. Best GFLOPs: 6274.9098
