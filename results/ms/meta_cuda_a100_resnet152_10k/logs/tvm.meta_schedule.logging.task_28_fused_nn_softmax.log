2024-04-29 11:32:43 [INFO] [task_scheduler.cc:160] Initializing Task #28: "fused_nn_softmax"
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_exp = T.alloc_buffer((T.int64(1), T.int64(1000)))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0, k in T.grid(T.int64(1), T.int64(1000)):
            with T.block("T_softmax_maxelem"):
                v_i0, v_k = T.axis.remap("SR", [i0, k])
                T.reads(p0[v_i0, v_k])
                T.writes(T_softmax_maxelem[v_i0])
                with T.init():
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0, i1 in T.grid(T.int64(1), T.int64(1000)):
            with T.block("T_softmax_exp"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0])
                T.writes(T_softmax_exp[v_i0, v_i1])
                T_softmax_exp[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0])
        for i0, k in T.grid(T.int64(1), T.int64(1000)):
            with T.block("T_softmax_expsum"):
                v_i0, v_k = T.axis.remap("SR", [i0, k])
                T.reads(T_softmax_exp[v_i0, v_k])
                T.writes(T_softmax_expsum[v_i0])
                with T.init():
                    T_softmax_expsum[v_i0] = T.float32(0)
                T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T_softmax_exp[v_i0, v_k]
        for i0, i1 in T.grid(T.int64(1), T.int64(1000)):
            with T.block("T_softmax_norm"):
                v_i0, v_i1 = T.axis.remap("SS", [i0, i1])
                T.reads(T_softmax_exp[v_i0, v_i1], T_softmax_expsum[v_i0])
                T.writes(T_softmax_norm[v_i0, v_i1])
                T.block_attr({"axis": 1})
                T_softmax_norm[v_i0, v_i1] = T_softmax_exp[v_i0, v_i1] / T_softmax_expsum[v_i0]
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:164] Total 4 design space(s) generated
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
            T_softmax_expsum = T.alloc_buffer((T.int64(1),))
            for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                    for k in range(T.int64(1000)):
                        with T.block("T_softmax_maxelem"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_k = T.axis.reduce(T.int64(1000), k)
                            T.reads(p0[v_i0, v_k])
                            T.writes(T_softmax_maxelem[v_i0])
                            with T.init():
                                T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
            for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                    for k in range(T.int64(1000)):
                        with T.block("T_softmax_expsum"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_k = T.axis.reduce(T.int64(1000), k)
                            T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                            T.writes(T_softmax_expsum[v_i0])
                            with T.init():
                                T_softmax_expsum[v_i0] = T.float32(0)
                            T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                        T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
            T_softmax_expsum = T.alloc_buffer((T.int64(1),))
            for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for k_0 in range(T.int64(4)):
                    for k_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                        with T.block("T_softmax_maxelem"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(256) + k_1)
                            T.where(k_0 * T.int64(256) + k_1 < T.int64(1000))
                            T.reads(p0[v_i0, v_k])
                            T.writes(T_softmax_maxelem[v_i0])
                            with T.init():
                                T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
            for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                    for k in range(T.int64(1000)):
                        with T.block("T_softmax_expsum"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_k = T.axis.reduce(T.int64(1000), k)
                            T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                            T.writes(T_softmax_expsum[v_i0])
                            with T.init():
                                T_softmax_expsum[v_i0] = T.float32(0)
                            T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
                for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                        T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
            T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
            for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                    for k in range(T.int64(1000)):
                        with T.block("T_softmax_maxelem"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_k = T.axis.reduce(T.int64(1000), k)
                            T.reads(p0[v_i0, v_k])
                            T.writes(T_softmax_maxelem[v_i0])
                            with T.init():
                                T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
            for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                    for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        with T.block("T_softmax_expsum"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                            T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                            T.writes(T_softmax_expsum_shared[v_i0])
                            with T.init():
                                T_softmax_expsum_shared[v_i0] = T.float32(0)
                            T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
                for i1_0 in range(T.int64(125)):
                    for i1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        with T.block("T_softmax_norm"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(8) + i1_1)
                            T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                            T.writes(T_softmax_norm[v_i0, v_i1])
                            T.block_attr({"axis": 1})
                            T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
2024-04-29 11:32:43 [INFO] [task_scheduler.cc:170] Design space #3:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 64})
            T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
            T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
            for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
                for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                    for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        with T.block("T_softmax_maxelem"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                            T.reads(p0[v_i0, v_k])
                            T.writes(T_softmax_maxelem_shared[v_i0])
                            with T.init():
                                T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                            T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
                for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                    for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        with T.block("T_softmax_expsum"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                            T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                            T.writes(T_softmax_expsum_shared[v_i0])
                            with T.init():
                                T_softmax_expsum_shared[v_i0] = T.float32(0)
                            T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
                for i1_0 in range(T.int64(125)):
                    for i1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        with T.block("T_softmax_norm"):
                            v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(8) + i1_1)
                            T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                            T.writes(T_softmax_norm[v_i0, v_i1])
                            T.block_attr({"axis": 1})
                            T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
2024-04-29 12:19:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 12:19:56 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 12:19:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x161a1108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b627818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca3a908)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x8006d38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xa8852b8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcb18bc8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b697808)]: 0 failure(s)
2024-04-29 12:19:57 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 12:19:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x161a1108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b627818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca3a908)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x8006d38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xa8852b8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcb18bc8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b697808)]: 0 failure(s)
2024-04-29 12:19:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x161a1108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b627818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca3a908)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x8006d38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xa8852b8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcb18bc8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b697808)]: 0 failure(s)
2024-04-29 12:19:58 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x161a1108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b627818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca3a908)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x8006d38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xa8852b8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcb18bc8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b697808)]: 0 failure(s)
2024-04-29 12:19:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x161a1108)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x1b627818)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca3a908)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x8006d38)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0xa8852b8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcb18bc8)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x1b697808)]: 0 failure(s)
2024-04-29 12:19:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9955  0.9939  0.9903  0.9804  0.9793  0.9781  0.9647  0.9642  0.9554  0.9548  0.9354  0.9345  0.9314  0.9280  0.9254  0.9232
[17 : 32]:	0.9232  0.9154  0.9151  0.9121  0.9097  0.9000  0.8987  0.8915  0.8902  0.8840  0.8754  0.8693  0.8644  0.8553  0.8526  0.8514
[33 : 48]:	0.8491  0.8475  0.8471  0.8468  0.8440  0.8433  0.8392  0.8318  0.8246  0.8217  0.8215  0.8194  0.8063  0.8055  0.8002  0.7995
[49 : 64]:	0.7982  0.7914  0.7882  0.7838  0.7827  0.7820  0.7809  0.7809  0.7758  0.7719  0.7713  0.7542  0.7539  0.7427  0.7425  0.7375
2024-04-29 12:19:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 12:19:59 [INFO] [evolutionary_search.cc:730] Sending 63 candidates(s) for measurement
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #1: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(16)):
                for k_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(64) + k_1)
                        T.where(k_0 * T.int64(64) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #2: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l26, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l26, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #3: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #4: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #5: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(16)):
                for k_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(64) + k_1)
                        T.where(k_0 * T.int64(64) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #6: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
l29, l30, l31 = sch.get_loops(block=b24)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #7: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(63)):
                for ax1_1 in T.thread_binding(T.int64(16), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(16) + ax1_1)
                        T.where(ax1_0 * T.int64(16) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(63)):
                for ax1_1 in T.thread_binding(T.int64(16), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(16) + ax1_1)
                        T.where(ax1_0 * T.int64(16) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(63)):
                for i1_1 in T.thread_binding(T.int64(16), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(16) + i1_1)
                        T.where(i1_0 * T.int64(16) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=2)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #8: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(4)):
                for i1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(256) + i1_1)
                        T.where(i1_0 * T.int64(256) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #9: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(4)):
                for i1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(256) + i1_1)
                        T.where(i1_0 * T.int64(256) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #10: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(250)):
                for k_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(4) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #11: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(16)):
                for k_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(64) + k_1)
                        T.where(k_0 * T.int64(64) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #12: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(16)):
                for k_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(64) + k_1)
                        T.where(k_0 * T.int64(64) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #13: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #14: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(250)):
                for k_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(4) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #15: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(8)):
                for ax1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(128) + ax1_1)
                        T.where(ax1_0 * T.int64(128) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(8)):
                for i1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(128) + i1_1)
                        T.where(i1_0 * T.int64(128) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #16: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(4)):
                for k_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(256) + k_1)
                        T.where(k_0 * T.int64(256) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #17: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l26, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l26, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #18: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(32)):
                for ax1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(32) + ax1_1)
                        T.where(ax1_0 * T.int64(32) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(32)):
                for ax1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(32) + ax1_1)
                        T.where(ax1_0 * T.int64(32) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(32)):
                for i1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(32) + i1_1)
                        T.where(i1_0 * T.int64(32) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=3)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #19: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(125)):
                for i1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(8) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #20: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(32)):
                for ax1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(32) + ax1_1)
                        T.where(ax1_0 * T.int64(32) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(32)):
                for ax1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(32) + ax1_1)
                        T.where(ax1_0 * T.int64(32) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(32)):
                for i1_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(32) + i1_1)
                        T.where(i1_0 * T.int64(32) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=3)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #21: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(2)):
                for k_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(512) + k_1)
                        T.where(k_0 * T.int64(512) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #22: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(4)):
                for k_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(256) + k_1)
                        T.where(k_0 * T.int64(256) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #23: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(4)):
                for i1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(256) + i1_1)
                        T.where(i1_0 * T.int64(256) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35, l36 = sch.get_loops(block=b28)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #24: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(2)):
                for k_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(512) + k_1)
                        T.where(k_0 * T.int64(512) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #25: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(2)):
                for i1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(512) + i1_1)
                        T.where(i1_0 * T.int64(512) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #26: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(2)):
                for i1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(512) + i1_1)
                        T.where(i1_0 * T.int64(512) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #27: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(2)):
                for i1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(512) + i1_1)
                        T.where(i1_0 * T.int64(512) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #28: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(8)):
                for ax1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(128) + ax1_1)
                        T.where(ax1_0 * T.int64(128) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(8)):
                for i1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(128) + i1_1)
                        T.where(i1_0 * T.int64(128) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #29: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(250)):
                for i1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(4) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #30: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(4)):
                for k_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(256) + k_1)
                        T.where(k_0 * T.int64(256) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #31: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(4)):
                for i1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(256) + i1_1)
                        T.where(i1_0 * T.int64(256) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #32: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l26, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l26, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #33: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(250)):
                for i1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(4) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #34: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #35: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #36: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(16)):
                for ax1_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(64) + ax1_1)
                        T.where(ax1_0 * T.int64(64) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(16)):
                for ax1_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(64) + ax1_1)
                        T.where(ax1_0 * T.int64(64) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(16)):
                for i1_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(64) + i1_1)
                        T.where(i1_0 * T.int64(64) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
l40, l41, l42, l43 = sch.get_loops(block=b34)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #37: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(2)):
                for i1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(512) + i1_1)
                        T.where(i1_0 * T.int64(512) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35, l36 = sch.get_loops(block=b28)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #38: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(2)):
                for k_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(512) + k_1)
                        T.where(k_0 * T.int64(512) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #39: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(63)):
                for k_1 in T.thread_binding(T.int64(16), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(16) + k_1)
                        T.where(k_0 * T.int64(16) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=2)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #40: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(250)):
                for k_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(4) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #41: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(2)):
                for k_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(512) + k_1)
                        T.where(k_0 * T.int64(512) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(512) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #42: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(250)):
                for k_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(4) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #43: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(250)):
                for i1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(4) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #44: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #45: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(125)):
                for i1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(8) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
sch.annotate(block_or_loop=l36, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l36, ann_key="pragma_unroll_explicit", ann_val=1)
l40, l41, l42, l43 = sch.get_loops(block=b34)
sch.annotate(block_or_loop=l40, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l40, ann_key="pragma_unroll_explicit", ann_val=1)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #46: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(32)):
                for k_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(32) + k_1)
                        T.where(k_0 * T.int64(32) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(32) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=3)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #47: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem_shared[v_i0])
                        with T.init():
                            T_softmax_maxelem_shared[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem_shared[v_i0] = T.max(T_softmax_maxelem_shared[v_i0], p0[v_i0, v_k])
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(250)):
                for ax1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(4) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem_shared[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem_shared[v_i0])
            for i1_0 in range(T.int64(250)):
                for i1_1 in T.thread_binding(T.int64(4), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(4) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem_shared[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem_shared[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=0)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
b16, b17 = sch.get_consumers(block=b0)
l18, l19, l20, l21 = sch.get_loops(block=b16)
sch.compute_at(block=b0, loop=l18, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b0, buffer_index=0, storage_scope="shared")
l22, l23, l24 = sch.get_loops(block=b0)
l25, l26 = sch.split(loop=l24, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l26, thread_axis="threadIdx.x")
v27 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v27)
l28, l29, l30 = sch.get_loops(block=b3)
l31 = sch.fuse(l28, preserve_unit_iters=True)
sch.bind(loop=l31, thread_axis="blockIdx.x")
sch.enter_postproc()
b32 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b32, ann_key="meta_schedule.unroll_explicit")
b33, b34, b35 = sch.get_child_blocks(b32)
l36, l37, l38, l39 = sch.get_loops(block=b33)
l40, l41, l42, l43 = sch.get_loops(block=b34)
l44, l45, l46 = sch.get_loops(block=b35)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #48: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #49: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(2)):
                for k_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(512) + k_1)
                        T.where(k_0 * T.int64(512) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #50: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #51: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(128) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #52: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l26, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l26, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #53: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(4)):
                for ax1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(256) + ax1_1)
                        T.where(ax1_0 * T.int64(256) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(4)):
                for i1_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(256) + i1_1)
                        T.where(i1_0 * T.int64(256) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=6)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #54: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(16)):
                for ax1_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(64) + ax1_1)
                        T.where(ax1_0 * T.int64(64) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(16)):
                for i1_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(64) + i1_1)
                        T.where(i1_0 * T.int64(64) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=4)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #55: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(8)):
                for k_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(128) + k_1)
                        T.where(k_0 * T.int64(128) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #56: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(32)):
                for k_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(32) + k_1)
                        T.where(k_0 * T.int64(32) + k_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=3)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #57: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #58: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v5)
l6, l7 = sch.get_loops(block=b3)
l8 = sch.fuse(l6, l7, preserve_unit_iters=True)
v9 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l10, l11 = sch.split(loop=l8, factors=[None, v9], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="blockIdx.x")
sch.bind(loop=l11, thread_axis="threadIdx.x")
l12, l13 = sch.get_loops(block=b2)
l14 = sch.fuse(l12, preserve_unit_iters=True)
l15, l16 = sch.split(loop=l14, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
sch.enter_postproc()
b22 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b22, ann_key="meta_schedule.unroll_explicit")
b23, b24, b25 = sch.get_child_blocks(b22)
l26, l27, l28 = sch.get_loops(block=b23)
sch.annotate(block_or_loop=l26, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l26, ann_key="pragma_unroll_explicit", ann_val=1)
l29, l30, l31 = sch.get_loops(block=b24)
sch.annotate(block_or_loop=l29, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l29, ann_key="pragma_unroll_explicit", ann_val=1)
l32, l33 = sch.get_loops(block=b25)
b34 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l35, l36, l37 = sch.get_loops(block=b34)
b38 = sch.decompose_reduction(block=b34, loop=l37)
b39 = sch.get_block(name="T_softmax_expsum", func_name="main")
l40, l41, l42 = sch.get_loops(block=b39)
b43 = sch.decompose_reduction(block=b39, loop=l42)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #59: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(2)):
                for ax1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(512) + ax1_1)
                        T.where(ax1_0 * T.int64(512) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(2)):
                for i1_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(512) + i1_1)
                        T.where(i1_0 * T.int64(512) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #60: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(256) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35 = sch.get_loops(block=b28)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #61: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x"):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(125)):
                for ax1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(8) + ax1_1)
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(125)):
                for i1_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(8) + i1_1)
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
l33, l34, l35, l36 = sch.get_loops(block=b28)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #62: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum_shared = T.alloc_buffer((T.int64(1),), scope="shared")
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_maxelem_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_maxelem[v_i0])
                    T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_maxelem_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ax0, ax1_0 in T.grid(T.int64(1), T.int64(8)):
                for ax1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_expsum"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_k = T.axis.reduce(T.int64(1000), ax1_0 * T.int64(128) + ax1_1)
                        T.where(ax1_0 * T.int64(128) + ax1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum_shared[v_i0])
                        with T.init():
                            T_softmax_expsum_shared[v_i0] = T.float32(0)
                        T_softmax_expsum_shared[v_i0] = T_softmax_expsum_shared[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
            for i1_0 in range(T.int64(8)):
                for i1_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    with T.block("T_softmax_norm"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_i1 = T.axis.spatial(T.int64(1000), i1_0 * T.int64(128) + i1_1)
                        T.where(i1_0 * T.int64(128) + i1_1 < T.int64(1000))
                        T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum_shared[v_i0])
                        T.writes(T_softmax_norm[v_i0, v_i1])
                        T.block_attr({"axis": 1})
                        T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum_shared[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
b5, = sch.get_consumers(block=b2)
l6, l7 = sch.get_loops(block=b5)
v8 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=5)
l9, l10 = sch.split(loop=l7, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l10, thread_axis="threadIdx.x")
sch.compute_at(block=b2, loop=l6, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="shared")
l11, l12, l13 = sch.get_loops(block=b2)
l14, l15 = sch.split(loop=l13, factors=[None, v8], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="threadIdx.x")
v16 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v16)
l17, l18, l19 = sch.get_loops(block=b3)
l20 = sch.fuse(l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
l21, l22 = sch.get_loops(block=b0)
l23 = sch.fuse(l21, preserve_unit_iters=True)
l24, l25 = sch.split(loop=l23, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l24, thread_axis="blockIdx.x")
sch.bind(loop=l25, thread_axis="threadIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35, l36 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l37, l38, l39 = sch.get_loops(block=b29)
b40 = sch.get_block(name="T_softmax_maxelem", func_name="main")
l41, l42, l43 = sch.get_loops(block=b40)
b44 = sch.decompose_reduction(block=b40, loop=l43)
2024-04-29 12:21:12 [INFO] [task_scheduler.cc:121] [Task #28: fused_nn_softmax] Trial #63: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_softmax_norm: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_softmax_maxelem = T.alloc_buffer((T.int64(1),))
        T_softmax_expsum = T.alloc_buffer((T.int64(1),))
        for i0_fused in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for k_0 in range(T.int64(125)):
                for k_1 in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                    with T.block("T_softmax_maxelem"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k_0 * T.int64(8) + k_1)
                        T.reads(p0[v_i0, v_k])
                        T.writes(T_softmax_maxelem[v_i0])
                        with T.init():
                            T_softmax_maxelem[v_i0] = T.float32(-3.4028234663852886e+38)
                        T_softmax_maxelem[v_i0] = T.max(T_softmax_maxelem[v_i0], p0[v_i0, v_k])
        for i0_fused_0 in T.thread_binding(T.int64(1), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for i0_fused_1 in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                with T.block("T_softmax_expsum_init"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    T.reads()
                    T.writes(T_softmax_expsum[v_i0])
                    T_softmax_expsum[v_i0] = T.float32(0)
                for k in range(T.int64(1000)):
                    with T.block("T_softmax_expsum_update"):
                        v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                        v_k = T.axis.reduce(T.int64(1000), k)
                        T.reads(T_softmax_expsum[v_i0], p0[v_i0, v_k], T_softmax_maxelem[v_i0])
                        T.writes(T_softmax_expsum[v_i0])
                        T_softmax_expsum[v_i0] = T_softmax_expsum[v_i0] + T.exp(p0[v_i0, v_k] - T_softmax_maxelem[v_i0])
        for i0_i1_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for i0_i1_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                with T.block("T_softmax_norm"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1000), i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1)
                    T.where(i0_i1_fused_0 * T.int64(64) + i0_i1_fused_1 < T.int64(1000))
                    T.reads(p0[v_i0, v_i1], T_softmax_maxelem[v_i0], T_softmax_expsum[v_i0])
                    T.writes(T_softmax_norm[v_i0, v_i1])
                    T.block_attr({"axis": 1})
                    T_softmax_norm[v_i0, v_i1] = T.exp(p0[v_i0, v_i1] - T_softmax_maxelem[v_i0]) / T_softmax_expsum[v_i0]
b0 = sch.get_block(name="T_softmax_maxelem", func_name="main")
b1 = sch.get_block(name="T_softmax_exp", func_name="main")
b2 = sch.get_block(name="T_softmax_expsum", func_name="main")
b3 = sch.get_block(name="T_softmax_norm", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b1)
v5 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=1)
l6, l7 = sch.get_loops(block=b0)
l8, l9 = sch.split(loop=l7, factors=[None, v5], preserve_unit_iters=True)
sch.bind(loop=l9, thread_axis="threadIdx.x")
v10 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v10)
l11, l12 = sch.get_loops(block=b3)
l13 = sch.fuse(l11, l12, preserve_unit_iters=True)
v14 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
l15, l16 = sch.split(loop=l13, factors=[None, v14], preserve_unit_iters=True)
sch.bind(loop=l15, thread_axis="blockIdx.x")
sch.bind(loop=l16, thread_axis="threadIdx.x")
l17, l18 = sch.get_loops(block=b2)
l19 = sch.fuse(l17, preserve_unit_iters=True)
l20, l21 = sch.split(loop=l19, factors=[None, 1], preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
sch.bind(loop=l21, thread_axis="threadIdx.x")
l22, l23, l24 = sch.get_loops(block=b0)
l25 = sch.fuse(l22, preserve_unit_iters=True)
sch.bind(loop=l25, thread_axis="blockIdx.x")
sch.enter_postproc()
b26 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b26, ann_key="meta_schedule.unroll_explicit")
b27, b28, b29 = sch.get_child_blocks(b26)
l30, l31, l32 = sch.get_loops(block=b27)
sch.annotate(block_or_loop=l30, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l30, ann_key="pragma_unroll_explicit", ann_val=1)
l33, l34, l35 = sch.get_loops(block=b28)
sch.annotate(block_or_loop=l33, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l33, ann_key="pragma_unroll_explicit", ann_val=1)
l36, l37 = sch.get_loops(block=b29)
b38 = sch.get_block(name="T_softmax_expsum", func_name="main")
l39, l40, l41 = sch.get_loops(block=b38)
b42 = sch.decompose_reduction(block=b38, loop=l41)
