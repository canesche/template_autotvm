2024-04-29 11:32:42 [INFO] [task_scheduler.cc:160] Initializing Task #23: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3"
2024-04-29 11:32:42 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(9), T.int64(9)))
        input_tile = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)))
        B = T.alloc_buffer((T.int64(4), T.int64(4)))
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        A = T.alloc_buffer((T.int64(4), T.int64(2)))
        inverse = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)))
        conv2d_winograd = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(9), T.int64(9)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3])
                data_pad[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for ci, p, eps, nu in T.grid(T.int64(512), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("input_tile"):
                v_ci, v_p, v_eps, v_nu = T.axis.remap("SSSS", [ci, p, eps, nu])
                T.reads(data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu])
                T.writes(input_tile[v_ci, v_p, v_eps, v_nu])
                T.block_attr({"schedule_rule": "None"})
                input_tile[v_ci, v_p, v_eps, v_nu] = data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu]
        for i, j in T.grid(T.int64(4), T.int64(4)):
            with T.block("B"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(B[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                B[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
        for eps, nu, ci, p, r_a, r_b in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("data_pack"):
                v_eps, v_nu, v_ci, v_p, v_r_a, v_r_b = T.axis.remap("SSSSRR", [eps, nu, ci, p, r_a, r_b])
                T.reads(input_tile[v_ci, v_p, v_r_a, v_r_b], B[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_eps, v_nu):T.min(v_eps, v_nu) + (T.max(v_eps, v_nu) + T.int64(1) - T.min(v_eps, v_nu))])
                T.writes(data_pack[v_eps, v_nu, v_ci, v_p])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                with T.init():
                    data_pack[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                data_pack[v_eps, v_nu, v_ci, v_p] = data_pack[v_eps, v_nu, v_ci, v_p] + input_tile[v_ci, v_p, v_r_a, v_r_b] * B[v_r_a, v_eps] * B[v_r_b, v_nu]
        for eps, nu, co, p, ci in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(16), T.int64(512)):
            with T.block("bgemm"):
                v_eps, v_nu, v_co, v_p, v_ci = T.axis.remap("SSSSR", [eps, nu, co, p, ci])
                T.reads(data_pack[v_eps, v_nu, v_ci, v_p], p1[v_eps, v_nu, v_ci, v_co])
                T.writes(bgemm[v_eps, v_nu, v_co, v_p])
                with T.init():
                    bgemm[v_eps, v_nu, v_co, v_p] = T.float32(0)
                bgemm[v_eps, v_nu, v_co, v_p] = bgemm[v_eps, v_nu, v_co, v_p] + data_pack[v_eps, v_nu, v_ci, v_p] * p1[v_eps, v_nu, v_ci, v_co]
        for i, j in T.grid(T.int64(4), T.int64(2)):
            with T.block("A"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(A[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                A[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
        for co, p, vh, vw, r_a, r_b in T.grid(T.int64(512), T.int64(16), T.int64(2), T.int64(2), T.int64(4), T.int64(4)):
            with T.block("inverse"):
                v_co, v_p, v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSSSRR", [co, p, vh, vw, r_a, r_b])
                T.reads(bgemm[v_r_a, v_r_b, v_co, v_p], A[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_vh, v_vw):T.min(v_vh, v_vw) + (T.max(v_vh, v_vw) + T.int64(1) - T.min(v_vh, v_vw))])
                T.writes(inverse[v_co, v_p, v_vh, v_vw])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                with T.init():
                    inverse[v_co, v_p, v_vh, v_vw] = T.float32(0)
                inverse[v_co, v_p, v_vh, v_vw] = inverse[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * A[v_r_a, v_vh] * A[v_r_b, v_vw]
        for n, co, h, w in T.grid(T.int64(1), T.int64(512), T.int64(7), T.int64(7)):
            with T.block("conv2d_winograd"):
                v_n, v_co, v_h, v_w = T.axis.remap("SSSS", [n, co, h, w])
                T.reads(inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                conv2d_winograd[v_n, v_co, v_h, v_w] = inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(7), T.int64(7)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(7), T.int64(7)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3], T.float32(0))
2024-04-29 11:32:42 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 11:32:42 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(512)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(8192)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(2048) // T.int64(1024))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + ax0_ax1_ax2_ax3_fused % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 1})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + co_3 * T.int64(4) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(32), T.int64(8)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 2, 8, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 1, 8, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
2024-04-29 11:32:42 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(64), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(512)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(8192)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(2048) // T.int64(1024))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + ax0_ax1_ax2_ax3_fused % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 1})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + co_3 * T.int64(4) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(8) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(32), T.int64(8)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 2, 8, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 1, 8, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
2024-04-29 11:32:42 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 16})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(8), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(64), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(512)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(8192)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(2048) // T.int64(1024))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(8) + ax0_ax1_ax2_ax3_fused % T.int64(1024) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + ax0_ax1_ax2_ax3_fused % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 1})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + co_3 * T.int64(4) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(8) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(32), T.int64(8)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(32) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 2, 8, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 1, 8, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 8, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
2024-04-29 12:13:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 12:13:09 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 12:13:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 505 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:13:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1008 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:13:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1512 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:13:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2021 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:13:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2522 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:13:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 3025 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:14:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 3526 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:14:06 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2024-04-29 12:14:23 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:14:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:14:54 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:15:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 89 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 12:15:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9994  0.9985  0.9983  0.9980  0.9977  0.9970  0.9942  0.9939  0.9934  0.9927  0.9924  0.9919  0.9917  0.9916  0.9889  0.9884
[17 : 32]:	0.9873  0.9868  0.9848  0.9836  0.9827  0.9827  0.9826  0.9825  0.9810  0.9805  0.9802  0.9799  0.9778  0.9774  0.9764  0.9764
[33 : 48]:	0.9763  0.9761  0.9760  0.9749  0.9741  0.9728  0.9722  0.9718  0.9716  0.9702  0.9700  0.9688  0.9676  0.9675  0.9670  0.9665
[49 : 64]:	0.9659  0.9654  0.9654  0.9650  0.9647  0.9646  0.9628  0.9627  0.9622  0.9619  0.9615  0.9613  0.9608  0.9608  0.9590  0.9576
2024-04-29 12:15:10 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 12:15:10 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #1: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(64), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(128))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 8, 16, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #2: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(32)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(2048) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 2, 8, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 8, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #3: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(128), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(128))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 8, 16, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 4, 2, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #4: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), nu_3_init * T.int64(4) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(256), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4) // T.int64(2))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(64))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), nu_3 * T.int64(4) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 4])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 2, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b151)
l182, l183, l184, l185, l186, l187, l188 = sch.get_loops(block=b152)
l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l189, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l189, ann_key="pragma_unroll_explicit", ann_val=1)
l203, l204, l205, l206, l207, l208, l209 = sch.get_loops(block=b154)
l210, l211, l212, l213, l214, l215, l216, l217 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l210, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l210, ann_key="pragma_unroll_explicit", ann_val=1)
l218, l219, l220, l221 = sch.get_loops(block=b156)
b222 = sch.get_block(name="data_pack", func_name="main")
l223, l224, l225, l226, l227, l228 = sch.get_loops(block=b222)
b229 = sch.decompose_reduction(block=b222, loop=l227)
b230 = sch.get_block(name="bgemm", func_name="main")
l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244 = sch.get_loops(block=b230)
b245 = sch.decompose_reduction(block=b230, loop=l234)
b246 = sch.get_block(name="inverse", func_name="main")
l247, l248, l249, l250, l251, l252, l253, l254 = sch.get_loops(block=b246)
b255 = sch.decompose_reduction(block=b246, loop=l253)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #5: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 8, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 8, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 4, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #6: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(64))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(1024) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(8) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 8, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 8, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 4, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 256, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #7: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(8) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(32))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(8) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(8) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 4, 16, 1, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 2, 4, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180, l181 = sch.get_loops(block=b151)
l182, l183, l184, l185, l186, l187, l188 = sch.get_loops(block=b152)
l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l189, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l189, ann_key="pragma_unroll_explicit", ann_val=1)
l203, l204, l205, l206, l207, l208, l209 = sch.get_loops(block=b154)
l210, l211, l212, l213, l214, l215, l216, l217 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l210, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l210, ann_key="pragma_unroll_explicit", ann_val=1)
l218, l219, l220, l221 = sch.get_loops(block=b156)
b222 = sch.get_block(name="data_pack", func_name="main")
l223, l224, l225, l226, l227, l228 = sch.get_loops(block=b222)
b229 = sch.decompose_reduction(block=b222, loop=l227)
b230 = sch.get_block(name="bgemm", func_name="main")
l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244 = sch.get_loops(block=b230)
b245 = sch.decompose_reduction(block=b230, loop=l234)
b246 = sch.get_block(name="inverse", func_name="main")
l247, l248, l249, l250, l251, l252, l253, l254 = sch.get_loops(block=b246)
b255 = sch.decompose_reduction(block=b246, loop=l253)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #8: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(256) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(256) // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(8) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(256), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(2048) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(2048) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(2048) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(2048) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(256))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(8)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(256) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(256) // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(8) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(256) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(256) // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 128, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 8])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 512, 4], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 512], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #9: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 < T.int64(64))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(128) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(128) // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 64, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 4, 1, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 256], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #10: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(128), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(64))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(4) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[32, 2, 4, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 8, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 2, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #11: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(64), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 8, 16, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 4, 2, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #12: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(128)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(2048))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(2048) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 8, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 8, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 4, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #13: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(128), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(4) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[32, 2, 4, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 2, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b150)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b152)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b154)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #14: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + co_3_init * T.int64(8) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + co_3 * T.int64(8) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(4) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 32, 1, 8])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 2, 2, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 1, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #15: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(8) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(8) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(4) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) // T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(4) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 32, 8, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 4, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 1, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 128], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #16: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(64), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(256), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(512))
                                        v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 16, 4, 8, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137 = sch.split(loop=l135, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #17: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(512), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(16)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(4))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(128))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(4))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(32) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[128, 1, 4, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[4, 1, 2, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[16, 16, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #18: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(128), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(64) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(128))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(64) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(64) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(64) // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused % T.int64(32) // T.int64(4) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 8, 16, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 4, 2, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #19: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(32))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(1), T.int64(4), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 1, 2, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 16, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 4, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143 = sch.split(loop=l141, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183 = sch.get_loops(block=b149)
l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l184, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l184, ann_key="pragma_unroll_explicit", ann_val=1)
l198, l199, l200, l201, l202, l203, l204 = sch.get_loops(block=b151)
l205, l206, l207, l208, l209, l210, l211, l212 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l205, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l205, ann_key="pragma_unroll_explicit", ann_val=1)
l213, l214, l215, l216 = sch.get_loops(block=b153)
b217 = sch.get_block(name="data_pack", func_name="main")
l218, l219, l220, l221, l222, l223 = sch.get_loops(block=b217)
b224 = sch.decompose_reduction(block=b217, loop=l222)
b225 = sch.get_block(name="bgemm", func_name="main")
l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239 = sch.get_loops(block=b225)
b240 = sch.decompose_reduction(block=b225, loop=l229)
b241 = sch.get_block(name="inverse", func_name="main")
l242, l243, l244, l245, l246, l247, l248, l249 = sch.get_loops(block=b241)
b250 = sch.decompose_reduction(block=b241, loop=l248)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #20: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(8))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8) // T.int64(4))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4) // T.int64(2))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(256))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 64, 2, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 2, 1, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #21: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(16) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(32)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(128))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(16) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(4) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(2) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 8, 4, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 2, 2, 4, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 8, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #22: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4) // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 4, 32, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 1, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #23: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(16) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(512), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(16)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(4))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(128))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(4))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(32) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 1, 4, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[128, 1, 4, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[4, 1, 2, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[16, 16, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #24: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(128), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(128))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(4) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(2) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(8) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[32, 2, 4, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 8, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 2, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #25: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(8) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(64))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(8) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(4) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(4) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(4) * T.int64(128) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 8, 4, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 4, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #26: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(16) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(64))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(256)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(4096))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(4096) // T.int64(2048))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(2048) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(16) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(4) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 4, 8, 4, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 4, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #27: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(2), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + nu_3_init * T.int64(2) + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(32)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(2), T.int64(2), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + nu_3 * T.int64(2) + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(2), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 1, 1, 2])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 16, 1, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 4, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #28: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) * T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) * T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(8) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) * T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) * T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(8) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(2), T.int64(4), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(32) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(2) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(512) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 1, 16, 4, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 8])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144 = sch.split(loop=l142, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #29: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(512), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4) // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused)
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(8) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 4, 16, 2, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 1, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
l119 = sch.fuse(l90, preserve_unit_iters=True)
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l119, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b97)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b108)
l144, l145 = sch.split(loop=l143, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #30: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(4))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(4) // T.int64(2))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(512))
                                        v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 64, 2, 4])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 2, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #31: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + p_3_init * T.int64(2) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(256))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(64))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(2) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(8) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(2) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 2, 16, 1, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 1, 4, 1, 2])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[64, 1, 8])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 256, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 256, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #32: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(8), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(8) + co_3_init * T.int64(8) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(128) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(64))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(64))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(8) + co_3 * T.int64(8) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(4) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) // T.int64(2) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[8, 2, 4, 1, 8])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 2, 4, 1, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[128, 1, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #33: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/mnt/home/gverma/ceph/opt/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  5: _ZN3tvm7runtime13PackedFun
  4: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  3: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  2: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  0: _ZN3tvm7runtime6deta
  File "/mnt/home/gverma/ceph/opt/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) * T.int64(2) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(32)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(2), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(4)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(64) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(64) // T.int64(4) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(4) * T.int64(4) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[16, 1, 16, 1, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 4])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[32, 4, 4])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 2], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #34: Error in running:
LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(8)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(8) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(64))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(256))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(8)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(8) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(8) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(8) // T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_2_nu_2_co_2_p_2_fused // T.int64(2) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 64, 2, 2])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[1, 1, 2, 1, 8])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b108)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #35: GFLOPs: 1393.1574. Time: 102.0217 us. Best GFLOPs: 1393.1574
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #36: GFLOPs: 3801.2391. Time: 37.3910 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #37: GFLOPs: 835.9530. Time: 170.0242 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #38: GFLOPs: 725.1373. Time: 196.0073 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #39: GFLOPs: 1566.3431. Time: 90.7414 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #40: GFLOPs: 514.6378. Time: 276.1791 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #41: GFLOPs: 1018.5940. Time: 139.5377 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #42: GFLOPs: 836.9447. Time: 169.8227 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #43: GFLOPs: 477.1859. Time: 297.8550 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #44: GFLOPs: 551.7134. Time: 257.6197 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #45: GFLOPs: 1009.8893. Time: 140.7404 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #46: GFLOPs: 2219.9483. Time: 64.0250 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #47: GFLOPs: 997.6105. Time: 142.4727 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #48: GFLOPs: 797.5999. Time: 178.1999 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #49: GFLOPs: 2084.2875. Time: 68.1922 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #50: GFLOPs: 851.5344. Time: 166.9131 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #51: GFLOPs: 36.7646. Time: 3866.0041 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #52: GFLOPs: 632.7560. Time: 224.6241 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #53: GFLOPs: 99.2246. Time: 1432.4297 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #54: GFLOPs: 438.9759. Time: 323.7814 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #55: GFLOPs: 11.6091. Time: 12243.1717 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:121] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #56: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(2), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(128), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init * T.int64(4) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(512)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0)
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(32) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0)
                                        v3 = T.axis.spatial(T.int64(512), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 * T.int64(4) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(1), T.int64(2), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_relu", func_name="main")
b6 = sch.get_block(name="root", func_name="main")
b7, b8 = sch.get_producers(block=b2)
sch.compute_inline(block=b8)
b9, = sch.get_consumers(block=b2)
l10, l11, l12, l13 = sch.get_loops(block=b9)
l14, l15 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
l16, l17 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l14, l16, l15, l17)
sch.compute_at(block=b2, loop=l16, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l18, l19, l20, l21, l22, l23, l24, l25, l26, l27 = sch.get_loops(block=b2)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
b28, b29 = sch.get_producers(block=b0)
sch.compute_inline(block=b29)
b30, = sch.get_producers(block=b28)
l31, l32, l33, l34, l35, l36 = sch.get_loops(block=b0)
sch.reorder(l33, l34, l31, l32, l35, l36)
sch.unroll(loop=l31)
sch.unroll(loop=l32)
sch.unroll(loop=l35)
sch.unroll(loop=l36)
l37 = sch.fuse(l33, l34, preserve_unit_iters=True)
v38 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l39, l40 = sch.split(loop=l37, factors=[None, v38], preserve_unit_iters=True)
sch.bind(loop=l39, thread_axis="blockIdx.x")
sch.bind(loop=l40, thread_axis="threadIdx.x")
b41 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b41, loop=l40, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b28, loop=l40, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b28, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b30)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l42, l43, l44, l45, l46 = sch.get_loops(block=b1)
v47, v48, v49, v50, v51 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 4])
l52, l53, l54, l55, l56 = sch.split(loop=l42, factors=[v47, v48, v49, v50, v51], preserve_unit_iters=True)
v57, v58, v59, v60, v61 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l62, l63, l64, l65, l66 = sch.split(loop=l43, factors=[v57, v58, v59, v60, v61], preserve_unit_iters=True)
v67, v68, v69, v70, v71 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 64, 4, 2, 1])
l72, l73, l74, l75, l76 = sch.split(loop=l44, factors=[v67, v68, v69, v70, v71], preserve_unit_iters=True)
v77, v78, v79, v80, v81 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[2, 2, 2, 2, 1])
l82, l83, l84, l85, l86 = sch.split(loop=l45, factors=[v77, v78, v79, v80, v81], preserve_unit_iters=True)
v87, v88, v89 = sch.sample_perfect_tile(loop=l46, n=3, max_innermost_factor=64, decision=[512, 1, 1])
l90, l91, l92 = sch.split(loop=l46, factors=[v87, v88, v89], preserve_unit_iters=True)
sch.reorder(l52, l62, l72, l82, l53, l63, l73, l83, l54, l64, l74, l84, l90, l91, l55, l65, l75, l85, l92, l56, l66, l76, l86)
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="blockIdx.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="vthread.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b96 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b96, loop=l95, preserve_unit_loops=True, index=-1)
b97 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b97, loop=l90, preserve_unit_loops=True, index=-1)
l98, l99, l100, l101, l102, l103, l104, l105 = sch.get_loops(block=b97)
l106 = sch.fuse(l102, l103, l104, l105, preserve_unit_iters=True)
v107 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch", ann_val=v107)
b108 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b108, loop=l90, preserve_unit_loops=True, index=-1)
l109, l110, l111, l112, l113, l114, l115, l116 = sch.get_loops(block=b108)
l117 = sch.fuse(l113, l114, l115, l116, preserve_unit_iters=True)
v118 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch", ann_val=v118)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b6, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b97, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b97)
l135, l136 = sch.split(loop=l134, factors=[None, 32], preserve_unit_iters=True)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b108, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b108)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b149)
l179, l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b150)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b152)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b154)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #57: GFLOPs: 1040.6093. Time: 136.5856 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #58: GFLOPs: 540.5724. Time: 262.9291 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #59: GFLOPs: 1100.7210. Time: 129.1265 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #60: GFLOPs: 539.9857. Time: 263.2148 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #61: GFLOPs: 961.0954. Time: 147.8857 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #62: GFLOPs: 2859.9455. Time: 49.6975 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #63: GFLOPs: 200.2880. Time: 709.6393 us. Best GFLOPs: 3801.2391
2024-04-29 12:21:02 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #64: GFLOPs: 195.7061. Time: 726.2534 us. Best GFLOPs: 3801.2391
2024-04-29 13:35:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 13:35:49 [INFO] [evolutionary_search.cc:715] Picked top 29 candidate(s) from database
2024-04-29 13:35:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 474 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 950 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1425 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1898 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2371 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2846 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:36:35 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2024-04-29 13:36:53 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:37:12 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:37:32 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:37:51 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 79 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 13:37:56 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.9087  1.7497  1.7385  1.7372  1.7137  1.7086  1.6951  1.6842  1.6779  1.6514  1.6407  1.6340  1.6311  1.6248  1.6240  1.6117
[17 : 32]:	1.6017  1.5863  1.5810  1.5796  1.5775  1.5742  1.5722  1.5668  1.5568  1.5548  1.5537  1.5468  1.5371  1.5321  1.5308  1.5307
[33 : 48]:	1.5214  1.5203  1.5185  1.5183  1.5115  1.5089  1.5061  1.4965  1.4948  1.4880  1.4848  1.4838  1.4742  1.4725  1.4711  1.4705
[49 : 64]:	1.4684  1.4650  1.4648  1.4640  1.4619  1.4616  1.4590  1.4549  1.4549  1.4490  1.4342  1.4298  1.4262  1.4153  1.4036  1.3963
2024-04-29 13:37:57 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 13:37:57 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #65: GFLOPs: 2635.2795. Time: 53.9344 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #66: GFLOPs: 2458.7637. Time: 57.8064 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #67: GFLOPs: 3049.9933. Time: 46.6008 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #68: GFLOPs: 2538.9598. Time: 55.9805 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #69: GFLOPs: 2524.3456. Time: 56.3046 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #70: GFLOPs: 2587.1805. Time: 54.9371 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #71: GFLOPs: 2497.0393. Time: 56.9203 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #72: GFLOPs: 2638.0146. Time: 53.8785 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #73: GFLOPs: 1881.9198. Time: 75.5251 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #74: GFLOPs: 2578.4837. Time: 55.1224 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #75: GFLOPs: 2488.5990. Time: 57.1133 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #76: GFLOPs: 2487.8548. Time: 57.1304 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #77: GFLOPs: 2552.9947. Time: 55.6727 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #78: GFLOPs: 1498.9462. Time: 94.8214 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #79: GFLOPs: 2500.7157. Time: 56.8366 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #80: GFLOPs: 3193.3126. Time: 44.5093 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #81: GFLOPs: 1432.6190. Time: 99.2115 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #82: GFLOPs: 3255.4369. Time: 43.6600 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #83: GFLOPs: 2839.3352. Time: 50.0583 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #84: GFLOPs: 2563.7787. Time: 55.4386 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #85: GFLOPs: 3254.5707. Time: 43.6716 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #86: GFLOPs: 3168.6355. Time: 44.8560 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #87: GFLOPs: 646.8324. Time: 219.7358 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #88: GFLOPs: 2453.1624. Time: 57.9384 us. Best GFLOPs: 3801.2391
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #89: GFLOPs: 3885.0415. Time: 36.5845 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #90: GFLOPs: 2552.2057. Time: 55.6900 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #91: GFLOPs: 3375.9472. Time: 42.1014 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #92: GFLOPs: 2635.3818. Time: 53.9323 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #93: GFLOPs: 3455.4421. Time: 41.1329 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #94: GFLOPs: 3016.7208. Time: 47.1148 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #95: GFLOPs: 2497.3854. Time: 56.9124 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #96: GFLOPs: 2622.0183. Time: 54.2072 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #97: GFLOPs: 2325.9713. Time: 61.1066 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #98: GFLOPs: 2725.6142. Time: 52.1469 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #99: GFLOPs: 3434.9803. Time: 41.3779 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #100: GFLOPs: 1326.7144. Time: 107.1310 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #101: GFLOPs: 2550.4064. Time: 55.7292 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #102: GFLOPs: 3276.2878. Time: 43.3821 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #103: GFLOPs: 3216.7687. Time: 44.1848 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #104: GFLOPs: 2632.9243. Time: 53.9826 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #105: GFLOPs: 3102.5626. Time: 45.8112 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #106: GFLOPs: 1475.3990. Time: 96.3348 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #107: GFLOPs: 2636.9653. Time: 53.8999 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #108: GFLOPs: 3156.4589. Time: 45.0290 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #109: GFLOPs: 1350.7958. Time: 105.2211 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #110: GFLOPs: 1713.9689. Time: 82.9258 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #111: GFLOPs: 1455.7133. Time: 97.6375 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #112: GFLOPs: 3170.0184. Time: 44.8364 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #113: GFLOPs: 1631.7810. Time: 87.1025 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #114: GFLOPs: 1017.1703. Time: 139.7330 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #115: GFLOPs: 511.9110. Time: 277.6503 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #116: GFLOPs: 2441.5968. Time: 58.2128 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #117: GFLOPs: 1195.7828. Time: 118.8612 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #118: GFLOPs: 3061.9892. Time: 46.4183 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #119: GFLOPs: 1639.5240. Time: 86.6912 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #120: GFLOPs: 3042.6905. Time: 46.7127 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #121: GFLOPs: 745.4185. Time: 190.6744 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #122: GFLOPs: 505.0139. Time: 281.4422 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #123: GFLOPs: 736.6336. Time: 192.9483 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #124: GFLOPs: 3365.4401. Time: 42.2329 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #125: GFLOPs: 2630.5061. Time: 54.0323 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #126: GFLOPs: 759.6444. Time: 187.1036 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #127: GFLOPs: 3220.9740. Time: 44.1271 us. Best GFLOPs: 3885.0415
2024-04-29 13:39:10 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #128: GFLOPs: 668.5906. Time: 212.5848 us. Best GFLOPs: 3885.0415
2024-04-29 14:49:24 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 14:49:27 [INFO] [evolutionary_search.cc:715] Picked top 93 candidate(s) from database
2024-04-29 14:49:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 411 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:49:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 823 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:49:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1239 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:49:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1649 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:50:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2057 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:50:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2469 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:50:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2880 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:50:14 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2024-04-29 14:50:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 87 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:50:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 78 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:51:09 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:51:29 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 75 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 14:51:34 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	2.1918  2.1562  2.0764  2.0647  1.9948  1.9766  1.9654  1.9212  1.8901  1.8801  1.8742  1.8706  1.8664  1.8585  1.8579  1.8494
[17 : 32]:	1.8483  1.8436  1.8416  1.8298  1.8104  1.8094  1.8029  1.8002  1.7925  1.7738  1.7449  1.7373  1.7281  1.7244  1.7172  1.7158
[33 : 48]:	1.7147  1.7004  1.6690  1.6667  1.6621  1.6593  1.6526  1.6464  1.6415  1.6287  1.6214  1.6006  1.5887  1.5785  1.5776  1.5619
[49 : 64]:	1.5511  1.5477  1.5367  1.5291  1.5253  1.5225  1.5210  1.5117  1.4993  1.4879  1.4861  1.4850  1.4850  1.4796  1.4785  1.4776
2024-04-29 14:51:35 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 14:51:35 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #129: GFLOPs: 1038.2010. Time: 136.9024 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #130: GFLOPs: 1205.9454. Time: 117.8596 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #131: GFLOPs: 1003.0370. Time: 141.7019 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #132: GFLOPs: 1040.7831. Time: 136.5628 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #133: GFLOPs: 1462.9374. Time: 97.1554 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #134: GFLOPs: 1900.5019. Time: 74.7867 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #135: GFLOPs: 1202.3895. Time: 118.2081 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #136: GFLOPs: 1201.5516. Time: 118.2906 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #137: GFLOPs: 2128.5605. Time: 66.7739 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #138: GFLOPs: 1902.2826. Time: 74.7167 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #139: GFLOPs: 1865.0669. Time: 76.2076 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #140: GFLOPs: 1899.8773. Time: 74.8113 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #141: GFLOPs: 1114.3527. Time: 127.5469 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #142: GFLOPs: 1014.5070. Time: 140.0998 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #143: GFLOPs: 1901.7635. Time: 74.7371 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #144: GFLOPs: 2315.2967. Time: 61.3883 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #145: GFLOPs: 1892.5010. Time: 75.1029 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #146: GFLOPs: 1884.2944. Time: 75.4299 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #147: GFLOPs: 2149.7677. Time: 66.1152 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #148: GFLOPs: 1868.3976. Time: 76.0717 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #149: GFLOPs: 758.2379. Time: 187.4507 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #150: GFLOPs: 1390.1500. Time: 102.2424 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #151: GFLOPs: 2119.4765. Time: 67.0601 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #152: GFLOPs: 2248.1325. Time: 63.2224 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #153: GFLOPs: 2710.3784. Time: 52.4400 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #154: GFLOPs: 783.7816. Time: 181.3416 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #155: GFLOPs: 2709.3559. Time: 52.4598 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #156: GFLOPs: 761.9192. Time: 186.5450 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #157: GFLOPs: 761.9954. Time: 186.5264 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #158: GFLOPs: 1885.7350. Time: 75.3723 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #159: GFLOPs: 2312.3271. Time: 61.4672 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #160: GFLOPs: 2715.1840. Time: 52.3472 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #161: GFLOPs: 778.2276. Time: 182.6358 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #162: GFLOPs: 786.1772. Time: 180.7890 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #163: GFLOPs: 1814.3513. Time: 78.3378 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #164: GFLOPs: 1840.4721. Time: 77.2260 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #165: GFLOPs: 1003.0489. Time: 141.7002 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #166: GFLOPs: 1845.5826. Time: 77.0121 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #167: GFLOPs: 2718.8521. Time: 52.2766 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #168: GFLOPs: 1713.4054. Time: 82.9531 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #169: GFLOPs: 706.4698. Time: 201.1866 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #170: GFLOPs: 1135.6818. Time: 125.1514 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #171: GFLOPs: 1143.3770. Time: 124.3092 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #172: GFLOPs: 1091.1903. Time: 130.2543 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #173: GFLOPs: 2316.7863. Time: 61.3489 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #174: GFLOPs: 615.6959. Time: 230.8481 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #175: GFLOPs: 1635.9803. Time: 86.8789 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #176: GFLOPs: 802.6965. Time: 177.0685 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #177: GFLOPs: 113.5410. Time: 1251.8144 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #178: GFLOPs: 819.8842. Time: 173.3565 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #179: GFLOPs: 113.5224. Time: 1252.0192 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #180: GFLOPs: 629.9698. Time: 225.6175 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #181: GFLOPs: 1027.4601. Time: 138.3336 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #182: GFLOPs: 130.7258. Time: 1087.2542 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #183: GFLOPs: 664.2673. Time: 213.9684 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #184: GFLOPs: 1028.6744. Time: 138.1703 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #185: GFLOPs: 682.8219. Time: 208.1542 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #186: GFLOPs: 2685.4131. Time: 52.9275 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #187: GFLOPs: 1181.7092. Time: 120.2768 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #188: GFLOPs: 826.5498. Time: 171.9585 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #189: GFLOPs: 832.9314. Time: 170.6410 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #190: GFLOPs: 2197.7807. Time: 64.6708 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #191: GFLOPs: 1194.2282. Time: 119.0160 us. Best GFLOPs: 3885.0415
2024-04-29 14:52:50 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #192: GFLOPs: 546.7388. Time: 259.9637 us. Best GFLOPs: 3885.0415
2024-04-29 16:02:40 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 16:02:43 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 16:02:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:02:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 805 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1210 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 1607 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2011 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 2408 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:22 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2024-04-29 16:03:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:03:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 65 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:04:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 72 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:04:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x14966c48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0xca0e368)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0xca0e268)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x161b9508)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x1318beb8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0xcac1ab8)]: 82 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0xcb63218)]: 0 failure(s)
2024-04-29 16:04:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.2656  1.2291  1.2181  1.2161  1.1967  1.1840  1.1781  1.1520  1.1181  1.0946  1.0873  1.0871  1.0692  1.0657  1.0626  1.0621
[17 : 32]:	1.0579  1.0535  1.0474  1.0451  1.0447  1.0422  1.0392  1.0391  1.0321  1.0312  1.0255  1.0199  1.0198  1.0190  1.0041  1.0014
[33 : 48]:	0.9956  0.9927  0.9925  0.9924  0.9906  0.9881  0.9832  0.9777  0.9773  0.9765  0.9756  0.9728  0.9706  0.9692  0.9692  0.9649
[49 : 64]:	0.9604  0.9604  0.9602  0.9593  0.9584  0.9547  0.9506  0.9501  0.9500  0.9495  0.9484  0.9465  0.9441  0.9431  0.9397  0.9383
2024-04-29 16:04:43 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 16:04:43 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #193: GFLOPs: 2501.0339. Time: 56.8294 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #194: GFLOPs: 1172.5449. Time: 121.2169 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #195: GFLOPs: 1725.0757. Time: 82.3919 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #196: GFLOPs: 699.6187. Time: 203.1567 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #197: GFLOPs: 3267.0938. Time: 43.5042 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #198: GFLOPs: 3237.2175. Time: 43.9057 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #199: GFLOPs: 3201.5039. Time: 44.3955 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #200: GFLOPs: 1094.3252. Time: 129.8812 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #201: GFLOPs: 3522.3712. Time: 40.3513 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #202: GFLOPs: 3169.1704. Time: 44.8484 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #203: GFLOPs: 1757.2574. Time: 80.8830 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #204: GFLOPs: 1506.0876. Time: 94.3718 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #205: GFLOPs: 1113.2533. Time: 127.6728 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #206: GFLOPs: 3149.8040. Time: 45.1241 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #207: GFLOPs: 3233.5840. Time: 43.9550 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #208: GFLOPs: 1096.4529. Time: 129.6291 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #209: GFLOPs: 1167.5334. Time: 121.7372 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #210: GFLOPs: 1221.1985. Time: 116.3875 us. Best GFLOPs: 3885.0415
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #211: GFLOPs: 4265.3223. Time: 33.3227 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #212: GFLOPs: 1096.7260. Time: 129.5968 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #213: GFLOPs: 2611.7278. Time: 54.4208 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #214: GFLOPs: 2439.7448. Time: 58.2570 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #215: GFLOPs: 4039.0570. Time: 35.1895 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #216: GFLOPs: 1286.0409. Time: 110.5192 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #217: GFLOPs: 2486.1940. Time: 57.1686 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #218: GFLOPs: 4040.0652. Time: 35.1807 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #219: GFLOPs: 4033.2298. Time: 35.2403 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #220: GFLOPs: 3002.4042. Time: 47.3395 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #221: GFLOPs: 2175.7299. Time: 65.3262 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #222: GFLOPs: 3437.1415. Time: 41.3519 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #223: GFLOPs: 3450.1482. Time: 41.1960 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #224: GFLOPs: 2873.6257. Time: 49.4609 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #225: GFLOPs: 1221.4879. Time: 116.3599 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #226: GFLOPs: 978.2324. Time: 145.2949 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #227: GFLOPs: 1274.3664. Time: 111.5317 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #228: GFLOPs: 2809.0667. Time: 50.5977 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #229: GFLOPs: 2645.7800. Time: 53.7203 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #230: GFLOPs: 3417.3499. Time: 41.5914 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #231: GFLOPs: 2838.1154. Time: 50.0798 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #232: GFLOPs: 3429.5524. Time: 41.4434 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #233: GFLOPs: 3045.4747. Time: 46.6700 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #234: GFLOPs: 3245.9664. Time: 43.7873 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #235: GFLOPs: 3204.3033. Time: 44.3567 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #236: GFLOPs: 2412.0535. Time: 58.9258 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #237: GFLOPs: 3204.2618. Time: 44.3572 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #238: GFLOPs: 1887.0780. Time: 75.3187 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #239: GFLOPs: 1946.5699. Time: 73.0168 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #240: GFLOPs: 3016.2975. Time: 47.1214 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #241: GFLOPs: 3744.7733. Time: 37.9548 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #242: GFLOPs: 3804.5190. Time: 37.3588 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #243: GFLOPs: 3792.7723. Time: 37.4745 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #244: GFLOPs: 1597.5898. Time: 88.9667 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #245: GFLOPs: 3384.5128. Time: 41.9949 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #246: GFLOPs: 4045.7162. Time: 35.1315 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #247: GFLOPs: 3393.7492. Time: 41.8806 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #248: GFLOPs: 3909.1974. Time: 36.3584 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #249: GFLOPs: 3816.0383. Time: 37.2460 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #250: GFLOPs: 2130.2976. Time: 66.7194 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #251: GFLOPs: 3702.4832. Time: 38.3884 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #252: GFLOPs: 723.3226. Time: 196.4991 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #253: GFLOPs: 2969.8532. Time: 47.8583 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #254: GFLOPs: 690.4686. Time: 205.8489 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #255: GFLOPs: 1208.0242. Time: 117.6568 us. Best GFLOPs: 4265.3223
2024-04-29 16:06:03 [INFO] [task_scheduler.cc:131] [Task #23: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_nn_relu_3] Trial #256: GFLOPs: 90.3386. Time: 1573.3280 us. Best GFLOPs: 4265.3223
