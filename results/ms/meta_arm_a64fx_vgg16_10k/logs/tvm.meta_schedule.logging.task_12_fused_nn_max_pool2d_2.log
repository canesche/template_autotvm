2024-04-29 19:45:09 [INFO] [task_scheduler.cc:160] Initializing Task #12: "fused_nn_max_pool2d_2"
2024-04-29 19:45:09 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        for ax0, ax1, ax2, ax3, ax4, rv0, rv1 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2), T.int64(2)):
            with T.block("pool_max"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, v_rv0, v_rv1 = T.axis.remap("SSSSSRR", [ax0, ax1, ax2, ax3, ax4, rv0, rv1])
                T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
                T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.block_attr({"schedule_rule": "meta_schedule.pool_max"})
                with T.init():
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
2024-04-29 19:45:09 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-29 19:45:09 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 16, "meta_schedule.vectorize": 64})
            pool_max_rf = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2)))
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2), T.int64(2)):
                with T.block("pool_max_rf"):
                    vrv0_rv1_fused_0, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1 = T.axis.remap("SSSSSSR", [rv0_rv1_fused_0, ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_1])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) // T.int64(2), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) % T.int64(2), v_ax4])
                    T.writes(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
                    with T.init():
                        pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0] = T.float32(-3.4028234663852886e+38)
                    pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0] = T.max(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) // T.int64(2), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) % T.int64(2), v_ax4])
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2)):
                with T.block("pool_max"):
                    vrv0_rv1_fused_0, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("RSSSSS", [rv0_rv1_fused_0, ax0, ax1, ax2, ax3, ax4])
                    T.reads(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.block_attr({"meta_schedule.random_compute_producer": 1})
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
l2, l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l7, l8, preserve_unit_iters=True)
v10, v11 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 2])
l12, l13 = sch.split(loop=l9, factors=[v10, v11], preserve_unit_iters=True)
b14 = sch.rfactor(loop=l12, factor_axis=5)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v15 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v15)
2024-04-29 19:45:09 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            pool_max_rf = T.alloc_buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2)))
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2), T.int64(2)):
                with T.block("pool_max_rf"):
                    vrv0_rv1_fused_1, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_0 = T.axis.remap("SSSSSSR", [rv0_rv1_fused_1, ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_0])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) // T.int64(2), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) % T.int64(2), v_ax4])
                    T.writes(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
                    with T.init():
                        pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1] = T.float32(-3.4028234663852886e+38)
                    pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1] = T.max(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) // T.int64(2), v_ax3 * T.int64(2) + (vrv0_rv1_fused_0 * T.int64(2) + vrv0_rv1_fused_1) % T.int64(2), v_ax4])
            for ax0, ax1, ax2, ax3, ax4, rv0_rv1_fused_1 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2)):
                with T.block("pool_max"):
                    vrv0_rv1_fused_1, v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("RSSSSS", [rv0_rv1_fused_1, ax0, ax1, ax2, ax3, ax4])
                    T.reads(pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.block_attr({"meta_schedule.random_compute_producer": 1})
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], pool_max_rf[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, vrv0_rv1_fused_1])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
l2, l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l7, l8, preserve_unit_iters=True)
v10, v11 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 2])
l12, l13 = sch.split(loop=l9, factors=[v10, v11], preserve_unit_iters=True)
b14 = sch.rfactor(loop=l13, factor_axis=5)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.random_compute_producer", ann_val=1)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v15 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v15)
2024-04-29 19:45:09 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(8), T.int64(56), T.int64(56), T.int64(32)), "float32"), pool_max: T.Buffer((T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            for ax0, ax1, ax2, ax3, ax4, rv0, rv1 in T.grid(T.int64(1), T.int64(8), T.int64(28), T.int64(28), T.int64(32), T.int64(2), T.int64(2)):
                with T.block("pool_max"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4, v_rv0, v_rv1 = T.axis.remap("SSSSSRR", [ax0, ax1, ax2, ax3, ax4, rv0, rv1])
                    T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
                    T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    with T.init():
                        pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.float32(-3.4028234663852886e+38)
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1, v_ax4])
b0 = sch.get_block(name="pool_max", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b0, ann_key="schedule_rule")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.vectorize", ann_val=64)
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
2024-04-29 20:13:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 20:13:59 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-29 20:13:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x37a7f18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3abe418)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x37472b8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x368b908)]: 0 failure(s)
2024-04-29 20:13:59 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-29 20:14:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x37a7f18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3abe418)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x37472b8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x368b908)]: 0 failure(s)
2024-04-29 20:14:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x37a7f18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3abe418)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x37472b8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x368b908)]: 0 failure(s)
2024-04-29 20:14:03 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x37a7f18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3abe418)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x37472b8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x368b908)]: 0 failure(s)
2024-04-29 20:14:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x37a7f18)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3abe418)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x37472b8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x368b908)]: 0 failure(s)
2024-04-29 20:14:05 [INFO] [evolutionary_search.cc:649] Scores of the best 63 candidates:
[1 : 16]:	0.9969  0.9729  0.9722  0.9682  0.9594  0.9497  0.9429  0.9143  0.8816  0.8763  0.8574  0.8486  0.8382  0.8331  0.8228  0.8100
[17 : 32]:	0.8026  0.7643  0.7612  0.7564  0.7452  0.7434  0.7332  0.7279  0.6819  0.6775  0.6537  0.6504  0.6451  0.6424  0.6264  0.5771
[33 : 48]:	0.5558  0.5441  0.5421  0.5306  0.5040  0.4419  0.4340  0.3999  0.3874  0.3727  0.3678  0.3457  0.3276  0.3241  0.3153  0.3152
[49 : 63]:	0.3142  0.2628  0.2090  0.1809  0.1379  0.1317  0.1285  0.1254  0.1128  0.1117  0.0897  0.0580  0.0518  0.0196  0.0065
2024-04-29 20:14:05 [INFO] [evolutionary_search.cc:727] Got 63 candidate(s) with evolutionary search
2024-04-29 20:14:05 [INFO] [evolutionary_search.cc:730] Sending 61 candidates(s) for measurement
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #1: GFLOPs: 23.2905. Time: 34.4697 us. Best GFLOPs: 23.2905
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #2: GFLOPs: 4.7671. Time: 168.4073 us. Best GFLOPs: 23.2905
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #3: GFLOPs: 17.2097. Time: 46.6492 us. Best GFLOPs: 23.2905
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #4: GFLOPs: 11.0416. Time: 72.7086 us. Best GFLOPs: 23.2905
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #5: GFLOPs: 52.2362. Time: 15.3690 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #6: GFLOPs: 26.8361. Time: 29.9156 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #7: GFLOPs: 13.6006. Time: 59.0280 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #8: GFLOPs: 1.7876. Time: 449.1139 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #9: GFLOPs: 11.1561. Time: 71.9622 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #10: GFLOPs: 13.4141. Time: 59.8486 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #11: GFLOPs: 16.5201. Time: 48.5962 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #12: GFLOPs: 26.3596. Time: 30.4563 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #13: GFLOPs: 16.8377. Time: 47.6798 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #14: GFLOPs: 51.6452. Time: 15.5448 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #15: GFLOPs: 23.3092. Time: 34.4420 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #16: GFLOPs: 26.1906. Time: 30.6528 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #17: GFLOPs: 16.4880. Time: 48.6909 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #18: GFLOPs: 13.8673. Time: 57.8929 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #19: GFLOPs: 14.3851. Time: 55.8090 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #20: GFLOPs: 21.4253. Time: 37.4705 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #21: GFLOPs: 26.6253. Time: 30.1524 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #22: GFLOPs: 8.7216. Time: 92.0491 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #23: GFLOPs: 15.5656. Time: 51.5762 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #24: GFLOPs: 9.9022. Time: 81.0748 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #25: GFLOPs: 10.1408. Time: 79.1671 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #26: GFLOPs: 26.3081. Time: 30.5159 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #27: GFLOPs: 9.5628. Time: 83.9519 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #28: GFLOPs: 26.4012. Time: 30.4084 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #29: GFLOPs: 3.2207. Time: 249.2651 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #30: GFLOPs: 13.3770. Time: 60.0146 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #31: GFLOPs: 8.7119. Time: 92.1518 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #32: GFLOPs: 15.4817. Time: 51.8560 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #33: GFLOPs: 13.8561. Time: 57.9395 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #34: GFLOPs: 25.6134. Time: 31.3436 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #35: GFLOPs: 21.3050. Time: 37.6820 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #36: GFLOPs: 23.7388. Time: 33.8188 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #37: GFLOPs: 15.5969. Time: 51.4727 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #38: GFLOPs: 3.9263. Time: 204.4722 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #39: GFLOPs: 21.2341. Time: 37.8078 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #40: GFLOPs: 0.8535. Time: 940.6063 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #41: GFLOPs: 2.1175. Time: 379.1406 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #42: GFLOPs: 28.0747. Time: 28.5957 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #43: GFLOPs: 7.6827. Time: 104.4965 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #44: GFLOPs: 17.1658. Time: 46.7684 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #45: GFLOPs: 17.4126. Time: 46.1056 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #46: GFLOPs: 25.1907. Time: 31.8695 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #47: GFLOPs: 51.3523. Time: 15.6335 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #48: GFLOPs: 18.3065. Time: 43.8541 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #49: GFLOPs: 23.8986. Time: 33.5927 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #50: GFLOPs: 9.9809. Time: 80.4352 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #51: GFLOPs: 20.6308. Time: 38.9135 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #52: GFLOPs: 14.0093. Time: 57.3061 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #53: GFLOPs: 17.0945. Time: 46.9634 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #54: GFLOPs: 26.2626. Time: 30.5689 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #55: GFLOPs: 8.1032. Time: 99.0735 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #56: GFLOPs: 4.3906. Time: 182.8482 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #57: GFLOPs: 5.8782. Time: 136.5761 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #58: GFLOPs: 5.9851. Time: 134.1350 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #59: GFLOPs: 26.5682. Time: 30.2172 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #60: GFLOPs: 17.4744. Time: 45.9423 us. Best GFLOPs: 52.2362
2024-04-29 20:59:44 [INFO] [task_scheduler.cc:131] [Task #12: fused_nn_max_pool2d_2] Trial #61: GFLOPs: 25.3952. Time: 31.6129 us. Best GFLOPs: 52.2362
