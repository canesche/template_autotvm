2024-04-28 20:34:49 [INFO] [task_scheduler.cc:160] Initializing Task #8: "fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1"
2024-04-28 20:34:49 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32), T.int64(64), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-28 20:34:50 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 20:34:50 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(58), T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(28) + oh_1 * T.int64(14) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(2), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(32)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
2024-04-28 20:34:50 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 512, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(58), T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), oh_0 * T.int64(28) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(2), T.int64(1)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(32)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(28), T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), oc_chunk_1 + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_1 * T.int64(28) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 20:34:50 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 64, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
            for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(8), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(28), T.int64(32)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_0 * T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(56) + ow_1 * T.int64(28) + ow_2 * T.int64(28) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(32) + oc_block_1 * T.int64(32) + oc_block_2 * T.int64(32) + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(56), T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 28])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 1, 32])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 20:45:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 20:45:06 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 20:45:12 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 20:45:12 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 20:45:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 20:45:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 20:45:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 20:45:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 20:45:37 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9983  0.9978  0.9975  0.9974  0.9973  0.9973  0.9964  0.9962  0.9960  0.9943  0.9937  0.9935  0.9931  0.9928  0.9928  0.9927
[17 : 32]:	0.9925  0.9920  0.9920  0.9913  0.9912  0.9910  0.9895  0.9891  0.9890  0.9877  0.9869  0.9858  0.9854  0.9853  0.9852  0.9851
[33 : 48]:	0.9850  0.9830  0.9826  0.9824  0.9819  0.9815  0.9813  0.9812  0.9811  0.9800  0.9798  0.9789  0.9777  0.9774  0.9772  0.9771
[49 : 64]:	0.9764  0.9758  0.9756  0.9752  0.9751  0.9748  0.9745  0.9745  0.9734  0.9733  0.9727  0.9721  0.9710  0.9703  0.9698  0.9697
2024-04-28 20:45:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 20:45:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #1: GFLOPs: 4.7927. Time: 48326.3230 us. Best GFLOPs: 4.7927
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #2: GFLOPs: 46.0826. Time: 5026.0284 us. Best GFLOPs: 46.0826
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #3: GFLOPs: 85.9225. Time: 2695.5966 us. Best GFLOPs: 85.9225
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #4: GFLOPs: 39.5595. Time: 5854.7841 us. Best GFLOPs: 85.9225
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #5: GFLOPs: 184.0018. Time: 1258.7508 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #6: GFLOPs: 78.9805. Time: 2932.5250 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #7: GFLOPs: 66.0089. Time: 3508.8049 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #8: GFLOPs: 29.9257. Time: 7739.5855 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #9: GFLOPs: 7.9598. Time: 29097.7185 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #10: GFLOPs: 34.6951. Time: 6675.6487 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #11: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(8), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(14) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(8) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(14) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(8) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(57) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(57), p0[v_n, v_ic // T.int64(64), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(64)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused // T.int64(14) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(14) // T.int64(2) * T.int64(8) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[7, 2, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 8, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[8, 8])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69 = sch.get_child_blocks(b67)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l70, l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97 = sch.fuse(l95, preserve_unit_iters=True)
sch.vectorize(loop=l97)
sch.annotate(block_or_loop=l96, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l96, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b105)
b128 = sch.decompose_reduction(block=b105, loop=l112)
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #12: GFLOPs: 14.1471. Time: 16371.7533 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #13: GFLOPs: 60.5738. Time: 3823.6384 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #14: GFLOPs: 33.2329. Time: 6969.3779 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #15: GFLOPs: 16.9922. Time: 13630.5159 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #16: GFLOPs: 15.0612. Time: 15378.1104 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #17: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(4)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(14) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(8), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(56), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 1, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 8, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[16, 4])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #18: GFLOPs: 14.4933. Time: 15980.6880 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #19: GFLOPs: 1.5356. Time: 150828.2363 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #20: GFLOPs: 81.0418. Time: 2857.9377 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #21: GFLOPs: 66.2675. Time: 3495.1108 us. Best GFLOPs: 184.0018
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #22: GFLOPs: 236.2540. Time: 980.3533 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #23: GFLOPs: 19.0464. Time: 12160.4137 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #24: GFLOPs: 12.8181. Time: 18069.1527 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #25: GFLOPs: 28.8238. Time: 8035.4559 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #26: GFLOPs: 1.0792. Time: 214605.0037 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #27: GFLOPs: 22.3957. Time: 10341.8171 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #28: GFLOPs: 23.5003. Time: 9855.7287 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #29: GFLOPs: 27.1412. Time: 8533.6226 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #30: GFLOPs: 43.3530. Time: 5342.4767 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #31: GFLOPs: 181.3752. Time: 1276.9793 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #32: GFLOPs: 35.0793. Time: 6602.5442 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #33: GFLOPs: 29.5709. Time: 7832.4386 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #34: GFLOPs: 131.7697. Time: 1757.7059 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #35: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(32)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(28) + oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(1), T.int64(64), T.int64(3)):
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(3), T.int64(1)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), kh_1 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(28) + oh_1 * T.int64(14) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(7) + ow_2 + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ic_1 + ax4)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                    for kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(28) + oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(32)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 1, 14])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 32, 1, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=19)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95 = sch.get_loops(block=b68)
l96 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l96)
l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b69)
l119 = sch.fuse(l97, preserve_unit_iters=True)
sch.parallel(loop=l119)
sch.annotate(block_or_loop=l119, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l119, ann_key="pragma_unroll_explicit", ann_val=1)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b70)
l126 = sch.fuse(l125, preserve_unit_iters=True)
sch.vectorize(loop=l126)
b127 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145, l146, l147, l148, l149 = sch.get_loops(block=b127)
b150 = sch.decompose_reduction(block=b127, loop=l134)
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #36: GFLOPs: 0.8496. Time: 272598.7303 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #37: GFLOPs: 157.3484. Time: 1471.9721 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #38: GFLOPs: 22.0378. Time: 10509.7968 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #39: GFLOPs: 2.4222. Time: 95621.0847 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #40: GFLOPs: 10.8741. Time: 21299.4606 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #41: GFLOPs: 29.7964. Time: 7773.1598 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #42: GFLOPs: 69.0571. Time: 3353.9267 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #43: GFLOPs: 77.1809. Time: 3000.9025 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #44: GFLOPs: 10.3748. Time: 22324.5584 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #45: GFLOPs: 2.6538. Time: 87275.0303 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #46: GFLOPs: 135.7004. Time: 1706.7928 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #47: GFLOPs: 5.1159. Time: 45272.7570 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #48: GFLOPs: 68.2081. Time: 3395.6714 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #49: GFLOPs: 16.3629. Time: 14154.7175 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #50: GFLOPs: 92.1727. Time: 2512.8097 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #51: GFLOPs: 183.7194. Time: 1260.6860 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #52: GFLOPs: 63.9232. Time: 3623.2934 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #53: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(448), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(56), ow_2_init * T.int64(4) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0 in T.grid(T.int64(1), T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(56)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), kw_0 + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(14), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(16) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_2 * T.int64(4) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(16) * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3136)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 2, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[28, 1, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 14, 4])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 4, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87 = sch.get_loops(block=b67)
l88 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l88)
l89 = sch.fuse(l87, preserve_unit_iters=True)
sch.vectorize(loop=l89)
l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b68)
l107 = sch.fuse(l90, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113 = sch.get_loops(block=b69)
l114 = sch.fuse(l109, l110, l111, l112, l113, preserve_unit_iters=True)
l115, l116 = sch.split(loop=l114, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l115)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b117)
b135 = sch.decompose_reduction(block=b117, loop=l119)
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #54: GFLOPs: 36.0771. Time: 6419.9205 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #55: GFLOPs: 7.5111. Time: 30836.1587 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #56: GFLOPs: 105.8303. Time: 2188.5263 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #57: GFLOPs: 75.8029. Time: 3055.4565 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #58: GFLOPs: 19.3680. Time: 11958.5313 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #59: GFLOPs: 166.9687. Time: 1387.1610 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #60: GFLOPs: 29.1252. Time: 7952.3099 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #61: GFLOPs: 22.8796. Time: 10123.0882 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #62: GFLOPs: 104.1407. Time: 2224.0334 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #63: GFLOPs: 7.2153. Time: 32100.1155 us. Best GFLOPs: 236.2540
2024-04-28 21:12:11 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #64: GFLOPs: 87.5298. Time: 2646.0979 us. Best GFLOPs: 236.2540
2024-04-28 21:23:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:23:11 [INFO] [evolutionary_search.cc:715] Picked top 60 candidate(s) from database
2024-04-28 21:23:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:23:15 [INFO] [evolutionary_search.cc:723] Sampled 452 candidate(s)
2024-04-28 21:23:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:23:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:23:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:24:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:24:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0953  0.9745  0.9536  0.9536  0.9250  0.9211  0.9174  0.9164  0.9141  0.9093  0.8959  0.8916  0.8896  0.8849  0.8808  0.8198
[17 : 32]:	0.8198  0.8185  0.8159  0.8152  0.8140  0.8086  0.7966  0.7966  0.7937  0.7908  0.7895  0.7861  0.7855  0.7801  0.7784  0.7784
[33 : 48]:	0.7770  0.7770  0.7770  0.7671  0.7619  0.7618  0.7618  0.7552  0.7544  0.7544  0.7525  0.7398  0.7371  0.7371  0.7321  0.7321
[49 : 64]:	0.7277  0.7257  0.7200  0.7094  0.7046  0.7005  0.6999  0.6945  0.6921  0.6920  0.6913  0.6874  0.6872  0.6856  0.6777  0.6777
2024-04-28 21:24:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:24:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #65: GFLOPs: 216.8103. Time: 1068.2724 us. Best GFLOPs: 236.2540
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #66: GFLOPs: 133.0049. Time: 1741.3819 us. Best GFLOPs: 236.2540
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #67: GFLOPs: 292.5769. Time: 791.6291 us. Best GFLOPs: 292.5769
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #68: GFLOPs: 362.1200. Time: 639.6013 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #69: GFLOPs: 183.0343. Time: 1265.4045 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #70: GFLOPs: 211.8353. Time: 1093.3610 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #71: GFLOPs: 134.2264. Time: 1725.5351 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #72: GFLOPs: 87.7854. Time: 2638.3939 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #73: GFLOPs: 23.0053. Time: 10067.7977 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #74: GFLOPs: 157.3302. Time: 1472.1422 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #75: GFLOPs: 158.9884. Time: 1456.7879 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #76: GFLOPs: 125.8077. Time: 1841.0034 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #77: GFLOPs: 322.5886. Time: 717.9808 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #78: GFLOPs: 213.0971. Time: 1086.8866 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #79: GFLOPs: 118.9551. Time: 1947.0580 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #80: GFLOPs: 177.8577. Time: 1302.2344 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #81: GFLOPs: 165.6717. Time: 1398.0201 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #82: GFLOPs: 204.9884. Time: 1129.8806 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #83: GFLOPs: 111.7335. Time: 2072.9007 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #84: GFLOPs: 188.6498. Time: 1227.7372 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #85: GFLOPs: 154.4318. Time: 1499.7720 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #86: GFLOPs: 160.4048. Time: 1443.9245 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #87: GFLOPs: 111.7042. Time: 2073.4448 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #88: GFLOPs: 69.5794. Time: 3328.7475 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #89: GFLOPs: 191.9219. Time: 1206.8055 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #90: GFLOPs: 131.9446. Time: 1755.3759 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #91: GFLOPs: 222.4933. Time: 1040.9862 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #92: GFLOPs: 257.5106. Time: 899.4286 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #93: GFLOPs: 77.1236. Time: 3003.1345 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #94: GFLOPs: 167.8092. Time: 1380.2131 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #95: GFLOPs: 121.4539. Time: 1906.9987 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #96: GFLOPs: 61.9598. Time: 3738.1062 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #97: GFLOPs: 78.8580. Time: 2937.0818 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #98: GFLOPs: 187.5885. Time: 1234.6834 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #99: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for i0_i1_i2_i3_fused in T.parallel(T.int64(3364)):
            for i4_fused in T.vectorized(T.int64(64)):
                with T.block("data_pad"):
                    v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i1 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_i2 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused // T.int64(58))
                    v_i3 = T.axis.spatial(T.int64(58), i0_i1_i2_i3_fused % T.int64(58))
                    v_i4 = T.axis.spatial(T.int64(64), i4_fused)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused in T.parallel(T.int64(1568), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(14) // T.int64(7) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused // T.int64(784) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(7) * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(784) // T.int64(14) + ow_1 + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(14) // T.int64(7) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused // T.int64(784) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(7) * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(784) // T.int64(14) + ow_1 + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(14) // T.int64(7) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused // T.int64(784) * T.int64(28) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(7) * T.int64(4) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused % T.int64(784) // T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[56, 1, 1, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 16])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[4, 16])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75 = sch.get_loops(block=b68)
l76 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l76)
l77 = sch.fuse(l75, preserve_unit_iters=True)
sch.vectorize(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l78, l79, l80, l81, l82, l83, l84, l85, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b70)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #100: GFLOPs: 87.1745. Time: 2656.8829 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #101: GFLOPs: 267.8697. Time: 864.6457 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #102: GFLOPs: 215.1656. Time: 1076.4379 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #103: GFLOPs: 214.5939. Time: 1079.3055 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #104: GFLOPs: 104.0373. Time: 2226.2436 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #105: GFLOPs: 167.2737. Time: 1384.6315 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #106: GFLOPs: 167.9704. Time: 1378.8885 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #107: GFLOPs: 195.2464. Time: 1186.2568 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #108: GFLOPs: 63.1769. Time: 3666.0940 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #109: GFLOPs: 202.7990. Time: 1142.0784 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #110: GFLOPs: 203.7239. Time: 1136.8939 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #111: GFLOPs: 160.3954. Time: 1444.0088 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #112: GFLOPs: 135.5330. Time: 1708.9003 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #113: GFLOPs: 103.1919. Time: 2244.4832 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #114: GFLOPs: 216.3651. Time: 1070.4705 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #115: GFLOPs: 107.0027. Time: 2164.5480 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #116: GFLOPs: 179.2297. Time: 1292.2655 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #117: GFLOPs: 234.9525. Time: 985.7839 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #118: GFLOPs: 357.7658. Time: 647.3856 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #119: GFLOPs: 44.0998. Time: 5252.0078 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #120: GFLOPs: 156.0341. Time: 1484.3708 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #121: GFLOPs: 192.4799. Time: 1203.3068 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #122: GFLOPs: 120.8541. Time: 1916.4637 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #123: GFLOPs: 183.6415. Time: 1261.2204 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #124: GFLOPs: 98.5193. Time: 2350.9335 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #125: GFLOPs: 127.5800. Time: 1815.4283 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #126: GFLOPs: 4.5916. Time: 50442.6563 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #127: GFLOPs: 88.2314. Time: 2625.0572 us. Best GFLOPs: 362.1200
2024-04-28 21:25:38 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #128: GFLOPs: 132.7323. Time: 1744.9586 us. Best GFLOPs: 362.1200
2024-04-28 21:44:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:44:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 21:45:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:45:00 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 21:45:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:45:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:45:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:45:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 21:45:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0157  1.0030  0.9761  0.9722  0.9706  0.9673  0.9568  0.9504  0.9145  0.8958  0.8889  0.8801  0.8798  0.8735  0.8703  0.8559
[17 : 32]:	0.8537  0.8441  0.8290  0.8140  0.8090  0.8055  0.8042  0.7967  0.7951  0.7914  0.7859  0.7845  0.7777  0.7733  0.7507  0.7489
[33 : 48]:	0.7435  0.7352  0.7330  0.7258  0.7255  0.7238  0.7206  0.7137  0.6977  0.6969  0.6959  0.6913  0.6877  0.6810  0.6803  0.6708
[49 : 64]:	0.6698  0.6640  0.6607  0.6595  0.6575  0.6507  0.6504  0.6501  0.6485  0.6447  0.6409  0.6383  0.6349  0.6349  0.6349  0.6333
2024-04-28 21:46:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:46:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #129: GFLOPs: 225.3668. Time: 1027.7132 us. Best GFLOPs: 362.1200
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #130: GFLOPs: 80.6648. Time: 2871.2956 us. Best GFLOPs: 362.1200
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #131: GFLOPs: 235.0051. Time: 985.5632 us. Best GFLOPs: 362.1200
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #132: GFLOPs: 178.4044. Time: 1298.2435 us. Best GFLOPs: 362.1200
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #133: GFLOPs: 433.4596. Time: 534.3345 us. Best GFLOPs: 433.4596
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #134: GFLOPs: 331.9069. Time: 697.8234 us. Best GFLOPs: 433.4596
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #135: GFLOPs: 393.5170. Time: 588.5703 us. Best GFLOPs: 433.4596
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #136: GFLOPs: 306.0601. Time: 756.7546 us. Best GFLOPs: 433.4596
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #137: GFLOPs: 440.6333. Time: 525.6352 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #138: GFLOPs: 357.6790. Time: 647.5427 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #139: GFLOPs: 132.4107. Time: 1749.1973 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #140: GFLOPs: 328.6314. Time: 704.7787 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #141: GFLOPs: 284.2178. Time: 814.9116 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #142: GFLOPs: 318.0709. Time: 728.1787 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #143: GFLOPs: 320.2745. Time: 723.1684 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #144: GFLOPs: 338.0743. Time: 685.0931 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #145: GFLOPs: 204.5585. Time: 1132.2554 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #146: GFLOPs: 304.7029. Time: 760.1255 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #147: GFLOPs: 318.5174. Time: 727.1577 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #148: GFLOPs: 402.0417. Time: 576.0905 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #149: GFLOPs: 287.4123. Time: 805.8542 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #150: GFLOPs: 153.6868. Time: 1507.0413 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #151: GFLOPs: 344.5401. Time: 672.2365 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #152: GFLOPs: 350.4405. Time: 660.9180 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #153: GFLOPs: 340.8234. Time: 679.5671 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #154: GFLOPs: 384.5521. Time: 602.2914 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #155: GFLOPs: 402.7737. Time: 575.0435 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #156: GFLOPs: 284.9846. Time: 812.7189 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #157: GFLOPs: 299.1847. Time: 774.1452 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #158: GFLOPs: 368.5594. Time: 628.4262 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #159: GFLOPs: 270.8371. Time: 855.1723 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #160: GFLOPs: 334.6749. Time: 692.0520 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #161: GFLOPs: 294.8464. Time: 785.5359 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #162: GFLOPs: 265.6792. Time: 871.7749 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #163: GFLOPs: 268.2672. Time: 863.3647 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #164: GFLOPs: 377.6289. Time: 613.3335 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #165: GFLOPs: 252.7458. Time: 916.3847 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #166: GFLOPs: 340.8214. Time: 679.5711 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #167: GFLOPs: 256.8979. Time: 901.5738 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #168: GFLOPs: 257.9651. Time: 897.8439 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #169: GFLOPs: 235.7184. Time: 982.5809 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #170: GFLOPs: 103.9620. Time: 2227.8565 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #171: GFLOPs: 282.7265. Time: 819.2102 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #172: GFLOPs: 321.6843. Time: 719.9991 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #173: GFLOPs: 266.1733. Time: 870.1566 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #174: GFLOPs: 177.9240. Time: 1301.7494 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #175: GFLOPs: 243.5571. Time: 950.9573 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #176: GFLOPs: 316.9586. Time: 730.7341 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #177: GFLOPs: 280.1184. Time: 826.8376 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #178: GFLOPs: 69.7475. Time: 3320.7293 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #179: GFLOPs: 253.2966. Time: 914.3922 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #180: GFLOPs: 177.7842. Time: 1302.7726 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #181: GFLOPs: 254.0561. Time: 911.6586 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #182: GFLOPs: 269.7769. Time: 858.5332 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #183: GFLOPs: 206.9848. Time: 1118.9827 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #184: GFLOPs: 177.5953. Time: 1304.1583 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #185: GFLOPs: 257.2243. Time: 900.4299 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #186: GFLOPs: 324.1684. Time: 714.4817 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #187: GFLOPs: 184.9535. Time: 1252.2738 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #188: GFLOPs: 246.6622. Time: 938.9862 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #189: GFLOPs: 206.3601. Time: 1122.3701 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #190: GFLOPs: 110.1917. Time: 2101.9036 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #191: GFLOPs: 45.4821. Time: 5092.3890 us. Best GFLOPs: 440.6333
2024-04-28 21:47:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #192: GFLOPs: 62.2740. Time: 3719.2475 us. Best GFLOPs: 440.6333
2024-04-28 22:07:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:07:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:07:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:07:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:07:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:07:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:07:54 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:08:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:08:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1136  1.0814  1.0044  0.9908  0.9895  0.9717  0.9610  0.9525  0.9285  0.9241  0.9189  0.9105  0.9088  0.9061  0.9030  0.9016
[17 : 32]:	0.9008  0.8951  0.8943  0.8940  0.8932  0.8916  0.8789  0.8783  0.8775  0.8768  0.8765  0.8676  0.8630  0.8630  0.8617  0.8609
[33 : 48]:	0.8592  0.8561  0.8420  0.8337  0.8310  0.8310  0.8246  0.8174  0.8147  0.8110  0.8103  0.8068  0.8035  0.8026  0.8026  0.8017
[49 : 64]:	0.7981  0.7973  0.7970  0.7965  0.7956  0.7948  0.7919  0.7914  0.7883  0.7875  0.7847  0.7844  0.7838  0.7836  0.7833  0.7831
2024-04-28 22:08:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:08:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #193: GFLOPs: 215.1564. Time: 1076.4840 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #194: GFLOPs: 370.9192. Time: 624.4282 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #195: GFLOPs: 388.1445. Time: 596.7170 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #196: GFLOPs: 161.4143. Time: 1434.8942 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #197: GFLOPs: 428.8808. Time: 540.0391 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #198: GFLOPs: 410.6852. Time: 563.9658 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #199: GFLOPs: 366.5246. Time: 631.9151 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #200: GFLOPs: 401.2297. Time: 577.2565 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #201: GFLOPs: 159.2005. Time: 1454.8470 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #202: GFLOPs: 220.6656. Time: 1049.6081 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #203: GFLOPs: 412.3616. Time: 561.6731 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #204: GFLOPs: 74.3257. Time: 3116.1820 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #205: GFLOPs: 388.5005. Time: 596.1701 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #206: GFLOPs: 119.8143. Time: 1933.0953 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #207: GFLOPs: 357.6966. Time: 647.5108 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #208: GFLOPs: 150.0995. Time: 1543.0590 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #209: GFLOPs: 325.9751. Time: 710.5217 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #210: GFLOPs: 90.4085. Time: 2561.8435 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #211: GFLOPs: 113.7407. Time: 2036.3188 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #212: GFLOPs: 345.0119. Time: 671.3171 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #213: GFLOPs: 75.1007. Time: 3084.0260 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #214: GFLOPs: 125.4273. Time: 1846.5866 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #215: GFLOPs: 326.9123. Time: 708.4848 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #216: GFLOPs: 391.9068. Time: 590.9885 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #217: GFLOPs: 334.6291. Time: 692.1467 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #218: GFLOPs: 115.2837. Time: 2009.0655 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #219: GFLOPs: 388.4560. Time: 596.2385 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #220: GFLOPs: 347.9183. Time: 665.7091 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #221: GFLOPs: 98.0833. Time: 2361.3859 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #222: GFLOPs: 62.1350. Time: 3727.5700 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #223: GFLOPs: 246.3432. Time: 940.2023 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #224: GFLOPs: 109.1688. Time: 2121.5994 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #225: GFLOPs: 323.5619. Time: 715.8211 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #226: GFLOPs: 392.0147. Time: 590.8258 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #227: GFLOPs: 120.9434. Time: 1915.0486 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #228: GFLOPs: 396.8361. Time: 583.6475 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #229: GFLOPs: 161.9034. Time: 1430.5589 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #230: GFLOPs: 164.4332. Time: 1408.5499 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #231: GFLOPs: 107.2243. Time: 2160.0731 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #232: GFLOPs: 326.0066. Time: 710.4531 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #233: GFLOPs: 127.3451. Time: 1818.7781 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #234: GFLOPs: 401.0128. Time: 577.5687 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #235: GFLOPs: 410.8993. Time: 563.6720 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #236: GFLOPs: 222.2737. Time: 1042.0145 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #237: GFLOPs: 341.6249. Time: 677.9729 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #238: GFLOPs: 95.2806. Time: 2430.8444 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #239: GFLOPs: 95.8433. Time: 2416.5732 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #240: GFLOPs: 401.2585. Time: 577.2150 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #241: GFLOPs: 305.2660. Time: 758.7233 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #242: GFLOPs: 148.1266. Time: 1563.6108 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #243: GFLOPs: 387.6574. Time: 597.4667 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #244: GFLOPs: 402.3273. Time: 575.6816 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #245: GFLOPs: 77.4837. Time: 2989.1772 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #246: GFLOPs: 316.4013. Time: 732.0210 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #247: GFLOPs: 417.2748. Time: 555.0596 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #248: GFLOPs: 352.8482. Time: 656.4081 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #249: GFLOPs: 378.4679. Time: 611.9737 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #250: GFLOPs: 122.1366. Time: 1896.3396 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #251: GFLOPs: 381.7587. Time: 606.6984 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #252: GFLOPs: 205.5084. Time: 1127.0217 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #253: GFLOPs: 52.0958. Time: 4445.8942 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #254: GFLOPs: 12.8184. Time: 18068.7338 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #255: GFLOPs: 228.9746. Time: 1011.5203 us. Best GFLOPs: 440.6333
2024-04-28 22:09:23 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #256: GFLOPs: 19.0264. Time: 12173.2049 us. Best GFLOPs: 440.6333
2024-04-28 22:12:13 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:12:14 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:12:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:12:19 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:12:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:12:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:12:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:13:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:13:16 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9606  0.9430  0.9349  0.9337  0.9208  0.9109  0.9074  0.9027  0.8869  0.8799  0.8798  0.8677  0.8601  0.8468  0.8444  0.8429
[17 : 32]:	0.8373  0.8328  0.8269  0.8097  0.8097  0.8062  0.8060  0.8059  0.8054  0.8010  0.7964  0.7962  0.7962  0.7958  0.7897  0.7873
[33 : 48]:	0.7854  0.7850  0.7850  0.7846  0.7820  0.7799  0.7777  0.7772  0.7769  0.7759  0.7759  0.7733  0.7723  0.7694  0.7694  0.7690
[49 : 64]:	0.7679  0.7669  0.7652  0.7627  0.7625  0.7622  0.7576  0.7548  0.7543  0.7542  0.7541  0.7540  0.7537  0.7534  0.7519  0.7495
2024-04-28 22:13:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:13:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #257: GFLOPs: 434.7280. Time: 532.7755 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #258: GFLOPs: 427.4566. Time: 541.8384 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #259: GFLOPs: 433.9552. Time: 533.7243 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #260: GFLOPs: 364.0591. Time: 636.1946 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #261: GFLOPs: 393.1028. Time: 589.1904 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #262: GFLOPs: 401.4836. Time: 576.8914 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #263: GFLOPs: 314.6774. Time: 736.0313 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #264: GFLOPs: 364.9640. Time: 634.6171 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #265: GFLOPs: 360.3853. Time: 642.6800 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #266: GFLOPs: 361.1497. Time: 641.3197 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #267: GFLOPs: 371.3623. Time: 623.6832 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #268: GFLOPs: 381.7735. Time: 606.6749 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #269: GFLOPs: 430.7273. Time: 537.7240 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #270: GFLOPs: 377.1298. Time: 614.1450 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #271: GFLOPs: 370.2105. Time: 625.6236 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #272: GFLOPs: 276.0991. Time: 838.8742 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #273: GFLOPs: 368.8662. Time: 627.9036 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #274: GFLOPs: 368.5368. Time: 628.4649 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #275: GFLOPs: 390.5075. Time: 593.1062 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #276: GFLOPs: 392.3009. Time: 590.3948 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #277: GFLOPs: 373.2902. Time: 620.4621 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #278: GFLOPs: 299.1881. Time: 774.1365 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #279: GFLOPs: 252.3904. Time: 917.6753 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #280: GFLOPs: 305.0918. Time: 759.1564 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #281: GFLOPs: 417.9424. Time: 554.1730 us. Best GFLOPs: 440.6333
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #282: GFLOPs: 461.8723. Time: 501.4642 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #283: GFLOPs: 390.2142. Time: 593.5520 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #284: GFLOPs: 349.0418. Time: 663.5665 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #285: GFLOPs: 346.0615. Time: 669.2811 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #286: GFLOPs: 342.7950. Time: 675.6586 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #287: GFLOPs: 313.6857. Time: 738.3582 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #288: GFLOPs: 351.0655. Time: 659.7413 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #289: GFLOPs: 173.5953. Time: 1334.2094 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #290: GFLOPs: 446.8542. Time: 518.3177 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #291: GFLOPs: 268.8973. Time: 861.3417 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #292: GFLOPs: 391.8398. Time: 591.0896 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #293: GFLOPs: 334.3889. Time: 692.6439 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #294: GFLOPs: 94.0102. Time: 2463.6937 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #295: GFLOPs: 388.7027. Time: 595.8601 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #296: GFLOPs: 353.6595. Time: 654.9023 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #297: GFLOPs: 453.5814. Time: 510.6303 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #298: GFLOPs: 329.5067. Time: 702.9067 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #299: GFLOPs: 368.0651. Time: 629.2703 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #300: GFLOPs: 295.9267. Time: 782.6682 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #301: GFLOPs: 113.0678. Time: 2048.4379 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #302: GFLOPs: 351.4498. Time: 659.0199 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #303: GFLOPs: 350.0300. Time: 661.6930 us. Best GFLOPs: 461.8723
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #304: GFLOPs: 463.9166. Time: 499.2545 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #305: GFLOPs: 393.9435. Time: 587.9331 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #306: GFLOPs: 416.0581. Time: 556.6829 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #307: GFLOPs: 318.9621. Time: 726.1441 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #308: GFLOPs: 280.6607. Time: 825.2398 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #309: GFLOPs: 343.4162. Time: 674.4366 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #310: GFLOPs: 315.3749. Time: 734.4035 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #311: GFLOPs: 401.2711. Time: 577.1968 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #312: GFLOPs: 321.7109. Time: 719.9397 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #313: GFLOPs: 361.3729. Time: 640.9237 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #314: GFLOPs: 374.9708. Time: 617.6811 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #315: GFLOPs: 415.8756. Time: 556.9272 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #316: GFLOPs: 26.8440. Time: 8628.0862 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #317: GFLOPs: 313.1202. Time: 739.6918 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #318: GFLOPs: 38.8039. Time: 5968.7910 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #319: GFLOPs: 61.1692. Time: 3786.4245 us. Best GFLOPs: 463.9166
2024-04-28 22:14:48 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #320: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(6), T.int64(4)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + oh_1 * T.int64(4) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(8), T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + oh_1 * T.int64(4) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3136)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[14, 1, 4, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81 = sch.get_loops(block=b67)
l82 = sch.fuse(l70, l71, l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l82)
l83 = sch.fuse(l81, preserve_unit_iters=True)
sch.vectorize(loop=l83)
l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l84, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b114)
b135 = sch.decompose_reduction(block=b114, loop=l119)
2024-04-28 22:32:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:32:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:32:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:32:35 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:32:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:33:00 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:33:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:33:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:33:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9482  0.8905  0.8769  0.8706  0.8697  0.8671  0.8633  0.8605  0.8507  0.8503  0.8474  0.8470  0.8468  0.8452  0.8448  0.8426
[17 : 32]:	0.8419  0.8419  0.8413  0.8398  0.8379  0.8336  0.8296  0.8223  0.8221  0.8214  0.8151  0.8108  0.8108  0.8072  0.8067  0.8066
[33 : 48]:	0.8064  0.8064  0.8019  0.7993  0.7986  0.7967  0.7961  0.7948  0.7948  0.7948  0.7946  0.7931  0.7924  0.7913  0.7913  0.7890
[49 : 64]:	0.7870  0.7868  0.7859  0.7829  0.7801  0.7773  0.7769  0.7760  0.7760  0.7753  0.7749  0.7749  0.7733  0.7729  0.7700  0.7687
2024-04-28 22:33:33 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:33:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #321: GFLOPs: 467.7058. Time: 495.2096 us. Best GFLOPs: 467.7058
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #322: GFLOPs: 493.3834. Time: 469.4370 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #323: GFLOPs: 448.0991. Time: 516.8777 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #324: GFLOPs: 285.7657. Time: 810.4975 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #325: GFLOPs: 405.9599. Time: 570.5303 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #326: GFLOPs: 392.0789. Time: 590.7291 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #327: GFLOPs: 467.2516. Time: 495.6910 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #328: GFLOPs: 383.4021. Time: 604.0979 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #329: GFLOPs: 396.8449. Time: 583.6346 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #330: GFLOPs: 452.7511. Time: 511.5668 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #331: GFLOPs: 430.1440. Time: 538.4532 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #332: GFLOPs: 448.9442. Time: 515.9047 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #333: GFLOPs: 453.7568. Time: 510.4329 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #334: GFLOPs: 406.0178. Time: 570.4489 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #335: GFLOPs: 397.5215. Time: 582.6412 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #336: GFLOPs: 452.2956. Time: 512.0820 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #337: GFLOPs: 456.6505. Time: 507.1984 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #338: GFLOPs: 243.7463. Time: 950.2192 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #339: GFLOPs: 396.2232. Time: 584.5503 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #340: GFLOPs: 375.5753. Time: 616.6871 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #341: GFLOPs: 379.1362. Time: 610.8950 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #342: GFLOPs: 388.8385. Time: 595.6519 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #343: GFLOPs: 414.0240. Time: 559.4179 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #344: GFLOPs: 370.4761. Time: 625.1750 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #345: GFLOPs: 400.1381. Time: 578.8311 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #346: GFLOPs: 397.9667. Time: 581.9895 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #347: GFLOPs: 392.1322. Time: 590.6488 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #348: GFLOPs: 358.5484. Time: 645.9726 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #349: GFLOPs: 369.6300. Time: 626.6061 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #350: GFLOPs: 364.8605. Time: 634.7972 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #351: GFLOPs: 401.1844. Time: 577.3216 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #352: GFLOPs: 419.0295. Time: 552.7353 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #353: GFLOPs: 353.1932. Time: 655.7669 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #354: GFLOPs: 354.7251. Time: 652.9349 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #355: GFLOPs: 192.9045. Time: 1200.6581 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #356: GFLOPs: 203.7863. Time: 1136.5453 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #357: GFLOPs: 390.0054. Time: 593.8697 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #358: GFLOPs: 402.6592. Time: 575.2070 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #359: GFLOPs: 273.2915. Time: 847.4921 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #360: GFLOPs: 362.1871. Time: 639.4827 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #361: GFLOPs: 361.3164. Time: 641.0239 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #362: GFLOPs: 364.6590. Time: 635.1479 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #363: GFLOPs: 355.7144. Time: 651.1190 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #364: GFLOPs: 388.4833. Time: 596.1965 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #365: GFLOPs: 358.4884. Time: 646.0806 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #366: GFLOPs: 91.3021. Time: 2536.7689 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #367: GFLOPs: 91.6393. Time: 2527.4358 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #368: GFLOPs: 377.4358. Time: 613.6471 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #369: GFLOPs: 378.8648. Time: 611.3327 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #370: GFLOPs: 370.2580. Time: 625.5433 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #371: GFLOPs: 337.2793. Time: 686.7080 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #372: GFLOPs: 369.2847. Time: 627.1920 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #373: GFLOPs: 353.3098. Time: 655.5506 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #374: GFLOPs: 420.3302. Time: 551.0250 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #375: GFLOPs: 438.2689. Time: 528.4711 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #376: GFLOPs: 366.6658. Time: 631.6717 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #377: GFLOPs: 75.5985. Time: 3063.7182 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #378: GFLOPs: 376.4762. Time: 615.2114 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #379: GFLOPs: 356.1964. Time: 650.2380 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #380: GFLOPs: 439.5980. Time: 526.8733 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #381: GFLOPs: 391.9257. Time: 590.9601 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #382: GFLOPs: 3.4114. Time: 67893.9087 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #383: GFLOPs: 17.8033. Time: 13009.5090 us. Best GFLOPs: 493.3834
2024-04-28 22:34:41 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #384: GFLOPs: 60.8582. Time: 3805.7689 us. Best GFLOPs: 493.3834
2024-04-28 22:47:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:47:35 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:47:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:47:39 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:47:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:48:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:48:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:48:30 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 22:48:37 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9124  0.8972  0.8782  0.8752  0.8728  0.8577  0.8522  0.8404  0.8314  0.8296  0.8278  0.8250  0.8250  0.8227  0.8216  0.8196
[17 : 32]:	0.8190  0.8139  0.8081  0.8068  0.8034  0.8004  0.8003  0.7995  0.7898  0.7851  0.7846  0.7836  0.7836  0.7824  0.7819  0.7810
[33 : 48]:	0.7795  0.7793  0.7791  0.7783  0.7783  0.7768  0.7767  0.7760  0.7755  0.7755  0.7749  0.7715  0.7706  0.7702  0.7693  0.7681
[49 : 64]:	0.7658  0.7658  0.7645  0.7625  0.7604  0.7599  0.7593  0.7591  0.7572  0.7558  0.7545  0.7514  0.7512  0.7505  0.7492  0.7484
2024-04-28 22:48:37 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:48:37 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #385: GFLOPs: 285.9569. Time: 809.9558 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #386: GFLOPs: 427.6711. Time: 541.5667 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #387: GFLOPs: 447.4362. Time: 517.6435 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #388: GFLOPs: 231.5828. Time: 1000.1279 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #389: GFLOPs: 429.4427. Time: 539.3326 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #390: GFLOPs: 474.6517. Time: 487.9628 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #391: GFLOPs: 322.3260. Time: 718.5657 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #392: GFLOPs: 429.4241. Time: 539.3558 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #393: GFLOPs: 104.9528. Time: 2206.8247 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #394: GFLOPs: 459.2134. Time: 504.3677 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #395: GFLOPs: 402.8879. Time: 574.8806 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #396: GFLOPs: 376.6424. Time: 614.9398 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #397: GFLOPs: 380.0657. Time: 609.4009 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #398: GFLOPs: 390.9895. Time: 592.3750 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #399: GFLOPs: 362.5643. Time: 638.8175 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #400: GFLOPs: 317.9503. Time: 728.4548 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #401: GFLOPs: 270.9861. Time: 854.7022 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #402: GFLOPs: 454.9890. Time: 509.0506 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #403: GFLOPs: 286.0178. Time: 809.7831 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #404: GFLOPs: 364.8828. Time: 634.7585 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #405: GFLOPs: 387.9239. Time: 597.0564 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #406: GFLOPs: 381.4798. Time: 607.1421 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #407: GFLOPs: 390.9303. Time: 592.4648 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #408: GFLOPs: 117.1350. Time: 1977.3113 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #409: GFLOPs: 468.9719. Time: 493.8727 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #410: GFLOPs: 296.7352. Time: 780.5358 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #411: GFLOPs: 403.9503. Time: 573.3686 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #412: GFLOPs: 210.6623. Time: 1099.4486 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #413: GFLOPs: 395.4244. Time: 585.7312 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #414: GFLOPs: 348.0526. Time: 665.4524 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #415: GFLOPs: 388.0531. Time: 596.8576 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #416: GFLOPs: 221.4644. Time: 1045.8224 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #417: GFLOPs: 440.0342. Time: 526.3509 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #418: GFLOPs: 389.7980. Time: 594.1857 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #419: GFLOPs: 398.0994. Time: 581.7955 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #420: GFLOPs: 352.5015. Time: 657.0538 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #421: GFLOPs: 385.6997. Time: 600.4994 us. Best GFLOPs: 493.3834
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #422: GFLOPs: 835.7740. Time: 277.1233 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #423: GFLOPs: 676.2283. Time: 342.5062 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #424: GFLOPs: 381.1727. Time: 607.6312 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #425: GFLOPs: 445.1642. Time: 520.2853 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #426: GFLOPs: 375.4269. Time: 616.9308 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #427: GFLOPs: 365.6567. Time: 633.4149 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #428: GFLOPs: 411.4816. Time: 562.8743 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #429: GFLOPs: 371.5974. Time: 623.2886 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #430: GFLOPs: 358.2934. Time: 646.4323 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #431: GFLOPs: 412.2366. Time: 561.8434 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #432: GFLOPs: 368.0033. Time: 629.3760 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #433: GFLOPs: 374.3333. Time: 618.7332 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #434: GFLOPs: 366.0184. Time: 632.7890 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #435: GFLOPs: 460.8038. Time: 502.6270 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #436: GFLOPs: 316.3399. Time: 732.1630 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #437: GFLOPs: 411.8188. Time: 562.4134 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #438: GFLOPs: 445.7139. Time: 519.6437 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #439: GFLOPs: 346.9859. Time: 667.4980 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #440: GFLOPs: 323.9517. Time: 714.9597 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #441: GFLOPs: 396.1566. Time: 584.6486 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #442: GFLOPs: 411.4665. Time: 562.8949 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #443: GFLOPs: 357.0463. Time: 648.6901 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #444: GFLOPs: 399.8156. Time: 579.2981 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #445: GFLOPs: 305.4804. Time: 758.1908 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #446: GFLOPs: 1.8293. Time: 126612.2540 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #447: GFLOPs: 1.6787. Time: 137972.2297 us. Best GFLOPs: 835.7740
2024-04-28 22:50:10 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #448: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_fused_fused in T.parallel(T.int64(2), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(58), T.int64(58)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_0, ow_0, oc_block_0 in T.grid(T.int64(2), T.int64(14), T.int64(8)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ow_1 * T.int64(4) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(2), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + oh_1 * T.int64(14) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ow_1 * T.int64(4) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_fused_fused + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), oh_0 * T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), ow_0 * T.int64(4) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 14, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 2, 2])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[8, 2, 1, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b68)
l78 = sch.fuse(l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142 = sch.get_loops(block=b117)
b143 = sch.decompose_reduction(block=b117, loop=l127)
2024-04-28 23:18:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:18:56 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:19:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:19:01 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:19:13 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:19:26 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:19:38 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:19:50 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:19:58 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9682  0.8582  0.8582  0.8458  0.8391  0.8071  0.7907  0.7857  0.7774  0.7730  0.7468  0.7389  0.7254  0.7249  0.7182  0.7154
[17 : 32]:	0.6904  0.6806  0.6767  0.6711  0.6710  0.6710  0.6669  0.6571  0.6507  0.6469  0.6449  0.6429  0.6318  0.6317  0.6114  0.6038
[33 : 48]:	0.5994  0.5978  0.5974  0.5962  0.5930  0.5908  0.5842  0.5823  0.5745  0.5737  0.5626  0.5611  0.5586  0.5535  0.5518  0.5513
[49 : 64]:	0.5472  0.5436  0.5417  0.5364  0.5318  0.5263  0.5195  0.5186  0.5180  0.5180  0.5154  0.5149  0.5129  0.5119  0.5119  0.5115
2024-04-28 23:19:58 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:19:58 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #449: GFLOPs: 524.0600. Time: 441.9578 us. Best GFLOPs: 835.7740
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #450: GFLOPs: 430.1398. Time: 538.4585 us. Best GFLOPs: 835.7740
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #451: GFLOPs: 412.7004. Time: 561.2120 us. Best GFLOPs: 835.7740
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #452: GFLOPs: 852.0657. Time: 271.8246 us. Best GFLOPs: 852.0657
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #453: GFLOPs: 802.9410. Time: 288.4551 us. Best GFLOPs: 852.0657
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #454: GFLOPs: 743.5938. Time: 311.4771 us. Best GFLOPs: 852.0657
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #455: GFLOPs: 930.4211. Time: 248.9329 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #456: GFLOPs: 759.7987. Time: 304.8339 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #457: GFLOPs: 812.3226. Time: 285.1237 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #458: GFLOPs: 529.7976. Time: 437.1715 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #459: GFLOPs: 345.4783. Time: 670.4108 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #460: GFLOPs: 683.1019. Time: 339.0599 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #461: GFLOPs: 844.6371. Time: 274.2153 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #462: GFLOPs: 569.4122. Time: 406.7571 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #463: GFLOPs: 344.3589. Time: 672.5902 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #464: GFLOPs: 824.4127. Time: 280.9423 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #465: GFLOPs: 712.8587. Time: 324.9065 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #466: GFLOPs: 717.6070. Time: 322.7566 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #467: GFLOPs: 543.3629. Time: 426.2573 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #468: GFLOPs: 550.9120. Time: 420.4164 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #469: GFLOPs: 866.9573. Time: 267.1555 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #470: GFLOPs: 713.3321. Time: 324.6909 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #471: GFLOPs: 708.2247. Time: 327.0324 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #472: GFLOPs: 736.0897. Time: 314.6524 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #473: GFLOPs: 765.1382. Time: 302.7067 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #474: GFLOPs: 540.0240. Time: 428.8928 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #475: GFLOPs: 711.0294. Time: 325.7424 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #476: GFLOPs: 564.4532. Time: 410.3306 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #477: GFLOPs: 619.9935. Time: 373.5723 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #478: GFLOPs: 525.9285. Time: 440.3877 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #479: GFLOPs: 666.8304. Time: 347.3333 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #480: GFLOPs: 593.8582. Time: 390.0130 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #481: GFLOPs: 534.3377. Time: 433.4570 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #482: GFLOPs: 534.1541. Time: 433.6060 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #483: GFLOPs: 560.5844. Time: 413.1624 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #484: GFLOPs: 652.5050. Time: 354.9589 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #485: GFLOPs: 108.5176. Time: 2134.3296 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #486: GFLOPs: 439.0692. Time: 527.5077 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #487: GFLOPs: 507.6923. Time: 456.2063 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #488: GFLOPs: 571.3601. Time: 405.3703 us. Best GFLOPs: 930.4211
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #489: GFLOPs: 933.9803. Time: 247.9843 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #490: GFLOPs: 476.2626. Time: 486.3124 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #491: GFLOPs: 92.8189. Time: 2495.3163 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #492: GFLOPs: 613.9507. Time: 377.2492 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #493: GFLOPs: 425.6941. Time: 544.0818 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #494: GFLOPs: 355.0164. Time: 652.3992 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #495: GFLOPs: 679.1143. Time: 341.0507 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #496: GFLOPs: 574.5531. Time: 403.1175 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #497: GFLOPs: 569.3516. Time: 406.8004 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #498: GFLOPs: 277.6432. Time: 834.2088 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #499: GFLOPs: 891.4501. Time: 259.8153 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #500: GFLOPs: 23.3824. Time: 9905.4343 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #501: GFLOPs: 410.8071. Time: 563.7985 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #502: GFLOPs: 477.7638. Time: 484.7844 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #503: GFLOPs: 568.8024. Time: 407.1931 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #504: GFLOPs: 329.4412. Time: 703.0464 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #505: GFLOPs: 302.1860. Time: 766.4565 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #506: GFLOPs: 302.2205. Time: 766.3689 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #507: GFLOPs: 404.2880. Time: 572.8897 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #508: GFLOPs: 414.3698. Time: 558.9510 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #509: GFLOPs: 440.5966. Time: 525.6791 us. Best GFLOPs: 933.9803
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #510: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(28)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(58)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), oh_1 * T.int64(2) + ax2)
                            v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(8), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        for oc_block_3_fused in T.vectorized(T.int64(2)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), oh_1 * T.int64(2) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(56), T.int64(56)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 28, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 8, 1, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 8, 2])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #511: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(58)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(28), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(8)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_fused_fused * T.int64(14) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), ow_0 * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(32) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(3136)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(2), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(100352))
                    v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(100352) // T.int64(1792))
                    v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(1792) // T.int64(32))
                    v_ax4 = T.axis.spatial(T.int64(32), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(32))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 7, 1, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[28, 1, 2, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 2, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[2, 32])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v64 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v64)
l65 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l65, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b66 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b66, ann_key="meta_schedule.unroll_explicit")
b67, b68, b69 = sch.get_child_blocks(b66)
l70, l71, l72, l73, l74, l75, l76, l77 = sch.get_loops(block=b67)
l78 = sch.fuse(l70, l71, l72, preserve_unit_iters=True)
sch.parallel(loop=l78)
l79 = sch.fuse(l77, preserve_unit_iters=True)
sch.vectorize(loop=l79)
l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b68)
l104 = sch.fuse(l80, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b69)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b114)
b139 = sch.decompose_reduction(block=b114, loop=l123)
2024-04-28 23:21:31 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #512: GFLOPs: 41.8799. Time: 5530.4013 us. Best GFLOPs: 933.9803
2024-04-28 23:31:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:31:58 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:32:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:32:02 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:32:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:32:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:32:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:32:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:33:00 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9706  0.9706  0.9706  0.9221  0.9216  0.9209  0.9195  0.9189  0.9171  0.9092  0.9077  0.9006  0.8931  0.8887  0.8880  0.8879
[17 : 32]:	0.8805  0.8795  0.8792  0.8774  0.8767  0.8698  0.8662  0.8661  0.8611  0.8602  0.8525  0.8496  0.8441  0.8427  0.8427  0.8415
[33 : 48]:	0.8411  0.8372  0.8369  0.8322  0.8320  0.8316  0.8306  0.8295  0.8276  0.8275  0.8245  0.8239  0.8235  0.8235  0.8231  0.8211
[49 : 64]:	0.8135  0.8129  0.8051  0.8029  0.7986  0.7986  0.7980  0.7963  0.7957  0.7947  0.7945  0.7941  0.7936  0.7931  0.7902  0.7900
2024-04-28 23:33:00 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:33:00 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #513: GFLOPs: 194.2275. Time: 1192.4802 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #514: GFLOPs: 64.3616. Time: 3598.6102 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #515: GFLOPs: 815.0326. Time: 284.1757 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #516: GFLOPs: 828.7953. Time: 279.4567 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #517: GFLOPs: 784.7029. Time: 295.1594 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #518: GFLOPs: 669.5223. Time: 345.9368 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #519: GFLOPs: 755.6771. Time: 306.4965 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #520: GFLOPs: 839.0825. Time: 276.0306 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #521: GFLOPs: 824.4050. Time: 280.9449 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #522: GFLOPs: 835.5173. Time: 277.2084 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #523: GFLOPs: 795.4741. Time: 291.1627 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #524: GFLOPs: 871.8412. Time: 265.6590 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #525: GFLOPs: 928.1095. Time: 249.5529 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #526: GFLOPs: 918.8062. Time: 252.0797 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #527: GFLOPs: 103.1068. Time: 2246.3358 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #528: GFLOPs: 836.6236. Time: 276.8419 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #529: GFLOPs: 174.4066. Time: 1328.0029 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #530: GFLOPs: 790.9696. Time: 292.8209 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #531: GFLOPs: 776.9134. Time: 298.1187 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #532: GFLOPs: 887.3446. Time: 261.0174 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #533: GFLOPs: 789.4339. Time: 293.3905 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #534: GFLOPs: 692.5254. Time: 334.4461 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #535: GFLOPs: 846.8180. Time: 273.5091 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #536: GFLOPs: 910.6379. Time: 254.3408 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #537: GFLOPs: 860.6079. Time: 269.1265 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #538: GFLOPs: 881.6714. Time: 262.6970 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #539: GFLOPs: 169.4515. Time: 1366.8359 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #540: GFLOPs: 771.6915. Time: 300.1360 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #541: GFLOPs: 863.9225. Time: 268.0940 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #542: GFLOPs: 182.6671. Time: 1267.9484 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #543: GFLOPs: 68.6483. Time: 3373.8991 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #544: GFLOPs: 686.4681. Time: 337.3972 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #545: GFLOPs: 717.3032. Time: 322.8933 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #546: GFLOPs: 674.0988. Time: 343.5882 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #547: GFLOPs: 703.3718. Time: 329.2887 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #548: GFLOPs: 735.2147. Time: 315.0269 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #549: GFLOPs: 690.7503. Time: 335.3055 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #550: GFLOPs: 830.5467. Time: 278.8674 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #551: GFLOPs: 350.1866. Time: 661.3971 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #552: GFLOPs: 635.8745. Time: 364.2424 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #553: GFLOPs: 744.8634. Time: 310.9462 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #554: GFLOPs: 852.7434. Time: 271.6086 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #555: GFLOPs: 582.4441. Time: 397.6561 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #556: GFLOPs: 317.7036. Time: 729.0204 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #557: GFLOPs: 698.0475. Time: 331.8004 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #558: GFLOPs: 873.9622. Time: 265.0142 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #559: GFLOPs: 702.9829. Time: 329.4709 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #560: GFLOPs: 806.3204. Time: 287.2461 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #561: GFLOPs: 781.4387. Time: 296.3923 us. Best GFLOPs: 933.9803
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #562: GFLOPs: 955.2402. Time: 242.4651 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #563: GFLOPs: 860.5230. Time: 269.1531 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #564: GFLOPs: 572.9204. Time: 404.2663 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #565: GFLOPs: 781.9874. Time: 296.1843 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #566: GFLOPs: 804.4690. Time: 287.9072 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #567: GFLOPs: 930.8958. Time: 248.8060 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #568: GFLOPs: 748.3770. Time: 309.4863 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #569: GFLOPs: 88.5373. Time: 2615.9880 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #570: GFLOPs: 801.4104. Time: 289.0060 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #571: GFLOPs: 939.9414. Time: 246.4115 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #572: GFLOPs: 858.7733. Time: 269.7015 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #573: GFLOPs: 642.9076. Time: 360.2577 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #574: GFLOPs: 52.2762. Time: 4430.5510 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #575: GFLOPs: 7.5135. Time: 30826.0688 us. Best GFLOPs: 955.2402
2024-04-28 23:34:32 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #576: GFLOPs: 3.3400. Time: 69344.8537 us. Best GFLOPs: 955.2402
2024-04-28 23:39:46 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:39:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:39:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:39:52 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:40:04 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:40:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:40:29 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:40:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-28 23:40:48 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9619  0.9415  0.9415  0.9311  0.9279  0.9249  0.9083  0.9072  0.8986  0.8913  0.8904  0.8875  0.8871  0.8809  0.8809  0.8809
[17 : 32]:	0.8785  0.8770  0.8757  0.8730  0.8711  0.8711  0.8663  0.8654  0.8623  0.8623  0.8590  0.8585  0.8525  0.8512  0.8500  0.8499
[33 : 48]:	0.8447  0.8397  0.8397  0.8397  0.8361  0.8361  0.8361  0.8339  0.8339  0.8303  0.8291  0.8288  0.8288  0.8286  0.8257  0.8237
[49 : 64]:	0.8214  0.8214  0.8193  0.8180  0.8176  0.8176  0.8139  0.8094  0.8082  0.8066  0.8065  0.8064  0.8040  0.8033  0.8027  0.7995
2024-04-28 23:40:49 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:40:49 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #577: GFLOPs: 482.1563. Time: 480.3679 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #578: GFLOPs: 189.7081. Time: 1220.8884 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #579: GFLOPs: 790.7773. Time: 292.8921 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #580: GFLOPs: 879.3164. Time: 263.4005 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #581: GFLOPs: 909.1476. Time: 254.7578 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #582: GFLOPs: 903.3015. Time: 256.4066 us. Best GFLOPs: 955.2402
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #583: GFLOPs: 970.3592. Time: 238.6873 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #584: GFLOPs: 848.6270. Time: 272.9261 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #585: GFLOPs: 452.7954. Time: 511.5167 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #586: GFLOPs: 875.2917. Time: 264.6117 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #587: GFLOPs: 867.5276. Time: 266.9799 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #588: GFLOPs: 668.6960. Time: 346.3643 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #589: GFLOPs: 841.5730. Time: 275.2137 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #590: GFLOPs: 174.8028. Time: 1324.9924 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #591: GFLOPs: 63.9923. Time: 3619.3795 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #592: GFLOPs: 792.3651. Time: 292.3052 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #593: GFLOPs: 828.3120. Time: 279.6198 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #594: GFLOPs: 873.2351. Time: 265.2349 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #595: GFLOPs: 668.0919. Time: 346.6775 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #596: GFLOPs: 695.3182. Time: 333.1027 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #597: GFLOPs: 916.8676. Time: 252.6127 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #598: GFLOPs: 878.4753. Time: 263.6527 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #599: GFLOPs: 802.8522. Time: 288.4870 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #600: GFLOPs: 825.9330. Time: 280.4252 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #601: GFLOPs: 629.3338. Time: 368.0279 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #602: GFLOPs: 822.0056. Time: 281.7650 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #603: GFLOPs: 926.6579. Time: 249.9438 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #604: GFLOPs: 746.9402. Time: 310.0816 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #605: GFLOPs: 637.6937. Time: 363.2033 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #606: GFLOPs: 861.4453. Time: 268.8649 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #607: GFLOPs: 822.9308. Time: 281.4482 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #608: GFLOPs: 863.9004. Time: 268.1008 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #609: GFLOPs: 814.8089. Time: 284.2537 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #610: GFLOPs: 906.8903. Time: 255.3919 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #611: GFLOPs: 771.3421. Time: 300.2720 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #612: GFLOPs: 771.7090. Time: 300.1292 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #613: GFLOPs: 183.1521. Time: 1264.5903 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #614: GFLOPs: 78.9665. Time: 2933.0457 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #615: GFLOPs: 191.1683. Time: 1211.5629 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #616: GFLOPs: 737.7028. Time: 313.9644 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #617: GFLOPs: 920.6440. Time: 251.5765 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #618: GFLOPs: 798.8124. Time: 289.9459 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #619: GFLOPs: 688.6885. Time: 336.3094 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #620: GFLOPs: 901.6873. Time: 256.8656 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #621: GFLOPs: 884.4826. Time: 261.8620 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #622: GFLOPs: 853.7164. Time: 271.2990 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #623: GFLOPs: 698.5858. Time: 331.5447 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #624: GFLOPs: 394.4899. Time: 587.1187 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #625: GFLOPs: 692.2171. Time: 334.5951 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #626: GFLOPs: 855.0289. Time: 270.8826 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #627: GFLOPs: 838.7475. Time: 276.1408 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #628: GFLOPs: 894.8219. Time: 258.8363 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #629: GFLOPs: 931.0753. Time: 248.7580 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #630: GFLOPs: 886.9153. Time: 261.1438 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #631: GFLOPs: 856.5671. Time: 270.3961 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #632: GFLOPs: 726.8312. Time: 318.6605 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #633: GFLOPs: 860.0562. Time: 269.2992 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #634: GFLOPs: 885.6906. Time: 261.5049 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #635: GFLOPs: 754.0908. Time: 307.1413 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #636: GFLOPs: 652.4673. Time: 354.9793 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #637: GFLOPs: 701.3400. Time: 330.2427 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #638: GFLOPs: 21.7418. Time: 10652.8443 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #639: GFLOPs: 60.4158. Time: 3833.6408 us. Best GFLOPs: 970.3592
2024-04-28 23:42:29 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #640: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(16), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(16)):
                for ax4_fused in T.vectorized(T.int64(64)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ax2)
                        v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ax3)
                        v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0 in range(T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(28), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(2), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(8) // T.int64(4) * T.int64(28) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(4) * T.int64(14) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(32), oc_block_0 * T.int64(16) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[2, 1, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 14, 2, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 2, 7])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 16, 1])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b68)
l80 = sch.fuse(l71, l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81 = sch.fuse(l79, preserve_unit_iters=True)
sch.vectorize(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b69)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b70)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b114)
b138 = sch.decompose_reduction(block=b114, loop=l122)
2024-04-29 00:45:21 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:45:22 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:45:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 00:45:26 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:45:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 00:45:51 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 00:46:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 00:46:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 00:46:24 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9565  0.9345  0.9231  0.9198  0.9169  0.9169  0.9143  0.9143  0.9130  0.9104  0.9086  0.9005  0.8964  0.8964  0.8964  0.8940
[17 : 32]:	0.8931  0.8894  0.8884  0.8837  0.8806  0.8792  0.8776  0.8760  0.8757  0.8706  0.8669  0.8668  0.8636  0.8630  0.8624  0.8618
[33 : 48]:	0.8603  0.8599  0.8544  0.8543  0.8533  0.8512  0.8512  0.8512  0.8512  0.8512  0.8512  0.8498  0.8432  0.8421  0.8413  0.8397
[49 : 64]:	0.8381  0.8376  0.8354  0.8354  0.8351  0.8338  0.8318  0.8300  0.8286  0.8268  0.8263  0.8244  0.8242  0.8240  0.8226  0.8222
2024-04-29 00:46:24 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:46:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #641: GFLOPs: 917.3142. Time: 252.4897 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #642: GFLOPs: 721.0611. Time: 321.2105 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #643: GFLOPs: 893.1994. Time: 259.3065 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #644: GFLOPs: 904.7663. Time: 255.9914 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #645: GFLOPs: 630.2777. Time: 367.4768 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #646: GFLOPs: 870.0487. Time: 266.2063 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #647: GFLOPs: 859.4910. Time: 269.4763 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #648: GFLOPs: 888.4178. Time: 260.7021 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #649: GFLOPs: 907.4170. Time: 255.2436 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #650: GFLOPs: 895.2202. Time: 258.7212 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #651: GFLOPs: 918.6927. Time: 252.1109 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #652: GFLOPs: 875.3105. Time: 264.6060 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #653: GFLOPs: 700.7627. Time: 330.5148 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #654: GFLOPs: 729.9786. Time: 317.2866 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #655: GFLOPs: 712.1991. Time: 325.2074 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #656: GFLOPs: 887.7787. Time: 260.8898 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #657: GFLOPs: 885.3474. Time: 261.6062 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #658: GFLOPs: 870.2344. Time: 266.1494 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #659: GFLOPs: 587.3329. Time: 394.3460 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #660: GFLOPs: 891.7483. Time: 259.7285 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #661: GFLOPs: 967.2850. Time: 239.4459 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #662: GFLOPs: 884.8634. Time: 261.7493 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #663: GFLOPs: 872.6706. Time: 265.4065 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #664: GFLOPs: 886.5630. Time: 261.2476 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #665: GFLOPs: 937.0922. Time: 247.1608 us. Best GFLOPs: 970.3592
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #666: GFLOPs: 980.8628. Time: 236.1313 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #667: GFLOPs: 920.1720. Time: 251.7056 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #668: GFLOPs: 886.1503. Time: 261.3692 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #669: GFLOPs: 837.8020. Time: 276.4524 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #670: GFLOPs: 969.3637. Time: 238.9324 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #671: GFLOPs: 973.7304. Time: 237.8609 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #672: GFLOPs: 966.3375. Time: 239.6807 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #673: GFLOPs: 419.9898. Time: 551.4716 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #674: GFLOPs: 481.9507. Time: 480.5728 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #675: GFLOPs: 867.8255. Time: 266.8882 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #676: GFLOPs: 951.7774. Time: 243.3472 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #677: GFLOPs: 952.0535. Time: 243.2767 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #678: GFLOPs: 899.8906. Time: 257.3784 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #679: GFLOPs: 857.0233. Time: 270.2522 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #680: GFLOPs: 860.8510. Time: 269.0505 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #681: GFLOPs: 889.9451. Time: 260.2547 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #682: GFLOPs: 860.8500. Time: 269.0509 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #683: GFLOPs: 860.6768. Time: 269.1050 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #684: GFLOPs: 719.9305. Time: 321.7150 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #685: GFLOPs: 652.1125. Time: 355.1725 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #686: GFLOPs: 808.8989. Time: 286.3305 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #687: GFLOPs: 635.0685. Time: 364.7046 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #688: GFLOPs: 702.4032. Time: 329.7428 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #689: GFLOPs: 745.4420. Time: 310.7048 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #690: GFLOPs: 947.1257. Time: 244.5424 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #691: GFLOPs: 759.7352. Time: 304.8594 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #692: GFLOPs: 828.6163. Time: 279.5171 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #693: GFLOPs: 907.6137. Time: 255.1883 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #694: GFLOPs: 905.1432. Time: 255.8848 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #695: GFLOPs: 273.2362. Time: 847.6639 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #696: GFLOPs: 683.6200. Time: 338.8028 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #697: GFLOPs: 845.1542. Time: 274.0475 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #698: GFLOPs: 793.4043. Time: 291.9223 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #699: GFLOPs: 723.3945. Time: 320.1744 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #700: GFLOPs: 811.6882. Time: 285.3465 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #701: GFLOPs: 810.1770. Time: 285.8788 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #702: GFLOPs: 57.0553. Time: 4059.4378 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #703: GFLOPs: 21.9346. Time: 10559.2396 us. Best GFLOPs: 980.8628
2024-04-29 00:48:08 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #704: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(32), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(9), T.int64(16)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + oh_1 * T.int64(7) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(7), T.int64(14), T.int64(4), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + oh_1 * T.int64(7) + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(14), T.int64(4), T.int64(2), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + oh_1 * T.int64(7) + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(2) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(8) * T.int64(14) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(8) // T.int64(2) * T.int64(14) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(16) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 2])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 7, 1])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[4, 1, 14, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 4, 4])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[32, 2])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[3, 1])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b68)
l84 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85 = sch.fuse(l83, preserve_unit_iters=True)
sch.vectorize(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b69)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b70)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-29 01:25:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:25:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:25:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:25:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:25:28 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:25:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:25:53 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:26:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:26:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9738  0.9736  0.9499  0.9430  0.9400  0.9332  0.9258  0.9246  0.9205  0.9141  0.9139  0.9139  0.9129  0.9121  0.9052  0.9024
[17 : 32]:	0.8990  0.8990  0.8990  0.8969  0.8947  0.8942  0.8920  0.8900  0.8880  0.8874  0.8863  0.8841  0.8804  0.8795  0.8778  0.8771
[33 : 48]:	0.8769  0.8733  0.8698  0.8682  0.8682  0.8614  0.8610  0.8581  0.8581  0.8581  0.8569  0.8566  0.8546  0.8532  0.8526  0.8516
[49 : 64]:	0.8470  0.8465  0.8463  0.8450  0.8426  0.8418  0.8385  0.8376  0.8361  0.8333  0.8313  0.8290  0.8288  0.8286  0.8276  0.8262
2024-04-29 01:26:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:26:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #705: GFLOPs: 529.6028. Time: 437.3323 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #706: GFLOPs: 886.7040. Time: 261.2060 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #707: GFLOPs: 933.2713. Time: 248.1727 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #708: GFLOPs: 939.7508. Time: 246.4615 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #709: GFLOPs: 743.2189. Time: 311.6342 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #710: GFLOPs: 938.3421. Time: 246.8315 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #711: GFLOPs: 733.0224. Time: 315.9691 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #712: GFLOPs: 957.5535. Time: 241.8793 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #713: GFLOPs: 915.0165. Time: 253.1238 us. Best GFLOPs: 980.8628
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #714: GFLOPs: 993.7768. Time: 233.0628 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #715: GFLOPs: 931.8521. Time: 248.5506 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #716: GFLOPs: 929.0176. Time: 249.3090 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #717: GFLOPs: 842.4325. Time: 274.9329 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #718: GFLOPs: 921.1650. Time: 251.4342 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #719: GFLOPs: 697.2702. Time: 332.1703 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #720: GFLOPs: 743.7021. Time: 311.4317 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #721: GFLOPs: 888.9246. Time: 260.5535 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #722: GFLOPs: 489.9397. Time: 472.7365 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #723: GFLOPs: 580.6628. Time: 398.8759 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #724: GFLOPs: 677.0525. Time: 342.0893 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #725: GFLOPs: 847.4506. Time: 273.3049 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #726: GFLOPs: 853.4971. Time: 271.3687 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #727: GFLOPs: 688.0990. Time: 336.5975 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #728: GFLOPs: 964.0617. Time: 240.2465 us. Best GFLOPs: 993.7768
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #729: GFLOPs: 1015.0167. Time: 228.1858 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #730: GFLOPs: 809.4580. Time: 286.1327 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #731: GFLOPs: 887.4712. Time: 260.9802 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #732: GFLOPs: 869.5903. Time: 266.3466 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #733: GFLOPs: 874.4281. Time: 264.8730 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #734: GFLOPs: 865.0102. Time: 267.7569 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #735: GFLOPs: 859.2817. Time: 269.5419 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #736: GFLOPs: 838.9470. Time: 276.0752 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #737: GFLOPs: 67.9224. Time: 3409.9579 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #738: GFLOPs: 410.8596. Time: 563.7264 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #739: GFLOPs: 427.5767. Time: 541.6863 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #740: GFLOPs: 42.4139. Time: 5460.7623 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #741: GFLOPs: 728.5576. Time: 317.9054 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #742: GFLOPs: 872.4682. Time: 265.4680 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #743: GFLOPs: 868.8387. Time: 266.5770 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #744: GFLOPs: 827.6015. Time: 279.8598 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #745: GFLOPs: 836.0972. Time: 277.0161 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #746: GFLOPs: 865.1474. Time: 267.7144 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #747: GFLOPs: 855.5515. Time: 270.7171 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #748: GFLOPs: 847.5815. Time: 273.2627 us. Best GFLOPs: 1015.0167
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #749: GFLOPs: 1060.7391. Time: 218.3500 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #750: GFLOPs: 924.5065. Time: 250.5255 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #751: GFLOPs: 744.4530. Time: 311.1176 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #752: GFLOPs: 848.7125. Time: 272.8985 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #753: GFLOPs: 794.4388. Time: 291.5422 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #754: GFLOPs: 830.1870. Time: 278.9882 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #755: GFLOPs: 816.5377. Time: 283.6518 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #756: GFLOPs: 800.6678. Time: 289.2740 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #757: GFLOPs: 908.5412. Time: 254.9278 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #758: GFLOPs: 781.8441. Time: 296.2386 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #759: GFLOPs: 866.8114. Time: 267.2005 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #760: GFLOPs: 848.1940. Time: 273.0654 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #761: GFLOPs: 731.4688. Time: 316.6402 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #762: GFLOPs: 855.0247. Time: 270.8839 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #763: GFLOPs: 652.2151. Time: 355.1166 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #764: GFLOPs: 875.3662. Time: 264.5892 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #765: GFLOPs: 790.8118. Time: 292.8793 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #766: GFLOPs: 178.7508. Time: 1295.7280 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #767: GFLOPs: 106.5586. Time: 2173.5675 us. Best GFLOPs: 1060.7391
2024-04-29 01:28:01 [INFO] [task_scheduler.cc:121] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #768: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(1), T.int64(56), T.int64(56), T.int64(64)), "float32"), p1: T.Buffer((T.int64(2), T.int64(1), T.int64(3), T.int64(3), T.int64(64), T.int64(32)), "float32"), p2: T.Buffer((T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(32)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(1), T.int64(58), T.int64(58), T.int64(64)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(56), T.int64(56), T.int64(32)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(30), T.int64(9)):
                    for ax4_fused in T.vectorized(T.int64(64)):
                        with T.block("data_pad"):
                            v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                            v_i2 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(32) * T.int64(28) + ax2)
                            v_i3 = T.axis.spatial(T.int64(58), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ax3)
                            v_i4 = T.axis.spatial(T.int64(64), ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(57) and T.int64(1) <= v_i3 and v_i3 < T.int64(57), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(32) * T.int64(28) + oh_1 * T.int64(4) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(1), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(2), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(32) * T.int64(28) + oh_1 * T.int64(4) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ow_1 * T.int64(7) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(64), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)], p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(64), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(64)] * p1[v_oc_chunk, v_ic // T.int64(64), v_kh, v_kw, v_ic % T.int64(64), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(28), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(32) * T.int64(28) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(56), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(32) // T.int64(4) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(32), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l4, l5, l6, l7, l8, l9, l10, l11 = sch.get_loops(block=b1)
v12, v13, v14, v15 = sch.sample_perfect_tile(loop=l4, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l16, l17, l18, l19 = sch.split(loop=l4, factors=[v12, v13, v14, v15], preserve_unit_iters=True)
v20, v21, v22, v23 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 2, 1, 1])
l24, l25, l26, l27 = sch.split(loop=l5, factors=[v20, v21, v22, v23], preserve_unit_iters=True)
v28, v29, v30, v31 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 7, 2, 2])
l32, l33, l34, l35 = sch.split(loop=l6, factors=[v28, v29, v30, v31], preserve_unit_iters=True)
v36, v37, v38, v39 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[8, 1, 7, 1])
l40, l41, l42, l43 = sch.split(loop=l7, factors=[v36, v37, v38, v39], preserve_unit_iters=True)
v44, v45, v46, v47 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[4, 1, 1, 8])
l48, l49, l50, l51 = sch.split(loop=l8, factors=[v44, v45, v46, v47], preserve_unit_iters=True)
v52, v53 = sch.sample_perfect_tile(loop=l9, n=2, max_innermost_factor=64, decision=[1, 64])
l54, l55 = sch.split(loop=l9, factors=[v52, v53], preserve_unit_iters=True)
v56, v57 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[1, 3])
l58, l59 = sch.split(loop=l10, factors=[v56, v57], preserve_unit_iters=True)
v60, v61 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l62, l63 = sch.split(loop=l11, factors=[v60, v61], preserve_unit_iters=True)
sch.reorder(l16, l24, l32, l40, l48, l17, l25, l33, l41, l49, l54, l58, l62, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51)
b64, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b64, loop=l48, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b3, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82 = sch.get_loops(block=b68)
l83 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l83)
l84 = sch.fuse(l82, preserve_unit_iters=True)
sch.vectorize(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b69)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
l108 = sch.fuse(l106, preserve_unit_iters=True)
sch.vectorize(loop=l108)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b70)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138 = sch.get_loops(block=b116)
b139 = sch.decompose_reduction(block=b116, loop=l123)
2024-04-29 01:36:47 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:36:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:36:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:36:53 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:37:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:37:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:37:31 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:37:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 01:37:52 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9095  0.8654  0.8630  0.8621  0.8581  0.8562  0.8488  0.8406  0.8368  0.8355  0.8355  0.8330  0.8330  0.8295  0.8295  0.8288
[17 : 32]:	0.8286  0.8281  0.8279  0.8277  0.8275  0.8258  0.8252  0.8221  0.8217  0.8196  0.8195  0.8179  0.8172  0.8161  0.8158  0.8148
[33 : 48]:	0.8140  0.8134  0.8124  0.8114  0.8104  0.8089  0.8079  0.8077  0.8062  0.8052  0.8042  0.8038  0.8031  0.8023  0.8009  0.7976
[49 : 64]:	0.7965  0.7958  0.7945  0.7938  0.7931  0.7931  0.7921  0.7891  0.7864  0.7861  0.7856  0.7846  0.7842  0.7814  0.7812  0.7775
2024-04-29 01:37:53 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:37:53 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #769: GFLOPs: 761.6585. Time: 304.0896 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #770: GFLOPs: 875.4050. Time: 264.5774 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #771: GFLOPs: 935.2206. Time: 247.6554 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #772: GFLOPs: 940.9466. Time: 246.1483 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #773: GFLOPs: 71.6426. Time: 3232.8878 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #774: GFLOPs: 855.0781. Time: 270.8670 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #775: GFLOPs: 890.5852. Time: 260.0677 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #776: GFLOPs: 844.6583. Time: 274.2084 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #777: GFLOPs: 957.0246. Time: 242.0130 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #778: GFLOPs: 882.9009. Time: 262.3312 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #779: GFLOPs: 920.6206. Time: 251.5829 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #780: GFLOPs: 914.1163. Time: 253.3730 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #781: GFLOPs: 909.8858. Time: 254.5511 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #782: GFLOPs: 913.0754. Time: 253.6619 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #783: GFLOPs: 880.2917. Time: 263.1087 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #784: GFLOPs: 866.6917. Time: 267.2374 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #785: GFLOPs: 731.2073. Time: 316.7534 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #786: GFLOPs: 928.4032. Time: 249.4739 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #787: GFLOPs: 893.7813. Time: 259.1377 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #788: GFLOPs: 916.6283. Time: 252.6787 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #789: GFLOPs: 859.2295. Time: 269.5583 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #790: GFLOPs: 897.4146. Time: 258.0885 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #791: GFLOPs: 67.5806. Time: 3427.2021 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #792: GFLOPs: 881.2407. Time: 262.8254 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #793: GFLOPs: 936.5881. Time: 247.2938 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #794: GFLOPs: 885.7601. Time: 261.4844 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #795: GFLOPs: 874.0928. Time: 264.9746 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #796: GFLOPs: 892.1578. Time: 259.6092 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #797: GFLOPs: 189.3552. Time: 1223.1635 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #798: GFLOPs: 715.3484. Time: 323.7757 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #799: GFLOPs: 848.3163. Time: 273.0260 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #800: GFLOPs: 848.3252. Time: 273.0232 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #801: GFLOPs: 682.3104. Time: 339.4532 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #802: GFLOPs: 517.4444. Time: 447.6083 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #803: GFLOPs: 849.9551. Time: 272.4996 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #804: GFLOPs: 903.6012. Time: 256.3215 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #805: GFLOPs: 879.9972. Time: 263.1968 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #806: GFLOPs: 855.5296. Time: 270.7240 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #807: GFLOPs: 915.5603. Time: 252.9734 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #808: GFLOPs: 852.8895. Time: 271.5620 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #809: GFLOPs: 691.3206. Time: 335.0290 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #810: GFLOPs: 868.3883. Time: 266.7153 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #811: GFLOPs: 899.8712. Time: 257.3840 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #812: GFLOPs: 938.2467. Time: 246.8566 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #813: GFLOPs: 901.7891. Time: 256.8366 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #814: GFLOPs: 842.8969. Time: 274.7814 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #815: GFLOPs: 867.5825. Time: 266.9630 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #816: GFLOPs: 892.8207. Time: 259.4165 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #817: GFLOPs: 873.0657. Time: 265.2864 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #818: GFLOPs: 845.0756. Time: 274.0730 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #819: GFLOPs: 895.7900. Time: 258.5566 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #820: GFLOPs: 834.8521. Time: 277.4293 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #821: GFLOPs: 971.9920. Time: 238.2863 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #822: GFLOPs: 928.1027. Time: 249.5547 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #823: GFLOPs: 770.3003. Time: 300.6781 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #824: GFLOPs: 914.8469. Time: 253.1707 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #825: GFLOPs: 877.6582. Time: 263.8982 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #826: GFLOPs: 132.8574. Time: 1743.3158 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #827: GFLOPs: 877.9114. Time: 263.8221 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #828: GFLOPs: 741.4500. Time: 312.3776 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #829: GFLOPs: 133.3719. Time: 1736.5902 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #830: GFLOPs: 195.3166. Time: 1185.8310 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #831: GFLOPs: 8.9639. Time: 25838.3033 us. Best GFLOPs: 1060.7391
2024-04-29 01:39:15 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #832: GFLOPs: 73.1240. Time: 3167.3945 us. Best GFLOPs: 1060.7391
2024-04-29 02:04:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:04:17 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:04:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:04:21 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:04:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:04:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:05:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:05:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:05:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9023  0.8988  0.8947  0.8885  0.8796  0.8753  0.8675  0.8667  0.8667  0.8633  0.8580  0.8454  0.8406  0.8379  0.8335  0.8335
[17 : 32]:	0.8333  0.8333  0.8327  0.8323  0.8315  0.8314  0.8307  0.8298  0.8295  0.8289  0.8286  0.8257  0.8204  0.8199  0.8195  0.8186
[33 : 48]:	0.8186  0.8157  0.8153  0.8153  0.8152  0.8130  0.8130  0.8124  0.8114  0.8114  0.8111  0.8110  0.8103  0.8091  0.8075  0.8053
[49 : 64]:	0.8033  0.8033  0.8033  0.8033  0.8011  0.7996  0.7989  0.7987  0.7969  0.7966  0.7952  0.7941  0.7923  0.7923  0.7869  0.7862
2024-04-29 02:05:22 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:05:22 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #833: GFLOPs: 996.7912. Time: 232.3580 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #834: GFLOPs: 832.5943. Time: 278.1816 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #835: GFLOPs: 915.3253. Time: 253.0384 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #836: GFLOPs: 808.8801. Time: 286.3372 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #837: GFLOPs: 905.4817. Time: 255.7892 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #838: GFLOPs: 892.8058. Time: 259.4208 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #839: GFLOPs: 896.1939. Time: 258.4401 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #840: GFLOPs: 936.7521. Time: 247.2505 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #841: GFLOPs: 941.6451. Time: 245.9657 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #842: GFLOPs: 889.3348. Time: 260.4333 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #843: GFLOPs: 448.4370. Time: 516.4882 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #844: GFLOPs: 967.1010. Time: 239.4914 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #845: GFLOPs: 882.0593. Time: 262.5814 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #846: GFLOPs: 932.9285. Time: 248.2638 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #847: GFLOPs: 945.6440. Time: 244.9256 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #848: GFLOPs: 895.2145. Time: 258.7228 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #849: GFLOPs: 594.2712. Time: 389.7420 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #850: GFLOPs: 828.0918. Time: 279.6941 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #851: GFLOPs: 931.4197. Time: 248.6660 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #852: GFLOPs: 879.5747. Time: 263.3232 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #853: GFLOPs: 885.0778. Time: 261.6859 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #854: GFLOPs: 851.0297. Time: 272.1555 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #855: GFLOPs: 911.7276. Time: 254.0369 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #856: GFLOPs: 748.4681. Time: 309.4486 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #857: GFLOPs: 872.0464. Time: 265.5964 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #858: GFLOPs: 710.9108. Time: 325.7968 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #859: GFLOPs: 846.4835. Time: 273.6172 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #860: GFLOPs: 875.1915. Time: 264.6420 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #861: GFLOPs: 847.5851. Time: 273.2615 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #862: GFLOPs: 811.0158. Time: 285.5831 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #863: GFLOPs: 171.3747. Time: 1351.4968 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #864: GFLOPs: 121.1933. Time: 1911.0986 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #865: GFLOPs: 880.8986. Time: 262.9274 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #866: GFLOPs: 856.6840. Time: 270.3592 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #867: GFLOPs: 743.8344. Time: 311.3763 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #868: GFLOPs: 739.3985. Time: 313.2444 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #869: GFLOPs: 910.0739. Time: 254.4985 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #870: GFLOPs: 850.5948. Time: 272.2947 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #871: GFLOPs: 856.8033. Time: 270.3216 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #872: GFLOPs: 645.9351. Time: 358.5692 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #873: GFLOPs: 936.8071. Time: 247.2360 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #874: GFLOPs: 73.1217. Time: 3167.4942 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #875: GFLOPs: 941.4820. Time: 246.0083 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #876: GFLOPs: 866.6912. Time: 267.2375 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #877: GFLOPs: 912.4084. Time: 253.8473 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #878: GFLOPs: 825.5360. Time: 280.5601 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #879: GFLOPs: 603.7849. Time: 383.6009 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #880: GFLOPs: 875.7580. Time: 264.4708 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #881: GFLOPs: 819.2691. Time: 282.7061 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #882: GFLOPs: 555.3278. Time: 417.0733 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #883: GFLOPs: 347.7021. Time: 666.1232 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #884: GFLOPs: 903.6973. Time: 256.2943 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #885: GFLOPs: 35.6165. Time: 6502.9492 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #886: GFLOPs: 845.1608. Time: 274.0454 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #887: GFLOPs: 891.8119. Time: 259.7099 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #888: GFLOPs: 911.8589. Time: 254.0003 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #889: GFLOPs: 959.9176. Time: 241.2836 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #890: GFLOPs: 915.5612. Time: 252.9732 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #891: GFLOPs: 966.4445. Time: 239.6541 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #892: GFLOPs: 843.3219. Time: 274.6429 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #893: GFLOPs: 790.0880. Time: 293.1476 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #894: GFLOPs: 4.9030. Time: 47238.7097 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #895: GFLOPs: 175.7386. Time: 1317.9374 us. Best GFLOPs: 1060.7391
2024-04-29 02:07:04 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #896: GFLOPs: 25.9659. Time: 8919.8783 us. Best GFLOPs: 1060.7391
2024-04-29 02:28:58 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:28:59 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:29:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:29:04 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:29:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:29:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:29:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:29:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x31c4698)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x33d4338)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x40756a8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x336aab8)]: 0 failure(s)
2024-04-29 02:30:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9322  0.9027  0.8902  0.8879  0.8772  0.8764  0.8736  0.8717  0.8664  0.8664  0.8664  0.8660  0.8627  0.8627  0.8607  0.8607
[17 : 32]:	0.8603  0.8587  0.8577  0.8546  0.8544  0.8544  0.8537  0.8483  0.8481  0.8481  0.8467  0.8467  0.8396  0.8386  0.8368  0.8367
[33 : 48]:	0.8329  0.8306  0.8279  0.8215  0.8215  0.8195  0.8195  0.8177  0.8164  0.8164  0.8135  0.8123  0.8121  0.8106  0.8102  0.8093
[49 : 64]:	0.8088  0.8088  0.8082  0.8074  0.8045  0.8034  0.7996  0.7992  0.7985  0.7970  0.7951  0.7951  0.7940  0.7933  0.7925  0.7924
2024-04-29 02:30:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:30:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #897: GFLOPs: 522.7216. Time: 443.0895 us. Best GFLOPs: 1060.7391
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #898: GFLOPs: 463.4794. Time: 499.7254 us. Best GFLOPs: 1060.7391
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #899: GFLOPs: 1018.1997. Time: 227.4725 us. Best GFLOPs: 1060.7391
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #900: GFLOPs: 109.6988. Time: 2111.3494 us. Best GFLOPs: 1060.7391
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #901: GFLOPs: 883.8241. Time: 262.0571 us. Best GFLOPs: 1060.7391
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #902: GFLOPs: 1062.5408. Time: 217.9798 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #903: GFLOPs: 165.8963. Time: 1396.1280 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #904: GFLOPs: 967.4006. Time: 239.4173 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #905: GFLOPs: 937.2545. Time: 247.1180 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #906: GFLOPs: 924.0011. Time: 250.6625 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #907: GFLOPs: 707.9448. Time: 327.1617 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #908: GFLOPs: 979.5596. Time: 236.4454 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #909: GFLOPs: 929.2758. Time: 249.2397 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #910: GFLOPs: 888.7703. Time: 260.5987 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #911: GFLOPs: 928.5152. Time: 249.4439 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #912: GFLOPs: 914.2845. Time: 253.3264 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #913: GFLOPs: 910.8047. Time: 254.2943 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #914: GFLOPs: 989.5612. Time: 234.0557 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #915: GFLOPs: 892.7335. Time: 259.4418 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #916: GFLOPs: 883.2140. Time: 262.2382 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #917: GFLOPs: 914.8637. Time: 253.1660 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #918: GFLOPs: 869.2186. Time: 266.4605 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #919: GFLOPs: 970.5058. Time: 238.6512 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #920: GFLOPs: 889.0618. Time: 260.5133 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #921: GFLOPs: 915.9633. Time: 252.8621 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #922: GFLOPs: 863.0324. Time: 268.3705 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #923: GFLOPs: 895.6385. Time: 258.6003 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #924: GFLOPs: 920.6800. Time: 251.5667 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #925: GFLOPs: 907.0233. Time: 255.3544 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #926: GFLOPs: 936.2430. Time: 247.3849 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #927: GFLOPs: 911.1587. Time: 254.1955 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #928: GFLOPs: 823.7338. Time: 281.1739 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #929: GFLOPs: 734.9493. Time: 315.1407 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #930: GFLOPs: 790.7734. Time: 292.8935 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #931: GFLOPs: 966.9421. Time: 239.5308 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #932: GFLOPs: 918.0901. Time: 252.2763 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #933: GFLOPs: 917.8962. Time: 252.3296 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #934: GFLOPs: 903.1940. Time: 256.4371 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #935: GFLOPs: 74.6196. Time: 3103.9069 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #936: GFLOPs: 775.2704. Time: 298.7505 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #937: GFLOPs: 935.8098. Time: 247.4995 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #938: GFLOPs: 872.7957. Time: 265.3684 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #939: GFLOPs: 871.9166. Time: 265.6360 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #940: GFLOPs: 816.5859. Time: 283.6351 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #941: GFLOPs: 199.0500. Time: 1163.5894 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #942: GFLOPs: 860.1641. Time: 269.2654 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #943: GFLOPs: 862.4542. Time: 268.5504 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #944: GFLOPs: 891.4617. Time: 259.8120 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #945: GFLOPs: 839.7015. Time: 275.8271 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #946: GFLOPs: 829.6051. Time: 279.1839 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #947: GFLOPs: 870.9339. Time: 265.9357 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #948: GFLOPs: 871.3087. Time: 265.8213 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #949: GFLOPs: 444.5104. Time: 521.0506 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #950: GFLOPs: 131.5792. Time: 1760.2506 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #951: GFLOPs: 842.5661. Time: 274.8893 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #952: GFLOPs: 849.9389. Time: 272.5048 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #953: GFLOPs: 841.5305. Time: 275.2276 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #954: GFLOPs: 674.8355. Time: 343.2132 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #955: GFLOPs: 845.9108. Time: 273.8024 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #956: GFLOPs: 848.3830. Time: 273.0045 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #957: GFLOPs: 675.3894. Time: 342.9316 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #958: GFLOPs: 130.8142. Time: 1770.5452 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #959: GFLOPs: 159.7539. Time: 1449.8080 us. Best GFLOPs: 1062.5408
2024-04-29 02:31:35 [INFO] [task_scheduler.cc:131] [Task #8: fused_nn_contrib_conv2d_NCHWc_add_nn_relu_1] Trial #960: GFLOPs: 66.5859. Time: 3478.3980 us. Best GFLOPs: 1062.5408
