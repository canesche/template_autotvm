2024-04-28 20:35:37 [INFO] [task_scheduler.cc:160] Initializing Task #21: "fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2"
2024-04-28 20:35:37 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0, i1, i2, i3, i4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [i0, i1, i2, i3, i4])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n, oc_chunk, oh, ow, oc_block, ic, kh, kw in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16), T.int64(256), T.int64(3), T.int64(3)):
            with T.block("conv2d_NCHWc"):
                v_n, v_oc_chunk, v_oh, v_ow, v_oc_block, v_ic, v_kh, v_kw = T.axis.remap("SSSSSRRR", [n, oc_chunk, oh, ow, oc_block, ic, kh, kw])
                T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                with T.init():
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T_add[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4]
        for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
2024-04-28 20:35:38 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2024-04-28 20:35:38 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(3)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(14), T.int64(4)):
                    with T.block("data_pad"):
                        v_i0 = T.axis.spatial(T.int64(1), ax0)
                        v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(32) + ax1)
                        v_i2 = T.axis.spatial(T.int64(16), oh_0 * T.int64(2) + ax2)
                        v_i3 = T.axis.spatial(T.int64(16), kw_0 + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(32) * T.int64(4) + ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)):
                with T.block("T_relu"):
                    v_ax0, v_ax1, v_ax2, v_ax3, v_ax4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=12)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
2024-04-28 20:35:38 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0 in T.grid(T.int64(1), T.int64(2)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2, v_i3, v_i4 = T.axis.remap("SSSSS", [ax0, ax1, ax2, ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_0, ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(7), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                        with T.block("conv2d_NCHWc"):
                            v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            with T.init():
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                    for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(14), T.int64(2)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + ax4)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-28 20:35:38 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.parallel": 768, "meta_schedule.unroll_explicit": 0, "meta_schedule.vectorize": 64})
            conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
            for n_0, oc_chunk_0, oh_0, ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2), T.int64(7), T.int64(1), T.int64(8)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1, ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(2), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc"):
                        v_n = T.axis.spatial(T.int64(1), n_0 + n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        with T.init():
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(8), T.int64(2), T.int64(14), T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_0 * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), oh_0 * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(2) + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 8, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 1, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
2024-04-28 20:58:55 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 20:58:55 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2024-04-28 20:59:01 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 20:59:01 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2024-04-28 20:59:07 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 20:59:13 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 20:59:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 20:59:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 20:59:27 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9997  0.9993  0.9992  0.9989  0.9987  0.9986  0.9985  0.9983  0.9983  0.9980  0.9980  0.9974  0.9972  0.9965  0.9959
[17 : 32]:	0.9953  0.9951  0.9948  0.9934  0.9930  0.9923  0.9912  0.9909  0.9899  0.9897  0.9892  0.9889  0.9885  0.9882  0.9880  0.9870
[33 : 48]:	0.9869  0.9862  0.9860  0.9857  0.9853  0.9846  0.9845  0.9843  0.9839  0.9819  0.9812  0.9811  0.9811  0.9803  0.9798  0.9793
[49 : 64]:	0.9788  0.9785  0.9769  0.9766  0.9765  0.9757  0.9753  0.9748  0.9743  0.9730  0.9723  0.9721  0.9715  0.9712  0.9709  0.9707
2024-04-28 20:59:27 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 20:59:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1: GFLOPs: 5.2195. Time: 44326.4457 us. Best GFLOPs: 5.2195
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #2: GFLOPs: 70.5934. Time: 3277.3811 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #3: GFLOPs: 34.1913. Time: 6766.6707 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #4: GFLOPs: 6.4028. Time: 36134.6403 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #5: GFLOPs: 7.4597. Time: 31014.7430 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #6: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused in T.parallel(T.int64(784), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ow_2_init + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0 in T.grid(T.int64(8), T.int64(3)):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                    for ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("data_pad"):
                            v_i0 = T.axis.spatial(T.int64(1), ax0)
                            v_i1 = T.axis.spatial(T.int64(2), ic_0 // T.int64(4) + ax1)
                            v_i2 = T.axis.spatial(T.int64(16), kh_0 + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + ax2)
                            v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ax3)
                            v_i4 = T.axis.spatial(T.int64(128), ic_0 % T.int64(4) * T.int64(32) + ax4_fused)
                            T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                            T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                            data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(4), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(2)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused // T.int64(392) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(392) // T.int64(56) * T.int64(2) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=11)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88 = sch.get_loops(block=b69)
l89 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, preserve_unit_iters=True)
sch.parallel(loop=l89)
l90 = sch.fuse(l88, preserve_unit_iters=True)
sch.vectorize(loop=l90)
l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l91, preserve_unit_iters=True)
sch.parallel(loop=l108)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b116)
b134 = sch.decompose_reduction(block=b116, loop=l118)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #7: GFLOPs: 1.7022. Time: 135915.2210 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #8: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(7), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(14), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(2) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(56) // T.int64(8) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b117)
b138 = sch.decompose_reduction(block=b117, loop=l122)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #9: GFLOPs: 13.3397. Time: 17343.8508 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #10: GFLOPs: 11.5905. Time: 19961.2595 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #11: GFLOPs: 1.4705. Time: 157335.6360 us. Best GFLOPs: 70.5934
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #12: GFLOPs: 89.7898. Time: 2576.7029 us. Best GFLOPs: 89.7898
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #13: GFLOPs: 8.3801. Time: 27608.5890 us. Best GFLOPs: 89.7898
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #14: GFLOPs: 129.4427. Time: 1787.3669 us. Best GFLOPs: 129.4427
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #15: GFLOPs: 124.5032. Time: 1858.2785 us. Best GFLOPs: 129.4427
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #16: GFLOPs: 22.4209. Time: 10319.0140 us. Best GFLOPs: 129.4427
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #17: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(14), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0 in T.grid(T.int64(1), T.int64(2)):
                for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2_init + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(8) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                        for oc_block_3_fused in T.vectorized(T.int64(8)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused + oh_1 + oh_2 + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(8) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(1), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(8)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[14, 1, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 1, 8])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114 = sch.get_loops(block=b71)
l115 = sch.fuse(l114, preserve_unit_iters=True)
sch.vectorize(loop=l115)
b116 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140 = sch.get_loops(block=b116)
b141 = sch.decompose_reduction(block=b116, loop=l125)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #18: GFLOPs: 132.0877. Time: 1751.5750 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #19: GFLOPs: 5.2717. Time: 43887.1547 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #20: GFLOPs: 1.5274. Time: 151476.6713 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #21: GFLOPs: 18.1685. Time: 12734.2085 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #22: GFLOPs: 6.7521. Time: 34264.9310 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #23: GFLOPs: 73.5498. Time: 3145.6433 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #24: GFLOPs: 10.0334. Time: 23059.2022 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #25: GFLOPs: 19.4089. Time: 11920.3734 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #26: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(28) * T.int64(2) + oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(28) // T.int64(4) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 * T.int64(2) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[8, 1, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 14, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #27: GFLOPs: 10.3804. Time: 22288.2266 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #28: GFLOPs: 0.4863. Time: 475758.0563 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #29: GFLOPs: 0.8587. Time: 269443.2377 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #30: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(16), T.int64(2), T.int64(2), T.int64(2), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(2)):
                    for ax4_fused in T.vectorized(T.int64(4)):
                        with T.block("T_relu"):
                            v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(14) * T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(8) + oc_block_1 * T.int64(4) + ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 2, 2, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133 = sch.get_loops(block=b115)
b134 = sch.decompose_reduction(block=b115, loop=l118)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #31: GFLOPs: 44.1401. Time: 5241.5219 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #32: GFLOPs: 23.4728. Time: 9856.5892 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #33: GFLOPs: 1.2936. Time: 178852.3290 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #34: GFLOPs: 29.5508. Time: 7829.2852 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #35: GFLOPs: 9.2530. Time: 25003.9162 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #36: GFLOPs: 18.6798. Time: 12385.6527 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #37: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(65536)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_i4_fused // T.int64(32768))
                v_i2 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(32768) // T.int64(2048))
                v_i3 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(2048) // T.int64(128))
                v_i4 = T.axis.spatial(T.int64(128), i0_i1_i2_i3_i4_fused % T.int64(128))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(8), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(7) + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(7), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(7) + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 2, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[8, 2, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b71)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #38: GFLOPs: 42.0379. Time: 5503.6403 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #39: GFLOPs: 21.9971. Time: 10517.8254 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #40: GFLOPs: 3.2938. Time: 70241.4953 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #41: GFLOPs: 44.9079. Time: 5151.9089 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #42: GFLOPs: 81.4011. Time: 2842.2415 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #43: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(98), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(2), T.int64(1), T.int64(2), T.int64(2), T.int64(2), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(49) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(32), T.int64(3), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(49) * T.int64(8) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(49) * T.int64(8) + oc_chunk_1 * T.int64(4) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_1 + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(8) + oc_block_1 + ax4)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 2, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
b118 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b118)
b142 = sch.decompose_reduction(block=b118, loop=l126)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #44: GFLOPs: 18.0407. Time: 12824.4325 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #45: GFLOPs: 33.6255. Time: 6880.5281 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #46: GFLOPs: 74.7196. Time: 3096.3976 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #47: GFLOPs: 18.1052. Time: 12778.7341 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #48: GFLOPs: 47.5371. Time: 4866.9701 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #49: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(2) + ax2)
                    v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_0, oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(2), T.int64(7), T.int64(4), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(4)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + oc_chunk_1 * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_0 * T.int64(14) + ow_1 * T.int64(14) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(2), T.int64(14)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_fused_fused // T.int64(7) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_fused_fused % T.int64(7) * T.int64(2) + ax2)
                            v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 1, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 7, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 4, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79 = sch.get_loops(block=b69)
l80 = sch.fuse(l72, l73, l74, preserve_unit_iters=True)
sch.parallel(loop=l80)
l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l81, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119 = sch.get_loops(block=b71)
l120 = sch.fuse(l119, preserve_unit_iters=True)
sch.vectorize(loop=l120)
b121 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143, l144, l145 = sch.get_loops(block=b121)
b146 = sch.decompose_reduction(block=b121, loop=l130)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #50: GFLOPs: 77.3438. Time: 2991.3372 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #51: GFLOPs: 42.5942. Time: 5431.7622 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #52: GFLOPs: 12.1145. Time: 19097.9280 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #53: GFLOPs: 56.7502. Time: 4076.8412 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #54: GFLOPs: 18.5228. Time: 12490.6183 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #55: GFLOPs: 6.3710. Time: 36314.7000 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #56: GFLOPs: 4.8866. Time: 47346.2380 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #57: GFLOPs: 6.3332. Time: 36531.4807 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #58: GFLOPs: 50.1606. Time: 4612.4119 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #59: GFLOPs: 62.1965. Time: 3719.8460 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #60: GFLOPs: 3.6081. Time: 64122.8927 us. Best GFLOPs: 132.0877
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #61: GFLOPs: 251.1899. Time: 921.0622 us. Best GFLOPs: 251.1899
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #62: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused in T.parallel(T.int64(64), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_init"):
                    v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(8) + oc_chunk_2_init * T.int64(4) + oc_chunk_3_init)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + oh_2_init * T.int64(7) + oh_3_init)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) * T.int64(2) + oc_block_2_init + oc_block_3_init)
                    T.reads()
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
            for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(8), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(32), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(7), T.int64(7), T.int64(1)):
                with T.block("conv2d_NCHWc_update"):
                    v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                    v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(8) + oc_chunk_2 * T.int64(4) + oc_chunk_3)
                    v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + oh_2 * T.int64(7) + oh_3)
                    v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                    v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) * T.int64(2) + oc_block_2 + oc_block_3)
                    v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(32) + ic_1)
                    v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                    v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                    T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                    T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                    T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                    conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + T.if_then_else(T.int64(1) <= v_oh + v_kh and v_oh + v_kh < T.int64(15) and T.int64(1) <= v_ow + v_kw and v_ow + v_kw < T.int64(15), p0[v_n, v_ic // T.int64(128), v_oh + v_kh - T.int64(1), v_ow + v_kw - T.int64(1), v_ic % T.int64(128)], T.float32(0)) * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(7), T.int64(7)):
                for ax4_fused in T.vectorized(T.int64(2)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(16) // T.int64(8) * T.int64(8) + ax1)
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(8) // T.int64(4) * T.int64(7) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused // T.int64(32) * T.int64(7) + ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(32) // T.int64(16) * T.int64(8) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_oc_block_1_fused % T.int64(4) * T.int64(2) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 2, 2, 4])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 4, 2, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[8, 32])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-2)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70 = sch.get_child_blocks(b68)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96 = sch.get_loops(block=b69)
l97 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l97)
sch.annotate(block_or_loop=l97, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l97, ann_key="pragma_unroll_explicit", ann_val=1)
l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l104)
b105 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l106, l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118, l119, l120, l121, l122 = sch.get_loops(block=b105)
b123 = sch.decompose_reduction(block=b105, loop=l107)
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #63: GFLOPs: 51.3035. Time: 4509.6643 us. Best GFLOPs: 251.1899
2024-04-28 21:12:44 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #64: GFLOPs: 58.6200. Time: 3946.8035 us. Best GFLOPs: 251.1899
2024-04-28 21:25:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:25:38 [INFO] [evolutionary_search.cc:715] Picked top 55 candidate(s) from database
2024-04-28 21:25:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:25:43 [INFO] [evolutionary_search.cc:723] Sampled 457 candidate(s)
2024-04-28 21:25:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:26:08 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:26:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:26:34 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:26:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9503  0.8660  0.8468  0.8456  0.8446  0.8441  0.8276  0.8179  0.8109  0.8017  0.8010  0.7923  0.7812  0.7797  0.7744  0.7674
[17 : 32]:	0.7632  0.7556  0.7536  0.7516  0.7512  0.7471  0.7464  0.7464  0.7464  0.7453  0.7445  0.7437  0.7425  0.7389  0.7388  0.7388
[33 : 48]:	0.7388  0.7388  0.7388  0.7298  0.7259  0.7249  0.7248  0.7204  0.7204  0.7179  0.7179  0.7102  0.7093  0.7076  0.7046  0.7024
[49 : 64]:	0.7022  0.7022  0.7016  0.7016  0.6999  0.6970  0.6958  0.6958  0.6958  0.6958  0.6948  0.6904  0.6865  0.6823  0.6819  0.6813
2024-04-28 21:26:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:26:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #65: GFLOPs: 223.7172. Time: 1034.1695 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #66: GFLOPs: 152.2654. Time: 1519.4625 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #67: GFLOPs: 103.7343. Time: 2230.3274 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #68: GFLOPs: 108.6356. Time: 2129.7032 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #69: GFLOPs: 93.7860. Time: 2466.9095 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #70: GFLOPs: 235.7971. Time: 981.1892 us. Best GFLOPs: 251.1899
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #71: GFLOPs: 265.6486. Time: 870.9309 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #72: GFLOPs: 68.0365. Time: 3400.5479 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #73: GFLOPs: 146.3417. Time: 1580.9677 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #74: GFLOPs: 227.5554. Time: 1016.7263 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #75: GFLOPs: 225.4425. Time: 1026.2551 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #76: GFLOPs: 105.7186. Time: 2188.4656 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #77: GFLOPs: 107.8784. Time: 2144.6509 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #78: GFLOPs: 118.7293. Time: 1948.6472 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #79: GFLOPs: 100.9934. Time: 2290.8575 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #80: GFLOPs: 14.6108. Time: 15835.0150 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #81: GFLOPs: 149.9269. Time: 1543.1619 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #82: GFLOPs: 88.7919. Time: 2605.6592 us. Best GFLOPs: 265.6486
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #83: GFLOPs: 276.1598. Time: 837.7814 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #84: GFLOPs: 11.1893. Time: 20676.9794 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #85: GFLOPs: 260.7389. Time: 887.3302 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #86: GFLOPs: 213.5589. Time: 1083.3618 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #87: GFLOPs: 73.7961. Time: 3135.1455 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #88: GFLOPs: 84.8436. Time: 2726.9188 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #89: GFLOPs: 84.8176. Time: 2727.7523 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #90: GFLOPs: 74.6921. Time: 3097.5369 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #91: GFLOPs: 129.8874. Time: 1781.2464 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #92: GFLOPs: 129.8742. Time: 1781.4278 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #93: GFLOPs: 68.2861. Time: 3388.1219 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #94: GFLOPs: 147.6617. Time: 1566.8351 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #95: GFLOPs: 206.0562. Time: 1122.8077 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #96: GFLOPs: 162.7341. Time: 1421.7149 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #97: GFLOPs: 121.3587. Time: 1906.4265 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #98: GFLOPs: 113.5296. Time: 2037.8960 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #99: GFLOPs: 202.8932. Time: 1140.3121 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #100: GFLOPs: 123.5383. Time: 1872.7917 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #101: GFLOPs: 11.7344. Time: 19716.4443 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #102: GFLOPs: 157.3891. Time: 1469.9970 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #103: GFLOPs: 134.6558. Time: 1718.1705 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #104: GFLOPs: 12.5503. Time: 18434.6987 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #105: GFLOPs: 12.6464. Time: 18294.6780 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #106: GFLOPs: 71.9930. Time: 3213.6659 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #107: GFLOPs: 109.3267. Time: 2116.2397 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #108: GFLOPs: 118.7566. Time: 1948.1989 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #109: GFLOPs: 127.9100. Time: 1808.7845 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #110: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(49), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #111: GFLOPs: 90.1787. Time: 2565.5895 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #112: GFLOPs: 108.8985. Time: 2124.5606 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #113: GFLOPs: 166.8774. Time: 1386.4164 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #114: GFLOPs: 144.0296. Time: 1606.3473 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #115: GFLOPs: 96.5546. Time: 2396.1733 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #116: GFLOPs: 129.7870. Time: 1782.6245 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #117: GFLOPs: 204.1892. Time: 1133.0745 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #118: GFLOPs: 153.8341. Time: 1503.9679 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #119: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(49), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #120: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(49), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #121: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_fused_fused in T.parallel(T.int64(49), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_0, n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(2), T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2_init * T.int64(16) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(1), T.int64(2)):
                    for oc_block_3_fused in T.vectorized(T.int64(16)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + oh_2 + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_0 * T.int64(16) + oc_block_1 * T.int64(16) + oc_block_2 * T.int64(16) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(8) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2 in T.grid(T.int64(1), T.int64(4), T.int64(1)):
                    for ax3_ax4_fused in T.vectorized(T.int64(32)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused // T.int64(7) * T.int64(2) + oh_1 + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_fused_fused % T.int64(7) * T.int64(2) + ax3_ax4_fused // T.int64(16))
                            v_ax4 = T.axis.spatial(T.int64(16), ax3_ax4_fused % T.int64(16))
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 2, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 1, 16])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[32, 8])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=3)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b69)
l81 = sch.fuse(l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l105)
l106 = sch.fuse(l104, preserve_unit_iters=True)
sch.vectorize(loop=l106)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l107, l108, l109, l110, l111, l112, l113, l114, l115, l116, l117, l118 = sch.get_loops(block=b71)
l119 = sch.fuse(l117, l118, preserve_unit_iters=True)
sch.vectorize(loop=l119)
b120 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141, l142, l143 = sch.get_loops(block=b120)
b144 = sch.decompose_reduction(block=b120, loop=l128)
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #122: GFLOPs: 62.0103. Time: 3731.0171 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #123: GFLOPs: 101.2122. Time: 2285.9052 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #124: GFLOPs: 119.3716. Time: 1938.1624 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #125: GFLOPs: 137.4000. Time: 1683.8535 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #126: GFLOPs: 4.9319. Time: 46911.4243 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #127: GFLOPs: 19.5238. Time: 11850.2561 us. Best GFLOPs: 276.1598
2024-04-28 21:28:03 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #128: GFLOPs: 93.4950. Time: 2474.5877 us. Best GFLOPs: 276.1598
2024-04-28 21:33:16 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 21:33:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 21:33:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:33:22 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 21:33:34 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:33:47 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:33:59 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:34:11 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 21:34:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9427  0.9254  0.9048  0.8851  0.8754  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618  0.8618
[17 : 32]:	0.8618  0.8583  0.8420  0.8407  0.8376  0.8123  0.8058  0.8029  0.7933  0.7917  0.7914  0.7891  0.7829  0.7818  0.7790  0.7766
[33 : 48]:	0.7731  0.7731  0.7731  0.7731  0.7731  0.7718  0.7689  0.7669  0.7624  0.7606  0.7569  0.7550  0.7544  0.7524  0.7465  0.7443
[49 : 64]:	0.7443  0.7429  0.7308  0.7258  0.7180  0.7173  0.7159  0.7143  0.7072  0.6994  0.6960  0.6944  0.6857  0.6838  0.6746  0.6744
2024-04-28 21:34:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 21:34:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #129: GFLOPs: 83.1958. Time: 2780.9272 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #130: GFLOPs: 227.3713. Time: 1017.5494 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #131: GFLOPs: 271.2300. Time: 853.0087 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #132: GFLOPs: 187.5513. Time: 1233.5904 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #133: GFLOPs: 167.4952. Time: 1381.3027 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #134: GFLOPs: 217.3395. Time: 1064.5166 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #135: GFLOPs: 128.5284. Time: 1800.0809 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #136: GFLOPs: 159.1029. Time: 1454.1626 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #137: GFLOPs: 139.1245. Time: 1662.9826 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #138: GFLOPs: 152.6330. Time: 1515.8025 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #139: GFLOPs: 188.3659. Time: 1228.2557 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #140: GFLOPs: 169.2708. Time: 1366.8132 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #141: GFLOPs: 187.5947. Time: 1233.3051 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #142: GFLOPs: 126.7786. Time: 1824.9253 us. Best GFLOPs: 276.1598
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #143: GFLOPs: 296.1038. Time: 781.3529 us. Best GFLOPs: 296.1038
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #144: GFLOPs: 167.9094. Time: 1377.8949 us. Best GFLOPs: 296.1038
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #145: GFLOPs: 265.3199. Time: 872.0099 us. Best GFLOPs: 296.1038
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #146: GFLOPs: 285.2135. Time: 811.1871 us. Best GFLOPs: 296.1038
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #147: GFLOPs: 322.8978. Time: 716.5162 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #148: GFLOPs: 136.0821. Time: 1700.1608 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #149: GFLOPs: 204.5014. Time: 1131.3444 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #150: GFLOPs: 276.2722. Time: 837.4404 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #151: GFLOPs: 94.7051. Time: 2442.9688 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #152: GFLOPs: 176.3232. Time: 1312.1446 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #153: GFLOPs: 168.5732. Time: 1372.4695 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #154: GFLOPs: 265.0175. Time: 873.0047 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #155: GFLOPs: 102.6779. Time: 2253.2747 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #156: GFLOPs: 285.8066. Time: 809.5039 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #157: GFLOPs: 95.5671. Time: 2420.9333 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #158: GFLOPs: 59.0943. Time: 3915.1227 us. Best GFLOPs: 322.8978
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #159: GFLOPs: 409.2860. Time: 565.2808 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #160: GFLOPs: 279.1323. Time: 828.8598 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #161: GFLOPs: 86.7522. Time: 2666.9248 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #162: GFLOPs: 136.1767. Time: 1698.9799 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #163: GFLOPs: 117.6122. Time: 1967.1554 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #164: GFLOPs: 117.4704. Time: 1969.5299 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #165: GFLOPs: 95.8270. Time: 2414.3677 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #166: GFLOPs: 92.1953. Time: 2509.4711 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #167: GFLOPs: 134.0719. Time: 1725.6525 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #168: GFLOPs: 174.7135. Time: 1324.2341 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #169: GFLOPs: 76.3968. Time: 3028.4180 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #170: GFLOPs: 151.3451. Time: 1528.7019 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #171: GFLOPs: 175.0625. Time: 1321.5936 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #172: GFLOPs: 140.7232. Time: 1644.0899 us. Best GFLOPs: 409.2860
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #173: GFLOPs: 411.4646. Time: 562.2878 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #174: GFLOPs: 315.1318. Time: 734.1740 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #175: GFLOPs: 335.3906. Time: 689.8271 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #176: GFLOPs: 226.0219. Time: 1023.6243 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #177: GFLOPs: 167.3071. Time: 1382.8555 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #178: GFLOPs: 242.2541. Time: 955.0368 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #179: GFLOPs: 67.2077. Time: 3442.4845 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #180: GFLOPs: 284.8203. Time: 812.3071 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #181: GFLOPs: 93.8186. Time: 2466.0530 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #182: GFLOPs: 311.1943. Time: 743.4632 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #183: GFLOPs: 241.5641. Time: 957.7647 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #184: GFLOPs: 236.6733. Time: 977.5564 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #185: GFLOPs: 209.0822. Time: 1106.5578 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #186: GFLOPs: 134.2575. Time: 1723.2674 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #187: GFLOPs: 364.9086. Time: 634.0259 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #188: GFLOPs: 143.6881. Time: 1610.1646 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #189: GFLOPs: 98.4601. Time: 2349.8011 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #190: GFLOPs: 8.1105. Time: 28526.1327 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #191: GFLOPs: 31.5261. Time: 7338.7354 us. Best GFLOPs: 411.4646
2024-04-28 21:35:38 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #192: GFLOPs: 35.5558. Time: 6507.0012 us. Best GFLOPs: 411.4646
2024-04-28 22:04:52 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:04:53 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:04:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:04:58 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:05:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:05:22 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:05:34 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:05:46 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:05:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9744  0.9534  0.9534  0.9281  0.9247  0.8081  0.8081  0.7830  0.7710  0.7575  0.7383  0.7383  0.7352  0.7299  0.7297  0.7297
[17 : 32]:	0.7251  0.7251  0.7145  0.7145  0.7078  0.7078  0.7037  0.7036  0.7009  0.7009  0.6976  0.6938  0.6862  0.6862  0.6822  0.6810
[33 : 48]:	0.6802  0.6789  0.6789  0.6789  0.6789  0.6776  0.6776  0.6744  0.6632  0.6501  0.6475  0.6441  0.6438  0.6380  0.6369  0.6350
[49 : 64]:	0.6316  0.6263  0.6194  0.6183  0.6169  0.6108  0.6101  0.6087  0.6059  0.6054  0.6050  0.6034  0.5983  0.5890  0.5880  0.5864
2024-04-28 22:05:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:05:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #193: GFLOPs: 410.0905. Time: 564.1719 us. Best GFLOPs: 411.4646
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #194: GFLOPs: 378.5645. Time: 611.1549 us. Best GFLOPs: 411.4646
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #195: GFLOPs: 193.6892. Time: 1194.4991 us. Best GFLOPs: 411.4646
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #196: GFLOPs: 415.0140. Time: 557.4789 us. Best GFLOPs: 415.0140
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #197: GFLOPs: 586.3739. Time: 394.5632 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #198: GFLOPs: 374.1872. Time: 618.3042 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #199: GFLOPs: 375.2353. Time: 616.5772 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #200: GFLOPs: 321.0301. Time: 720.6848 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #201: GFLOPs: 315.2210. Time: 733.9661 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #202: GFLOPs: 301.9608. Time: 766.1972 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #203: GFLOPs: 261.9396. Time: 883.2629 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #204: GFLOPs: 282.1851. Time: 819.8929 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #205: GFLOPs: 322.6607. Time: 717.0427 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #206: GFLOPs: 116.4798. Time: 1986.2809 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #207: GFLOPs: 321.7903. Time: 718.9822 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #208: GFLOPs: 120.8782. Time: 1914.0049 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #209: GFLOPs: 281.9052. Time: 820.7068 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #210: GFLOPs: 281.6466. Time: 821.4604 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #211: GFLOPs: 279.9985. Time: 826.2957 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #212: GFLOPs: 129.5836. Time: 1785.4225 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #213: GFLOPs: 288.5720. Time: 801.7462 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #214: GFLOPs: 110.7069. Time: 2089.8568 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #215: GFLOPs: 295.6026. Time: 782.6777 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #216: GFLOPs: 366.4420. Time: 631.3729 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #217: GFLOPs: 98.6887. Time: 2344.3562 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #218: GFLOPs: 190.6077. Time: 1213.8097 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #219: GFLOPs: 284.6668. Time: 812.7450 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #220: GFLOPs: 75.1107. Time: 3080.2743 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #221: GFLOPs: 155.5731. Time: 1487.1569 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #222: GFLOPs: 156.6632. Time: 1476.8082 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #223: GFLOPs: 255.5010. Time: 905.5210 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #224: GFLOPs: 347.1816. Time: 666.3991 us. Best GFLOPs: 586.3739
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #225: GFLOPs: 596.4778. Time: 387.8796 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #226: GFLOPs: 286.2534. Time: 808.2404 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #227: GFLOPs: 131.7203. Time: 1756.4610 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #228: GFLOPs: 128.7325. Time: 1797.2265 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #229: GFLOPs: 189.9198. Time: 1218.2062 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #230: GFLOPs: 168.5570. Time: 1372.6008 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #231: GFLOPs: 168.2157. Time: 1375.3862 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #232: GFLOPs: 374.2616. Time: 618.1813 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #233: GFLOPs: 327.7915. Time: 705.8191 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #234: GFLOPs: 245.6966. Time: 941.6553 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #235: GFLOPs: 160.8020. Time: 1438.7975 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #236: GFLOPs: 121.7675. Time: 1900.0276 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #237: GFLOPs: 88.2423. Time: 2621.8906 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #238: GFLOPs: 401.7856. Time: 575.8334 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #239: GFLOPs: 369.6648. Time: 625.8685 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #240: GFLOPs: 174.6514. Time: 1324.7047 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #241: GFLOPs: 419.2046. Time: 551.9060 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #242: GFLOPs: 237.0979. Time: 975.8060 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #243: GFLOPs: 141.9227. Time: 1630.1937 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #244: GFLOPs: 186.8380. Time: 1238.3002 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #245: GFLOPs: 236.5704. Time: 977.9817 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #246: GFLOPs: 303.3308. Time: 762.7367 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #247: GFLOPs: 93.7725. Time: 2467.2645 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #248: GFLOPs: 123.5881. Time: 1872.0373 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #249: GFLOPs: 287.4245. Time: 804.9471 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #250: GFLOPs: 365.6776. Time: 632.6927 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #251: GFLOPs: 123.9280. Time: 1866.9029 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #252: GFLOPs: 244.0173. Time: 948.1360 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #253: GFLOPs: 134.1643. Time: 1724.4640 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #254: GFLOPs: 130.1107. Time: 1778.1899 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #255: GFLOPs: 3.1612. Time: 73186.7383 us. Best GFLOPs: 596.4778
2024-04-28 22:07:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #256: GFLOPs: 11.9239. Time: 19403.1580 us. Best GFLOPs: 596.4778
2024-04-28 22:22:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:22:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:22:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:22:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:22:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:23:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:23:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:23:26 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:23:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9644  0.9469  0.9469  0.9469  0.9466  0.9457  0.9427  0.9401  0.9323  0.9323  0.9260  0.9232  0.9232  0.9124  0.9103  0.9096
[17 : 32]:	0.9086  0.9079  0.9051  0.9044  0.9044  0.9002  0.8995  0.8948  0.8919  0.8906  0.8825  0.8807  0.8714  0.8659  0.8648  0.8450
[33 : 48]:	0.8418  0.8336  0.8334  0.8305  0.8268  0.8224  0.8223  0.8219  0.8219  0.8077  0.8019  0.8008  0.7989  0.7933  0.7898  0.7881
[49 : 64]:	0.7815  0.7769  0.7766  0.7752  0.7687  0.7669  0.7654  0.7630  0.7577  0.7572  0.7572  0.7538  0.7494  0.7491  0.7378  0.7373
2024-04-28 22:23:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:23:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #257: GFLOPs: 355.9623. Time: 649.9607 us. Best GFLOPs: 596.4778
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #258: GFLOPs: 617.5038. Time: 374.6722 us. Best GFLOPs: 617.5038
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #259: GFLOPs: 614.1390. Time: 376.7250 us. Best GFLOPs: 617.5038
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #260: GFLOPs: 616.6512. Time: 375.1903 us. Best GFLOPs: 617.5038
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #261: GFLOPs: 580.6445. Time: 398.4565 us. Best GFLOPs: 617.5038
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #262: GFLOPs: 697.9617. Time: 331.4817 us. Best GFLOPs: 697.9617
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #263: GFLOPs: 368.7033. Time: 627.5006 us. Best GFLOPs: 697.9617
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #264: GFLOPs: 715.9567. Time: 323.1502 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #265: GFLOPs: 327.6275. Time: 706.1725 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #266: GFLOPs: 328.2554. Time: 704.8217 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #267: GFLOPs: 598.5593. Time: 386.5307 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #268: GFLOPs: 613.3523. Time: 377.2083 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #269: GFLOPs: 340.8475. Time: 678.7832 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #270: GFLOPs: 503.8731. Time: 459.1663 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #271: GFLOPs: 509.1307. Time: 454.4247 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #272: GFLOPs: 522.0598. Time: 443.1705 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #273: GFLOPs: 325.8497. Time: 710.0253 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #274: GFLOPs: 536.6263. Time: 431.1409 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #275: GFLOPs: 474.1003. Time: 488.0012 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #276: GFLOPs: 613.5158. Time: 377.1077 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #277: GFLOPs: 619.0651. Time: 373.7273 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #278: GFLOPs: 337.3515. Time: 685.8175 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #279: GFLOPs: 338.4509. Time: 683.5896 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #280: GFLOPs: 587.3282. Time: 393.9221 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #281: GFLOPs: 519.0891. Time: 445.7068 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #282: GFLOPs: 608.5827. Time: 380.1645 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #283: GFLOPs: 481.8641. Time: 480.1386 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #284: GFLOPs: 633.4491. Time: 365.2409 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #285: GFLOPs: 623.0168. Time: 371.3568 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #286: GFLOPs: 646.8347. Time: 357.6826 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #287: GFLOPs: 494.9714. Time: 467.4241 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #288: GFLOPs: 395.5148. Time: 584.9631 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #289: GFLOPs: 322.2346. Time: 717.9909 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #290: GFLOPs: 95.6241. Time: 2419.4905 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #291: GFLOPs: 589.6807. Time: 392.3505 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #292: GFLOPs: 707.8316. Time: 326.8596 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #293: GFLOPs: 494.8810. Time: 467.5094 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #294: GFLOPs: 506.9256. Time: 456.4014 us. Best GFLOPs: 715.9567
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #295: GFLOPs: 772.0683. Time: 299.6646 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #296: GFLOPs: 324.8627. Time: 712.1825 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #297: GFLOPs: 330.0276. Time: 701.0370 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #298: GFLOPs: 154.1812. Time: 1500.5821 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #299: GFLOPs: 473.8114. Time: 488.2988 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #300: GFLOPs: 417.6358. Time: 553.9792 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #301: GFLOPs: 155.6716. Time: 1486.2159 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #302: GFLOPs: 420.4463. Time: 550.2761 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #303: GFLOPs: 696.2505. Time: 332.2964 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #304: GFLOPs: 337.8049. Time: 684.8970 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #305: GFLOPs: 100.9016. Time: 2292.9422 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #306: GFLOPs: 103.4804. Time: 2235.7995 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #307: GFLOPs: 65.3068. Time: 3542.6879 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #308: GFLOPs: 141.1175. Time: 1639.4951 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #309: GFLOPs: 276.2117. Time: 837.6239 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #310: GFLOPs: 128.3942. Time: 1801.9631 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #311: GFLOPs: 433.1748. Time: 534.1067 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #312: GFLOPs: 432.5785. Time: 534.8428 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #313: GFLOPs: 365.8987. Time: 632.3104 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #314: GFLOPs: 271.7686. Time: 851.3181 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #315: GFLOPs: 238.9618. Time: 968.1947 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #316: GFLOPs: 407.9046. Time: 567.1952 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #317: GFLOPs: 554.7316. Time: 417.0693 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #318: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(16), T.int64(9), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1, v_i2 = T.axis.remap("SSS", [ax0, ax1, ax2])
                        v_i3 = T.axis.spatial(T.int64(16), ow_1 * T.int64(7) + ax3)
                        v_i4 = T.axis.spatial(T.int64(128), ax4)
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(7)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2_init * T.int64(14) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(3), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(14), T.int64(7)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + oc_chunk_1 * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(14) + oh_2 * T.int64(14) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 * T.int64(2) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(8), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(8)):
                    with T.block("T_relu"):
                        v_ax0 = T.axis.spatial(T.int64(1), ax0)
                        v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(2) * T.int64(8) + ax1)
                        v_ax2, v_ax3 = T.axis.remap("SS", [ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 1, 1, 14])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 4, 1, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[3, 1])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=9)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85, l86 = sch.get_loops(block=b69)
l87 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l87)
l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l88, preserve_unit_iters=True)
sch.parallel(loop=l110)
l111 = sch.fuse(l109, preserve_unit_iters=True)
sch.vectorize(loop=l111)
sch.annotate(block_or_loop=l110, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l110, ann_key="pragma_unroll_explicit", ann_val=1)
l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b71)
l118 = sch.fuse(l117, preserve_unit_iters=True)
sch.vectorize(loop=l118)
b119 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139, l140, l141 = sch.get_loops(block=b119)
b142 = sch.decompose_reduction(block=b119, loop=l126)
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #319: GFLOPs: 7.0752. Time: 32700.2845 us. Best GFLOPs: 772.0683
2024-04-28 22:25:09 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #320: GFLOPs: 27.3115. Time: 8471.2266 us. Best GFLOPs: 772.0683
2024-04-28 22:37:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 22:37:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 22:37:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:37:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 22:37:45 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:37:57 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:38:08 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:38:19 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 22:38:25 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9038  0.8962  0.8761  0.8750  0.8750  0.8750  0.8602  0.8564  0.8423  0.8419  0.8391  0.8391  0.8385  0.8223  0.8212  0.8211
[17 : 32]:	0.8139  0.8073  0.8056  0.8050  0.8050  0.7935  0.7935  0.7890  0.7888  0.7833  0.7714  0.7708  0.7703  0.7632  0.7628  0.7614
[33 : 48]:	0.7590  0.7556  0.7518  0.7518  0.7517  0.7487  0.7468  0.7373  0.7367  0.7358  0.7348  0.7307  0.7268  0.7253  0.7236  0.7215
[49 : 64]:	0.7187  0.7180  0.7170  0.7154  0.7067  0.7041  0.7041  0.7021  0.7007  0.7006  0.6962  0.6927  0.6924  0.6921  0.6921  0.6912
2024-04-28 22:38:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 22:38:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #321: GFLOPs: 357.5284. Time: 647.1137 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #322: GFLOPs: 353.8870. Time: 653.7724 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #323: GFLOPs: 691.5371. Time: 334.5613 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #324: GFLOPs: 542.7604. Time: 426.2682 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #325: GFLOPs: 547.1949. Time: 422.8138 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #326: GFLOPs: 549.3031. Time: 421.1910 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #327: GFLOPs: 700.2178. Time: 330.4137 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #328: GFLOPs: 674.5895. Time: 342.9664 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #329: GFLOPs: 702.3635. Time: 329.4043 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #330: GFLOPs: 614.2210. Time: 376.6748 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #331: GFLOPs: 768.0945. Time: 301.2149 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #332: GFLOPs: 771.5852. Time: 299.8522 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #333: GFLOPs: 686.0980. Time: 337.2136 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #334: GFLOPs: 601.6667. Time: 384.5344 us. Best GFLOPs: 772.0683
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #335: GFLOPs: 786.0016. Time: 294.3525 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #336: GFLOPs: 766.4719. Time: 301.8526 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #337: GFLOPs: 776.0936. Time: 298.1104 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #338: GFLOPs: 487.5157. Time: 474.5725 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #339: GFLOPs: 600.1464. Time: 385.5085 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #340: GFLOPs: 617.4139. Time: 374.7268 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #341: GFLOPs: 620.3475. Time: 372.9547 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #342: GFLOPs: 611.5522. Time: 378.3186 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #343: GFLOPs: 674.8729. Time: 342.8224 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #344: GFLOPs: 595.3829. Time: 388.5929 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #345: GFLOPs: 722.8400. Time: 320.0730 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #346: GFLOPs: 25.8918. Time: 8935.7192 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #347: GFLOPs: 596.0956. Time: 388.1282 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #348: GFLOPs: 746.9366. Time: 309.7472 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #349: GFLOPs: 606.1693. Time: 381.6781 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #350: GFLOPs: 674.0474. Time: 343.2422 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #351: GFLOPs: 585.3914. Time: 395.2254 us. Best GFLOPs: 786.0016
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #352: GFLOPs: 793.6937. Time: 291.4998 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #353: GFLOPs: 361.6486. Time: 639.7413 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #354: GFLOPs: 533.0104. Time: 434.0657 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #355: GFLOPs: 670.3774. Time: 345.1213 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #356: GFLOPs: 671.1081. Time: 344.7456 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #357: GFLOPs: 594.1662. Time: 389.3886 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #358: GFLOPs: 589.5435. Time: 392.4418 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #359: GFLOPs: 546.9829. Time: 422.9776 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #360: GFLOPs: 678.3338. Time: 341.0733 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #361: GFLOPs: 588.5025. Time: 393.1361 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #362: GFLOPs: 526.2652. Time: 439.6292 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #363: GFLOPs: 667.0028. Time: 346.8674 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #364: GFLOPs: 470.9233. Time: 491.2934 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #365: GFLOPs: 434.6698. Time: 532.2697 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #366: GFLOPs: 25.1150. Time: 9212.0935 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #367: GFLOPs: 597.5019. Time: 387.2147 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #368: GFLOPs: 559.7799. Time: 413.3080 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #369: GFLOPs: 588.7050. Time: 393.0008 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #370: GFLOPs: 719.1248. Time: 321.7265 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #371: GFLOPs: 566.7417. Time: 408.2310 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #372: GFLOPs: 374.1711. Time: 618.3308 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #373: GFLOPs: 661.1043. Time: 349.9622 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #374: GFLOPs: 566.5304. Time: 408.3833 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #375: GFLOPs: 564.7284. Time: 409.6864 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #376: GFLOPs: 337.2748. Time: 685.9733 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #377: GFLOPs: 677.8915. Time: 341.2958 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #378: GFLOPs: 445.8086. Time: 518.9705 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #379: GFLOPs: 591.6506. Time: 391.0442 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #380: GFLOPs: 566.5569. Time: 408.3642 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #381: GFLOPs: 532.7472. Time: 434.2802 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #382: GFLOPs: 33.8453. Time: 6835.8566 us. Best GFLOPs: 793.6937
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #383: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(4), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1 in T.grid(T.int64(1), T.int64(16), T.int64(7)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), oh_1 * T.int64(2) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused_init in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_init"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                                v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2_init + ow_3_init)
                                v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2_init * T.int64(4) + oc_block_3_fused_init)
                                T.reads()
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(14), T.int64(1), T.int64(64), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        for oc_block_3_fused in T.vectorized(T.int64(4)):
                            with T.block("conv2d_NCHWc_update"):
                                v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                                v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                                v_oh = T.axis.spatial(T.int64(14), oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                                v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(14) + ow_2 + ow_3)
                                v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + oc_block_1 * T.int64(4) + oc_block_2 * T.int64(4) + oc_block_3_fused)
                                v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(64) + ic_1)
                                v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                                v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                                T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                                T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                                T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                                conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(14), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 16, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 1, 14, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 1, 1, 4])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[4, 64])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106, l107 = sch.get_loops(block=b70)
l108 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l108)
l109 = sch.fuse(l107, preserve_unit_iters=True)
sch.vectorize(loop=l109)
sch.annotate(block_or_loop=l108, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l108, ann_key="pragma_unroll_explicit", ann_val=1)
l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b71)
l116 = sch.fuse(l115, preserve_unit_iters=True)
sch.vectorize(loop=l116)
b117 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137, l138, l139 = sch.get_loops(block=b117)
b140 = sch.decompose_reduction(block=b117, loop=l124)
2024-04-28 22:40:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #384: GFLOPs: 9.2276. Time: 25072.8622 us. Best GFLOPs: 793.6937
2024-04-28 23:05:17 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:05:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:05:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:05:23 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:05:35 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:05:46 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:05:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:06:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:06:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9305  0.9253  0.9104  0.9065  0.8725  0.8725  0.8679  0.8645  0.8560  0.8557  0.8538  0.8481  0.8450  0.8391  0.8387  0.8380
[17 : 32]:	0.8373  0.8351  0.8341  0.8333  0.8297  0.8207  0.8195  0.8097  0.8090  0.8068  0.8021  0.7983  0.7964  0.7964  0.7940  0.7934
[33 : 48]:	0.7928  0.7889  0.7879  0.7867  0.7860  0.7835  0.7824  0.7818  0.7799  0.7767  0.7758  0.7758  0.7758  0.7739  0.7682  0.7677
[49 : 64]:	0.7669  0.7661  0.7630  0.7602  0.7588  0.7579  0.7577  0.7575  0.7551  0.7521  0.7510  0.7488  0.7488  0.7462  0.7454  0.7454
2024-04-28 23:06:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:06:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #385: GFLOPs: 713.6112. Time: 324.2123 us. Best GFLOPs: 793.6937
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #386: GFLOPs: 744.5555. Time: 310.7378 us. Best GFLOPs: 793.6937
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #387: GFLOPs: 805.7013. Time: 287.1555 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #388: GFLOPs: 754.0306. Time: 306.8331 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #389: GFLOPs: 692.2646. Time: 334.2097 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #390: GFLOPs: 714.8303. Time: 323.6594 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #391: GFLOPs: 626.2527. Time: 369.4380 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #392: GFLOPs: 677.0353. Time: 341.7275 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #393: GFLOPs: 696.0657. Time: 332.3846 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #394: GFLOPs: 671.5660. Time: 344.5105 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #395: GFLOPs: 713.4757. Time: 324.2739 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #396: GFLOPs: 665.5656. Time: 347.6164 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #397: GFLOPs: 653.0409. Time: 354.2834 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #398: GFLOPs: 701.2433. Time: 329.9305 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #399: GFLOPs: 685.6668. Time: 337.4256 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #400: GFLOPs: 646.1348. Time: 358.0701 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #401: GFLOPs: 187.2449. Time: 1235.6091 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #402: GFLOPs: 745.5960. Time: 310.3041 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #403: GFLOPs: 321.4588. Time: 719.7237 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #404: GFLOPs: 752.9724. Time: 307.2643 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #405: GFLOPs: 695.9224. Time: 332.4531 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #406: GFLOPs: 784.7994. Time: 294.8034 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #407: GFLOPs: 639.1100. Time: 362.0058 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #408: GFLOPs: 663.6045. Time: 348.6437 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #409: GFLOPs: 632.8589. Time: 365.5816 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #410: GFLOPs: 421.4986. Time: 548.9023 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #411: GFLOPs: 655.3772. Time: 353.0204 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #412: GFLOPs: 629.0759. Time: 367.7800 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #413: GFLOPs: 688.7695. Time: 335.9056 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #414: GFLOPs: 686.5421. Time: 336.9954 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #415: GFLOPs: 660.9337. Time: 350.0526 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #416: GFLOPs: 677.9431. Time: 341.2698 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #417: GFLOPs: 357.1033. Time: 647.8841 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #418: GFLOPs: 594.6473. Time: 389.0736 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #419: GFLOPs: 590.1232. Time: 392.0563 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #420: GFLOPs: 663.8076. Time: 348.5370 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #421: GFLOPs: 646.2152. Time: 358.0256 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #422: GFLOPs: 632.1783. Time: 365.9751 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #423: GFLOPs: 657.2543. Time: 352.0122 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #424: GFLOPs: 609.9846. Time: 379.2908 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #425: GFLOPs: 706.4087. Time: 327.5179 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #426: GFLOPs: 636.9593. Time: 363.2281 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #427: GFLOPs: 737.4317. Time: 313.7396 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #428: GFLOPs: 799.6023. Time: 289.3458 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #429: GFLOPs: 331.7400. Time: 697.4183 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #430: GFLOPs: 317.8847. Time: 727.8159 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #431: GFLOPs: 319.4879. Time: 724.1636 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #432: GFLOPs: 645.4613. Time: 358.4437 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #433: GFLOPs: 592.7894. Time: 390.2929 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #434: GFLOPs: 629.7592. Time: 367.3810 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #435: GFLOPs: 536.6561. Time: 431.1169 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #436: GFLOPs: 620.0303. Time: 373.1455 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #437: GFLOPs: 640.9133. Time: 360.9873 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #438: GFLOPs: 601.5292. Time: 384.6223 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #439: GFLOPs: 598.3858. Time: 386.6428 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #440: GFLOPs: 695.4347. Time: 332.6862 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #441: GFLOPs: 534.2778. Time: 433.0360 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #442: GFLOPs: 535.6212. Time: 431.9499 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #443: GFLOPs: 647.6199. Time: 357.2489 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #444: GFLOPs: 454.0495. Time: 509.5514 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #445: GFLOPs: 568.7784. Time: 406.7692 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #446: GFLOPs: 4.2642. Time: 54256.4417 us. Best GFLOPs: 805.7013
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #447: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(28), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1 in T.grid(T.int64(1), T.int64(8)):
                for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(16), T.int64(128)):
                    with T.block("data_pad"):
                        v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                        v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax2)
                        v_i3, v_i4 = T.axis.remap("SS", [ax3, ax4])
                        T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                        T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                        data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
                for oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(7), T.int64(4)):
                    for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                    for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(1), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + oc_block_1 + oc_block_2 + oc_block_3)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(4)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(4) * T.int64(2) + ax2)
                        v_ax3 = T.axis.spatial(T.int64(14), ax3)
                        v_ax4 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(4) * T.int64(4) + ax4_fused)
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=6)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83 = sch.get_loops(block=b69)
l84 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l84)
l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b70)
l107 = sch.fuse(l85, preserve_unit_iters=True)
sch.parallel(loop=l107)
sch.annotate(block_or_loop=l107, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l107, ann_key="pragma_unroll_explicit", ann_val=1)
l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135, l136, l137 = sch.get_loops(block=b115)
b138 = sch.decompose_reduction(block=b115, loop=l122)
2024-04-28 23:07:53 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #448: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(196), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(98) * T.int64(8) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(49) // T.int64(7) * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(7) * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(98) // T.int64(49) * T.int64(8) + oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(4) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[1, 7, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 1, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[64, 4])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b68)
l85 = sch.fuse(l71, l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110 = sch.get_loops(block=b70)
l111 = sch.fuse(l106, l107, l108, l109, l110, preserve_unit_iters=True)
l112, l113 = sch.split(loop=l111, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l112)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b114)
b133 = sch.decompose_reduction(block=b114, loop=l117)
2024-04-28 23:34:32 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-28 23:34:33 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-28 23:34:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:34:38 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-28 23:34:50 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:35:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:35:13 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:35:24 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-28 23:35:31 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9665  0.9523  0.9343  0.9343  0.9260  0.9206  0.9196  0.9187  0.9152  0.9124  0.9075  0.9075  0.8960  0.8919  0.8808  0.8550
[17 : 32]:	0.8549  0.8543  0.8543  0.8524  0.8497  0.8497  0.8435  0.8435  0.8432  0.8400  0.8387  0.8323  0.8286  0.8263  0.8260  0.8219
[33 : 48]:	0.8196  0.8171  0.8154  0.8154  0.8131  0.8119  0.8112  0.8081  0.8053  0.8039  0.8024  0.7994  0.7941  0.7931  0.7889  0.7871
[49 : 64]:	0.7870  0.7768  0.7759  0.7700  0.7700  0.7700  0.7689  0.7682  0.7679  0.7648  0.7638  0.7638  0.7638  0.7629  0.7629  0.7594
2024-04-28 23:35:31 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-28 23:35:31 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #449: GFLOPs: 753.1425. Time: 307.1949 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #450: GFLOPs: 380.7478. Time: 607.6503 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #451: GFLOPs: 781.0313. Time: 296.2257 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #452: GFLOPs: 784.7009. Time: 294.8404 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #453: GFLOPs: 742.0709. Time: 311.7782 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #454: GFLOPs: 742.4227. Time: 311.6305 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #455: GFLOPs: 705.7449. Time: 327.8260 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #456: GFLOPs: 689.9391. Time: 335.3362 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #457: GFLOPs: 741.5811. Time: 311.9841 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #458: GFLOPs: 753.6015. Time: 307.0078 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #459: GFLOPs: 744.9386. Time: 310.5780 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #460: GFLOPs: 765.4909. Time: 302.2395 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #461: GFLOPs: 690.8765. Time: 334.8812 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #462: GFLOPs: 744.9291. Time: 310.5820 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #463: GFLOPs: 754.0336. Time: 306.8319 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #464: GFLOPs: 748.5182. Time: 309.0927 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #465: GFLOPs: 712.2703. Time: 324.8227 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #466: GFLOPs: 703.0448. Time: 329.0850 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #467: GFLOPs: 733.9293. Time: 315.2368 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #468: GFLOPs: 622.0438. Time: 371.9377 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #469: GFLOPs: 680.9124. Time: 339.7816 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #470: GFLOPs: 680.5387. Time: 339.9682 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #471: GFLOPs: 702.4624. Time: 329.3579 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #472: GFLOPs: 705.5144. Time: 327.9331 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #473: GFLOPs: 673.8645. Time: 343.3354 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #474: GFLOPs: 683.8617. Time: 338.3163 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #475: GFLOPs: 736.5811. Time: 314.1019 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #476: GFLOPs: 685.4353. Time: 337.5396 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #477: GFLOPs: 686.1366. Time: 337.1946 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #478: GFLOPs: 683.4376. Time: 338.5262 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #479: GFLOPs: 636.2496. Time: 363.6333 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #480: GFLOPs: 676.8041. Time: 341.8442 us. Best GFLOPs: 805.7013
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #481: GFLOPs: 820.2847. Time: 282.0503 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #482: GFLOPs: 562.1379. Time: 411.5744 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #483: GFLOPs: 684.4164. Time: 338.0421 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #484: GFLOPs: 688.8922. Time: 335.8458 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #485: GFLOPs: 684.7994. Time: 337.8530 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #486: GFLOPs: 684.5211. Time: 337.9904 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #487: GFLOPs: 705.0849. Time: 328.1329 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #488: GFLOPs: 568.4518. Time: 407.0029 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #489: GFLOPs: 729.2346. Time: 317.2663 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #490: GFLOPs: 769.1975. Time: 300.7830 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #491: GFLOPs: 813.3025. Time: 284.4717 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #492: GFLOPs: 653.7351. Time: 353.9072 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #493: GFLOPs: 597.8084. Time: 387.0162 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #494: GFLOPs: 617.1524. Time: 374.8856 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #495: GFLOPs: 741.9616. Time: 311.8241 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #496: GFLOPs: 599.9093. Time: 385.6609 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #497: GFLOPs: 679.8041. Time: 340.3356 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #498: GFLOPs: 684.3069. Time: 338.0961 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #499: GFLOPs: 320.0179. Time: 722.9643 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #500: GFLOPs: 102.5362. Time: 2256.3886 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #501: GFLOPs: 638.2043. Time: 362.5195 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #502: GFLOPs: 633.9930. Time: 364.9276 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #503: GFLOPs: 639.6862. Time: 361.6797 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #504: GFLOPs: 583.1162. Time: 396.7675 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #505: GFLOPs: 603.1269. Time: 383.6034 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #506: GFLOPs: 644.4737. Time: 358.9930 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #507: GFLOPs: 708.2267. Time: 326.6773 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #508: GFLOPs: 708.8173. Time: 326.4050 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #509: GFLOPs: 539.6946. Time: 428.6898 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #510: GFLOPs: 51.0470. Time: 4532.3199 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #511: GFLOPs: 37.1730. Time: 6223.9095 us. Best GFLOPs: 820.2847
2024-04-28 23:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #512: GFLOPs: 24.2709. Time: 9532.4604 us. Best GFLOPs: 820.2847
2024-04-29 00:10:47 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:10:48 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:10:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:10:53 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:11:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:11:16 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:11:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:11:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:11:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9615  0.9540  0.9538  0.9454  0.9435  0.9426  0.9426  0.9376  0.9374  0.9360  0.9348  0.9259  0.9180  0.9180  0.9161  0.9101
[17 : 32]:	0.9062  0.8985  0.8940  0.8928  0.8882  0.8798  0.8791  0.8712  0.8712  0.8680  0.8593  0.8592  0.8592  0.8592  0.8566  0.8537
[33 : 48]:	0.8446  0.8442  0.8432  0.8430  0.8428  0.8425  0.8260  0.8233  0.8230  0.8192  0.8174  0.8174  0.8136  0.8127  0.8091  0.8059
[49 : 64]:	0.8059  0.8031  0.7985  0.7891  0.7891  0.7822  0.7729  0.7675  0.7669  0.7669  0.7659  0.7641  0.7640  0.7633  0.7595  0.7590
2024-04-29 00:11:48 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:11:48 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #513: GFLOPs: 753.0604. Time: 307.2284 us. Best GFLOPs: 820.2847
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #514: GFLOPs: 824.1532. Time: 280.7264 us. Best GFLOPs: 824.1532
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #515: GFLOPs: 820.9521. Time: 281.8210 us. Best GFLOPs: 824.1532
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #516: GFLOPs: 707.6102. Time: 326.9618 us. Best GFLOPs: 824.1532
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #517: GFLOPs: 378.4972. Time: 611.2636 us. Best GFLOPs: 824.1532
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #518: GFLOPs: 824.9643. Time: 280.4503 us. Best GFLOPs: 824.9643
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #519: GFLOPs: 823.2245. Time: 281.0431 us. Best GFLOPs: 824.9643
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #520: GFLOPs: 835.4238. Time: 276.9391 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #521: GFLOPs: 809.4302. Time: 285.8326 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #522: GFLOPs: 744.8768. Time: 310.6038 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #523: GFLOPs: 753.4506. Time: 307.0693 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #524: GFLOPs: 778.3812. Time: 297.2342 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #525: GFLOPs: 744.4839. Time: 310.7677 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #526: GFLOPs: 757.5572. Time: 305.4047 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #527: GFLOPs: 768.4005. Time: 301.0950 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #528: GFLOPs: 744.0652. Time: 310.9425 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #529: GFLOPs: 746.4591. Time: 309.9454 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #530: GFLOPs: 813.7099. Time: 284.3293 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #531: GFLOPs: 582.9252. Time: 396.8975 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #532: GFLOPs: 745.6073. Time: 310.2994 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #533: GFLOPs: 745.2909. Time: 310.4312 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #534: GFLOPs: 704.9204. Time: 328.2095 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #535: GFLOPs: 779.0861. Time: 296.9653 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #536: GFLOPs: 619.6806. Time: 373.3561 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #537: GFLOPs: 769.4962. Time: 300.6662 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #538: GFLOPs: 772.5722. Time: 299.4691 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #539: GFLOPs: 697.6789. Time: 331.6161 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #540: GFLOPs: 712.6493. Time: 324.6499 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #541: GFLOPs: 712.0254. Time: 324.9344 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #542: GFLOPs: 711.3820. Time: 325.2283 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #543: GFLOPs: 804.6383. Time: 287.5348 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #544: GFLOPs: 711.1624. Time: 325.3287 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #545: GFLOPs: 718.3643. Time: 322.0671 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #546: GFLOPs: 718.1844. Time: 322.1478 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #547: GFLOPs: 736.6317. Time: 314.0803 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #548: GFLOPs: 533.7169. Time: 433.4911 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #549: GFLOPs: 707.7882. Time: 326.8796 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #550: GFLOPs: 700.6189. Time: 330.2245 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #551: GFLOPs: 801.9456. Time: 288.5003 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #552: GFLOPs: 757.9829. Time: 305.2332 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #553: GFLOPs: 407.1704. Time: 568.2179 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #554: GFLOPs: 680.1217. Time: 340.1766 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #555: GFLOPs: 651.3627. Time: 355.1961 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #556: GFLOPs: 627.6784. Time: 368.5989 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #557: GFLOPs: 683.9330. Time: 338.2810 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #558: GFLOPs: 633.4988. Time: 365.2123 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #559: GFLOPs: 778.1001. Time: 297.3416 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #560: GFLOPs: 668.4977. Time: 346.0918 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #561: GFLOPs: 672.5733. Time: 343.9945 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #562: GFLOPs: 571.7310. Time: 404.6685 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #563: GFLOPs: 545.9958. Time: 423.7424 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #564: GFLOPs: 656.7263. Time: 352.2952 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #565: GFLOPs: 650.5158. Time: 355.6586 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #566: GFLOPs: 547.3718. Time: 422.6771 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #567: GFLOPs: 687.3428. Time: 336.6028 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #568: GFLOPs: 680.9161. Time: 339.7798 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #569: GFLOPs: 543.5977. Time: 425.6117 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #570: GFLOPs: 537.4162. Time: 430.5072 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #571: GFLOPs: 431.4605. Time: 536.2287 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #572: GFLOPs: 730.3822. Time: 316.7677 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #573: GFLOPs: 620.2989. Time: 372.9839 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #574: GFLOPs: 1.6318. Time: 141780.3947 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #575: GFLOPs: 5.2196. Time: 44325.2907 us. Best GFLOPs: 835.4238
2024-04-29 00:13:21 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #576: GFLOPs: 10.8103. Time: 21401.9726 us. Best GFLOPs: 835.4238
2024-04-29 00:26:28 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:26:29 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:26:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:26:33 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:26:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:26:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:27:10 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:27:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:27:30 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9825  0.9777  0.9455  0.9388  0.9217  0.9131  0.9125  0.9125  0.9078  0.9047  0.8947  0.8883  0.8872  0.8795  0.8747  0.8701
[17 : 32]:	0.8683  0.8669  0.8661  0.8656  0.8640  0.8626  0.8619  0.8619  0.8601  0.8593  0.8592  0.8590  0.8530  0.8519  0.8482  0.8389
[33 : 48]:	0.8386  0.8377  0.8322  0.8260  0.8241  0.8222  0.8195  0.8108  0.8092  0.8023  0.7973  0.7969  0.7954  0.7943  0.7933  0.7903
[49 : 64]:	0.7888  0.7877  0.7864  0.7837  0.7837  0.7828  0.7821  0.7821  0.7820  0.7813  0.7791  0.7757  0.7757  0.7727  0.7708  0.7705
2024-04-29 00:27:30 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:27:30 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #577: GFLOPs: 800.9518. Time: 288.8583 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #578: GFLOPs: 810.3126. Time: 285.5213 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #579: GFLOPs: 784.3604. Time: 294.9684 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #580: GFLOPs: 818.0034. Time: 282.8369 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #581: GFLOPs: 806.4318. Time: 286.8954 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #582: GFLOPs: 764.6411. Time: 302.5753 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #583: GFLOPs: 724.7150. Time: 319.2449 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #584: GFLOPs: 723.9487. Time: 319.5828 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #585: GFLOPs: 787.4121. Time: 293.8252 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #586: GFLOPs: 734.5918. Time: 314.9525 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #587: GFLOPs: 734.2921. Time: 315.0811 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #588: GFLOPs: 708.8209. Time: 326.4034 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #589: GFLOPs: 475.6087. Time: 486.4536 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #590: GFLOPs: 392.7781. Time: 589.0387 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #591: GFLOPs: 755.6791. Time: 306.1637 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #592: GFLOPs: 718.4137. Time: 322.0450 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #593: GFLOPs: 740.3220. Time: 312.5148 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #594: GFLOPs: 697.4564. Time: 331.7219 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #595: GFLOPs: 691.3810. Time: 334.6368 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #596: GFLOPs: 693.2673. Time: 333.7263 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #597: GFLOPs: 744.4316. Time: 310.7895 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #598: GFLOPs: 689.9947. Time: 335.3091 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #599: GFLOPs: 769.6304. Time: 300.6138 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #600: GFLOPs: 760.9778. Time: 304.0319 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #601: GFLOPs: 700.0252. Time: 330.5046 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #602: GFLOPs: 480.3875. Time: 481.6144 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #603: GFLOPs: 588.3921. Time: 393.2098 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #604: GFLOPs: 790.9678. Time: 292.5044 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #605: GFLOPs: 755.7729. Time: 306.1258 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #606: GFLOPs: 703.5301. Time: 328.8580 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #607: GFLOPs: 776.7990. Time: 297.8396 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #608: GFLOPs: 779.2828. Time: 296.8903 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #609: GFLOPs: 688.1696. Time: 336.1984 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #610: GFLOPs: 702.9634. Time: 329.1231 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #611: GFLOPs: 390.3724. Time: 592.6687 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #612: GFLOPs: 788.0080. Time: 293.6030 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #613: GFLOPs: 692.5699. Time: 334.0623 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #614: GFLOPs: 643.4835. Time: 359.5454 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #615: GFLOPs: 687.1879. Time: 336.6787 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #616: GFLOPs: 591.6810. Time: 391.0241 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #617: GFLOPs: 744.8305. Time: 310.6231 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #618: GFLOPs: 702.3204. Time: 329.4245 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #619: GFLOPs: 474.8097. Time: 487.2721 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #620: GFLOPs: 674.4198. Time: 343.0527 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #621: GFLOPs: 652.2452. Time: 354.7156 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #622: GFLOPs: 706.8243. Time: 327.3254 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #623: GFLOPs: 649.8770. Time: 356.0082 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #624: GFLOPs: 111.2476. Time: 2079.6986 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #625: GFLOPs: 744.9394. Time: 310.5776 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #626: GFLOPs: 496.8027. Time: 465.7010 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #627: GFLOPs: 627.2251. Time: 368.8652 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #628: GFLOPs: 93.1642. Time: 2483.3728 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #629: GFLOPs: 93.3355. Time: 2478.8154 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #630: GFLOPs: 589.1511. Time: 392.7033 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #631: GFLOPs: 472.2083. Time: 489.9565 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #632: GFLOPs: 473.0989. Time: 489.0342 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #633: GFLOPs: 582.9703. Time: 396.8668 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #634: GFLOPs: 591.2158. Time: 391.3318 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #635: GFLOPs: 627.0931. Time: 368.9429 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #636: GFLOPs: 681.8034. Time: 339.3376 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #637: GFLOPs: 685.2034. Time: 337.6538 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #638: GFLOPs: 4.2835. Time: 54012.5340 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #639: GFLOPs: 54.4903. Time: 4245.9198 us. Best GFLOPs: 835.4238
2024-04-29 00:28:58 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #640: GFLOPs: 5.7356. Time: 40337.9793 us. Best GFLOPs: 835.4238
2024-04-29 00:34:11 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 00:34:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 00:34:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:34:17 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 00:34:30 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:34:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:34:56 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:35:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 00:35:17 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9678  0.9649  0.9649  0.9612  0.9459  0.9455  0.9374  0.9321  0.9306  0.9240  0.9179  0.9177  0.9145  0.9110  0.9093  0.9053
[17 : 32]:	0.9053  0.9039  0.9023  0.8937  0.8931  0.8870  0.8864  0.8864  0.8863  0.8863  0.8826  0.8753  0.8661  0.8645  0.8606  0.8593
[33 : 48]:	0.8505  0.8504  0.8501  0.8484  0.8483  0.8483  0.8466  0.8429  0.8413  0.8413  0.8383  0.8380  0.8352  0.8318  0.8307  0.8288
[49 : 64]:	0.8202  0.8196  0.8187  0.8177  0.8172  0.8172  0.8165  0.8125  0.8105  0.8097  0.8088  0.8080  0.8079  0.8055  0.8044  0.7982
2024-04-29 00:35:17 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 00:35:17 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #641: GFLOPs: 830.1192. Time: 278.7088 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #642: GFLOPs: 820.4026. Time: 282.0097 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #643: GFLOPs: 823.0235. Time: 281.1117 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #644: GFLOPs: 753.6668. Time: 306.9812 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #645: GFLOPs: 745.2192. Time: 310.4611 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #646: GFLOPs: 403.5656. Time: 573.2935 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #647: GFLOPs: 791.5052. Time: 292.3058 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #648: GFLOPs: 761.3258. Time: 303.8929 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #649: GFLOPs: 819.8360. Time: 282.2047 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #650: GFLOPs: 464.3434. Time: 498.2553 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #651: GFLOPs: 784.2706. Time: 295.0022 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #652: GFLOPs: 769.1277. Time: 300.8103 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #653: GFLOPs: 774.6136. Time: 298.6799 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #654: GFLOPs: 818.2162. Time: 282.7633 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #655: GFLOPs: 793.7570. Time: 291.4765 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #656: GFLOPs: 736.2684. Time: 314.2353 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #657: GFLOPs: 734.4130. Time: 315.0292 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #658: GFLOPs: 738.3809. Time: 313.3363 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #659: GFLOPs: 784.8167. Time: 294.7969 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #660: GFLOPs: 780.8703. Time: 296.2868 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #661: GFLOPs: 784.4650. Time: 294.9291 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #662: GFLOPs: 750.7075. Time: 308.1913 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #663: GFLOPs: 768.7634. Time: 300.9529 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #664: GFLOPs: 772.1165. Time: 299.6459 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #665: GFLOPs: 778.6540. Time: 297.1301 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #666: GFLOPs: 768.4170. Time: 301.0885 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #667: GFLOPs: 727.1145. Time: 318.1914 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #668: GFLOPs: 724.8627. Time: 319.1798 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #669: GFLOPs: 773.8450. Time: 298.9766 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #670: GFLOPs: 725.5718. Time: 318.8679 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #671: GFLOPs: 674.0126. Time: 343.2600 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #672: GFLOPs: 772.6940. Time: 299.4219 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #673: GFLOPs: 747.8810. Time: 309.3561 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #674: GFLOPs: 711.6176. Time: 325.1206 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #675: GFLOPs: 698.2066. Time: 331.3654 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #676: GFLOPs: 722.1913. Time: 320.3604 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #677: GFLOPs: 727.4323. Time: 318.0523 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #678: GFLOPs: 719.7273. Time: 321.4572 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #679: GFLOPs: 699.2122. Time: 330.8889 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #680: GFLOPs: 683.5961. Time: 338.4477 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #681: GFLOPs: 779.3881. Time: 296.8502 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #682: GFLOPs: 691.6420. Time: 334.5105 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #683: GFLOPs: 715.2071. Time: 323.4889 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #684: GFLOPs: 793.9850. Time: 291.3928 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #685: GFLOPs: 739.5080. Time: 312.8587 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #686: GFLOPs: 695.0991. Time: 332.8469 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #687: GFLOPs: 682.1958. Time: 339.1424 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #688: GFLOPs: 767.8026. Time: 301.3294 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #689: GFLOPs: 706.9554. Time: 327.2647 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #690: GFLOPs: 667.6949. Time: 346.5079 us. Best GFLOPs: 835.4238
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #691: GFLOPs: 842.0957. Time: 274.7449 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #692: GFLOPs: 750.9656. Time: 308.0854 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #693: GFLOPs: 696.5098. Time: 332.1727 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #694: GFLOPs: 705.7487. Time: 327.8242 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #695: GFLOPs: 641.5270. Time: 360.6419 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #696: GFLOPs: 686.0383. Time: 337.2429 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #697: GFLOPs: 703.8529. Time: 328.7072 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #698: GFLOPs: 677.5627. Time: 341.4614 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #699: GFLOPs: 551.3616. Time: 419.6185 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #700: GFLOPs: 244.2955. Time: 947.0561 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #701: GFLOPs: 686.4074. Time: 337.0615 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #702: GFLOPs: 144.6315. Time: 1599.6626 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #703: GFLOPs: 47.0366. Time: 4918.7558 us. Best GFLOPs: 842.0957
2024-04-29 00:37:02 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #704: GFLOPs: 8.8400. Time: 26172.1983 us. Best GFLOPs: 842.0957
2024-04-29 01:03:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:03:20 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:03:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:03:25 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:03:37 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:03:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:04:04 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:04:18 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:04:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9700  0.9462  0.9401  0.9395  0.9280  0.9241  0.9215  0.9194  0.9122  0.9122  0.9069  0.9054  0.9008  0.9002  0.8934  0.8926
[17 : 32]:	0.8893  0.8862  0.8862  0.8853  0.8819  0.8769  0.8739  0.8733  0.8729  0.8647  0.8617  0.8603  0.8553  0.8513  0.8504  0.8502
[33 : 48]:	0.8493  0.8447  0.8447  0.8424  0.8361  0.8344  0.8337  0.8314  0.8301  0.8293  0.8186  0.8169  0.8157  0.8134  0.8106  0.8080
[49 : 64]:	0.8039  0.8010  0.7943  0.7929  0.7924  0.7901  0.7901  0.7856  0.7845  0.7820  0.7713  0.7697  0.7670  0.7670  0.7670  0.7665
2024-04-29 01:04:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:04:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:06:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #705: GFLOPs: 790.0844. Time: 292.8314 us. Best GFLOPs: 842.0957
2024-04-29 01:06:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #706: GFLOPs: 804.7469. Time: 287.4960 us. Best GFLOPs: 842.0957
2024-04-29 01:06:07 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #707: GFLOPs: 760.6864. Time: 304.1484 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #708: GFLOPs: 810.7196. Time: 285.3780 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #709: GFLOPs: 742.8714. Time: 311.4422 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #710: GFLOPs: 743.5916. Time: 311.1406 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #711: GFLOPs: 781.0248. Time: 296.2282 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #712: GFLOPs: 800.4746. Time: 289.0304 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #713: GFLOPs: 802.7500. Time: 288.2112 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #714: GFLOPs: 802.3938. Time: 288.3391 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #715: GFLOPs: 792.8182. Time: 291.8217 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #716: GFLOPs: 726.1825. Time: 318.5997 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #717: GFLOPs: 637.6478. Time: 362.8359 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #718: GFLOPs: 785.4652. Time: 294.5535 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #719: GFLOPs: 748.8144. Time: 308.9705 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #720: GFLOPs: 803.4719. Time: 287.9522 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #721: GFLOPs: 735.0287. Time: 314.7653 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #722: GFLOPs: 652.0335. Time: 354.8308 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #723: GFLOPs: 807.5620. Time: 286.4938 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #724: GFLOPs: 759.8915. Time: 304.4665 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #725: GFLOPs: 747.9306. Time: 309.3356 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #726: GFLOPs: 744.5897. Time: 310.7235 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #727: GFLOPs: 758.9887. Time: 304.8287 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #728: GFLOPs: 711.6233. Time: 325.1180 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #729: GFLOPs: 741.8896. Time: 311.8544 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #730: GFLOPs: 749.5380. Time: 308.6722 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #731: GFLOPs: 755.8606. Time: 306.0902 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #732: GFLOPs: 622.6809. Time: 371.5572 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #733: GFLOPs: 617.4271. Time: 374.7188 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #734: GFLOPs: 794.8852. Time: 291.0628 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #735: GFLOPs: 348.1458. Time: 664.5536 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #736: GFLOPs: 754.4281. Time: 306.6714 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #737: GFLOPs: 736.6864. Time: 314.0570 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #738: GFLOPs: 765.1740. Time: 302.3646 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #739: GFLOPs: 802.3831. Time: 288.3430 us. Best GFLOPs: 842.0957
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #740: GFLOPs: 852.1599. Time: 271.5001 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #741: GFLOPs: 786.0204. Time: 294.3454 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #742: GFLOPs: 704.1319. Time: 328.5770 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #743: GFLOPs: 661.0527. Time: 349.9895 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #744: GFLOPs: 757.8351. Time: 305.2927 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #745: GFLOPs: 754.5951. Time: 306.6035 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #746: GFLOPs: 651.8192. Time: 354.9474 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #747: GFLOPs: 375.4869. Time: 616.1640 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #748: GFLOPs: 678.5815. Time: 340.9488 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #749: GFLOPs: 717.9999. Time: 322.2306 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #750: GFLOPs: 704.9031. Time: 328.2175 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #751: GFLOPs: 675.4113. Time: 342.5491 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #752: GFLOPs: 566.7494. Time: 408.2255 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #753: GFLOPs: 690.3501. Time: 335.1365 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #754: GFLOPs: 671.5341. Time: 344.5269 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #755: GFLOPs: 648.5896. Time: 356.7149 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #756: GFLOPs: 739.0089. Time: 313.0700 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #757: GFLOPs: 773.1882. Time: 299.2306 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #758: GFLOPs: 574.3792. Time: 402.8027 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #759: GFLOPs: 797.8320. Time: 289.9878 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #760: GFLOPs: 679.9066. Time: 340.2843 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #761: GFLOPs: 697.1680. Time: 331.8591 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #762: GFLOPs: 776.0086. Time: 298.1430 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #763: GFLOPs: 598.8069. Time: 386.3709 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #764: GFLOPs: 739.7889. Time: 312.7400 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #765: GFLOPs: 456.5498. Time: 506.7608 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #766: GFLOPs: 7.3795. Time: 31351.9813 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #767: GFLOPs: 33.3379. Time: 6939.8968 us. Best GFLOPs: 852.1599
2024-04-29 01:06:08 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #768: GFLOPs: 98.5238. Time: 2348.2807 us. Best GFLOPs: 852.1599
2024-04-29 01:22:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:22:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:22:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:22:35 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:22:47 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:23:01 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:23:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:23:28 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:23:35 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9581  0.9474  0.9392  0.9380  0.9351  0.9317  0.9220  0.9206  0.9206  0.9197  0.9153  0.9153  0.9153  0.9109  0.9042  0.9025
[17 : 32]:	0.9019  0.8968  0.8897  0.8876  0.8841  0.8822  0.8795  0.8795  0.8764  0.8703  0.8672  0.8595  0.8588  0.8588  0.8556  0.8556
[33 : 48]:	0.8533  0.8492  0.8492  0.8463  0.8435  0.8370  0.8364  0.8342  0.8248  0.8240  0.8212  0.8163  0.8028  0.8002  0.7974  0.7970
[49 : 64]:	0.7961  0.7934  0.7905  0.7899  0.7863  0.7795  0.7790  0.7766  0.7742  0.7734  0.7725  0.7700  0.7685  0.7678  0.7666  0.7633
2024-04-29 01:23:36 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:23:36 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #769: GFLOPs: 824.1241. Time: 280.7363 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #770: GFLOPs: 815.8831. Time: 283.5719 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #771: GFLOPs: 344.8794. Time: 670.8476 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #772: GFLOPs: 416.1568. Time: 555.9479 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #773: GFLOPs: 810.8790. Time: 285.3219 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #774: GFLOPs: 815.8237. Time: 283.5926 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #775: GFLOPs: 807.2465. Time: 286.6058 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #776: GFLOPs: 805.0086. Time: 287.4026 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #777: GFLOPs: 794.6545. Time: 291.1473 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #778: GFLOPs: 793.2133. Time: 291.6763 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #779: GFLOPs: 782.2736. Time: 295.7553 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #780: GFLOPs: 783.2249. Time: 295.3960 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #781: GFLOPs: 785.6107. Time: 294.4990 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #782: GFLOPs: 808.1450. Time: 286.2872 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #783: GFLOPs: 794.2397. Time: 291.2994 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #784: GFLOPs: 798.3253. Time: 289.8086 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #785: GFLOPs: 770.5644. Time: 300.2494 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #786: GFLOPs: 816.1876. Time: 283.4661 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #787: GFLOPs: 791.6304. Time: 292.2595 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #788: GFLOPs: 783.4282. Time: 295.3194 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #789: GFLOPs: 751.6332. Time: 307.8118 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #790: GFLOPs: 806.7557. Time: 286.7802 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #791: GFLOPs: 736.7052. Time: 314.0490 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #792: GFLOPs: 753.4133. Time: 307.0845 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #793: GFLOPs: 795.3812. Time: 290.8813 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #794: GFLOPs: 741.7790. Time: 311.9009 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #795: GFLOPs: 683.0228. Time: 338.7318 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #796: GFLOPs: 788.2950. Time: 293.4961 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #797: GFLOPs: 797.5970. Time: 290.0732 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #798: GFLOPs: 786.9018. Time: 294.0158 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #799: GFLOPs: 730.7939. Time: 316.5893 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #800: GFLOPs: 749.2779. Time: 308.7793 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #801: GFLOPs: 778.9198. Time: 297.0287 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #802: GFLOPs: 737.4580. Time: 313.7284 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #803: GFLOPs: 732.8377. Time: 315.7064 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #804: GFLOPs: 773.9102. Time: 298.9514 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #805: GFLOPs: 783.7078. Time: 295.2140 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #806: GFLOPs: 781.8088. Time: 295.9311 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #807: GFLOPs: 707.6199. Time: 326.9574 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #808: GFLOPs: 607.5380. Time: 380.8182 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #809: GFLOPs: 758.1795. Time: 305.1540 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #810: GFLOPs: 812.2829. Time: 284.8288 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #811: GFLOPs: 706.1375. Time: 327.6437 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #812: GFLOPs: 706.1137. Time: 327.6548 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #813: GFLOPs: 750.0140. Time: 308.4763 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #814: GFLOPs: 793.7105. Time: 291.4936 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #815: GFLOPs: 756.5482. Time: 305.8120 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #816: GFLOPs: 688.7832. Time: 335.8989 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #817: GFLOPs: 663.5588. Time: 348.6677 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #818: GFLOPs: 694.7564. Time: 333.0110 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #819: GFLOPs: 649.4967. Time: 356.2167 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #820: GFLOPs: 655.6665. Time: 352.8647 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #821: GFLOPs: 583.3111. Time: 396.6349 us. Best GFLOPs: 852.1599
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #822: GFLOPs: 895.2575. Time: 258.4301 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #823: GFLOPs: 811.9123. Time: 284.9588 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #824: GFLOPs: 723.5201. Time: 319.7721 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #825: GFLOPs: 683.0727. Time: 338.7071 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #826: GFLOPs: 708.0731. Time: 326.7481 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #827: GFLOPs: 654.8844. Time: 353.2861 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #828: GFLOPs: 648.9213. Time: 356.5325 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #829: GFLOPs: 656.0102. Time: 352.6798 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #830: GFLOPs: 13.5249. Time: 17106.3537 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #831: GFLOPs: 32.1148. Time: 7204.1983 us. Best GFLOPs: 895.2575
2024-04-29 01:25:10 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #832: GFLOPs: 104.4470. Time: 2215.1102 us. Best GFLOPs: 895.2575
2024-04-29 01:30:59 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:31:00 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:31:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:31:04 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:31:17 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:31:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:31:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:31:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:32:06 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9081  0.8948  0.8870  0.8863  0.8863  0.8862  0.8856  0.8831  0.8797  0.8775  0.8727  0.8691  0.8691  0.8649  0.8648  0.8499
[17 : 32]:	0.8499  0.8495  0.8477  0.8419  0.8333  0.8333  0.8262  0.8211  0.8202  0.8145  0.8104  0.8075  0.8074  0.8060  0.8040  0.8040
[33 : 48]:	0.8030  0.7966  0.7952  0.7902  0.7891  0.7842  0.7828  0.7799  0.7799  0.7799  0.7769  0.7690  0.7661  0.7626  0.7619  0.7566
[49 : 64]:	0.7566  0.7533  0.7510  0.7499  0.7483  0.7474  0.7459  0.7444  0.7437  0.7437  0.7426  0.7426  0.7407  0.7399  0.7394  0.7361
2024-04-29 01:32:06 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:32:07 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #833: GFLOPs: 815.2978. Time: 283.7755 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #834: GFLOPs: 816.9891. Time: 283.1880 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #835: GFLOPs: 800.8282. Time: 288.9028 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #836: GFLOPs: 789.4355. Time: 293.0721 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #837: GFLOPs: 802.6771. Time: 288.2374 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #838: GFLOPs: 778.7368. Time: 297.0985 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #839: GFLOPs: 775.8325. Time: 298.2107 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #840: GFLOPs: 765.3157. Time: 302.3086 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #841: GFLOPs: 786.4714. Time: 294.1767 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #842: GFLOPs: 791.6260. Time: 292.2611 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #843: GFLOPs: 807.2300. Time: 286.6117 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #844: GFLOPs: 783.4414. Time: 295.3144 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #845: GFLOPs: 622.3078. Time: 371.7799 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #846: GFLOPs: 779.7423. Time: 296.7154 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #847: GFLOPs: 684.2894. Time: 338.1048 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #848: GFLOPs: 794.6693. Time: 291.1419 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #849: GFLOPs: 798.0421. Time: 289.9114 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #850: GFLOPs: 745.2528. Time: 310.4471 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #851: GFLOPs: 804.2927. Time: 287.6584 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #852: GFLOPs: 790.2247. Time: 292.7794 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #853: GFLOPs: 884.6920. Time: 261.5165 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #854: GFLOPs: 876.3418. Time: 264.0083 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #855: GFLOPs: 714.1286. Time: 323.9774 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #856: GFLOPs: 755.6974. Time: 306.1563 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #857: GFLOPs: 728.5579. Time: 317.5610 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #858: GFLOPs: 638.0948. Time: 362.5817 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #859: GFLOPs: 685.4246. Time: 337.5448 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #860: GFLOPs: 697.3472. Time: 331.7738 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #861: GFLOPs: 627.7769. Time: 368.5410 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #862: GFLOPs: 633.8611. Time: 365.0035 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #863: GFLOPs: 712.5930. Time: 324.6756 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #864: GFLOPs: 714.9201. Time: 323.6188 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #865: GFLOPs: 644.3648. Time: 359.0537 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #866: GFLOPs: 729.6170. Time: 317.1000 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #867: GFLOPs: 670.5538. Time: 345.0306 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #868: GFLOPs: 734.1688. Time: 315.1340 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #869: GFLOPs: 748.0995. Time: 309.2657 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #870: GFLOPs: 688.8095. Time: 335.8861 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #871: GFLOPs: 844.7149. Time: 273.8930 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #872: GFLOPs: 700.4296. Time: 330.3138 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #873: GFLOPs: 749.2224. Time: 308.8022 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #874: GFLOPs: 750.7685. Time: 308.1663 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #875: GFLOPs: 644.5313. Time: 358.9609 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #876: GFLOPs: 689.4152. Time: 335.5910 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #877: GFLOPs: 559.7775. Time: 413.3098 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #878: GFLOPs: 703.8134. Time: 328.7257 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #879: GFLOPs: 775.5979. Time: 298.3009 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #880: GFLOPs: 693.2103. Time: 333.7537 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #881: GFLOPs: 693.4665. Time: 333.6304 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #882: GFLOPs: 583.6547. Time: 396.4014 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #883: GFLOPs: 657.6954. Time: 351.7761 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #884: GFLOPs: 788.3891. Time: 293.4611 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #885: GFLOPs: 658.4736. Time: 351.3604 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #886: GFLOPs: 573.8274. Time: 403.1901 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #887: GFLOPs: 693.4051. Time: 333.6600 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #888: GFLOPs: 522.4296. Time: 442.8568 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #889: GFLOPs: 609.0103. Time: 379.8976 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #890: GFLOPs: 310.9439. Time: 744.0620 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #891: GFLOPs: 631.2058. Time: 366.5390 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #892: GFLOPs: 498.4677. Time: 464.1455 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #893: GFLOPs: 536.1500. Time: 431.5239 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #894: GFLOPs: 3.2514. Time: 71158.0210 us. Best GFLOPs: 895.2575
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #895: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused in T.parallel(T.int64(392), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(4), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(8)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(4) + oc_chunk_1 + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2_init * T.int64(2) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(3), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused // T.int64(98) * T.int64(4) + oc_chunk_1 + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(98) // T.int64(14) * T.int64(2) + oh_1 * T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(14) // T.int64(2) * T.int64(2) + ow_1 * T.int64(2) + ow_2 * T.int64(2) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused_fused % T.int64(2) * T.int64(8) + oc_block_1 + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
        for ax0_ax1_ax2_ax3_ax4_fused_0 in T.parallel(T.int64(784)):
            for ax0_ax1_ax2_ax3_ax4_fused_1 in T.vectorized(T.int64(64)):
                with T.block("T_relu"):
                    v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                    v_ax1 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) // T.int64(3136))
                    v_ax2 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(3136) // T.int64(224))
                    v_ax3 = T.axis.spatial(T.int64(14), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(224) // T.int64(16))
                    v_ax4 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_ax4_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_ax4_fused_1) % T.int64(16))
                    T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                    T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 4, 1, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 2, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[2, 8, 1, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v65 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v65)
l66 = sch.sample_compute_location(block=b0, decision=4)
sch.compute_at(block=b0, loop=l66, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b67 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b67, ann_key="meta_schedule.unroll_explicit")
b68, b69, b70 = sch.get_child_blocks(b67)
l71, l72, l73, l74, l75, l76, l77, l78, l79, l80 = sch.get_loops(block=b68)
l81 = sch.fuse(l71, l72, l73, l74, l75, preserve_unit_iters=True)
sch.parallel(loop=l81)
l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b69)
l104 = sch.fuse(l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109 = sch.get_loops(block=b70)
l110 = sch.fuse(l105, l106, l107, l108, l109, preserve_unit_iters=True)
l111, l112 = sch.split(loop=l110, factors=[None, 64], preserve_unit_iters=True)
sch.parallel(loop=l111)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-29 01:33:55 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #896: GFLOPs: 23.3273. Time: 9918.0802 us. Best GFLOPs: 895.2575
2024-04-29 01:47:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 01:47:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 01:47:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:47:44 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 01:47:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:48:11 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:48:24 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:48:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 01:48:46 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9033  0.9033  0.8913  0.8850  0.8835  0.8828  0.8819  0.8819  0.8819  0.8813  0.8803  0.8758  0.8709  0.8704  0.8684  0.8665
[17 : 32]:	0.8662  0.8662  0.8654  0.8615  0.8615  0.8562  0.8557  0.8557  0.8556  0.8543  0.8535  0.8507  0.8457  0.8364  0.8330  0.8258
[33 : 48]:	0.8244  0.8241  0.8181  0.8135  0.8119  0.8109  0.8003  0.8003  0.7983  0.7970  0.7958  0.7803  0.7764  0.7754  0.7743  0.7708
[49 : 64]:	0.7688  0.7686  0.7646  0.7620  0.7600  0.7500  0.7494  0.7485  0.7477  0.7460  0.7409  0.7404  0.7354  0.7341  0.7337  0.7312
2024-04-29 01:48:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 01:48:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #897: GFLOPs: 422.7745. Time: 547.2457 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #898: GFLOPs: 420.2301. Time: 550.5592 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #899: GFLOPs: 796.7892. Time: 290.3673 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #900: GFLOPs: 783.9781. Time: 295.1122 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #901: GFLOPs: 791.5663. Time: 292.2832 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #902: GFLOPs: 784.6355. Time: 294.8650 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #903: GFLOPs: 792.0596. Time: 292.1012 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #904: GFLOPs: 759.8968. Time: 304.4644 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #905: GFLOPs: 768.3296. Time: 301.1228 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #906: GFLOPs: 670.3254. Time: 345.1481 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #907: GFLOPs: 587.5499. Time: 393.7734 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #908: GFLOPs: 806.7502. Time: 286.7821 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #909: GFLOPs: 778.4912. Time: 297.1922 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #910: GFLOPs: 793.8717. Time: 291.4344 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #911: GFLOPs: 786.9904. Time: 293.9827 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #912: GFLOPs: 775.0060. Time: 298.5287 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #913: GFLOPs: 791.9448. Time: 292.1435 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #914: GFLOPs: 786.0244. Time: 294.3439 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #915: GFLOPs: 797.2559. Time: 290.1973 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #916: GFLOPs: 812.5254. Time: 284.7437 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #917: GFLOPs: 800.4189. Time: 289.0505 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #918: GFLOPs: 767.5913. Time: 301.4124 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #919: GFLOPs: 818.5189. Time: 282.6588 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #920: GFLOPs: 814.1296. Time: 284.1827 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #921: GFLOPs: 810.1713. Time: 285.5711 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #922: GFLOPs: 738.8724. Time: 313.1279 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #923: GFLOPs: 792.2911. Time: 292.0158 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #924: GFLOPs: 792.9973. Time: 291.7558 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #925: GFLOPs: 817.1568. Time: 283.1299 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #926: GFLOPs: 747.5004. Time: 309.5136 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #927: GFLOPs: 863.7231. Time: 267.8654 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #928: GFLOPs: 724.0784. Time: 319.5255 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #929: GFLOPs: 748.0551. Time: 309.2841 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #930: GFLOPs: 738.5912. Time: 313.2471 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #931: GFLOPs: 777.8549. Time: 297.4353 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #932: GFLOPs: 797.4614. Time: 290.1226 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #933: GFLOPs: 682.4133. Time: 339.0343 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #934: GFLOPs: 753.6584. Time: 306.9846 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #935: GFLOPs: 763.3761. Time: 303.0767 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #936: GFLOPs: 762.6925. Time: 303.3484 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #937: GFLOPs: 773.4481. Time: 299.1300 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #938: GFLOPs: 617.2308. Time: 374.8380 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #939: GFLOPs: 733.8898. Time: 315.2538 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #940: GFLOPs: 606.2474. Time: 381.6289 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #941: GFLOPs: 707.9219. Time: 326.8179 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #942: GFLOPs: 679.4561. Time: 340.5099 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #943: GFLOPs: 491.1049. Time: 471.1041 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #944: GFLOPs: 757.0311. Time: 305.6170 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #945: GFLOPs: 749.6021. Time: 308.6458 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #946: GFLOPs: 755.7260. Time: 306.1447 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #947: GFLOPs: 788.5237. Time: 293.4110 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #948: GFLOPs: 797.8636. Time: 289.9763 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #949: GFLOPs: 785.0901. Time: 294.6942 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #950: GFLOPs: 714.0363. Time: 324.0193 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #951: GFLOPs: 660.4991. Time: 350.2829 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #952: GFLOPs: 666.2871. Time: 347.2400 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #953: GFLOPs: 785.5914. Time: 294.5062 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #954: GFLOPs: 684.1637. Time: 338.1669 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #955: GFLOPs: 650.7716. Time: 355.5188 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #956: GFLOPs: 673.7391. Time: 343.3993 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #957: GFLOPs: 660.5569. Time: 350.2523 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #958: GFLOPs: 35.1451. Time: 6583.0465 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #959: GFLOPs: 30.8404. Time: 7501.8914 us. Best GFLOPs: 895.2575
2024-04-29 01:50:34 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #960: GFLOPs: 16.9019. Time: 13688.5010 us. Best GFLOPs: 895.2575
2024-04-29 02:11:56 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:11:57 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:12:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:12:02 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:12:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:12:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:12:42 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:12:56 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:13:05 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9527  0.9271  0.9236  0.9147  0.9056  0.9034  0.9027  0.8941  0.8919  0.8902  0.8877  0.8877  0.8852  0.8832  0.8814  0.8783
[17 : 32]:	0.8767  0.8727  0.8697  0.8695  0.8695  0.8691  0.8676  0.8636  0.8630  0.8628  0.8628  0.8621  0.8619  0.8610  0.8610  0.8579
[33 : 48]:	0.8545  0.8545  0.8439  0.8438  0.8391  0.8370  0.8361  0.8337  0.8320  0.8265  0.8258  0.8238  0.8232  0.8203  0.8184  0.8099
[49 : 64]:	0.8015  0.7995  0.7971  0.7896  0.7863  0.7841  0.7806  0.7800  0.7779  0.7765  0.7759  0.7755  0.7749  0.7714  0.7704  0.7646
2024-04-29 02:13:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:13:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #961: GFLOPs: 901.1241. Time: 256.7477 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #962: GFLOPs: 832.6197. Time: 277.8718 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #963: GFLOPs: 838.5676. Time: 275.9009 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #964: GFLOPs: 793.2474. Time: 291.6638 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #965: GFLOPs: 815.5885. Time: 283.6744 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #966: GFLOPs: 829.9310. Time: 278.7720 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #967: GFLOPs: 819.1281. Time: 282.4485 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #968: GFLOPs: 809.0286. Time: 285.9745 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #969: GFLOPs: 815.8775. Time: 283.5739 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #970: GFLOPs: 819.1931. Time: 282.4261 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #971: GFLOPs: 818.3618. Time: 282.7130 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #972: GFLOPs: 818.7733. Time: 282.5709 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #973: GFLOPs: 806.2651. Time: 286.9547 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #974: GFLOPs: 785.1658. Time: 294.6658 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #975: GFLOPs: 669.5945. Time: 345.5248 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #976: GFLOPs: 790.4458. Time: 292.6975 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #977: GFLOPs: 807.4250. Time: 286.5424 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #978: GFLOPs: 812.1419. Time: 284.8782 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #979: GFLOPs: 803.5399. Time: 287.9279 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #980: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(16), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(8) // T.int64(2) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(16) // T.int64(8) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=112)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #981: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused in T.parallel(T.int64(112), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(2) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for oc_block_1 in range(T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(4) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(16), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(4) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(4), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(16) // T.int64(4) * T.int64(4) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused // T.int64(16) * T.int64(2) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(4) // T.int64(2) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_ow_1_fused_fused % T.int64(2) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 4, 4, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=448)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=8)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84, l85 = sch.get_loops(block=b69)
l86 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, l80, preserve_unit_iters=True)
sch.parallel(loop=l86)
l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l87, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112 = sch.get_loops(block=b71)
l113 = sch.fuse(l112, preserve_unit_iters=True)
sch.vectorize(loop=l113)
b114 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132 = sch.get_loops(block=b114)
b133 = sch.decompose_reduction(block=b114, loop=l117)
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #982: GFLOPs: 828.1585. Time: 279.3687 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #983: GFLOPs: 804.2155. Time: 287.6860 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #984: GFLOPs: 348.6571. Time: 663.5791 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #985: GFLOPs: 729.5868. Time: 317.1131 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #986: GFLOPs: 672.4591. Time: 344.0530 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #987: GFLOPs: 792.5025. Time: 291.9379 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #988: GFLOPs: 456.5321. Time: 506.7804 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #989: GFLOPs: 519.3509. Time: 445.4821 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #990: GFLOPs: 763.7585. Time: 302.9250 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #991: GFLOPs: 764.2873. Time: 302.7154 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #992: GFLOPs: 786.9883. Time: 293.9834 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #993: GFLOPs: 794.1524. Time: 291.3314 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #994: GFLOPs: 805.6855. Time: 287.1611 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #995: GFLOPs: 803.2765. Time: 288.0223 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #996: GFLOPs: 712.3560. Time: 324.7836 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #997: GFLOPs: 684.6294. Time: 337.9369 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #998: GFLOPs: 614.0224. Time: 376.7965 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #999: GFLOPs: 649.8379. Time: 356.0296 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1000: GFLOPs: 616.2082. Time: 375.4600 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1001: GFLOPs: 458.4708. Time: 504.6374 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1002: GFLOPs: 667.4238. Time: 346.6486 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1003: GFLOPs: 795.5963. Time: 290.8027 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1004: GFLOPs: 691.8150. Time: 334.4269 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1005: GFLOPs: 730.7309. Time: 316.6166 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1006: GFLOPs: 769.8649. Time: 300.5223 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1007: GFLOPs: 730.8842. Time: 316.5502 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1008: GFLOPs: 740.1394. Time: 312.5919 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1009: GFLOPs: 740.2002. Time: 312.5661 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1010: GFLOPs: 758.0376. Time: 305.2111 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1011: GFLOPs: 625.7170. Time: 369.7543 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1012: GFLOPs: 637.8012. Time: 362.7487 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1013: GFLOPs: 707.4447. Time: 327.0384 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1014: GFLOPs: 375.9871. Time: 615.3444 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1015: GFLOPs: 381.6039. Time: 606.2872 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1016: GFLOPs: 690.3742. Time: 335.1248 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1017: GFLOPs: 720.7962. Time: 320.9805 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1018: GFLOPs: 732.8346. Time: 315.7077 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1019: GFLOPs: 766.4034. Time: 301.8796 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1020: GFLOPs: 781.6079. Time: 296.0072 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1021: GFLOPs: 775.6898. Time: 298.2655 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1022: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(65536)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_i4_fused // T.int64(32768))
                v_i2 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(32768) // T.int64(2048))
                v_i3 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(2048) // T.int64(128))
                v_i4 = T.axis.spatial(T.int64(128), i0_i1_i2_i3_i4_fused % T.int64(128))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(8), T.int64(1), T.int64(7), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused_init in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_init"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2_init * T.int64(2) + oc_chunk_3_init)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oh_1 * T.int64(2) + oh_2_init * T.int64(2) + oh_3_init)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2_init + ow_3_init)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init * T.int64(2) + oc_block_3_fused_init)
                            T.reads()
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(2), T.int64(3), T.int64(3), T.int64(1), T.int64(2), T.int64(2), T.int64(1)):
                    for oc_block_3_fused in T.vectorized(T.int64(2)):
                        with T.block("conv2d_NCHWc_update"):
                            v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                            v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(2) + oc_chunk_2 * T.int64(2) + oc_chunk_3)
                            v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oh_1 * T.int64(2) + oh_2 * T.int64(2) + oh_3)
                            v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(2) + ow_2 + ow_3)
                            v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 * T.int64(2) + oc_block_3_fused)
                            v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(2) + ic_1)
                            v_kh = T.axis.reduce(T.int64(3), kh_0 * T.int64(3) + kh_1)
                            v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                            T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                            T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                            T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                            conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 8, 1, 2])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 1, 1, 2])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 7, 2, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 4, 2])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[128, 2])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[1, 3])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
l105 = sch.fuse(l103, preserve_unit_iters=True)
sch.vectorize(loop=l105)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111 = sch.get_loops(block=b71)
l112 = sch.fuse(l111, preserve_unit_iters=True)
sch.vectorize(loop=l112)
b113 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134, l135 = sch.get_loops(block=b113)
b136 = sch.decompose_reduction(block=b113, loop=l120)
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1023: GFLOPs: 58.4923. Time: 3955.4188 us. Best GFLOPs: 901.1241
2024-04-29 02:14:54 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1024: GFLOPs: 6.6406. Time: 34840.7075 us. Best GFLOPs: 901.1241
2024-04-29 02:46:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:46:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:46:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:46:16 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:46:29 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:46:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:46:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:47:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:47:20 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9826  0.8857  0.8765  0.8671  0.8663  0.8656  0.8588  0.8588  0.8578  0.8551  0.8452  0.8451  0.8445  0.8406  0.8406  0.8406
[17 : 32]:	0.8382  0.8347  0.8301  0.8250  0.8213  0.8205  0.8196  0.8196  0.8189  0.8111  0.8096  0.8077  0.8077  0.8068  0.8009  0.8005
[33 : 48]:	0.8005  0.7872  0.7851  0.7835  0.7807  0.7775  0.7775  0.7707  0.7695  0.7644  0.7628  0.7625  0.7600  0.7559  0.7511  0.7511
[49 : 64]:	0.7458  0.7451  0.7445  0.7445  0.7409  0.7390  0.7383  0.7383  0.7368  0.7345  0.7343  0.7340  0.7339  0.7295  0.7271  0.7266
2024-04-29 02:47:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:47:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 02:49:00 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1025: GFLOPs: 904.9283. Time: 255.6684 us. Best GFLOPs: 904.9283
2024-04-29 02:49:00 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1026: GFLOPs: 842.0050. Time: 274.7746 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1027: GFLOPs: 791.2219. Time: 292.4104 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1028: GFLOPs: 820.3922. Time: 282.0133 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1029: GFLOPs: 796.6918. Time: 290.4028 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1030: GFLOPs: 801.1754. Time: 288.7777 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1031: GFLOPs: 792.5718. Time: 291.9124 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1032: GFLOPs: 535.2010. Time: 432.2890 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1033: GFLOPs: 800.6366. Time: 288.9720 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1034: GFLOPs: 797.3543. Time: 290.1615 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1035: GFLOPs: 819.6242. Time: 282.2776 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1036: GFLOPs: 814.8810. Time: 283.9206 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1037: GFLOPs: 827.0233. Time: 279.7521 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1038: GFLOPs: 815.9411. Time: 283.5518 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1039: GFLOPs: 785.9468. Time: 294.3730 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1040: GFLOPs: 812.3958. Time: 284.7892 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1041: GFLOPs: 783.3046. Time: 295.3660 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1042: GFLOPs: 782.5612. Time: 295.6466 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1043: GFLOPs: 692.6300. Time: 334.0334 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1044: GFLOPs: 405.6110. Time: 570.4025 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1045: GFLOPs: 796.7378. Time: 290.3860 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1046: GFLOPs: 844.6945. Time: 273.8997 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1047: GFLOPs: 808.9493. Time: 286.0025 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1048: GFLOPs: 809.3564. Time: 285.8587 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1049: GFLOPs: 772.0672. Time: 299.6650 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1050: GFLOPs: 803.7233. Time: 287.8622 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1051: GFLOPs: 742.5338. Time: 311.5838 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1052: GFLOPs: 748.1589. Time: 309.2412 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1053: GFLOPs: 752.7176. Time: 307.3683 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1054: GFLOPs: 762.3933. Time: 303.4674 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1055: GFLOPs: 710.8985. Time: 325.4494 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1056: GFLOPs: 757.4644. Time: 305.4421 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1057: GFLOPs: 659.6552. Time: 350.7310 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1058: GFLOPs: 677.6148. Time: 341.4352 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1059: GFLOPs: 698.8149. Time: 331.0770 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1060: GFLOPs: 691.0401. Time: 334.8019 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1061: GFLOPs: 527.0969. Time: 438.9355 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1062: GFLOPs: 759.4308. Time: 304.6512 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1063: GFLOPs: 769.1899. Time: 300.7860 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1064: GFLOPs: 785.7536. Time: 294.4454 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1065: GFLOPs: 719.4625. Time: 321.5755 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1066: GFLOPs: 695.8042. Time: 332.5095 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1067: GFLOPs: 740.3486. Time: 312.5035 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1068: GFLOPs: 534.3261. Time: 432.9969 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1069: GFLOPs: 741.5207. Time: 312.0096 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1070: GFLOPs: 817.3102. Time: 283.0768 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1071: GFLOPs: 679.7085. Time: 340.3835 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1072: GFLOPs: 792.4557. Time: 291.9552 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1073: GFLOPs: 646.9685. Time: 357.6086 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1074: GFLOPs: 679.4313. Time: 340.5224 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1075: GFLOPs: 653.4671. Time: 354.0523 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1076: GFLOPs: 650.3969. Time: 355.7236 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1077: GFLOPs: 696.0132. Time: 332.4097 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1078: GFLOPs: 595.0877. Time: 388.7856 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1079: GFLOPs: 112.9977. Time: 2047.4898 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1080: GFLOPs: 542.3486. Time: 426.5919 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1081: GFLOPs: 179.5708. Time: 1288.4144 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1082: GFLOPs: 674.1920. Time: 343.1686 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1083: GFLOPs: 119.5199. Time: 1935.7570 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1084: GFLOPs: 819.8959. Time: 282.1840 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1085: GFLOPs: 685.1024. Time: 337.7036 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1086: GFLOPs: 123.2803. Time: 1876.7109 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1087: GFLOPs: 23.6805. Time: 9770.1232 us. Best GFLOPs: 904.9283
2024-04-29 02:49:01 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1088: GFLOPs: 0.9592. Time: 241199.5933 us. Best GFLOPs: 904.9283
2024-04-29 02:57:23 [INFO] [evolutionary_search.cc:713] Generating candidates......
2024-04-29 02:57:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2024-04-29 02:57:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:57:29 [INFO] [evolutionary_search.cc:723] Sampled 410 candidate(s)
2024-04-29 02:57:42 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:57:56 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:58:11 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:58:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x35b4628)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteParallelVectorizeUnroll(0x3ff5878)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteReductionBlock(0x3264ca8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteLayout(0x3f00d98)]: 0 failure(s)
2024-04-29 02:58:33 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9299  0.9299  0.9149  0.9108  0.9106  0.9088  0.8991  0.8990  0.8910  0.8902  0.8784  0.8738  0.8708  0.8664  0.8659  0.8650
[17 : 32]:	0.8644  0.8594  0.8578  0.8577  0.8535  0.8521  0.8476  0.8466  0.8456  0.8434  0.8416  0.8411  0.8389  0.8376  0.8337  0.8312
[33 : 48]:	0.8311  0.8302  0.8302  0.8263  0.8263  0.8246  0.8219  0.8191  0.8184  0.8008  0.7994  0.7986  0.7961  0.7950  0.7950  0.7931
[49 : 64]:	0.7928  0.7928  0.7917  0.7892  0.7887  0.7864  0.7672  0.7642  0.7618  0.7557  0.7535  0.7412  0.7412  0.7404  0.7352  0.7332
2024-04-29 02:58:34 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2024-04-29 02:58:34 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1089: GFLOPs: 841.0636. Time: 275.0821 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1090: GFLOPs: 832.2371. Time: 277.9996 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1091: GFLOPs: 844.8844. Time: 273.8381 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1092: GFLOPs: 822.8810. Time: 281.1604 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1093: GFLOPs: 790.0299. Time: 292.8516 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1094: GFLOPs: 837.2556. Time: 276.3332 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1095: GFLOPs: 830.3103. Time: 278.6447 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1096: GFLOPs: 796.4519. Time: 290.4903 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1097: GFLOPs: 795.7827. Time: 290.7346 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1098: GFLOPs: 805.8436. Time: 287.1048 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1099: GFLOPs: 764.3606. Time: 302.6864 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1100: GFLOPs: 786.8586. Time: 294.0319 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1101: GFLOPs: 778.6989. Time: 297.1130 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1102: GFLOPs: 796.9990. Time: 290.2909 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1103: GFLOPs: 777.3287. Time: 297.6367 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1104: GFLOPs: 807.3584. Time: 286.5661 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1105: GFLOPs: 770.6042. Time: 300.2339 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1106: GFLOPs: 779.7381. Time: 296.7170 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1107: GFLOPs: 415.6169. Time: 556.6702 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1108: GFLOPs: 796.3712. Time: 290.5197 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1109: GFLOPs: 782.1834. Time: 295.7894 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1110: GFLOPs: 773.2029. Time: 299.2249 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1111: GFLOPs: 786.5389. Time: 294.1514 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1112: GFLOPs: 774.1129. Time: 298.8731 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1113: GFLOPs: 740.3968. Time: 312.4831 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1114: GFLOPs: 740.3034. Time: 312.5226 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1115: GFLOPs: 755.5289. Time: 306.2246 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1116: GFLOPs: 770.4620. Time: 300.2893 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1117: GFLOPs: 757.5390. Time: 305.4121 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1118: GFLOPs: 799.9498. Time: 289.2201 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1119: GFLOPs: 785.2496. Time: 294.6344 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1120: GFLOPs: 780.8947. Time: 296.2775 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1121: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused in T.parallel(T.int64(224), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ax0, ax1, ax2, ax3, ax4 in T.grid(T.int64(1), T.int64(2), T.int64(3), T.int64(9), T.int64(128)):
                with T.block("data_pad"):
                    v_i0, v_i1 = T.axis.remap("SS", [ax0, ax1])
                    v_i2 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                    v_i3 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + ax3)
                    v_i4 = T.axis.spatial(T.int64(128), ax4)
                    T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                    T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                    data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
            for ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2_init + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + ow_1 * T.int64(7) + ow_2_init * T.int64(7) + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(16), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + oc_chunk_2 + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + ow_1 * T.int64(7) + ow_2 * T.int64(7) + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(16) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7)):
                    for ax4_fused in T.vectorized(T.int64(16)):
                        with T.block("T_relu"):
                            v_ax0 = T.axis.spatial(T.int64(1), ax0)
                            v_ax1 = T.axis.spatial(T.int64(16), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused // T.int64(56) * T.int64(4) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(14) // T.int64(7) * T.int64(2) + ax1)
                            v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(56) // T.int64(28) * T.int64(7) + n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(7) + ax2)
                            v_ax3 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_n_1_oc_chunk_1_oh_1_fused_fused % T.int64(28) // T.int64(14) * T.int64(7) + ax3)
                            v_ax4 = T.axis.spatial(T.int64(16), ax4_fused)
                            T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                            T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[4, 2, 2, 1])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[2, 7, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[2, 1, 1, 7])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 1, 16, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l50, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=7)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76, l77, l78, l79, l80, l81, l82, l83, l84 = sch.get_loops(block=b69)
l85 = sch.fuse(l72, l73, l74, l75, l76, l77, l78, l79, preserve_unit_iters=True)
sch.parallel(loop=l85)
l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b70)
l105 = sch.fuse(l86, preserve_unit_iters=True)
sch.parallel(loop=l105)
sch.annotate(block_or_loop=l105, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l105, ann_key="pragma_unroll_explicit", ann_val=1)
l106, l107, l108, l109, l110, l111, l112, l113 = sch.get_loops(block=b71)
l114 = sch.fuse(l113, preserve_unit_iters=True)
sch.vectorize(loop=l114)
b115 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b115)
b135 = sch.decompose_reduction(block=b115, loop=l119)
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1122: GFLOPs: 787.1216. Time: 293.9337 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1123: GFLOPs: 786.4759. Time: 294.1750 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1124: GFLOPs: 729.1077. Time: 317.3215 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1125: GFLOPs: 772.9700. Time: 299.3150 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1126: GFLOPs: 736.7755. Time: 314.0190 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1127: GFLOPs: 809.1403. Time: 285.9350 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1128: GFLOPs: 750.2953. Time: 308.3606 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1129: GFLOPs: 813.0293. Time: 284.5673 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1130: GFLOPs: 686.0799. Time: 337.2224 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1131: GFLOPs: 731.6199. Time: 316.2319 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1132: GFLOPs: 732.5547. Time: 315.8283 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1133: GFLOPs: 751.3943. Time: 307.9096 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1134: GFLOPs: 687.0956. Time: 336.7239 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1135: GFLOPs: 709.3418. Time: 326.1637 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1136: GFLOPs: 705.8205. Time: 327.7909 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1137: GFLOPs: 713.2288. Time: 324.3861 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1138: GFLOPs: 693.5495. Time: 333.5905 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1139: GFLOPs: 690.1545. Time: 335.2315 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1140: GFLOPs: 758.8308. Time: 304.8921 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1141: GFLOPs: 151.0629. Time: 1531.5576 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1142: GFLOPs: 670.4249. Time: 345.0969 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1143: GFLOPs: 688.4053. Time: 336.0833 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1144: GFLOPs: 659.7205. Time: 350.6963 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1145: GFLOPs: 393.9333. Time: 587.3115 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1146: GFLOPs: 712.4535. Time: 324.7391 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1147: GFLOPs: 454.5646. Time: 508.9740 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1148: GFLOPs: 583.5216. Time: 396.4918 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1149: GFLOPs: 758.5088. Time: 305.0215 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1150: GFLOPs: 1.0448. Time: 221448.5167 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:131] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1151: GFLOPs: 89.0961. Time: 2596.7640 us. Best GFLOPs: 904.9283
2024-04-29 03:00:33 [INFO] [task_scheduler.cc:121] [Task #21: fused_nn_contrib_conv2d_NCHWc_add_add_nn_relu_2] Trial #1152: Error in building:
LocalBuilder: Timeout, killed after 30.0 seconds
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(2), T.int64(14), T.int64(14), T.int64(128)), "float32"), p1: T.Buffer((T.int64(16), T.int64(2), T.int64(3), T.int64(3), T.int64(128), T.int64(16)), "float32"), p2: T.Buffer((T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(16)), "float32"), p3: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)), "float32")):
        T.func_attr({"tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(2), T.int64(16), T.int64(16), T.int64(128)))
        conv2d_NCHWc = T.alloc_buffer((T.int64(1), T.int64(16), T.int64(14), T.int64(14), T.int64(16)))
        for i0_i1_i2_i3_i4_fused in T.parallel(T.int64(65536)):
            with T.block("data_pad"):
                v_i0 = T.axis.spatial(T.int64(1), T.int64(0))
                v_i1 = T.axis.spatial(T.int64(2), i0_i1_i2_i3_i4_fused // T.int64(32768))
                v_i2 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(32768) // T.int64(2048))
                v_i3 = T.axis.spatial(T.int64(16), i0_i1_i2_i3_i4_fused % T.int64(2048) // T.int64(128))
                v_i4 = T.axis.spatial(T.int64(128), i0_i1_i2_i3_i4_fused % T.int64(128))
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3, v_i4])
                data_pad[v_i0, v_i1, v_i2, v_i3, v_i4] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1), v_i4], T.float32(0))
        for n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused in T.parallel(T.int64(7), annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_1, oc_chunk_1, oh_1, ow_1, oc_block_1 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(2)):
                for n_2_init, oc_chunk_2_init, oh_2_init, ow_2_init, oc_block_2_init, n_3_init, oc_chunk_3_init, oh_3_init, ow_3_init, oc_block_3_init in T.grid(T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_init"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2_init + n_3_init)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2_init * T.int64(8) + oc_chunk_3_init)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oh_1 + oh_2_init + oh_3_init)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2_init + ow_3_init)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2_init + oc_block_3_init)
                        T.reads()
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = T.float32(0)
                for ic_0, kh_0, kw_0, n_2, oc_chunk_2, oh_2, ow_2, oc_block_2, ic_1, kh_1, kw_1, n_3, oc_chunk_3, oh_3, ow_3, oc_block_3 in T.grid(T.int64(16), T.int64(3), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(7), T.int64(8), T.int64(16), T.int64(1), T.int64(3), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1)):
                    with T.block("conv2d_NCHWc_update"):
                        v_n = T.axis.spatial(T.int64(1), n_1 + n_2 + n_3)
                        v_oc_chunk = T.axis.spatial(T.int64(16), oc_chunk_1 * T.int64(16) + oc_chunk_2 * T.int64(8) + oc_chunk_3)
                        v_oh = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + oh_1 + oh_2 + oh_3)
                        v_ow = T.axis.spatial(T.int64(14), ow_1 * T.int64(7) + ow_2 + ow_3)
                        v_oc_block = T.axis.spatial(T.int64(16), oc_block_1 * T.int64(8) + oc_block_2 + oc_block_3)
                        v_ic = T.axis.reduce(T.int64(256), ic_0 * T.int64(16) + ic_1)
                        v_kh = T.axis.reduce(T.int64(3), kh_0 + kh_1)
                        v_kw = T.axis.reduce(T.int64(3), kw_0 * T.int64(3) + kw_1)
                        T.reads(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block], data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)], p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block])
                        T.writes(conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block])
                        T.block_attr({"meta_schedule.tiling_structure": "SSRSRS"})
                        conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] = conv2d_NCHWc[v_n, v_oc_chunk, v_oh, v_ow, v_oc_block] + data_pad[v_n, v_ic // T.int64(128), v_oh + v_kh, v_ow + v_kw, v_ic % T.int64(128)] * p1[v_oc_chunk, v_ic // T.int64(128), v_kh, v_kw, v_ic % T.int64(128), v_oc_block]
            for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(16), T.int64(2), T.int64(14)):
                for ax4_fused in T.vectorized(T.int64(16)):
                    with T.block("T_relu"):
                        v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                        v_ax2 = T.axis.spatial(T.int64(14), n_0_oc_chunk_0_oh_0_ow_0_oc_block_0_fused * T.int64(2) + ax2)
                        v_ax3, v_ax4 = T.axis.remap("SS", [ax3, ax4_fused])
                        T.reads(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4], p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4])
                        T_relu[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] = T.max(conv2d_NCHWc[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4] + p2[v_ax0, v_ax1, T.int64(0), T.int64(0), v_ax4] + p3[v_ax0, v_ax1, v_ax2, v_ax3, v_ax4], T.float32(0))
b0 = sch.get_block(name="data_pad", func_name="main")
b1 = sch.get_block(name="conv2d_NCHWc", func_name="main")
b2 = sch.get_block(name="T_add", func_name="main")
b3 = sch.get_block(name="T_add_1", func_name="main")
b4 = sch.get_block(name="root", func_name="main")
sch.compute_inline(block=b3)
sch.compute_inline(block=b2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSRSRS")
l5, l6, l7, l8, l9, l10, l11, l12 = sch.get_loops(block=b1)
v13, v14, v15, v16 = sch.sample_perfect_tile(loop=l5, n=4, max_innermost_factor=64, decision=[1, 1, 1, 1])
l17, l18, l19, l20 = sch.split(loop=l5, factors=[v13, v14, v15, v16], preserve_unit_iters=True)
v21, v22, v23, v24 = sch.sample_perfect_tile(loop=l6, n=4, max_innermost_factor=64, decision=[1, 1, 2, 8])
l25, l26, l27, l28 = sch.split(loop=l6, factors=[v21, v22, v23, v24], preserve_unit_iters=True)
v29, v30, v31, v32 = sch.sample_perfect_tile(loop=l7, n=4, max_innermost_factor=64, decision=[7, 2, 1, 1])
l33, l34, l35, l36 = sch.split(loop=l7, factors=[v29, v30, v31, v32], preserve_unit_iters=True)
v37, v38, v39, v40 = sch.sample_perfect_tile(loop=l8, n=4, max_innermost_factor=64, decision=[1, 2, 7, 1])
l41, l42, l43, l44 = sch.split(loop=l8, factors=[v37, v38, v39, v40], preserve_unit_iters=True)
v45, v46, v47, v48 = sch.sample_perfect_tile(loop=l9, n=4, max_innermost_factor=64, decision=[1, 2, 8, 1])
l49, l50, l51, l52 = sch.split(loop=l9, factors=[v45, v46, v47, v48], preserve_unit_iters=True)
v53, v54 = sch.sample_perfect_tile(loop=l10, n=2, max_innermost_factor=64, decision=[16, 16])
l55, l56 = sch.split(loop=l10, factors=[v53, v54], preserve_unit_iters=True)
v57, v58 = sch.sample_perfect_tile(loop=l11, n=2, max_innermost_factor=64, decision=[3, 1])
l59, l60 = sch.split(loop=l11, factors=[v57, v58], preserve_unit_iters=True)
v61, v62 = sch.sample_perfect_tile(loop=l12, n=2, max_innermost_factor=64, decision=[1, 3])
l63, l64 = sch.split(loop=l12, factors=[v61, v62], preserve_unit_iters=True)
sch.reorder(l17, l25, l33, l41, l49, l18, l26, l34, l42, l50, l55, l59, l63, l19, l27, l35, l43, l51, l56, l60, l64, l20, l28, l36, l44, l52)
b65, = sch.get_consumers(block=b1)
sch.reverse_compute_at(block=b65, loop=l49, preserve_unit_loops=True, index=-1)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.parallel", ann_val=768)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.vectorize", ann_val=64)
v66 = sch.sample_categorical(candidates=[0, 16, 64, 512], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b4, ann_key="meta_schedule.unroll_explicit", ann_val=v66)
l67 = sch.sample_compute_location(block=b0, decision=-1)
sch.compute_at(block=b0, loop=l67, preserve_unit_loops=True, index=-1)
sch.enter_postproc()
b68 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.parallel")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.vectorize")
sch.unannotate(block_or_loop=b68, ann_key="meta_schedule.unroll_explicit")
b69, b70, b71 = sch.get_child_blocks(b68)
l72, l73, l74, l75, l76 = sch.get_loops(block=b69)
l77 = sch.fuse(l72, l73, l74, l75, l76, preserve_unit_iters=True)
sch.parallel(loop=l77)
l78, l79, l80, l81, l82, l83, l84, l85, l86, l87, l88, l89, l90, l91, l92, l93, l94, l95, l96, l97, l98, l99, l100, l101, l102, l103 = sch.get_loops(block=b70)
l104 = sch.fuse(l78, l79, l80, l81, l82, preserve_unit_iters=True)
sch.parallel(loop=l104)
sch.annotate(block_or_loop=l104, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l104, ann_key="pragma_unroll_explicit", ann_val=1)
l105, l106, l107, l108, l109, l110 = sch.get_loops(block=b71)
l111 = sch.fuse(l110, preserve_unit_iters=True)
sch.vectorize(loop=l111)
b112 = sch.get_block(name="conv2d_NCHWc", func_name="main")
l113, l114, l115, l116, l117, l118, l119, l120, l121, l122, l123, l124, l125, l126, l127, l128, l129, l130, l131, l132, l133, l134 = sch.get_loops(block=b112)
b135 = sch.decompose_reduction(block=b112, loop=l119)
